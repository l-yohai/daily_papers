## Daily Papers (2025-01-10)

### [Search-o1: Agentic Search-Enhanced Large Reasoning Models](https://arxiv.org/abs/2501.05366)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05366.png)

Vote: 39

Authors: Xiaoxi Li, Zhicheng Dou, Yujia Zhou, Yutao Zhu, Peitian Zhang, Guanting Dong, Jiajie Jin, Yuyao Zhang

- ***What's New***: 이 연구는 Search-o1이라는 프레임워크를 소개합니다. 이는 대규모 추론 모델(Large Reasoning Models; LRMs)의 지식 부족 문제를 해결하기 위해 능동성 검색 워크플로우가 통합된 새로운 접근법을 제시합니다. Search-o1은 능동적 검색(Retrieval-Augmented Generation; RAG) 메커니즘과 Reason-in-Documents 모듈을 결합하여 외부 정보를 자동으로 검색하고 이를 추론 과정에 통합합니다.
- ***Technical Details***: Search-o1은 LRMs가 특정 지식 포인트를 확인할 때마다 능동적으로 검색 쿼리를 생성하여 외부 정보를 검색하도록 합니다. 검색된 문서는 길이와 중복성이 문제일 수 있으므로 Reason-in-Documents 모듈을 통해 분석하고 기존의 추론 체인에 적절히 통합됩니다. 이 과정은 검색된 정보가 논리적 흐름을 방해하지 않고 추론 체인에 통합되도록 합니다.
- ***Performance Highlights***: Search-o1은 과학, 수학, 코딩 등 복잡한 추론 작업에서 강력한 성능을 보여줬으며, 인간 전문가와 비교하여도 특정 도메인에서는 탁월한 성능을 기록했습니다. 특히 GPQA 확장 세트에서는 인간 전문가를 넘어서는 성능을 발휘했고, 여러 도메인에서 수준 높은 결과를 제공하여 크로스 도메인 성능도 입증했습니다.

### [The GAN is dead; long live the GAN! A Modern GAN Baseline](https://arxiv.org/abs/2501.05441)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05441.png)

Vote: 24

Authors: Aaron Gokaslan, Volodymyr Kuleshov, James Tompkin, Yiwen Huang

- ***What's New***: 이 논문에서는 기존의 GAN(Generative Adversarial Network)이 훈련하기 어렵다는 일반적인 주장에 반대하는 증거를 제시하고, 보다 원칙적인 방식으로 현대적 베이스라인 GAN을 구축합니다. 새로운 정규화된 상대적 GAN 손실(Relativistic GAN Loss)을 도입하여 모드 드롭핑 및 수렴 문제를 해결하며 기존의 임시방편적인 트릭을 제거할 수 있는 방법을 제시합니다.
- ***Technical Details***: 새로 제안된 손실 함수는 상대적 페어링 GAN 손실(RpGAN)을 0-중심의 그래디언트 페널티(Zero-centered Gradient Penalties; 0-GP)와 결합하여 훈련 안정성을 향상시킵니다. 스타일 기반의 생성 아키텍처인 StyleGAN2를 활용하여 RpGAN + R1 + R2 손실과 모던한 네트워크 백본(Modern Network Backbone)을 이용하여 새로운 최소주의 기반의 베이스라인, 즉 R3GAN(Re-GAN)을 제안합니다.
- ***Performance Highlights***: R3GAN은 StyleGAN2를 FFHQ, ImageNet, CIFAR, Stacked MNIST와 같은 데이터셋에서 능가하며, 현대적인 최첨단 GAN 및 확산 모델(Diffusion Models)과 비교했을 때 유리한 성능을 보입니다. FFHQ-256 모델에서 FID가 2.75로, StyleGAN2의 3.78보다 낮은 수치를 기록했으며, 기존 모델들에 비해 낫거나 동등한 성능을 나타냈습니다.

### [An Empirical Study of Autoregressive Pre-training from Videos](https://arxiv.org/abs/2501.05453)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05453.png)

Vote: 16

Authors: Ilija Radosavovic, Jathushan Rajasegaran, Jitendra Malik, Rahul Ravishankar, Yossi Gandelsman, Christoph Feichtenhofer

- ***What's New***: 이 연구는 영상(Autoregressive) 사전 훈련의 실증적 연구로, 영상을 시각적 토큰(Visual Tokens)의 시퀀스로 처리하여 예측하는 토토(Toto) 모델을 제안합니다. 이는 다양한 다운스트림 작업에서 경쟁력 있는 성능을 보여주며, 비디오 모델의 확장 곡선이 언어 모델과 유사함을 발견했습니다.
- ***Technical Details***: 토토 모델은 비디오와 이미지 데이터를 1조 개 이상의 시각적 토큰으로 구성된 데이터셋에서 사전 훈련되며, 토큰화에는 dVAE를 사용합니다. 다양한 아키텍처 및 토크나이저 디자인을 탐구하며, 주어진 시각적 문맥 내에서 다음 토큰을 예측하도록 영상 시퀀스를 학습합니다. LLaMa 아키텍처를 기반으로 비디오 타임라인의 예측 작업을 수행하며, 모델의 중간 레이어에서 최상의 성능을 발휘하는 것을 관찰했습니다.
- ***Performance Highlights***: Toto 모델은 ImageNet 분류와 Kinetics-400 액션 인식에서 효과적인 성능을 보이며, 1억 1천만 파라미터(1.1B)의 모델이 75.3%와 74.4%의 정확도를 기록하며, 기존의 생성적 모델들과 비교하여 최고의 성과를 보였습니다. 비디오 추적 및 로봇 조작에서도 출중한 성능을 보였습니다.

### [Are VLMs Ready for Autonomous Driving? An Empirical Study from the Reliability, Data, and Metric Perspectives](https://arxiv.org/abs/2501.04003)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04003.png)

Vote: 8

Authors: Shaoyuan Xie, Yuhao Dong, Wenwei Zhang, Liang Pan, Ziwei Liu, Qi Alfred Chen, Chonghao Sima, Lingdong Kong

- ***What's New***: 이 연구는 Vision-Language Models (VLMs)의 자율 주행에서의 신뢰성을 평가하기 위한 새로운 벤치마크 DriveBench를 소개합니다. 이 벤치마크는 다양한 조건(깨끗한 상태, 손상된 상태, 텍스트 전용 입력)에서 자율 주행의 네 가지 주요 작업 - 인식(Perception), 예측(Prediction), 계획(Planning), 설명(Explanation) - 즉, 해석 가능하고 신뢰할 수 있는 자율 주행을 촉진하기 위해 설계되었습니다.
- ***Technical Details***: DriveBench는 19,200 프레임과 20,498개 질문-답변(QA) 쌍으로 구성되어 있으며, 12개의 인기있는 VLMs를 평가합니다. 이 벤치마크는 데이터 세트 불균형과 평가 지표의 부족으로 VLMs가 시각의 부재 하에서도 일반적인 지식에 의존한 답변을 생성할 수 있음을 보여줍니다. 또한, 이미지를 사용하지 않고도 합리적인 답변을 생성할 수 있으며, 이는 모델 로버스트 보다는 훈련 데이터의 일반 지식에 기인한다고 설명합니다.
- ***Performance Highlights***: GPT-4o와 같은 독점 모델은 예상과 달리 낮은 시각 입력 제공 시에도 텍스트 전용 프롬프트에서 높은 성능을 보입니다. 대부분의 VLMs가 시각적 부패에 민감하며, 포괄적인 문맥 인식을 향상시킬 필요가 있다는 것을 보여줍니다. 인간의 평가에서는 시각적 손상 하에서 성능이 저하되는 반면, 대부분의 VLMs는 거의 변화가 없는 결과를 보여줍니다. 이는 언어 프롬프트로부터 정보를 유추하는 경향이 있음을 시사합니다.

### [Entropy-Guided Attention for Private LLMs](https://arxiv.org/abs/2501.03489)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.03489.png)

Vote: 5

Authors: Nandan Kumar Jha, Brandon Reagen

- ***What's New***: 이 논문은 비공개 LLMs(Private LLMs)에서 논리적 비선형성의 역할을 정보 이론적 관점에서 분석하여, 프라이버시를 보호하는 추론 환경에서도 효율적인 학습이 가능하도록 하는 새로운 엔트로피 기반 주의 메커니즘(Entropy-Guided Attention)을 제안합니다.
- ***Technical Details***: 이 연구는 Shannon 엔트로피를 통해 비선형성이 LLM 훈련 안정성을 확보하고, 주의(head) 간 다양성을 유지하는 이중 역할을 한다는 것을 밝혀냈습니다. 제안된 방법은 각 주의 머리(head)의 특성에 맞게 조정 가능한 정규화 강도를 설정하고, 과도한 페널티를 피하는 허용 마진을 도입하여 정보 과부하를 방지합니다. 또한, 새로운 정규화 기법을 통해 비선형성을 줄인 LLM 훈련의 안정성을 개선합니다.
- ***Performance Highlights***: 연구 결과, 비선형성을 줄인 모델은 전체적으로 지연(latency)과 통신 오버헤드(communication overhead)를 크게 줄일 수 있음을 입증했습니다. 제안된 엔트로피 정규화 기법을 통해 모델의 복잡성을 완화하고 성능을 향상시킬 수 있는 가능성을 확인했습니다.

### [Enhancing Human-Like Responses in Large Language Models](https://arxiv.org/abs/2501.05032)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05032.png)

Vote: 5

Authors: Ethem Yağız Çalık, Talha Rüzgar Akkuş

- ***What's New***: 이 논문은 대형 언어 모델(Large Language Models; LLMs)을 더욱 인간과 유사하게 발전시키는 방법을 탐구합니다. 자연어 이해, 대화의 일관성, 감성 지능을 향상시켜 사용자와의 상호작용을 개선하려는 시도입니다.
- ***Technical Details***: 본 연구에서는 Direct Preference Optimization (DPO) 기술을 적용하여 모델을 미세 조정하였으며, 문장을 생성하는 동안 자연스러운 대화와 구조적 주제 기반 대화를 균형 있게 유지하기 위한 합성 데이터셋을 개발하였습니다. 또한, LoRA (Low-Rank Adaptation) 기술을 활용하여 모델 파라미터를 미세 조정하였으며, 심리학적 통찰을 통합하여 캐주얼하고 공식적인 대답을 유도하는 시스템 프롬프트를 사용하였습니다.
- ***Performance Highlights***: 인간 유사성 평가에서 우리의 미세 조정된 모델은 공식 지시 모델보다 더 인간과 유사한 응답을 꾸준히 생성했습니다. Human-Like-Llama-3-8B-Instruct 모델은 평가에서 89.6%의 선호도를 얻었으며, 이는 모델의 대화 능력과 사용자 참여를 크게 향상시켰음을 보여줍니다.

### [On Computational Limits and Provably Efficient Criteria of Visual Autoregressive Models: A Fine-Grained Complexity Analysis](https://arxiv.org/abs/2501.04377)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04377.png)

Vote: 5

Authors: Zhao Song, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Yekun Ke, Zhenmei Shi

- ***What's New***: 이 연구는 최근 이미지 생성 분야에서 혁신적인 '차후-스케일(next-scale) 예측' 패러다임을 도입한 시각적 자회귀 모델(Visual Autoregressive Models; VAR 모델)의 계산적 한계를 매우 세밀한 복잡성 분석을 통해 조사합니다. 이 연구는 강력한 지수 시간 가설(Strong Exponential Time Hypothesis; SETH)을 전제로 새로운 sub-quadratic 시간 복잡성을 달성할 수 있는 조건을 식별했습니다.
- ***Technical Details***: VAR 모델에 대한 분석은 주의(attention) 메커니즘의 입력 행렬의 노름이 특정 임계값을 초과할 때, SETH 가설 하에서 sub-quartic 시간 알고리즘이 불가능하다는 것을 밝힙니다. 필요한 조건 아래서 VAR 계산을 sub-quadratic 시간으로 효율적으로 가속할 수 있는 알고리즘을 제안하며, 저차원 근사(low-rank approximation)를 활용하여 이러한 기준에 맞춘 효율적 구성을 제시합니다.
- ***Performance Highlights***: 높은 부분에서 저차원 근사를 활용해 거의 이차 시간(almost quadratic time) 내에 VAR 모델을 근사할 수 있는 알고리즘을 설계할 수 있음을 증명하였습니다. 이로 인해 학계에 발전된 이미지 생성 알고리즘을 설계할 수 있는 기반을 제공하며, 시각적 자회귀 모델의 확장 가능성과 효율성을 크게 높였습니다.

### [Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model](https://arxiv.org/abs/2501.05122)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05122.png)

Vote: 4

Authors: Chris Biemann, Carolin Holtermann, Goran Glavaš, Radu Timofte, Anne Lauscher, Florian Schneider, Gregor Geigle

- ***What's New***: Centurio는 대형 이미지-언어 모델(Large Vision-Language Models; LVLMs)의 다국어 성능을 향상시키기 위한 최적의 학습 데이터 구성을 탐색한 연구입니다. 연구 결과는 100개의 언어를 포함하면서도 영어 성능을 유지할 수 있는 학습 전략을 제시하고 있습니다.
- ***Technical Details***: Centurio 연구에서는 13개 다운스트림 비전-언어 과제와 43개 언어에 대한 일련의 다단계 실험을 수행하였습니다. 여기서 (1) 영어 성능의 저하 없이 포함할 수 있는 학습 언어의 최대 수, (2) 최적의 사전 학습 언어 분포, 그리고 (3) 대화 조정 데이터의 분포를 체계적으로 조사했습니다. 또한 (4) 다국어 이미지 속 텍스트 이해를 향상시키기 위해 새로운 벤치마크를 소개하였습니다.
- ***Performance Highlights***: Centurio는 14개 과제와 56개 언어를 포함한 평가에서 최신 성능을 달성하며, 특히 낮은 자원 언어에서 두각을 나타냈습니다. 실험 결과는 다국어 학습 데이터의 25-50%가 비영어 데이터로 구성되었을 때 강력한 다국어 성능을 발휘하며, 영어 데이터의 비중이 너무 높아지면 성능이 저하될 수 있음을 보여줍니다.

### [Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models](https://arxiv.org/abs/2501.04828)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04828.png)

Vote: 3

Authors: Tarık Emre Tıraş, Ece Elif Adak, Berat Doğan, Fatih Burak Karagöz, Esma F. Bilgin Taşdemir, Efe Eren Genç, Şaziye Betül Özateş

- ***What's New***: 이 연구는 역사적인 터키어 자연어 처리(NLP)를 위한 초석이 되는 리소스와 모델들을 소개합니다. HisTR은 역사적 터키어의 최초 고유 명사 인식(NER) 데이터셋이고, OTA-BOUN은 역사적 터키어에 대한 첫 번째 Universal Dependencies 트리뱅크입니다. 또한, 15세기부터 20세기까지의 다양한 시대를 포괄하는 옵토만 텍스트 코퍼스(OTC)를 도입하였습니다. 이들 데이터를 활용한 Transformer 기반 모델들은 고유 명사 인식, 의존 구문 분석, 품사 태깅 등의 태스크에 대해 훈련되었습니다.
- ***Technical Details***: HisTR 데이터셋은 17세기부터 19세기까지의 기간 동안 작성된 812개의 문장을 수작업으로 레이블링하였으며, OTA-BOUN 트리뱅크는 역사적 터키어의 514 문장에 대한 의존성 관계와 품사 태그의 골드 주석을 포함하고 있습니다. Transformer 기반의 BERTurk, mBERT, TURNA 모델이 NER과 의존 구문 분석, 품사 태깅 태스크에 사용되었습니다. 모든 리소스와 모델은 huggingface 플랫폼에서 공개되어 있습니다.
- ***Performance Highlights***: 고유 명사 인식(NER) 과제에서는 BERTurk가 BERTurk+MilliyetNER+HisTR 모드에서 F1 점수 91.21로 가장 좋은 성능을 보였습니다. 하지만 Ruznamçe 테스트 세트에서는 F1 점수 61.91로 성능이 많이 낮아졌습니다. 의존 구문 분석 태스크에서는 BERTurk에 기반한 모델이 OTA-BOUN 테스트 세트에서 약 73.79%의 성능을 기록하여 역사적 터키어 텍스트에 대해 mBERT 기반 모델보다 우수한 성능을 보였습니다.

### [SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution](https://arxiv.org/abs/2501.05040)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05040.png)

Vote: 3

Authors: Wai Lam, Chengxing Xie, Bowen Li, Chang Gao, He Du, Kai Chen, Difan Zou

- ***What's New***: SWE-Fixer는 GitHub 이슈 해결을 위한 공개 소스 대형 언어 모델(Open-Source Large Language Models; LLMs)을 효과적이고 효율적으로 개발하기 위해 설계된 새로운 알고리즘입니다. 이 모델은 GitHub의 실제 이슈를 해결하는 능력을 강화하도록 특별히 설계되었습니다.
- ***Technical Details***: SWE-Fixer는 두 가지 핵심 모듈, 즉 코드 파일 검색 모듈과 코드 편집 모듈로 구성됩니다. 검색 모듈은 BM25와 경량 LLM 모델을 사용하여 초기 파일 검색을 수행한 후 코드를 수정해야 할 파일을 특정합니다. 편집 모듈은 코드 에디터로서 검출된 파일에 필요한 패치를 생성하며, 이를 위해 체인 오브 소트(Chain-of-Thought; CoT) 데이터를 활용하여 훈련됩니다. 대규모 데이터셋(110K 이상의 GitHub 이슈와 그에 상응하는 패치)을 수집하여 모듈을 개별적으로 훈련합니다.
- ***Performance Highlights***: SWE-Fixer는 SWE-Bench Lite와 Verified 벤치마크에서 각각 23.3%와 30.2%의 성능을 기록하며, 공개 소스 모델 중 최상의 성능을 보였습니다. 이 모델은 GPT-4o, Claude-3-Opus 등 여러 독점 모델 기반 방법을 능가하며, 효율적이고 경제적인 문제 해결 방법으로 주목받고 있습니다.

