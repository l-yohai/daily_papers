## Daily Papers (2025-01-25)

### [EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents](https://arxiv.org/abs/2501.11858)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11858.png)

Vote: 2

Authors: Ran Li, Yuge Tu, Maosong Sun, Zhili Cheng, Weize Chen, Jiahao Li, Lei Shi, Shengding Hu, Jinyi Hu, Yang Shi, Shiqi Dai, Tianyu Yu

- ***What's New***: EMBODIEDEVAL은 다중 모달 대형 언어 모델(MLLMs)을 구현된 에이전트로 평가하기 위한 상호 작용 벤치마크로서 제안되었습니다. 이 벤치마크는 기존의 정적 이미지나 비디오를 이용해 평가하는 단점을 뛰어넘어, 다양한 3차원 장면에서 328개의 구체적이고 다양한 태스크로 구성되며, 시뮬레이션과 평가 프레임워크를 포함하여 MLLMs의 구현 능력을 종합적으로 테스트합니다.
- ***Technical Details***: EMBODIEDEVAL은 내비게이션, 객체 상호작용, 사회적 상호작용, 속성 질문응답, 공간 질문응답 등 5가지 주요 카테고리로 구성된 태스크를 통해 에이전트의 다양한 능력을 평가합니다. 이 벤치마크는 LEGENT 플랫폼을 기반으로 한 통합 시뮬레이션 프레임워크를 사용하여, 다채로운 상호작용 및 태스크 기반 평가를 진행합니다. 평가 프로세스는 주어진 이미지와 동작 목록을 기반으로 MLLM이 다음 동작을 선택하도록 설계되었습니다.
- ***Performance Highlights***: 최신 MLLMs 모델들을 EMBODIEDEVAL에서 평가한 결과, 인간 수준의 구현 능력과 비교할 때 상당히 낮은 성과를 보였습니다. GPT-4o 모델은 약 25%의 성공률을 기록했으며, 대부분의 열린 소스 모델들은 이보다 더 낮은 결과를 보여 현재 MLLM의 구현 능력이 상당한 도전에 직면해 있음을 지적합니다.

