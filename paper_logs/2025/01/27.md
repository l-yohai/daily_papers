## Daily Papers (2025-01-27)

### [Humanity's Last Exam](https://arxiv.org/abs/2501.14249)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14249.png)

Vote: 29

Authors: Lisa Schut, Jainam Shah, Ragavendran P V, Xiaoxiang Zhou, Mustafa Mehkary, Bikun Li, Jiawei Shen, Roselynn Grace Montecillo, Joseph W. Jackson, Tim Gehrunger, G. Bruno De Luca, Alexandr Wang, Aymeric Dieuleveut, Daphiny Pottmaier, Freddie Vargus, Brian P Coppola, Andrew Redenti, Archimedes Apronti, Angel Ramirez-Trinidad, Tung Nguyen, Mikhail Kalinin, David Holmes, Ziqiao Ma, Filippo Bigi, Florencia de la Rosa, Gabriel Loiseau, Wen-Ding Li, Linjie Dai, Oleksandr Pokutnyi, Jiayi Pan, Ben Segev, Tom Goertzen, Alesia Yakimchyk, Alexander Piperski, Kaustubh Sridhar, Dakotah Martinez, Ning Tang, Jules Robins, Dae Hyun Kim, Robin Zhang, Ronald Clark, Biró Bálint, Xinyu Zhang, Vladislav Poritski, Jeremy Nguyen, Alena Friedrich, Prajvi Saxena, Ng Ze-An, Ariel Ghislain Kemogne Kamdoum, Rafał Poświata, David Avagian, Haline Heidinger, Allison Tee, Lawrence Hollom, Ida Bosio, Denis Efremov, Eve J. Y. Lo, Faraz Farhidi, Sergey Ivanov, Ziye Chen, Brian Amaro, Aaron Kirtland, Mohammadreza Mofayezi, Ali Dasouqi, Carl J Fossum, Niels Mündler, Omer Faruk Bodur, Emilien Duc, Richard Stanley, Jason O. Matos, Francesco Fournier-Facio, Priti Shukla, William Merrill, George Medley, Chris Harjadi, Siranut Usawasutsakorn, Stefan Steinerberger, Chelsea Zou, Adrian Cosma, Kushal Thaman, Michael Yu, Sean Shi, Julian Salazar, Michael K. Cohen, Johan Ferret, Ronak Pradeep, Qiuyu Ren, Antonella Pinto, Thomas C. H. Lux, Huanxu, Laxman Prasad Goswami, Andrew Gritsevskiy, Shaipranesh Senthilkuma, Zihan Wang, Hossam Elgnainy, Sarah Hoback, Wiktor Morak, Zienab EL-Wasif, Alexis C Garretson, Justin Xu, Veit Elser, Andrey Pupasov Maksimov, Kaiqu Liang, Joanna Tam, Pierre Clavier, Gashaw M. Goshu, Joshua Robinson, Alvaro Sanchez, Jungbae Nam, Alina Borisovna Zhidkovskaya, Emil Verkama, Freddie Martin, Omkar Dhamane, Joseph Marvin Imperial, M Saiful Bari, Daniel Espinosa Gonzalez, Saiteja Utpala, Younesse Kaddar, Firuz Kamalov, Andrew Favre D. O., Anmol Sahu, Noam Kolt, Felipe Meneguitti Dias, Avi Semler, Tong Jiang, Samuel Perry, Sean R. Green, Shankar Sivarajan, Ryan Stendall, David K. Zhang, Damien Sileo, Qijia Chen, Gang Zhang, Julien Guillod, Muhammad Rehan Siddiqi, Eric Hallman, Yuqi Li, Gabriel Recchia, Frank Reidegeld, Tony Fruhauff, Andrew R. Tawfeek, Sandra Mendoza, Mohanad Mohamed, Jessica P. Wang, Chidozie Agu, Mark H Inlow, Niv Cohen, Adam Khoja, Jinzhou Yang, Leon Lang, Jennifer Zampese, Harrison K Wang, Prashant Joshi, Cary Friday, Muhammad Fayez Aziz, Vladimir Goryachev, Nasser Heydari, Dustin Wehr, Benjamin Myklebust, Ethan Delaney, Minghao Yan, Roman Leventov, David Stap, Edson Oliveira, Adithya Shenoy, Hsiaoyun Milliron, Renas Bacho, Gongbo Sun, Ali Khajegili Mirabadi, Ali Dehghan, Hao Qi, Aleksey Kuchkin, Pawan Kumar, Marc Roth, Derek Lim, Wanyoung Kim, Xi Jiang, Sergei Bogdanov, Stanley Stepanic, Nikita Shulga, Darling Duclosel, Emma Rodman, Taylor D. Hartman, Eric Chu, Varun Gangal, Bryan Johnson, Shiv Halasyamani, James Koppel, Rajat Maheshwari, Tobias Kreiman, Eshawn Jessica Scipio, Mátyás Vincze, Demosthenes Patramanis, Anji Zhang, John Lai, Mantas Mazeika, Natanael Wildner Fraga, Peyman Kassani, Tran Đuc Huy, Daniil S. Antonenko, William Alley, Wenjin Zhang, Kelin Zhu, Mike Battaglia, Anil Radhakrishnan, Zachary Berger, Jason Gross, Daniel Pyda, Hossein Shahrtash, Sören Möller, Diana T. Pham, Max Bartolo, Antonio Franca, Olle Häggström, I. M. J. McInnis, Hannah Szlyk, Bingchen Zhao, Serguei Popov, Yosi Kratish, Hamid Mostaghimi, Adam Zweiger, Evgenii Zheltonozhskii, Johannes Veith, Maksym Ovchynnikov, Yuzhou Wang, Carlo Bosio, Juan Gonzalez, Gautier Abou Loume, Jérémy Andréoletti, Fredrik Ekström, Ben Rank, Fiona Feng, Sarah-Jane Crowson, Edwin Taylor, Jennifer Sandlin, Yiyang Fan, Maja Somrak, Daniel Tordera, Geoff Galgon, Ryan Kim, Yuzhou Nie, Immo Klose, Behzad Ansarinejad, Ben McCarty, Alvin Jin, Arun Rao, Mohammad Safdari, Jiaqi Cai, Dylan Ler, Kyle Montgomery, Jacob Loader, Daron Anderson, Will Yeadon, Juan Carlos Gonzalez, Javier Gimenez, Chao Zhuang, Jonathan Crozier, Mohammad Maghsoudimehrabani, Alex Hoover, Daniil Orel, Gabe Maayan, Yuzheng Hu, Yuchen Anna Zhou, Madellene Peñaflor, Ankit Singh, Daniel Munro, Nick Crispino, Ethan D. L. Brown, Chiara Ceconello, Niklas Muennighoff, Philippe Schwaller, Ameya Prabhu, Tejal Patwardhan, Antoine Jallon, Benjámin Borbás, Aline Menezes, Justine Leon Uro, Luke Askew, Hailey Schoelkopf, Zahra Adoul, Sk Md Salauddin, Bita Golshani, Shashank Agnihotri, Emanuele Rodolà, Dan Hendrycks, Roberto Pereira, Nathaniel Li, Sherwin Abdoli, Orion Weller, Tim Tarver, Dave Hulbert, Angela Hammon, Gunjan Chhablani, Fatimah Adesanya, Forough Mohammadzadeh, Jakub Łucki, Honglu Fan, Alexander Shen, Ignat Soroko, Max Lamparth, Michael Wang, Samir Shamseldeen, Vage Taamazyan, Michael Choi, Stephane Durand, Christian Stump, Michael Krause, Sarah Martinson, Jesyin Lai, Rasoul Pouriamanesh, Warren S. Vaz, Samuel Albanie, Shaun Phillips, Yanxu Chen, Ashley Cartwright, Don Clarke, Isaac C. McAlister, Oam Patel, Mobeen Mahmood, Eric Zheng, Haile Kassahun, Zheng-Xin Yong, Saeed Soori, Mohammed Berkani, Zakayo Kazibwe, Steven Y. Feng, Jiangnan Xu, Krishnamurthy Iyer, Vivien Rossbach, Daattavya Aggarwal, Hodjat Mariji, Tong Yang, Avishy Carmi, Ryan G. Hoerr, Richard Wheeler, Kevin Zhou, Haon Park, Hans Gundlach, Liu, Joshua Vendrow, Jing Fan, Gbenga Daniel Obikoya, Vladimir Vinnikov, Tim Santens, Sara Fish, Longke Tang, Hieu Hoang, Parker Whitfill, Mstyslav Kazakov, Rafael Sayous, Josh Ducey, Laila Yacar, Rynaa Grover, Milind Jagota, Jamie Tucker-Foltz, Alessandro Tomasiello, Alejandro José Moyano, Stefan Ivanov, Sumeet Motwani, Subrata Mishra, Deepakkumar Patil, Lina Brüssel, Lynna Kvistad, Lixin Zhang, Søren Riis, Colin White, Innocent Enyekwe, Chris G. Willcocks, Michael Kirchhof, Alon Ragoler, Andrew Ho, Raghav Singhal, Armel Randy Zebaze, Claire Sparrow, Marcus Abramovitch, Moon Twayana, Mohsen Bahaloo, Marco Lukas, Tobias Garcia Vilchis, Allen Zang, Pierre Marion, Frank Sommerhage, Julien Laurendeau, Mara Popescu, Kanu Priya Agarwal, Mukhwinder Singh, Micah Carroll, Abdelkader Dendane, Fereshteh Kazemi, Nicolas Remy, Ben Pageler, Anna Liakhovitskaia, Yuexuan Zu, Pierrot Arsene, Sandy Zhao, Zachary Brown, Sangwon Lee, Scott Sauers, Aleksandr Maksapetyan, Ziwen Han, John-Clark Levin, Martin Lackner, Gözdenur Demir, Alice Gatti, Martin Stehberger, Danyelle Ferreira, Anna-Katharina Dick, Omid Taheri, Brecht Verbeken, Paolo Giordano, Declan Grabb, Jack Stade, Raúl Adrián Huerta Rodríguez, Liangti Dai, Emily de Oliveira Santos, Farzad Habibi, Murat Islam, Nate Stambaugh, Zhehang Du, Arunim Agarwal, Krzysztof Burdzy, Kalyan Ramakrishnan, Brian Weber, Pablo Hernández-Cámara, Fabian Giska, Daofeng Li, Jeffery Li, Ismail Alarab, Kengo Zenitani, Volodymyr Nevirkovets, Archan Sen, Zerui Cheng, Jasdeep Sidhu, Vladyslav Kuchkin, Orr Paradise, Usman Qazi, Alexander Ivanov, Jacob Platnick, Donato Crisostomi, Tania C. B. Santos, Josephina Hu, Kang Yong Loh, Philipp Petersen, Michael Chen, David Outevsky, Egor Kretov, Jan Hendrik Kirchner, Carter Harris, Vincent Ginis, Thomas Preu, Tad Hogg, Lukas Lewark, Paolo Rissone, Linh Ho, Dimitri Zvonkine, Stephen Mensah, Adam Jones, Xavier Alapont, John Arnold Ambay, Joshua Cole, Hector Haffenden, Leonor Brito-Santana, Maksim Radionov, Hyunwoo Park, Pascal Lauer, Zaki Hossain, Evan Kim, David M. Cunningham, Ruicheng Xian, Kaivalya Rawal, Daniel Bugas, Josef Tkadlec, Dmitry Malishev, Jeremiah Milbauer, Václav Rozhoň, Stephen Malina, Julian Wykowski, David Perrella, Rodrigo De Oliveira Pena, Shreyas Verma, Thorben Jansen, Oliver Zhang, Asankhaya Sharma, Mikalai Uzhou, Benedito Alves de Oliveira Junior, Himanshu Gupta, Lavr Vetoshkin, Hangrui Cao, Jayson Lynch, Ori Press, Ilya Gusev, Guillaume Malod, Long Phan, Michelle X Yuan, Marco Piccardo, Mohinder Maheshbhai Naiya, Jason Hausenloy, Muthu Chidambaram, David Aldous, Jiang Muzhen, Zihao Wang, Jack Lindsey, David Noever, Shaul Barkan, Alan Goldfarb, Eric Singer, Hubeyb Gurdogan, Khalida Meer, Eric Vergo, Ali Karakoc, Vinh-Kha Le, Nicholas Farina, Nurdin Kaparov, Paul Rosu, Juehang Qin, Dominic Williamson, Timothy Manik, Elliott Thornley, Ting Wang, Vasilios Mavroudis, Justin Tan, Kevin Joseph Scaria, Nicolas Daans, Evan Chen, Loukmane Karim, Keith Schneider, Pavel Zhelnov, Mariana Costa, Yiğit Yalın, Stanislaw Barzowski, Anka Reuel, Victor Souza, Seri Khoury, Johannes Schmitt, Stefano Cavalleri, Ferenc Jeanplong, Jonathan Roberts, John Wydallis, Colin Tang, Colin Ni, Steffi Chern, Joan of Arc Xavier, Mao Mao, Robert Gerbicz, Alan Givré, Simon Weber, Ciprian Manolescu, Ilias Magoulas, Jonathan Eicher, Luca Arnaboldi, Jingxuan Fan, Nathan Andre, Alexey Pronin, Robert Lauff, Yibo Jiang, Ricardo Lorena, Russell Campbell, Siriphan Arthornthurasuk, Ngefor Mildred Tanwie, Lennart Finke, William Held, Zixuan Wang, Ilia Sucholutsky, Gabriel Poesia Reis e Silva, Piotr Padlewski, Andres Algaba, Andy Zou, Yan Carlos Leyva Labrador, Rebeka Plecnik, Murat Eron, Shailesh Shah, Christian Schroeder de Witt, Edward Vendrow, Earth Anderson, Kunyang Sun, Lian, Michael Foster, Kaniuar Bacho, Himanshu Narayan, Xiuyu Li, Antonio Terpin, Lianghui Li, Johannes Lengler, Haoran Zhao, Abdallah Galal, Julien Portier, Joseph M Cavanagh, Tej Shah, Robin Riblet, Martí Oller, Hew Wolff, Harsh Kumar, John Maar, George Balabanian, Shi-Zhuo Looi, Tran Quoc Khánh, Sam Ali, Anish Agrawal, Taom Sakal, Shreen Gul, Jacob Votava, Mark Nandor, Vivek Vajipey, Vincent Cheng, Dashiell Stander, Guglielmo Albani, Chenguang Wang, Aleksandar Mikov, Will Cai, Song Bian, T. Ryan Rogers, Sreenivas Goud Raparthi, Wenjie Ma, Nate Resman, Yongki Lee, Jaehyeok Jin, Arkil Patel, Arnav Chopra, Jacob Drori, Linwei Xin, Mohamed Zekry, Ujjwala Anantheswaran, Long, Alon Amit, Summer Yue, Tomek Korbak, Joshua Duersch, Abhishek Shukla, Yewen Sun, Luke Basler, Aras Bacho, Kunvar Thaman, Wentao Wu, Guillaume Douville, Andres M Bran, Henry Tang, Hanmeng Xu, Ido Akov, Jiaqi Wang, Marc Carauleanu, Anna Sztyber-Betley, Julian Noah Leser, Anton Peristyy, Erik Y. Wang, Shalev Ben-David, Shannon Coleman, Rai, Dan Bar Hava, Victor Efren Guadarrama Vilchis, Zachary Giboney, Hugh Zhang, Michael P. Brenner, Jean-Christophe Mourrat, Syed M. Shahid, Doru Cojoc, Christoph Demian, Kaylie Hausknecht, Glen Sherman, Noah Burns, Ahmad Sakor, Pavel Arkhipov, Andrea Achilleos, Jack Wei Lun Shi

- ***What's New***: Humanity's Last Exam (HLE)는 인류 지식의 최전선에 위치한 멀티모달 벤치마크로, 도전적인 다수의 주제를 아우르는 3,000개의 질문으로 구성되어 있습니다. 이 벤치마크는 지속적인 LLM(대형 언어 모델) 발전을 따라가지 못하는 기존 벤치마크에 대한 대응으로 설계되었습니다. HLE는 인류의 마지막 폐쇄형 학술 벤치마크가 되도록 의도된 것입니다.
- ***Technical Details***: HLE는 수학, 인문학, 자연과학 등 다양한 분야의 문제로 구성되어 있으며, 명확하고 모호하지 않은 해법을 갖고 있어 모델의 능력을 평가하는 데 적합합니다. 질문들은 전 세계의 전문가들에 의해 설계되었으며, 복잡한 문제 해결을 위한 다단계 평가 프로세스를 거칩니다.
- ***Performance Highlights***: 최신 LLM 모델들은 HLE에서 낮은 정확도(10% 미만)를 보이며, 이러한 어려운 질문에 대한 자신감 부족을 드러냈습니다. 이는 현재 LLM의 능력과 인간 전문가 간의 큰 격차를 강조합니다. HLE의 테스트 결과는 이러한 모델들이 아직 학문적 문제 해결 영역에서 명확한 한계를 가지고 있음을 보여줍니다.

### [Redundancy Principles for MLLMs Benchmarks](https://arxiv.org/abs/2501.13953)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13953.png)

Vote: 21

Authors: Xinyu Fang, Haodong Duan, Kai Chen, Xiaohong Liu, Zicheng Zhang, Xiongkuo Min, Guangtao Zhai, Chunyi Li, Xiangyu Zhao

- ***What's New***: 본 연구는 MLLM(Multi-modality Large Language Models) 벤치마크의 평가에서 다차원적 중복성을 체계적으로 분석하고, 이를 줄이기 위한 원칙을 제안합니다. 기존 벤치마크의 중복성을 줄이기 위한 가이드라인을 제공하여, 효과적인 MLLM 평가를 돕습니다.
- ***Technical Details***: 이 연구는 MLLM 능력 평가에서 중복성을 평가하는 'Performance Correlation Redundancy Framework'를 제안합니다. 이 프레임워크는 VLMEvalKit의 종합 데이터를 활용해 여러 벤치마크의 성능 순위를 통한 중복성을 정량화합니다. 중복성은 벤치마크의 능력 차원 내 중복성, 테스트 과제 수에서의 중복성, 특정 도메인 내 벤치마크 간의 중복성을 포함합니다.
- ***Performance Highlights***: 평가 결과, MLLM 벤치마크의 대다수가 인스턴스의 절반 이상이 중복되는 것으로 나타났으며, SRCC 및 PLCC 지표를 통해 상위 50개 모델의 정밀한 랭킹을 위해 더 많은 인스턴스가 필요하다는 점이 드러났습니다. 이는 상위 성능 MLLM(Top-50)이 하위 성능 모델(Bottom-50)보다 중복성이 낮음을 보여줍니다.

### [Chain-of-Retrieval Augmented Generation](https://arxiv.org/abs/2501.14342)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14342.png)

Vote: 19

Authors: Furu Wei, Liang Wang, Haonan Chen, Zhicheng Dou, Nan Yang, Xiaolong Huang

- ***What's New***: 이 논문에서는 복합 질문에 대해 점진적으로 정보를 검색하고 추론하여 최종 답변을 생성하는 CoRAG(Chain-of-Retrieval Augmented Generation) 방법을 소개합니다. 기존의 RAG(Retrieval-Augmented Generation) 방식은 단일 검색 단계만 수행한 후 답변을 생성하는데, 이는 불완전한 검색 결과로 복잡한 질의에 대응하기에 한계가 있습니다. CoRAG는 질의를 동적으로 수정하며 검색 상태를 발전시킵니다.
- ***Technical Details***: CoRAG에서는 거절 샘플링(Rejection Sampling)을 활용하여 중간 검색 체인(Retrieval Chain)을 자동으로 생성하고, 이를 기존 RAG 데이터셋에 추가합니다. 테스트 시에는 여러 디코딩 전략(Decoding Strategies)을 사용하여 검색 체인의 길이와 수를 조절해 모델의 테스트 시간 계산을 확장할 수 있도록 합니다. LLM은 증강된 데이터셋을 기반으로 여러 작업의 다음 토큰 예측 목표를 사용해 미세 조정(Fine-Tuning)합니다.
- ***Performance Highlights***: CoRAG는 여러 벤치마크 특히 멀티-홉 질문 응답(Multi-Hop QA)에서 강력한 기준선을 10점을 초과하는 EM(Exact Match) 점수 개선을 보였습니다. KILT 벤치마크에서는 다양한 지식 집중 작업에서 새로운 최고 성능을 기록했습니다.

### [RealCritic: Towards Effectiveness-Driven Evaluation of Language Model Critiques](https://arxiv.org/abs/2501.14492)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14492.png)

Vote: 13

Authors: Ruoyu Sun, Bowen Yu, Dayiheng Liu, Tian Ding, Ziniu Li, Junyang Lin, Zhengyang Tang, Zhenyang Xiao, Benyou Wang, Tianyu Liu, Fei Huang

- ***What's New***: RealCritic은 대형 언어 모델(LLMs)의 비판 역량을 평가하기 위해 설계된 새로운 벤치마크입니다. 이 벤치마크는 기존 방식과 달리 교정 효과를 통해 비판의 질을 평가하는 폐쇄 루프 방식을 도입했습니다. 또한 자가 비판, 교차 비판, 반복 비판 기능을 포함하여 다양한 고급 추론 모델의 능력을 평가할 수 있도록 구성되었습니다.
- ***Technical Details***: RealCritic 벤치마크는 8개의 도전적인 추론 과제를 통해 모델의 비판 역량을 테스트합니다. 기존 벤치마크가 주어진 솔루션의 정확성을 예측하는 것에 그쳤던 반면, RealCritic은 수정 (Correction)을 통해 비판 자체의 품질을 직접 측정하도록 설계되었습니다. 이 방식은 제어 이론의 피드백 시스템을 참고하여, 비판의 입력 효과성을 평가합니다.
- ***Performance Highlights***: o1-mini 모델은 다양한 비판 시나리오에서 동료 언어 모델보다 뛰어난 성능을 보여주며, 자가 비판 및 교차 비판에서도 유의미한 성과를 냈습니다. 특히 자가 비판 환경에서 평균 성능이 다른 모델 대비 3.3% 향상된 점이 두드러집니다. 하지만 대다수 모델들이 전문 분야 (예: MMLU-STEM)에서 자가 비판 시 성능 하락을 보였습니다.

### [Relightable Full-Body Gaussian Codec Avatars](https://arxiv.org/abs/2501.14726)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14726.png)

Vote: 5

Authors: Shoou-I Yu, Roman Lubachersky, Javier Romero, Tomas Simon, Jason Saragih, Michael Zollhoefer, Igor Santesteban, Vasu Agrawal, Fabian Prada, Junxuan Li, Matt Gramlich, Timur Bagautdinov, Shaofei Wang, Pace Nalbone, Andreas Geiger, Siyu Tang, Shunsuke Saito, Chenglei Wu

- ***What's New***: 이 연구는 최초로 전체 신체 아바타의 조명 재구성(relighting)과 애니메이션을 가능하게 하는 Gaussian Codec Avatars 기법을 제시합니다. 이 방법은 조명 운반 방식을 학습하여 전체적으로 아바타의 외형을 생생하게 재조명하고 애니메이션할 수 있습니다.
- ***Technical Details***: Gaussian Codec Avatars는 3D Gaussian Splitting(3DGS)을 기반으로 하며, 지역 및 비지역적인 광운반을 학습합니다. 특히, 방향에 의존하는 확산 방사 전송(diffuse radiance transfer)을 얻기 위해 배향 가능 Zonal Harmonics(ZH)를 활용하여 기존의 Spherical Harmonics(SH)보다 효율적입니다. 또한, 비지역적 그림자를 포착하기 위해 그림자 네트워크를 도입하였습니다.
- ***Performance Highlights***: 본 연구의 방법은 새로운 조명 조건과 포즈에서 탁월한 일반화 능력을 보여 줍니다. 이는 학습을 통해 구현된 조명 운반 모델이 높은 충실도의 렌더링 품질을 제공하는 것으로, PSNR과 SSIM 등 다양한 평가 척도에서 기존의 물리 기반 렌더링을 크게 능가합니다.

### [RL + Transformer = A General-Purpose Problem Solver](https://arxiv.org/abs/2501.14176)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14176.png)

Vote: 4

Authors: Micah Rentschler, Jesse Roberts

- ***What's New***: 이 연구는 미리 학습된 트랜스포머(Transformer)를 강화 학습(Reinforcement Learning)을 통해 미세 조정하면, 이전에 만나보지 못한 문제를 해결할 수 있는 능력이 개발된다는 사실을 보여줍니다. 이를 통해 In-Context Reinforcement Learning(ICRL)이라는 새로운 메타 학습 능력을 얻었습니다. 이 연구는 특히 다양한 데이터 품질에 견고하고, 비정적 환경에서도 적응력이 뛰어나며, 일반적인 문제 해결사로서 우수한 성능을 발휘한다는 것을 시사합니다.
- ***Technical Details***: ICRL의 실험에는 LLaMA 3.1 8B라는 오픈 소스 대형 언어 모델(LLM)을 사용하였으며, 이는 Deep Q-Network(DQN) 알고리즘을 통해 강화 학습 방식으로 미세 조정되었습니다. Frozen Lake라는 변화하는 환경에서 최적의 행동을 학습하는 것이 목표였으며, H역할, 관찰, 보상을 사용하는 대화형 데이터 형식으로 학습을 진행했습니다. 이 과정을 통해 모델이 비정적 환경에 적응하고 사용자 요구에 맞는 최적의 솔루션을 찾을 수 있도록 설계하였습니다.
- ***Performance Highlights***: ICRL 훈련된 트랜스포머는 같은 분포에서 생성된 새 환경에서 900%의 성능 향상을 보였습니다. 새로운 비분포 환경에서도 성능이 개선되었으며, 데이터 품질에 크게 의존하지 않았습니다. 이는 ICRL이 다양한 경험으로부터 학습할 수 있는 능력을 시사합니다.

### [GeoPixel: Pixel Grounding Large Multimodal Model in Remote Sensing](https://arxiv.org/abs/2501.13925)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13925.png)

Vote: 3

Authors: Fahad S. Khan, Akashah Shabbir, Mohammed Bennamoun, Salman Khan, Mohammed Zumri

- ***What's New***: GeoPixel은 고해상도 원격 감지(Remote Sensing; RS)에 특화된 최초의 종단 간 멀티모달 모델(Large Multimodal Model; LMM)로, 픽셀 레벨의 자세한 시각적 이해를 통한 시각적 요소 식별을 지원하여 기존 LMM의 한계를 극복합니다.
- ***Technical Details***: GeoPixel은 고해상도의 RS 이미지를 효율적으로 분석하기 위해 입력 이미지를 지역 및 글로벌 영역으로 적응적으로 분할합니다. 모델의 아키텍처는 Adaptive Image Divider, Vision Encoder, Large Language Model, Grounding Vision Encoder 및 Pixel Decoder의 5가지 주요 구성 요소로 구성됩니다. 이러한 모듈의 통합은 고해상도 인식과 세밀한 해석 및 기반을 가능케 합니다.
- ***Performance Highlights***: GeoPixel은 Uni-Target, Multi-Target, 그리고 Overall 세그먼테이션 작업에서 기존 모델보다 월등한 성능을 보여주었습니다. 이 모델은 Uni-Target의 AP50과 mIoU, 그리고 Multi-Target의 AP50과 Recall에서 경쟁 모델을 능가했습니다.

### [Question Answering on Patient Medical Records with Private Fine-Tuned LLMs](https://arxiv.org/abs/2501.13687)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13687.png)

Vote: 3

Authors: Sara Kothari, Ayush Gupta

- ***What's New***: 이 논문은 개인화된 미세 조정된 대형 언어 모델(Fine-Tuned Large Language Models; LLMs)을 활용하여 환자의 전자의료기록(EHR)에서 질문에 대한 답변을 제공하는 방법을 제안합니다. 이 접근법은 환자 데이터를 가진 FHIR(Fast Healthcare Interoperability Resources) 표준을 사용하여 데이터를 추출하고 답변을 생성하는 2단계로 구성되어 있으며, 프라이버시를 보장하기 위해 개인 호스팅이 가능합니다.
- ***Technical Details***: 제안된 접근법은 Task 1로서 사용자의 의료 질문에 가장 관련이 있는 FHIR 자원을 식별하고, Task 2로서 관련 자원을 바탕으로 질문에 답변하는 과정을 포함합니다. 각 Task에 적합하도록 LLMs을 미세 조정하며, Mistral 네모(Mistral NeMo)와 Llama-3.1과 같은 모델을 활용합니다. 데이터 생성에는 Synthea라는 오픈 소스 인공 환자 생성기를 이용하여 다양한 JSON 형식의 FHIR 데이터를 생성하였습니다.
- ***Performance Highlights***: 실험 결과, 미세 조정된 LLMs는 성능과 효율성에서 GPT-4와 같은 대형 모델을 상회했습니다. 특히, Task 1에서는 0.55% 의 F1 점수 향상을, Task 2에서는 METEOR 점수에서 42%의 성능 향상을 이루었습니다. 이는 적절한 미세 조정과 개인 호스팅이 가능한 모델이 의료 분야에서의 데이터를 효과적으로 처리할 수 있음을 보여줍니다.

### [AdaIR: Adaptive All-in-One Image Restoration via Frequency Mining and Modulation](https://arxiv.org/abs/2403.14614)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.14614.png)

Vote: 2

Authors: Mubarak Shah, Alois Knoll, Yuning Cui, Salman Khan, Fahad Shahbaz Khan, Syed Waqas Zamir

- ***What's New***: AdaIR은 모든 종류의 이미지 열화(degradation)를 효과적으로 제거할 수 있는 적응형 올인원 이미지 복원 모델입니다. 이 모델은 다양한 열화가 각기 다른 주파수 대역에 영향을 미치는 것을 관찰하고, 주파수 채굴(frequency mining) 및 변조(modulation) 모듈을 도입하여 입력 이미지에 존재하는 열화 패턴에 따라 관련 주파수 성분을 찾아내고 강조합니다.
- ***Technical Details***: AdaIR은 주파수 채굴 모듈(Frequency Mining Module;FMiM)과 주파수 변조 모듈(Frequency Modulation Module;FMoM)을 통해 입력 이미지의 스펙트럼 특성을 이용하여 특정 주파수 요소를 추출하고, 상호 보완적인 정보를 교환하여 주파수 성분을 강화합니다. 이 과정에서 'Adaptive Frequency Learning Block(AFLB)'라는 구성 요소를 사용하여, 기존 복원 네트워크에 쉽게 통합할 수 있습니다.
- ***Performance Highlights***: AdaIR은 여러 이미지 복원 작업에서 최첨단 성능을 발휘하며, SOTS 데이터셋에서 31.06dB PSNR을 기록하게 되어 PromptIR보다 0.48dB 향상된 결과를 보여줍니다. 실험 결과는 AdaIR이 다양한 열화를 효과적으로 복원할 수 있음을 증명하였습니다.

### [Multiview Equivariance Improves 3D Correspondence Understanding with Minimal Feature Finetuning](https://arxiv.org/abs/2411.19458)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19458.png)

Vote: 1

Authors: Yue Wang, Leonidas Guibas, Yixin Li, Congyue Deng, Yang You

- ***What's New***: 이 논문은 비전 트랜스포머(Vision Transformer; ViT) 기반의 대형 비전 모델들이 3D 구조를 이해하고, 2D 이미지 기반 모델들이 가진 한계를 극복하기 위한 새로운 분석과 방법론을 제안합니다. 특히 최소한의 특징 미세 조정으로 3D 대응성을 향상시키는 전이 학습 전략을 통해 3D 대응 이해 능력을 크게 개선할 수 있음을 보여줍니다.
- ***Technical Details***: 기존의 2D 비전 모델에 3D 등가 특성을 강제하는 학습 방법을 소개합니다. Objaverse와 MVImgNet에서 여러 뷰로 생성된 데이터세트를 사용하여, 다중 뷰 이미지에서 동일한 3D 포인트를 표현하는 2D 이미지 특징 사이의 일관성을 학습시킵니다. 학습 과정에서는 AdamW 옵티마이저를 사용하고, SmoothAP 손실 함수를 적용하여 대응하는 픽셀 간의 특징 유사성을 높입니다. 이 방법은 LoRA와 비전 트랜스포머의 추가 컨볼루션 레이어를 통해 10K번 반복으로 작은 데이터로도 훈련할 수 있습니다.
- ***Performance Highlights***: 모델 성능은 Pose Estimation, Video Tracking, Semantic Correspondence와 같은 여러 3D 작업에서 향상됩니다. 예를 들어, DINOv2는 Pose Estimation에서 3cm-3deg 기준으로 9.58 포인트, Video Tracking에서 평균 Jaccard로 5.0 포인트, Semantic Correspondence에서 PCK@0.05 기준으로 5.06 포인트 개선되었습니다. 이러한 성과는 최소한의 학습 셋업으로도 비전 모델이 3D 공간 관계를 효과적으로 포착할 수 있음을 보여줍니다.

### [Denoising as Adaptation: Noise-Space Domain Adaptation for Image Restoration](https://arxiv.org/abs/2406.18516)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.18516.png)

Vote: 0

Authors: Zongsheng Yue, Chen Change Loy, Kang Liao, Zhouxia Wang

- ***What's New***: 이 논문은 '노이즈 공간 내에서 도메인 간 적응(Denoising as Adaptation)'이라는 새로운 방법을 제안합니다. 이는 이미지 복원(Image Restoration) 분야에서 복잡한 도메인 간 격차를 줄이기 위해 확산 모델(Diffusion Model)을 활용하는 최초의 접근 방식입니다. 특히 다단계 제거 프로세스를 통해 복원된 합성 및 실세계 이미지를 목표 클린 분포와 정렬시키는 과정에서 의미 있는 확산 손실(Diffusion Loss)을 도출했습니다.
- ***Technical Details***: 이 연구는 합성 데이터와 실세계 변형 이미지 모두에서 학습 모델이 잘 일반화될 수 있도록, 노이즈 예측 오류의 최솟값과 목표 클린 분포를 일치시키기 위해 회로적 층 및 잔여 교환 대조 학습(Residual-Swapping Contrastive Learning) 전략을 제안합니다. 이 방법을 통해 네트워크가 쉽게 구별할 수 있는 기능에 의존하지 않도록 하여 단일하고 안정적인 학습 프레임워크를 유지합니다.
- ***Performance Highlights***: 세 가지 클래식 이미지 복원 작업(이미지 노이즈 제거(Denoising), 블러 제거(Deblurring), 비 제거(Deraining))에서 실험 결과는 제안된 방법의 우수성을 보여줍니다. 특히 기존의 특징 공간 및 픽셀 공간 도메인 적응 방법보다 더 나은 성능을 발휘하며, 학습이 불안정해지는 문제를 피할 수 있었습니다.

### [CatV2TON: Taming Diffusion Transformers for Vision-Based Virtual Try-On with Temporal Concatenation](https://arxiv.org/abs/2501.11325)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11325.png)

Vote: 0

Authors: Yiling Wu, Xiaodan Liang, Wenqing Zhang, Haoxiang Li, Zheng Chong, Xiao Dong, Shiyue Zhang, Dongmei Jiang, Jun Zheng

- ***What's New***: CatV2TON은 이미지 기반과 비디오 기반의 가상 착용(Virtual Try-On; VTON) 작업을 모두 지원하는 단일 디퓨전 트랜스포머(Diffusion Transformer) 모델을 제안합니다. 의상과 인체의 입력 데이터를 시간적(Temporal)으로 결합하여 이미지와 비디오 데이터셋에서 함께 학습함으로써 정적 및 동적 환경 모두에서 안정적인 착용 성능을 발휘합니다.
- ***Technical Details***: CatV2TON은 기본 네트워크의 20% 이하의 파라미터로 훈련이 가능한 효율적인 프레임워크입니다. 중복 프레임을 활용한 클립 기반 추론(Overlapping Clip-Based Inference) 전략과 Adaptive Clip Normalization (AdaCN)을 도입하여 긴 비디오 생성 동안 일관성을 유지하면서 자원 소모를 줄입니다. ViViD-S라는 새로운 비디오 착용 데이터셋도 제시하여 배경 소음을 줄이고, 3D 마스크 스무딩(3D Mask Smoothing)을 통해 더욱 강화된 시간적 일관성을 가지고 있습니다.
- ***Performance Highlights***: CatV2TON은 정량적 및 정성적 평가에서 기존의 이미지 및 비디오 기반 가상 착용 방법을 능가하며, 특히 다양한 시나리오에서 견고하며 신뢰할 수 있는 솔루션을 제공합니다.

