## Daily Papers (2025-01-20)

### [Evolving Deeper LLM Thinking](https://arxiv.org/abs/2501.09891)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.09891.png)

Vote: 57

Authors: Shumeet Baluja, Xinyun Chen, Kuang-Huei Lee, Dave Marwood, Dale Schuurmans, Yueh-Hua Wu, Ian Fischer

- ***What's New***: 이 논문에서는 대형 언어 모델(Large Language Models; LLMs)의 추론 능력을 확장하기 위한 진화적 검색 전략인 '마인드 에볼루션(Mind Evolution)'을 제안합니다. 이는 LLM을 사용하여 후보 응답을 생성, 재조합, 정제하며, 형식적인 추론 문제를 공식화할 필요 없이 솔루션 평가자가 있는 경우 신속한 문제 해결을 지원합니다.
- ***Technical Details***: 마인드 에볼루션은 언어 기반 유전 알고리즘을 결합하여 정적 탐색과 대규모 반복적 정제를 통해 LLM의 효율적인 문제 해결을 도모합니다. 이를 통해 선택 및 교차, 유전적 표현 변이 등을 통해 다양한 후보 솔루션을 진화시키고 평가자의 피드백을 바탕으로 해결합니다. 이는 또한 병렬화가 용이한 방식입니다.
- ***Performance Highlights***: TravelPlanner 및 자연 계획(Natural Plan) 벤치마크에서, 제안된 마인드 에볼루션 방법은 Best-of-N 및 순차적 수정방식보다 우수한 성능을 보여 98% 이상의 문제해결 성공률을 달성했습니다. 또한 Gemini 1.5 Pro 모델을 사용할 경우 TravelPlanner 테스트 세트에서 99.9%의 성공률을 기록했습니다. 이를 통해 형식적인 솔버를 명시적으로 사용하지 않고도 문제 해결 능력을 크게 향상시킬 수 있음을 입증했습니다.

### [PaSa: An LLM Agent for Comprehensive Academic Paper Search](https://arxiv.org/abs/2501.10120)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10120.png)

Vote: 18

Authors: Peiyuan Feng, Yuchen Zhang, Yuan Lin, Guanhua Huang, Weinan E, Hang Li, Yichen He

- ***What's New***: PaSa는 복잡한 학술 검색 질의를 위한 종합적이며 정확한 검색 결과를 제공하는 LLM 기반의 새로운 페이퍼 검색 에이전트입니다. 이 시스템은 인간의 논문 검색 행동을 모방하며, 두 개의 LLM 에이전트(Crawler와 Selector)를 활용하여 사용자가 원하는 정보를 효과적으로 수집합니다. PaSa는 또한 강화 학습(Reinforcement Learning)을 통해 최적화되어 뛰어난 성능을 발휘합니다.
- ***Technical Details***: PaSa는 두 개의 LLM 에이전트로 구성되며, 첫 번째 에이전트인 Crawler는 사용자 질의를 처리하며, 논문 검색 도구를 활용하여 관련 논문을 수집하고 이를 논문 큐(queue)에 추가합니다. 두 번째 에이전트인 Selector는 논문 큐에 있는 각 논문을 검토하여 사용자의 요구 사항을 충족하는지 여부를 평가합니다. 이 시스템은 AGILE이라는 강화 학습 프레임워크를 사용하여 최적화되었으며, AutoScholarQuery와 RealScholarQuery라는 두 가지 고품질 데이터셋으로 학습되었습니다.
- ***Performance Highlights***: PaSa는 AutoScholarQuery 테스트 세트에서 기존의 모든 기준점을 초과하는 성과를 보여줍니다. 특히 PaSa-7b는 Google 기반의 가장 강력한 기준점인 Google with GPT-4o에 비해 Recall@20에서 33.80%, Recall@50에서 38.83%, Recall@100에서 42.64% 향상된 결과를 제공합니다. RealScholarQuery에서 PaSa-7b는 실질적인 학술 검색 시나리오에서도 뛰어난 성능을 나타내며, Google with GPT-4o에 비해 Recall@20에서 37.78%, Recall@50에서 39.90%, Recall@100에서 39.83% 더 높은 성과를 보입니다.

### [Multiple Choice Questions: Reasoning Makes Large Language Models (LLMs) More Self-Confident Even When They Are Wrong](https://arxiv.org/abs/2501.09775)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.09775.png)

Vote: 12

Authors: Gonzalo Martínez, Javier Conde, María Grandury, Tairan Fu, Pedro Reviriego

- ***What's New***: 이 논문은 대형 언어 모델(Large Language Models; LLMs)의 자신감이 직접 답변을 제출하는 경우와 사전 추론을 먼저 하는 경우에 따라 어떻게 변하는지를 다룹니다. 중요한 발견은 LLMs가 오류가 있을지라도 먼저 사고 체인을 제공할 때 더욱 자신감을 보이는 경향이 있다는 것입니다.
- ***Technical Details***: 평가 방법론으로, 두 가지 프롬프트 방법을 사용했습니다. 첫 번째는 LLM에게 바로 답변을 요청하고, 두 번째는 Chain of Thought(CoT)를 통해 논리적인 단계들을 차례로 제공한 후 최종 답변을 요청하는 것입니다. 총 57개의 카테고리와 15,000개 이상의 질문으로 구성된 Massive Multitask Language Understanding(MMLU) 벤치마크를 통해 실험을 진행했습니다.
- ***Performance Highlights***: 모든 테스트된 모델들은 CoT 기법을 사용했을 때 자신감이 증가했습니다. 이는 모든 주제에서 관찰되었고, 특히 추론이 필수적인 주제에서 더욱 두드러졌습니다. 흥미롭게도, LLM의 자신감 증가는 정답을 맞췄을 때뿐만 아니라 틀린 답을 선택했을 때도 관찰되었으며, 오히려 틀린 답일 경우 더 큰 자신감 증가가 나타났습니다.

### [Textoon: Generating Vivid 2D Cartoon Characters from Text Descriptions](https://arxiv.org/abs/2501.10020)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10020.png)

Vote: 12

Authors: Chao He, Liefeng Bo, Jianqiang Ren

- ***What's New***: Textoon은 텍스트 설명을 통해 다채로운 2D 만화 캐릭터를 Live2D 포맷으로 생성하는 혁신적인 방법입니다. Textoon은 문장 생성 및 비전 모델을 활용하여 1분 내에 다양한 2D 캐릭터를 생성할 수 있으며, 이는 Live2D 캐릭터 생성에 있어서 최초의 시도로 평가됩니다.
- ***Technical Details***: Textoon은 텍스트 파싱(Text Parsing), 조절 가능한 외형 생성(Controllable Appearance Generation), 재편집(Re-editing), 컴포넌트 완성(Component Completion) 모듈을 포함합니다. 텍스트 파싱은 복잡한 텍스트에서 정확하게 컴포넌트를 추출하며, 세밀 조정을 통한 사용자 맞춤형 캐릭터 생성을 지원합니다. SDXL 모델을 사용하여 최상의 제어력과 텍스트 관련성을 가지는 이미지를 생성하며, 고해상도의 원본 아트워크에 또한 잘 맞습니다. ARKit의 얼굴 블렌드 형태를 통합하여 더 사실적인 입 동작 애니메이션을 만듭니다.
- ***Performance Highlights***: Textoon을 통해 생성된 Live2D 캐릭터는 시각적 매력과 다양성 측면에서 유효성을 확인받았으며, HTML5를 통해 매끄럽게 렌더링이 가능하여 광범위한 응용 가능성을 제공합니다. 최대진행시간에서 단문 입력을 통해 1분 이내로 새로운 캐릭터를 만들 수 있는 능력을 보여주며, 애니메이션의 생동감을 크게 향상시켰습니다.

### [Bridging Language Barriers in Healthcare: A Study on Arabic LLMs](https://arxiv.org/abs/2501.09825)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.09825.png)

Vote: 8

Authors: Clément Christophe, Marco AF Pimentel, Nada Saadi, Ronnie Rajan, Praveen K Kanithi, Tathagata Raha

- ***What's New***: 이 연구는 다국어 이해와 의학적 지식에 능한 대형 언어 모델(LLMs)을 개발하는데 있어서의 도전 과제를 탐구합니다. 단순히 의학 데이터를 번역하는 것만으로는 목표 언어 임상 작업에서 강력한 성능을 보장할 수 없음을 보여줍니다. 최적의 언어 혼합은 다양한 의학 작업에 따라 크게 달라지며, 데이터 집약적 사전 훈련이 여전히 필요할 수 있음을 발견했습니다.
- ***Technical Details***: 이 연구에서는 Llama 3.1 모델을 사용하여 다양한 원본 및 합성 아랍어 의학 데이터를 활용한 미세조정(fine-tuning)을 시도했습니다. 이는 모델의 성능을 임상 작업에서 분석하고, 번역, 패러프레이징(paraphrasing), 합성 데이터 생성 등을 통해 아랍어로 된 의학 데이터 세트를 증강함으로써 개선하려는 노력을 포함했습니다. 아랍어 평가에는 PubMedQA, MedMCQA, MedQA, Medical MMLU 등의 데이터 세트를 사용하였습니다.
- ***Performance Highlights***: 결과에 따르면, 모두 영어에서는 높은 정확도를 기록한 Llama3.1 모델이 아랍어에서는 성능이 상당히 저하되었습니다(MedQA에서 62.0에서 29.5로 감소). 뿐만 아니라, Qwen2.5 모델이 아랍어에서 상대적으로 더 나은 성능을 보였지만, 여전히 최적의 성능에 미치지 못했습니다. 이는 현재의 번역 방법론이 의학적 정보 이해 및 생성에 미치는 한계를 강조합니다.

### [X-Dyna: Expressive Dynamic Human Image Animation](https://arxiv.org/abs/2501.10021)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10021.png)

Vote: 5

Authors: Mohammad Soleymani, You Xie, Yipeng Gao, Di Chang, Yichun Shi, Shijie Zhou, Guoxian Song, Chao Wang, Chenxu Zhang, Linjie Luo, Zeyuan Chen, Zhengfei Kuang, Shengqu Cai, Gordon Wetzstein, Hongyi Xu

- ***What's New***: X-Dyna는 단일 인간 이미지를 드라이빙 비디오에서 파생된 얼굴 표정 및 신체 움직임을 사용하여 애니메이션화하는 새로운 제로샷(diffusion-based) 파이프라인을 소개합니다. 이는 피사체와 주변 환경 모두에 대한 사실적이고 컨텍스트 인식적인 동적 표현을 생성하는 데 중점을 둡니다.
- ***Technical Details***: X-Dyna의 핵심에는 Dynamics-Adapter라는 경량 모듈이 있으며, 이는 diffusion backbone의 공간적 주의에 참조 외형 정보를 효과적으로 통합합니다. 또한, 로컬 제어 모듈을 도입하여 신체 자세 제어를 넘어 얼굴 표정을 제어하며, 이는 더욱 사실적인 애니메이션 장면을 만듭니다. 다양한 인간 및 장면 비디오를 통해 물리적 인간 동작과 자연 환경의 역학을 학습할 수 있는 통합 프레임워크를 형성합니다.
- ***Performance Highlights***: 질적, 양적 평가 결과는 X-Dyna가 최신 기술을 능가하여 매우 사실적이고 생동감 넘치는 애니메이션을 생성하는 것으로 나타났습니다. 실험에서는 배경 및 포그라운드의 동적 텍스처가 보존되고, 얼굴과 신체의 정체성이 제대로 보존된다는 것을 보여줍니다.

### [HiFi-SR: A Unified Generative Transformer-Convolutional Adversarial Network for High-Fidelity Speech Super-Resolution](https://arxiv.org/abs/2501.10045)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10045.png)

Vote: 4

Authors: Zexu Pan, Kun Zhou, Shengkui Zhao, Yukun Ma, Bin Ma, Chong Zhang

- ***What's New***: HiFi-SR은 고해상도의 음성 복원(Speech Super-Resolution)을 구현하는 통합적인 네트워크로, Transformer-Convolutional 구조와 끝에서 끝까지의 적대적 훈련(Adversarial Training)을 활용하여 높은 주파수의 충실도와 범용성을 보장합니다. 이 모델은 기존의 SR 방법이 갖는 도메인 외 발화 시나리오에서의 일관성 및 음질 문제를 극복하며, 모든 입력 스피치 신호를 48kHz로 확장할 수 있습니다.
- ***Technical Details***: HiFi-SR 모델은 Transformer와 Convolutional 네트워크가 결합된 Transformer-Convolutional Generator로 구성되어 있으며, 입력으로 Mel-Spectrogram을 받아 고해상도 원시 파형(Waveform)을 출력합니다. 이 Generator는 MossFormer2 모듈을 재사용하여 긴 시간 의존성을 집중적으로 포착하고, HiFi-GAN을 기반으로 하는 Convolutional 네트워크는 높은 품질의 파형 생성을 보장합니다. 또한, 멀티 밴드 및 멀티 스케일 시간-주파수 판별기를 도입하여 고주파수의 충실도를 향상시킵니다.
- ***Performance Highlights***: HiFi-SR은 VCTK 테스트 세트에서 평균 LSD 0.82를 기록하며 NVSR 등 기존 음성 SR 모델보다 우수한 성능을 보입니다. EXPRESSO와 VocalSet 등의 다양한 데이터세트에서도 NVSR을 보다 크게 능가하여 도메인 외 데이터에 대한 일반화 능력이 뛰어남을 입증했습니다. 주관적 평가인 ABX 테스트에서도 HiFi-SR의 오디오 출력이 NVSR보다 높은 선호도를 보여주었습니다.

### [ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling under Long-Context Scenario](https://arxiv.org/abs/2501.10132)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10132.png)

Vote: 4

Authors: Jie Tang, Lucen Zhong, Zhengxiao Du, Haiyi Hu, Xiaohan Zhang

- ***What's New***: ComplexFuncBench는 실제 시나리오에서 대형 언어 모델(LLMs)의 복잡한 함수 호출 능력을 평가하기 위한 새로운 벤치마크입니다. 이 벤치마크는 다단계 및 제약 최적화 함수 호출을 포함하며, 긴 파라미터 값을 요구하고, 128k 길이의 컨텍스트를 다룹니다.
- ***Technical Details***: ComplexFuncBench는 Booking.com 등에서 유래된 5개 도메인의 43개의 실시간 API를 포함하고 있으며, 1000개의 복합 함수 호출 샘플을 수작업으로 주석했습니다. 자동 평가 프레임워크인 ComplexEval을 제안하여 함수 호출의 정확성을 평가하며, 헝가리언 매핑(Hungarian Mapping), 다차원 매칭(Multi-Dimensional Matching)을 통합하여 더욱 정밀한 평가를 제공합니다.
- ***Performance Highlights***: 실험 결과, 폐쇄형 모델인 Claude-3.5-Sonnet이 설명 완전성 및 정확성에서 1.84, 1.85의 점수를 기록하여 가장 뛰어난 성능을 보였으며, 공개된 모델 중에서는 Qwen2.5-72B가 1.80, 1.75의 점수로 가장 높은 점수를 기록했습니다. 특히 OpenAI의 GPT-4o는 호텔과 명소 도메인에서 각각 70%와 82%의 높은 성공률을 보였습니다.

### [GaussianAvatar-Editor: Photorealistic Animatable Gaussian Head Avatar Editor](https://arxiv.org/abs/2501.09978)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.09978.png)

Vote: 2

Authors: Xiangyue Liu, Ping Tan, Qi Zhang, Yuan Liu, Heng Li, Kunming Luo, Li Yi

- ***What's New***: GaussianAvatar-Editor는 텍스트 기반의 제어로 animatable Gaussian head avatars를 편집할 수 있는 혁신적인 프레임워크를 소개합니다. 표정, 자세, 시점을 완전히 조절할 수 있으며, 모션폐색 및 시공간 불일치와 같은 4D Gaussian avatar 편집의 어려움을 해결하는 새로운 방법을 제공합니다.
- ***Technical Details***: GaussianAvatar-Editor는 Weighted Alpha Blending Equation(WABE)을 제안하여 모션 폐색 문제를 효과적으로 처리합니다. 또한, 조건부 적대적 학습(Conditional Adversarial Learning)을 통해 편집 품질을 향상시키고, 시공간 일관성을 보장합니다. Gaussian alpha blending의 새로운 활성화 함수와 2D diffusion 기반의 편집기를 통합하여, 4D animatable Gaussian 편집에서 사용자의 텍스트 입력에 따른 고품질 편집을 가능하게 합니다.
- ***Performance Highlights***: GaussianAvatar-Editor는 다양한 실험에서 기존 방법들보다 일관적으로 뛰어난 성능을 보여주었습니다. 특히, novel view rendering, self-reenactment 및 cross-identity reenactment에서 높은 CLIP-S 및 CLIP-C 점수를 기록했습니다. 해당 프레임워크는 모션 폐색 및 시공간 불일치 문제를 해결함으로써 타의 추종을 불허하는 품질의 편집 결과를 제공합니다.

