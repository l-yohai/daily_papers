## Daily Papers (2024-03-14)

### [Gemma: Open Models Based on Gemini Research and Technology](https://arxiv.org/abs/2403.08295)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08295.png)

Vote: 25

Authors: Aditya Barua, Thomas Mesnard, Alex Botev, +, Laurent Sifre, Anna Bulanova, Shreya Pathak, Amélie Héliou, Antonia Paterson, Alex Castro-Ros, Surya Bhupatiraju, Andrea Tacchetti, Morgane Rivière, Adam Roberts, Aakanksha Chowdhery, Robert Dadashi, Gemma Team, Léonard Hussenot, Ambrose Slone, Pouya Tafti, Mihir Sanjay Kale, Cassidy Hardin, Juliette Love

- 본 연구에서는 Gemini 모델 연구 및 기술을 바탕으로 제작된 경량화된 최첨단 오픈 모델인 Gemma를 소개한다.
- Gemma 모델은 언어 이해, 추론, 안전성 등 학술 벤치마크 분야에서 뛰어난 성능을 보여준다.
- 20억 및 70억 매개변수를 가진 두 가지 크기의 모델을 공개하며, 사전 훈련된 체크포인트와 미세 조정된 체크포인트 모두를 제공한다.
- Gemma는 18개의 텍스트 기반 과제 중 11개에서 동등한 규모의 오픈 모델들을 능가하는 성과를 달성했다.
- 모델의 안전성과 책임성 측면에서의 광범위한 평가와 함께 모델 개발에 대한 상세한 설명을 제시한다.
- 대형 언어 모델(LLM)의 안전성 향상과 다음 세대 LLM 혁신을 가능하게 하기 위해 책임감 있는 LLM의 공개를 중요하다고 믿는다.

### [Simple and Scalable Strategies to Continually Pre-train Large Language Models](https://arxiv.org/abs/2403.08763)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08763.png)

Vote: 22

Authors: Eugene Belilovsky, Irina Rish, Timothée Lesort, Kshitij Gupta, Quentin Anthony, Mats L. Richter, Adam Ibrahim, Benjamin Thérien

- 대규모 언어 모델(LLM)을 계속해서 효율적으로 사전 학습하기 위한 간단하고 확장 가능한 전략을 제시합니다.
- 신규 데이터로 때문에 발생하는 분배 이동이 있을 때 기존 데이터의 성능 저하나 새 데이터에 대한 적응성 문제를 해결합니다.
- 학습률(LR) 재온난화, LR 재감소, 이전 데이터의 재생 방식을 결합하여 처음부터 다시 학습하는 것과 동일한 성능을 달성합니다.
- 영어에서 영어로, 그리고 영어에서 독일어로의 데이터셋 간 약한 및 강력한 분배 이동 사례에서 이 방법의 효과를 검증했습니다.
- 특히, 실험을 통해 405M 파라미터 규모 모델은 물론 10B 파라미터 규모의 대형 모델에서도 계속된 학습 전략이 재학습 기준치와 일치함을 확인했습니다.
- 이 연구 결과는 적은 계산 자원을 사용하여 LLM을 성공적으로 업데이트할 수 있다는 것을 보여줍니다.
- 또한, 기존 연구에 기반하여 학습률 재온난화로 인한 잊어버림 현상을 방지하고 고정된 토큰 예산에 구속되지 않는 코사인 학습률 일정의 대안을 제안합니다.

### [VLOGGER: Multimodal Diffusion for Embodied Avatar Synthesis](https://arxiv.org/abs/2403.08764)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08764.png)

Vote: 17

Authors: Cristian Sminchisescu, Thiemo Alldieck, Enric Corona, Eduard Gabriel Bazavan, Andrei Zanfir, Nikos Kolotouros

- 우리는 개인의 단일 입력 이미지에서 오디오 기반의 인간 비디오 생성을 위한 방법인 VLOGGER를 제안한다.
- 이 방법은 1) 확률적 인간-3D-동작 확산 모델과 2) 공간적 및 시간적 제어가 가능한 텍스트-이미지 모델을 보완하는 새로운 확산 기반 아키텍처로 구성되어 있다.
- VLOGGER는 고급 표현을 통해 쉽게 제어되며 다양한 길이의 고품질 비디오를 생성하며, 각 개인 마다 훈련할 필요 없이 전체 이미지를 생성한다.
- 우리는 3D 자세 및 표정 주석이 있는 다양하고 새로운 데이터셋 MENTOR를 큐레이션하고, 주요 기술 기여를 훈련 및 평가한다.
- VLOGGER는 세 개의 공개 벤치마크에서 이미지 품질, 정체성 유지 및 시간적 일관성 면에서 최신 방법을 초과하는 성능을 보여준다.
- 우리는 VLOGGER의 성능을 다양성 지표에 대해 분석하고, 아키텍처 선택과 MENTOR 사용이 공정하고 편향 없는 모델을 대규모로 훈련하는데 유익함을 보여준다.
- 마지막으로, 우리는 비디오 편집 및 개인화에서 VLOGGER의 응용을 보여준다.

### [SOTOPIA-$π$: Interactive Learning of Socially Intelligent Language Agents](https://arxiv.org/abs/2403.08715)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08715.png)

Vote: 14

Authors: Haofei Yu, Yonatan Bisk, Zhengyang Qi, Wenxin Zhang, Maarten Sap, Ruiyi Wang, Graham Neubig, Hao Zhu

- 인간은 모방과 사회적 상호작용을 통해 사회적 기술을 학습하며, 이러한 사회적 학습 과정은 언어 에이전트를 구축하는 기존 연구에서 대체로 미흡하게 연구되었다.
- 이러한 간극을 해소하고자 본 논문에서는 언어 에이전트의 사회 지능을 향상시키는 상호작용 학습 방법인 SOTOPIA-$π$를 제안한다.
- 이 방법은 대규모 언어 모델(LLM) 평가에 따라 필터링된 사회적 상호작용 데이터에 대한 행동 복제 및 자기 강화 훈련을 활용한다.
- 연구 결과, 7B 크기의 LLM을 사용한 우리의 훈련 방법이 전문가 모델(예: GPT-4 기반 에이전트)의 사회적 목표 달성 능력에 도달하면서도 언어 에이전트의 안전성을 향상시키고 MMLU 벤치마크에서 일반적인 QA 능력을 유지할 수 있음을 보여주었다.
- 또한, 이 훈련 패러다임은 사회적 상호작용을 위해 특별히 훈련된 언어 에이전트의 능력을 과대평가하는 LLM 기반 평가자들의 어려움을 밝혀낸다.

### [Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts](https://arxiv.org/abs/2403.08268)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08268.png)

Vote: 10

Authors: Hongfa Wang, Zhifeng Li, Andong Wang, Yue Ma, Chenyang Qi, Xiu Li, Chengfei Cai, Qifeng Chen, Heung-Yeung Shum, Wei Liu, Yingqing He

- 최근 이미지에서 비디오로의 생성(image-to-video generation)이 발전하였지만, 제어 가능성과 지역 애니메이션에 대한 연구는 덜 탐구되었습니다.
- 기존의 이미지에서 비디오로의 방법들은 지역적으로 인식하지 못하며 전체 장면을 이동시키는 경향이 있습니다.
- 또한 현재 I2V 방법들은 대상 움직임을 묘사하는 것뿐만 아니라 프레임 내용의 불필요한 세부 설명을 제공해야 합니다.
- 본 논문에서는 사용자가 클릭으로 이동할 대상을 지정하고 짧은 모션 프롬프트로 이동 방식을 지정하는 것으로 이미지 애니메이션을 달성하는 실용적인 프레임워크인 Follow-Your-Click를 제안합니다.
- 기술적으로, 비디오 생성 품질을 크게 향상시키는 첫 프레임 마스킹 전략을 제안하고 모델의 짧은 프롬프트 따르기 능력을 향상시키기 위해 짧은 모션 프롬프트 데이터셋을 갖춘 모션 확장 모듈을 제안합니다.
- 목표 움직임의 속도를 더 정확히 제어하기 위해 흐름 기반 모션 크기 제어 방법을 제안합니다.
- 우리의 프레임워크는 이전 방법보다 더 간단하지만 정확한 사용자 제어와 더 나은 생성 성능을 가지고 있습니다.
- 상용 도구와 연구 방법을 포함한 7가지 베이스라인과 8가지 지표와의 광범위한 실험을 통해 우리의 접근법의 우수성을 제안합니다.
- 프로젝트 페이지: https://follow-your-click.github.io/

### [Scaling Up Dynamic Human-Scene Interaction Modeling](https://arxiv.org/abs/2403.08629)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08629.png)

Vote: 9

Authors: Tengyu Liu, Nan Jiang, Siyuan Huang, Hongjie Li, Yixin Zhu, Yixin Chen, Xiaoxuan Ma, Zan Wang, Zhiyuan Zhang

- 인간-장면 상호작용 모델링에서 데이터 부족과 고급 모션 합성의 어려움에 직면하여, TRUMANS 데이터셋과 함께 새로운 HSI 모션 합성 방법을 소개합니다.
- TRUMANS는 현재 사용 가능한 가장 포괄적인 모션 캡처 HSI 데이터셋으로, 100개의 실내 장면에 걸쳐 15시간이 넘는 인간 상호작용을 포함합니다.
- 이 데이터셋은 신체 전체의 인간 동작과 물체의 부분 수준 동적 정보를 세심하게 캡처하며, 접촉의 리얼리즘에 중점을 둡니다.
- 물리적 환경을 정확한 가상 모델로 변환하고 인간과 물체의 모양과 동작에 대한 광범위한 증강을 적용함으로써 상호작용 충실도를 유지하면서 데이터셋을 확장합니다.
- TRUMANS를 활용하여, 장면의 맥락과 의도된 행동을 모두 고려하여 임의의 길이의 HSI 시퀀스를 효율적으로 생성하는 확산 기반의 자기회귀 모델을 고안했습니다.
- 실험에서는 PROX, Replica, ScanNet, ScanNet++과 같은 다양한 3D 장면 데이터셋에서 높은 제로샷 일반화 능력을 보여 주며, 정량적 실험과 인간 연구에 의해 확인된 바와 같이 원래 모션 캡쳐 시퀀스를 밀접하게 모방하는 동작을 생성합니다.

### [Language models scale reliably with over-training and on downstream tasks](https://arxiv.org/abs/2403.08540)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08540.png)

Vote: 8

Authors: Georgios Smyrnis, Marianna Nezhurina, Igor Vasiljevic, Gabriel Ilharco, +, Reinhard Heckel, Jenia Jitsev, Thomas Kollar, Alexandros G. Dimakis, Niklas Muennighoff, Mitchell Wortsman, Vaishaal Shankar, Achal Dave, Rulin Shao, Jean Mercat, Alex Fang, Jeffrey Li, Rui Xin, Yair Carmon, Suchin Gururangan, Samir Yitzhak Gadre, Shuran Song, Sedrick Keh

- 언어 모델의 개발에서 스케일링 법칙은 유용한 가이드를 제공하지만 현실에서의 모델 훈련과 평가 시 관찰되는 차이점들이 여전히 존재합니다.
- 대부분의 스케일링 법칙은 계산 최적화 훈련 체제에서 연구되지만, 실제로 모델들은 추론 비용을 줄이기 위해 과대 훈련됩니다.
- 또한, 스케일링 법칙은 다음 토큰 예측에 대한 손실을 예측하는데 주로 초점을 맞추지만, 모델은 궁극적으로 하류 작업 성능에 기반하여 비교됩니다.
- 이 논문에서는 이 두 가지 단점을 해결합니다. 이를 위해 0.011B에서 6.9B 파라미터를 가지는 104개의 다양한 토큰 수로 훈련된 모델들의 테스트베드를 만들었습니다.
- 우리는 과대 훈련된 정권에서 스케일링을 조사합니다. 이를 통해 모델 파라미터 수와 훈련 토큰 대 파라미터 비율의 관점에서 스케일링 법칙을 추정해, 더 적은 연산으로 대규모 모델의 검증 손실을 예측할 수 있습니다.
- 또한 언어 모델의 난해성(perplexity)을 그것의 다운스트림 작업 성능과 관련지어 지수 법칙을 통해 예측합니다. 이 법칙을 사용하여 적은 연산으로 두 모델의 하류 작업에 대한 평균 탑-1 오류를 예측합니다.
- 이러한 실험들은 https://github.com/mlfoundations/scaling 주소에서 확인할 수 있습니다.

### [GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting](https://arxiv.org/abs/2403.08551)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.08551.png)

Vote: 6

Authors: Xingtong Ge, Dailan He, Jun Zhang, Hongwei Qin, Tongda Xu, Guo Lu, Yan Wang, Jing Geng, Xinjie Zhang

- 최근 명시적인 신경 표현(implicit neural representations, INRs) 기술은 충분한 GPU 자원이 있는 경우, 높은 시각적 품질과 빠른 렌더링 속도(10-1000 FPS)를 달성했지만, 이는 메모리가 제한적인 저성능 기기에서 사용하기 어려운 문제가 있습니다.
- 이에 대응하여, GaussianImage라고 명명한 2D 가우스 분포를 이용한 새로운 이미지 표현 및 압축 패러다임을 제안합니다.
- 이 방법은 각 가우시안이 위치, 공분산, 색상을 포함한 8개의 매개변수로 이미지를 표현하며, 누적합산을 기반으로 한 새로운 렌더링 알고리즘을 도입합니다.
- 우리의 방법은 최소 3배 낮은 GPU 메모리 사용과 5배 빠른 피팅 시간을 유지하면서도 WIRE나 I-NGP와 같은 INR 기술의 이미지 표현 성능과 비교할만 하고, 매개변수 크기에 무관하게 1500-2000 FPS라는 더 빠른 렌더링 속도를 제공합니다.
- 또한, 기존의 벡터 양자화 기술을 통합하여 이미지 코덱을 구축했으며, 실험 결과로 우리의 코덱이 COIN 및 COIN++과 같은 압축 기반 INR의 비트율-왜곡 성능에 필적하는 동시에 약 1000 FPS의 디코딩 속도를 촉진함을 보여줍니다.
- 추가적으로, 부분 비트-백 코딩을 사용할 때 우리의 코덱이 COIN과 COIN++의 성능을 능가하는 것을 보여주는 예비 개념 증명이 제시되었습니다.

### [On the Societal Impact of Open Foundation Models](https://arxiv.org/abs/2403.07918)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.07918.png)

Vote: 5

Authors: Sayash Kapoor, Rumman Chowdhury, +, Victor Storchan, Kevin Klyman, Yacine Jernite, Kevin Bankston, Dawn Song, Ashwin Ramaswami, Alex Engler, Stella Biderman, Stefano Maffulli, Miranda Bogen, Aspen Hopkins, Peter Cihon, Joelle Pineau, Shayne Longpre, Aviya Skowron, Alondra Nelson, Seth Lazar, Daniel Zhang, Rishi Bommasani, Peter Henderson

- 이 논문은 모델 가중치가 널리 사용 가능한 오픈 파운데이션 모델(예: Llama 2, Stable Diffusion XL)의 사회적 영향에 대해 다룬다.
- 오픈 파운데이션 모델의 독특한 다섯 가지 특성(예: 높은 사용자 정의 가능성, 불충분한 모니터링)이 이점과 위험을 동시에 가져온다고 지적한다.
- 이 모델들은 혁신, 경쟁, 의사결정 권한의 분배, 투명성 등 여러 이점을 제공하지만, 일부 유보 사항이 존재한다.
- 논문은 오픈 파운데이션 모델의 오용 위험을 분석하기 위한 위험 평가 프레임워크를 설계한다.
- 사이버 공격, 생물 무기 등의 여러 오용 벡터를 통해 현재 연구가 이 모델들의 추가적인 위험을 효과적으로 특정하기에 부족함을 발견한다.
- 제안된 프레임워크는 특정 사례에서의 추가적 위험이 낮은 이유를 설명하고, 이전 연구가 프레임워크의 다른 부분에 초점을 맞추며 서로 다른 가정을 했기 때문에 오용 위험에 대한 의견 불일치가 발생했음을 밝힌다.
- 또한, 구체적인 토론을 위한 방향을 제시하며, 이 모델들의 이론적 이점과 위험을 경험적으로 검증하기 위해 필요한 연구가 무엇인지에 대한 개요를 제공한다.

