## Daily Papers (2024-03-01)

### [StarCoder 2 and The Stack v2: The Next Generation](https://arxiv.org/abs/2402.19173)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/FUbEjaqJTyfiCVLfIMcgk.png)

Vote: 51

Authors: Arthur Zucker, Dmitry Abulkhanov, Anton Lozhkov, Ao Tang, Wen-Ding Li, Qian Liu, Raymond Li, Joel Lamy-Poirier, Dmytro Pykhtar, Loubna Ben Allal, Zijian Wang, Tianyang Liu, Yuxiang Wei, Denis Kocetkov, Zhuang Li, Federico Cassano, Nouamane Tazi, +, Jiawei Liu, Megan Risdal, Indraneil Paul, Max Tian, Younes Belkada

- 코드 대규모 언어 모델(Large Language Models for Code, Code LLMs)의 책임 있는 개발에 집중하는 오픈-사이언티픽 협력 프로젝트인 BigCode 프로젝트가 새로운 StarCoder2를 소개했습니다.
- 소프트웨어 헤리티지(Software Heritage, SWH)와의 파트너십을 통해 그들의 소스 코드 아카이브 위에 The Stack v2를 구축했으며, 이는 619개 프로그래밍 언어를 아우르는 SWH 리포지터리와 함께 고품질 데이터 소스를 선별적으로 추가했습니다.
- 추가된 데이터 소스에는 GitHub 풀 리퀘스트, Kaggle 노트북, 코드 문서화 등이 포함되어, 기존의 StarCoder 데이터셋보다 4배 큰 훈련 세트를 만들었습니다.
- StarCoder2 모델은 3B, 7B, 15B 파라미터를 가진 모델을 3.3에서 4.3조 토큰에 대해 훈련시켰으며, 코드 LLM 벤치마크의 광범위한 세트에서 철저하게 평가되었습니다.
- 소형 모델인 StarCoder2-3B는 비슷한 크기의 다른 코드 LLM들 대부분의 벤치마크에서 우수한 성능을 보였고, 15B 파라미터를 가진 StarCoderBase-15B보다도 뛰어난 결과를 보였습니다.
- 대형 모델인 StarCoder2-15B는 비슷한 크기의 다른 모델들을 획기적으로 뛰어넘었으며, 다른 모델들 중 2배 큰 CodeLlama-34B와 동등하거나 뛰어난 성능을 보여주었습니다.
- 비록 DeepSeekCoder-33B가 고자원 언어에 대한 코드 완성에서 가장 좋은 성능을 보이는 모델이지만, StarCoder2-15B는 수학 및 코드 추론 벤치마크와 몇몇 저자원 언어에서 더 우수한 성능을 보였습니다.
- 모델의 가중치는 OpenRAIL 라이선스 하에 공개되며, 소스 코드 데이터의 SoftWare Heritage persistent IDentifiers (SWHIDs)를 공개함으로써 훈련 데이터에 대한 투명성을 완벽하게 보장합니다.

### [Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models](https://arxiv.org/abs/2402.19427)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/5e68p09De9fBpLfPl_uUJ.png)

Vote: 23

Authors: Caglar Gulcehre, Samuel L. Smith, Srivatsan Srinivasan, George Cristian-Muraru, Razvan Pascanu, Yee Whye Teh, Albert Gu, Ruba Haroun, David Budden, Nando De Freitas, Anushan Fernando, Yutian Chen, Guillaume Desjardins, Aleksandar Botev, Soham De, Leonard Berrada, Arnaud Doucet

- 순환 신경망(RNN)은 빠른 추론 속도와 긴 시퀀스에서의 효율적인 확장력을 가지고 있지만, 훈련이 어렵고 확장에 한계가 있습니다.
- 게이트가 있는 선형 순환을 이용한 새로운 RNN인 Hawk와 게이트가 있는 선형 순환과 로컬 어텐션을 혼합한 하이브리드 모델 Griffin을 제안합니다.
- Hawk는 하위 작업에서 Mamba의 성능을 능가하고, Griffin은 6배 적은 토큰으로 훈련함에도 불구하고 Llama-2의 성능을 일치시킵니다.
- Griffin은 훈련 중 본 적 없는 훨씬 긴 시퀀스에 대해 외삽할 수 있음을 보여줍니다.
- 이 모델들은 훈련 중에 트랜스포머와 같은 하드웨어 효율성을 보이며, 추론 중에는 낮은 지연 시간과 훨씬 높은 처리량을 가집니다.
- 14B 파라미터까지 Griffin을 확장하고 효율적인 분산 훈련을 위해 모델을 샤딩하는 방법을 설명합니다.

### [Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers](https://arxiv.org/abs/2402.19479)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/VSE0UHuPnl98dY-q2yjTH.png)

Vote: 19

Authors: Yuwei Fang, Sergey Tulyakov, Aliaksandr Siarohin, Hsiang-wei Chao, Ekaterina Deyneka, Hsin-Ying Lee, Tsai-Shien Chen, Jian Ren, Byung Eun Jeon, Willi Menapace, Ming-Hsuan Yang

- 고품질의 영상-텍스트 데이터 수집이 힘든 가운데, 본 연구는 텍스트 영상 설명, 자막, 개별 영상 프레임과 같은 다양한 모달리티를 활용하여 자동으로 데이터셋을 구축하는 방법을 제안합니다.
- 3.8M 개의 고화질 영상을 공개적으로 이용 가능한 HD-VILA-100M 데이터셋에서 선택하고, 이를 의미론적으로 일관된 비디오 클립으로 나누었습니다.
- 다중 교차 모달리티 교사 모델을 적용해 각 비디오 클립에 대한 캡션을 생성한 후, 소규모 서브셋에서 수동으로 선택된 최고의 캡션을 활용해서 검색 모델을 미세 조정합니다.
- 조정된 모델을 사용하여 전체 데이터셋에서 각 비디오의 최상의 캡션을 선정하였고, 이를 통해 70M 개의 고품질 텍스트 캡션과 짝을 이룬 비디오를 얻었습니다.
- 이렇게 구축된 Panda-70M 데이터셋은 비디오 캡셔닝, 비디오 및 텍스트 검색, 텍스트 기반 비디오 생성 등 세 가지 다운스트림 작업에 대해 우수한 성능을 보여줌으로써 데이터셋의 가치를 입증하였습니다.

### [Beyond Language Models: Byte Models are Digital World Simulators](https://arxiv.org/abs/2402.19155)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/8d3oJgqtVy6AvG8Frsxfw.png)

Vote: 17

Authors: Rui Wang, Xiaobing Li, Maosong Sun, Xu Tan, Zili Wang, Shangda Wu

- 전통적인 딥러닝은 디지털 세계의 기본 단위인 바이트를 종종 간과하는데, 이는 모든 정보와 연산이 이진 형식으로 인코딩되고 조작되는 곳입니다.
- 자연어 처리에서 다음 토큰 예측의 성공에 영감을 받아, 우리는 디지털 세계를 시뮬레이션하기 위해 다음 바이트 예측 모델인 bGPT를 소개합니다.
- bGPT는 텍스트, 오디오, 이미지 등 다양한 모달리티에서 전문화된 모델의 성능에 맞먹으며, 알고리즘 또는 하드웨어 동작의 예측, 시뮬레이션 및 진단에 새로운 가능성을 제공합니다.
- bGPT는 심볼릭 음악 데이터를 변환하는 과정에서 거의 완벽하게 복제해 ABC 표기법을 MIDI 형식으로 변환 시 바이트 당 0.0011 비트의 낮은 오류율을 달성했습니다.
- 또한, bGPT는 CPU 동작을 시뮬레이션하는 데에 있어서 다양한 연산을 실행하는데 99.99%를 넘는 정확도로 뛰어난 능력을 보여주었습니다.
- 다음 바이트 예측을 활용하는 모델들은 bGPT와 같이 거대한 바이너리 데이터로부터 직접 학습하여 디지털 세계의 복잡한 패턴들을 효과적으로 시뮬레이트 할 수 있습니다.

### [Humanoid Locomotion as Next Token Prediction](https://arxiv.org/abs/2402.19469)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/RdzS9K3DCfonN0pfyHKZJ.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/RdzS9K3DCfonN0pfyHKZJ.mp4" muted="false"></video></div>

Vote: 16

Authors: Sarthak Kamat, Jathushan Rajasegaran, Bike Zhang, Koushil Sreenath, Jitendra Malik, Ilija Radosavovic, Baifeng Shi, Trevor Darrell

- 이 논문에서는 현실 세계의 휴머노이드 제어를 언어에서 다음 단어를 예측하는 것과 유사한 '다음 토큰 예측 문제'로 변환하여 접근합니다.
- 연구진은 센서모터 궤적의 자기 회귀 예측을 통해 훈련된 인과적 변환기 모델을 제안합니다.
- 데이터의 다중 모달성을 고려하여, 모달리티 연계 방식으로 예측을 수행하며, 각 입력 토큰에 대해 동일한 모달리티에서 다음 토큰을 예측합니다.
- 이 일반적인 형식은 동작 없이 비디오 궤적만 있는 것과 같은 누락된 모달리티를 가진 데이터를 활용할 수 있게 합니다.
- 연구진은 기존의 신경망 정책, 모델 기반 컨트롤러, 모션 캡처 데이터, 그리고 인간의 YouTube 비디오 등에서 가져온 시뮬레이션된 궤적을 이용하여 모델을 훈련시켰습니다.
- 이 모델은 San Francisco에서 사전 설정 없이 완전한 크기의 휴머노이드로 걷게 하는 것을 가능하게 합니다.
- 실제 세계에 바로 적용할 수 있는 모델은 단지 27시간의 걷기 데이터만으로도 훈련되며, 훈련 중에 보지 못한 명령어, 예를 들면 뒤로 걷는 것과 같은 새로운 명령어에도 일반화될 수 있습니다.
- 이러한 발견은 센서모터 궤적의 생성 모델링을 통해 실제 세계에서 도전적인 제어 과제를 배우는 것에 대한 유망한 길을 제시합니다.

### [MOSAIC: A Modular System for Assistive and Interactive Cooking](https://arxiv.org/abs/2402.18796)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Pg0wqi5vENUDkzEFjrH7m.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Pg0wqi5vENUDkzEFjrH7m.mp4" muted="false"></video></div>

Vote: 15

Authors: Prithwish Dan, Kelly Y Chen, Rahma Abdullah, Angela Chao, Atiksh Bhardwaj, Juntao Ren, Sanjiban Choudhury, Yash Sharma, Nathaniel Chin, Neha Sunkara, Aditya Kompella, Xiangwan Sun, Maximus Adrian Pace, Kushal Kedia, Gonzalo Gonzalez-Pumariega, Xinyi Fan, Huaxiaoyue Wang

- MOSAIC 프로젝트는 일반 사용자와 요리를 하는 것과 같은 복잡한 협업 과제를 수행하기 위한 가정용 로봇을 위한 모듈식 아키텍처를 제시합니다.
- 이 시스템은 인간과 긴밀히 협력하며, 자연어를 사용해 사용자와 의사소통하고, 여러 로봇을 조정하며, 일상적인 대상들의 개방형 어휘를 관리합니다.
- MOSAIC의 핵심은 모든 구성요소의 모듈화로, 언어 및 이미지 인식과 같은 일반적인 태스크를 위해 대규모 사전 훈련된 모델을 활용하면서, 특정 태스크 제어를 위한 간소화된 모듈을 사용합니다.
- 시스템은 두 로봇이 인간 사용자와 협력하여 6가지 요리 조합을 요리하는 60번의 종단간 시험, 물체 집기를 위한 180회의 visuomotor 시험, 인간의 움직임 예측을 위한 60회의 에피소드, 태스크 플래너의 온라인 사용자 평가 46건 등을 포함한 광범위한 평가를 통해 검증되었습니다.
- MOSAIC는 실제 인간 사용자와 함께 전체 시스템을 종단간으로 운영해내며, 6가지 다른 레시피를 대상으로 하는 협력 요리 시도 중 68.3%(41/60)를 완료함으로써 인간과의 효율적인 협력 능력을 입증했으며, 부분 태스크 완료율은 91.6%에 달했습니다.
- 마지막으로 현재 시스템의 한계점과 이 분야에서의 흥미로운 미해결 과제들에 대해 논의합니다.
- 프로젝트 웹사이트는 https://portal-cornell.github.io/MOSAIC/ 에서 확인할 수 있습니다.

### [Trajectory Consistency Distillation](https://arxiv.org/abs/2402.19159)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/WNn2aze7DMaqNyGmnNcAy.png)

Vote: 9

Authors: Chaoyue Wang, Changxing Ding, Minghui Hu, Tat-Jen Cham, Dacheng Tao, Jianbin Zheng, Zhongyi Fan

- 'Latent Consistency Model (LCM)'은 일관성 모델을 잠재 공간으로 확장하고 가이드 일관성 증류 기술을 활용하여 텍스트-이미지 합성 가속화에서 인상적인 성능을 달성했습니다.
- 그러나 LCM은 선명도와 자세한 정교함을 동시에 갖춘 이미지 생성에 어려움을 겪는 것으로 나타났습니다.
- 본 연구는 이 문제점에 대하여 근본 원인을 파악하고 해결하기 위한 깊은 분석을 수행하였습니다.
- 세 가지 영역에서 오류가 발생함을 확인하고, 이를 해결하기 위해 'Trajectory Consistency Distillation (TCD)'를 소개합니다.
- TCD는 잠재적 일관성 기능을 확장하고 Probability Flow ODE의 전체 궤적을 정확히 추적할 수 있도록 합니다.
- 또한, 다단계 일관성 샘플링에서 발생하는 누적 오류를 방지하기 위해 전략적인 확률 샘플링을 특별히 설계하였습니다.
- 실험 결과 TCD는 낮은 NFE에서 이미지 품질을 크게 향상시킬 뿐만 아니라, 높은 NFE에서는 교사 모델보다 더 상세한 결과를 생성함을 보여주었습니다.

### [Simple linear attention language models balance the recall-throughput tradeoff](https://arxiv.org/abs/2402.18668)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/YfWiKNu_gMu7gX8CBQB2E.png)

Vote: 8

Authors: Aman Timalsina, Christopher Ré, James Zou, Atri Rudra, Sabri Eyuboglu, Silas Alberti, Simran Arora, Michael Zhang, Dylan Zinsley

- 최근 연구는 주목 기반 언어 모델이 컨텍스트에서 본 토큰들을 기반으로 생성물을 만들어내는 '회상(recall)'에 뛰어남을 보여줬지만, KV-cache에 의해 인퍼런스 중에 효율성이 저하된다는 것을 지적하였습니다.
- 이 연구에서는 언어 모델의 효율성(예: 메모리 소비 감소)을 개선하고 동시에 회상 능력을 유지할 수 있는지 여부를 탐구합니다.
- 다양한 아키텍처에 대한 실험과 이론을 적용하여, 모델의 상태 크기와 회상 능력 간의 주요 트레이드오프를 식별하였습니다.
- 저자들은 BASED라는 간단한 아키텍처를 제안하며, 이는 선형 및 슬라이딩윈도우 주의 기법을 결합합니다.
- BASED의 윈도우 크기와 선형 주의 특징 차원을 조절하여, 회상-메모리 트레이드오프 곡선의 파레토 최적선을 따라 상태 크기를 조정할 수 있습니다.
- 1.3b 매개변수를 가진 언어 모델을 훈련하여, BASED가 복잡하지 않은 모델들(예: Mamba)과 퍼플렉서티에서 비슷한 성능을 보이고 실제 세계의 회상 집중적 작업에서 6.22 정확도 포인트로 뛰어난 성능을 보인다는 것을 보여줍니다.
- 선형 주의 구현은 종종 표준 주의 구현보다 효율이 떨어진다는 문제를 해결하기 위해, 저자들은 IO-aware 알고리즘을 개발하여 언어 생성에서 FlashAttention-2보다 24배 높은 처리량을 달성하였습니다.
- 이 작업의 코드는 https://github.com/HazyResearch/based 에서 제공됩니다.

### [ViewFusion: Towards Multi-View Consistency via Interpolated Denoising](https://arxiv.org/abs/2402.18842)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/c5xVMiG3rAsMUujOcU1X8.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/c5xVMiG3rAsMUujOcU1X8.mp4" muted="false"></video></div>

Vote: 8

Authors: Gil Avraham, Sameera Ramasinghe, Loris Bazzani, Yan Zuo, Anton van den Hengel, Xianghui Yang

- 확산 모델을 통한 새로운 시점 합성은 다양하고 고품질의 이미지 생성에서 놀라운 가능성을 보여주었습니다.
- 하지만 기존 방법에서 이미지를 독립적으로 생성하는 과정은 여러 시점의 일관성을 유지하는 데 어려움을 가져왔습니다.
- 이를 해결하기 위하여, 우리는 기존에 사전 훈련된 확산 모델에 쉽게 통합될 수 있는 새로운, 훈련이 필요 없는 알고리즘인 ViewFusion을 소개합니다.
- 저희 접근법은 이전에 생성된 시점들을 다음 시점 생성의 맥락으로 내재적으로 활용하는 자동회귀 방식을 채택합니다.
- 이를 통해, 새로운 시점 생성 과정에서 견고한 다중 시점 일관성을 보장합니다.
- 알려진 시점 정보를 내삽된 노이즈 제거를 통해 융합하는 확산 과정을 통해, 우리의 프레임워크는 단일 시점 조건부 모델을 추가적인 미세 조정 없이 다중 시점 조건부 설정에서 작동하도록 성공적으로 확장합니다.
- 광범위한 실험 결과는 ViewFusion이 일관되고 세밀한 새로운 시점들을 생성하는 데 효과적임을 보여줍니다.

### [DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models](https://arxiv.org/abs/2402.19481)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/l3RaqnhAKiCFa5xHOSQfH.png)

Vote: 6

Authors: Tianle Cai, Ming-Yu Liu, Junjie Bai, Han Cai, Jiaxin Cao, Kai Li, Song Han, Yangqing Jia, Qinsheng Zhang, Muyang Li

- 확산 모델은 고품질 이미지 합성에 큰 성공을 거두었으나, 거대한 연산 비용 때문에 고해상도 이미지 생성이 여전히 도전적인 문제로 남아있습니다.
- 대화형 응용 프로그램에서 사용하기에 지연 시간이 너무 긴 이 문제를 해결하기 위해 본 논문에서는 여러 GPU에 걸쳐 병렬 처리를 활용하는 DistriFusion을 제안합니다.
- 제안된 방법은 모델 입력을 여러 패치로 나누고 각 패치를 GPU에 할당하지만, 이런 단순한 구현은 패치 간 상호작용을 손상시켜 화질을 저하시킴을 알 수 있습니다.
- 그러나 패치 간 상호작용을 포함시키면 방대한 통신 오버헤드가 발생합니다.
- 이 딜레마를 극복하기 위해, 저희는 인접한 확산 단계 간의 높은 유사성을 관찰하고 이전 타임스텝에서 미리 계산된 피처 맵을 재사용하여 현재 단계에 대한 컨텍스트를 제공하는 '변위 패치 병렬처리'를 제안합니다.
- 따라서, 저희 방법은 연산을 통해 파이프라인화될 수 있는 비동기 통신을 지원합니다.
- 광범위한 실험을 통해 저희의 방법이 최근의 Stable Diffusion XL에 품질 저하 없이 적용 가능하며, 하나의 NVIDIA A100에 비해 여덟 개를 사용하여 최대 6.1배의 속도 향상을 달성할 수 있음을 입증하였습니다.
- 저희 코드는 https://github.com/mit-han-lab/distrifuser 에서 공개적으로 이용 가능합니다.

### [Priority Sampling of Large Language Models for Compilers](https://arxiv.org/abs/2402.18734)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Pd3hUuaovnlxf5_8AXWge.png)

Vote: 5

Authors: Hugh Leather, Chris Cummins, Volker Seeker, Dejan Grubisic

- 대규모 언어 모델은 코드 생성 및 최적화 잠재력이 크지만, 기존의 샘플링 방법들은 다양성 증가를 위해 사용되지만 낮은 온도에서는 반복적인 예시를, 높은 온도에서는 일관성 없는 예시를 만들어내는 문제가 있다.
- 이에 따라, 온도 계수를 각 작업에 맞게 조정해야 하는 한계점이 있어 사용성이 제한적이다.
- 우리는 모델의 확신도에 따라 정렬된 유일한 예시를 생성하는 간단하고 결정론적인 샘플링 기술인 Priority Sampling을 제시한다.
- Priority Sampling은 향상된 검색 트리에서 확률이 가장 높은 미확장 토큰을 확장함으로써 새 예시를 생성한다.
- 또한, 정규 표현식에 기반한 생성을 지원하여 제어 가능하고 구조화된 탐색 과정을 제공한다.
- Priority Sampling은 Nucleus Sampling을 초과하는 성능을 보여주며, 어떠한 샘플 수에서도 성능을 향상시킨다.
- 본 연구에서 제시한 모델은 기존의 -Oz 최적화 수준을 2.87%에서 5%까지 향상시켰으며, 30개의 샘플만으로도 원래 모델의 훈련을 위한 라벨 생성에 사용된 자동 조율기보다 더 뛰어난 성과를 보였다.

