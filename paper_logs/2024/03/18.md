## Daily Papers (2024-03-18)

### [Uni-SMART: Universal Science Multimodal Analysis and Research Transformer](https://arxiv.org/abs/2403.10301)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.10301.png)

Vote: 40

Authors: Mingjun Xu, Guolin Ke, Lin Yao, Xiaochen Cai, Junhan Chang, Hongshuai Wang, Yaqi Li, Sihang Li, Zhifeng Gao, Changxin Wang, Jiankun Wang, Yuqi Yin, Linfeng Zhang, Hengxing Cai, Yongge Li, Mujie Lin, Shuwen Yang

- 과학 연구 및 응용 분야에서 많은 과학 문헌 분석이 필수적이지만, 과학 지식의 급격한 성장으로 인해 학술 기사의 양이 크게 증가하여 문헌 분석이 더 어려워지고 시간이 많이 소요됩니다.
- 대규모 언어 모델(Large Language Models, LLMs)은 텍스트 요약 능력이 강하여 과학 문헌 분석의 새로운 해결책으로 제시되었지만, 기존 LLM들은 과학 문헌에 포함된 분자 구조, 표, 그래프와 같은 다양한 멀티모달 요소들을 이해하고 분석하는 데 한계가 있습니다.
- 이러한 문제를 해결하기 위해, 멀티모달 과학 문헌을 깊이 있게 이해하고 분석하기 위해 설계된 새롭고 혁신적인 모델인 Uni-SMART(Universal Science Multimodal Analysis and Research Transformer)를 제안합니다.
- Uni-SMART는 여러 분야에 걸쳐 정량적 평가를 통해 기존 텍스트 중심의 LLM들보다 우수한 성능을 보여주었습니다.
- 또한, Uni-SMART의 실용적 적용 범위를 특허 침해 탐지 및 차트의 미묘한 분석을 포함하여 확장하였으며, 이것은 Uni-SMART의 적응성을 강조할 뿐만 아니라 과학 문헌과의 상호 작용 방식을 혁신할 잠재력을 보여줍니다.

### [VideoAgent: Long-form Video Understanding with Large Language Model as Agent](https://arxiv.org/abs/2403.10517)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.10517.png)

Vote: 21

Authors: Xiaohan Wang, Serena Yeung-Levy, Yuhui Zhang, Orr Zohar

- 긴 형식의 동영상 이해는 컴퓨터 비전 내에서 상당한 도전과제로, 긴 멀티모달 시퀀스를 이해할 수 있는 모델이 필요합니다.
- 인간의 인지 과정을 모방하여, 긴 시각 자료 처리 능력보다는 상호 작용적 추론 및 계획 능력을 강조하고 있습니다.
- 본 논문에서는 큰 언어 모델을 중심 에이전트로 활용하는 새로운 에이전트 기반 시스템, VideoAgent를 소개합니다.
- 이 시스템은 비전-언어 기반 모델을 사용하여 질문에 대답하기 위해 중요한 정보를 반복적으로 식별하고 수집합니다.
- VideoAgent는 EgoSchema와 NExT-QA 벤치마크에서 각각 54.1% 및 71.3%의 제로샷 정확도를 평균 8.4개 및 8.2개 프레임만 사용하여 달성했습니다.
- 이 결과는 현재 최신 방식보다 에이전트 기반 접근 방식의 우수한 효과와 효율성을 보여주며, 긴 형식 비디오 이해 분야를 발전시킬 잠재력을 강조합니다.

### [Recurrent Drafter for Fast Speculative Decoding in Large Language Models](https://arxiv.org/abs/2403.09919)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09919.png)

Vote: 13

Authors: Xuanyu Zhang, Yunfei Cheng, Aonan Zhang, Chong Wang, Yi Wang

- 본 논문에서는 대규모 언어 모델을 효율적으로 서비스하기 위해 추측적 디코딩(speculative decoding) 방법을 개선한 새로운 접근법을 제안합니다.
- 이 방법은 고전적인 두 모델 추측적 디코딩 접근법과 최근에 등장한 단일 모델 접근법인 메두사(Medusa)의 강점을 결합합니다.
- 메두사에서 영감을 받아 추측적 디코딩을 위한 단일 모델 전략을 채택하고 있으나, 복잡한 풀 트랜스포머 구조 없이 반복적 의존성을 가진 경량의 초안(draft) 헤드를 사용하는 것이 특징입니다.
- 이러한 반복적 의존성 덕분에, 초안 헤드를 사용하여 빔 탐색(beam search)으로 원치 않는 후보를 신속하게 필터링할 수 있습니다.
- 결과적으로, 단일 모델 디자인의 단순성과 메두사에서 추론을 위해 데이터 의존적 트리 주의 구조를 만드는 데 필요한 복잡성을 피할 수 있는 방법을 결합합니다.
- 저자는 여러 인기 있는 오픈소스 언어 모델에서 제안된 방법의 효과를 실증적으로 보여주며, 이 접근법을 채택함으로써 발생하는 상충되는 요소들에 대한 포괄적인 분석을 제공합니다.

### [RAFT: Adapting Language Model to Domain Specific RAG](https://arxiv.org/abs/2403.10131)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.10131.png)

Vote: 11

Authors: Naman Jain, Sheng Shen, Shishir G. Patil, Matei Zaharia, Tianjun Zhang, Joseph E. Gonzalez, Ion Stoica

- 대규모 텍스트 데이터 셋에서 사전 트레이닝된 대형 언어 모델(Large Language Models, LLMs)을 다운스트림 테스크에 사용할 때 새로운 지식(시급한 뉴스, 사적 도메인 지식 등)을 추가하는 것이 표준이 되었지만 모델이 새로운 지식을 획득하는 최적의 방법론은 아직 미해결 문제이다.
- 본 논문에서는 'in-domain' 설정에서 질문에 답하는 모델의 능력을 향상시키는 훈련 방법인 'Retrieval Augmented FineTuning (RAFT)'를 제시한다.
- RAFT는 질문과 검색된 문서 묶음이 주어졌을 때, 질문에 답하는 데 도움이 되지 않는 문서, 즉 관련 없는 문서를 모델이 무시하도록 훈련시킨다.
- 또한, RAFT는 관련 있는 문서에서 바로 답변에 도움이 될 수 있는 정확한 부분을 인용함으로써 모델이 추론 능력을 향상할 수 있도록 한다.
- 도메인 특화 RAG에서 RAFT는 PubMed, HotpotQA, Gorilla 데이터셋에서 모델의 성능을 일관되게 향상시켜, 사전 트레이닝된 LLMs을 개선하기 위한 포스트-트레이닝 방법을 제시한다.
- RAFT의 코드와 데모는 'github.com/ShishirPatil/gorilla'에서 오픈 소스로 제공된다.

### [Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations](https://arxiv.org/abs/2403.09704)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09704.png)

Vote: 10

Authors: Ndivhuwo Makondo, Djallel Bouneffouf, Orna Raz, Jesus Rios, Kush R. Varshney, Manish Nagireddy, Rosario A. Uceda-Sosa, Siphiwe Thwala, Ioana Baldini, Eitan Farchi, Swapnaja Achintalwar, Inkit Padhi, Pierre Dognin, Maria Chang, Aleksandra Mojsilovic, Joan Byamugisha, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Moninder Singh

- 대형 언어 모델의 정렬은 일반적으로 모델 공급자에 의해 사용 사례 및 맥락 전반에 공통적으로 이해되는 행동을 추가하거나 제어하기 위해 수행됩니다.
- 이 논문에서는 개발자가 모델을 자신의 특정 가치, 사회 규범, 법률 등의 규정에 맞게 조정하고, 맥락에서 잠재적으로 상충되는 요구 사항을 조정할 수 있는 접근 방식 및 아키텍처를 제시합니다.
- 'Alignment Studio' 아키텍처의 세 가지 주요 구성 요소인 Framers, Instructors 및 Auditors가 언어 모델의 행동을 제어하기 위해 협력하여 작동합니다.
- 우리는 회사의 내부 직원 대상 엔터프라이즈 챗봇을 비즈니스 행동 지침에 맞게 조정하는 예시를 통해 이 접근 방법을 설명합니다.

### [MusicHiFi: Fast High-Fidelity Stereo Vocoding](https://arxiv.org/abs/2403.10493)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.10493.png)

Vote: 8

Authors: Ge Zhu, Zhiyao Duan, Juan-Pablo Caceres, Nicholas J. Bryan

- 음악 생성 모델은 종종 오디오의 이미지 표현(예: 멜-스펙트로그램)을 구성한 후에 이를 오디오로 변환하지만, 기존 보코더는 일반적으로 저해상도(예: 16-24kHz)의 단일음표 오디오를 생성하여 효과가 제한되었습니다.
- 본 논문에서 제안하는 MusicHiFi는 고효율 고해상도 스테레오포닉 보코더로, 다단계의 생성적 적대 신경망(GANs)을 이용하여 저해상도 멜-스펙트로그램을 오디오로 변환, 대역폭 확장을 통해 고해상도로 업샘플링하고 스테레오 오디오로 업믹싱하는 과정을 포함합니다.
- 특히, 연속적인 GAN 기반의 생성기와 판별기 아키텍처 및 훈련 절차를 새롭게 제안하고, 빠르고 거의 다운샘플링과 호환되는 새로운 대역폭 확장 모듈과 다운믹스와 호환되는 새로운 고속 모노-투-스테레오 업믹서를 개발하여 단일음표 콘텐츠의 보존을 보장합니다.
- 목적 기반 및 주관적 청취 테스트를 통해 평가한 결과, 이 접근법은 기존의 연구들에 비해 비교 가능하거나 더 나은 오디오 품질과 더 나은 공간화 제어를 제공하며 특히 추론 속도를 크게 향상시킨 것으로 나타났습니다.
- 본 연구의 사운드 예시는 https://MusicHiFi.github.io/web/ 에서 확인할 수 있습니다.

### [Controllable Text-to-3D Generation via Surface-Aligned Gaussian Splatting](https://arxiv.org/abs/2403.09981)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09981.png)

Vote: 6

Authors: Lingzhe Zhao, Peidong Liu, Yiming Chen, Zhiqi Li

- 본 연구는 텍스트-투-3D 생성 작업에서 조절 가능한 생성을 위해 다루는 새로운 영역에 주목하고 있습니다.
- 새로운 신경망 구조인 Multi-view ControlNet (MVControl)을 소개하며, 이는 에지맵, 깊이맵, 정규맵 및 스크리블맵과 같은 추가적인 입력 조건들을 통합하여 기존 훈련된 멀티뷰 확산 모델을 향상시킵니다.
- MVControl은 입력 조건 이미지와 카메라 위치에서 계산된 지역적 및 전역적 임베딩을 사용하여 기본 확산 모델을 제어하는 컨디셔닝 모듈을 도입하는 것이 혁신입니다.
- 효율적인 다단계 3D 생성 파이프라인을 제안하며, 이는 최신 대규모 복원 모델과 점수 증류 알고리즘의 이점을 활용합니다.
- 3D 가우시안을 대표로 사용하여 일반적으로 사용되는 암시적 표현 대신 새로운 하이브리드 확산 유도 방법으로 최적화 과정을 직접 지도합니다.
- 가우시안을 메쉬 삼각형 표면에 묶는 SuGaR이라는 혁신적인 하이브리드 표현을 사용하여, 3D 가우시안의 부실한 기하학적 문제를 해결하고 메쉬 위의 세부적인 기하학을 직접 조각할 수 있게 합니다.
- 우리의 방법은 광범위한 실험을 통해 뛰어난 일반화 능력을 보여주며 조절 가능한 고품질 3D 콘텐츠의 생성을 가능하게 합니다.

### [Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding](https://arxiv.org/abs/2403.10395)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.10395.png)

Vote: 5

Authors: Hongxiang Xue, Pengkun Liu, Jiafang Li, Fuchun Sun, Yikai Wang, Hang Xiao, Xinzhou Wang

- 선행된 2D 확산 모델들의 증가하는 가용성에 힘입어, Score Distillation Sampling (SDS)을 이용한 이미지-3D 생성이 놀라운 발전을 이루고 있다.
- 기존의 방법들은 대부분 참조 이미지를 조건으로 활용하는 2D 확산 모델에서의 새로운 시점 생성(novel-view lifting)과 참조 시점에서의 엄격한 L2 이미지 감독을 결합하는데, 이는 종종 평평하거나 왜곡된 3D 생성을 초래한다.
- 본 연구에서는 새로운 관점에서 이미지-3D 생성 문제를 재검토하고, CLIP 임베딩만을 입력으로 하는 Isotropic3D라는 이미지-3D 생성 파이프라인을 제시한다.
- Isotropic3D는 SDS 손실에만 의존하여 방위각에 대해 동등한 최적화를 허용한다.
- 우리 프레임워크의 핵심은 두 단계의 확산 모델 파인튜닝에 있다: 첫째, 텍스트-3D 확산 모델을 이미지 인코더로 대체하여 이미지-이미지 능력을 preliminary하게 습득하도록 파인튜닝한다.
- 둘째, Explicit Multi-view Attention (EMA)을 사용하여 노이지한 다중 시점 이미지와 노이즈가 없는 참조 이미지를 명시적인 조건으로 결합하여 파인튜닝을 수행한다.
- 전체 과정에서 CLIP 임베딩이 확산 모델에 전송되는 반면, 참조 이미지는 파인튜닝 후 한 번 사용되고 폐기된다.
- 결과적으로, 단일 이미지 CLIP 임베딩으로 Isotropic3D는 상호 일관된 다중 시점 이미지와 더 대칭적이고 깔끔한 내용, 잘 조정된 기하학적 형태, 풍부한 컬러 텍스처, 기존 이미지-3D 방법들에 비해 왜곡이 적은 3D 모델을 생성할 수 있으며 아직 참조 이미지와의 유사성을 큰 폭으로 보존한다.
- 프로젝트 페이지와 코드 및 모델은 https://isotropic3d.github.io/ 및 https://github.com/pkunliu/Isotropic3D에서 확인할 수 있다.

### [FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model](https://arxiv.org/abs/2403.10242)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.10242.png)

Vote: 4

Authors: Qijun Feng, Yu-Gang Jiang, Zuxuan Wu, Zhen Xing

- 단일 시점의 이미지에서 상세한 3D 객체를 재구성하는 것은 제한된 정보 때문에 여전히 도전적인 과제입니다.
- 본 논문에서는 FDGaussian이라는 새로운 두 단계 프레임워크를 소개하며, 이는 단일 이미지를 통해 3D 재구성을 수행합니다.
- 최근 방법들은 사전 훈련된 2D 확산 모델을 활용하여 입력 이미지로부터 가능성 있는 새로운 시점의 이미지들을 생성하지만, 다중 시점의 일관성이 없거나 기하학적 정확성이 결여된 문제가 있었습니다.
- 이러한 문제를 극복하기 위해, 저자들은 2D 입력으로부터 3D 기하학적 특징을 추출하여 일관된 다중 시점 이미지를 생성하는 기하학 기반의 평면 분해 메커니즘을 제안합니다.
- 또한, 서로 다른 시점의 이미지들을 융합하기 위해 에피폴라 주의(epipolar attention)를 통합한 최신의 가우시안 스플래팅 기법을 가속화합니다.
- FDGaussian은 다양한 시점에 걸친 일관된 이미지를 생성하고, 질적으로나 양적으로 모두 고품질의 3D 객체를 재구성한다는 것을 보여줍니다.
- 더 많은 예시들은 웹사이트 (https://qjfeng.net/FDGaussian/)에서 볼 수 있습니다.

### [EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba](https://arxiv.org/abs/2403.09977)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.09977.png)

Vote: 4

Authors: Tao Huang, Xiaohuan Pei, Chang Xu

- 이 연구는 경량 모델 개발에서 지속되는 정확도 및 효율성의 상충 문제를 해결하기 위해 시각 상태 공간 모델(visual state space models)의 잠재력을 탐구한다.
- CNN은 지역적 특징 추출에 능숙하나 해상도 저하가 발생하며, Transformer는 전역적 범위를 제공하지만 O(N^2)의 계산 복잡성을 증가시킨다.
- 최근 상태 공간 모델(SSM), 예를 들어 Mamba는 언어 모델링 및 컴퓨터 비전과 같은 다양한 작업에서 뛰어난 성능을 보이며 전역 정보 추출의 시간 복잡도를 O(N)으로 줄였다.
- 본 논문은 아트로스 기반 선택적 스캔을 접목한 효율적인 경량 모델 버전인 EfficientVMamba를 제안하며, 이는 전역 및 지역 특징 추출을 모두 활용하도록 설계되었다.
- 또한, SSM 블록과 컨볼루션 간 통합을 연구하고, 추가 컨볼루션 분기와 결합된 효율적인 시각 상태 공간 블록을 도입하여 모델 성능을 한층 향상시켰다.
- 실험 결과, EfficientVMamba는 계산 복잡성을 낮추면서도 다양한 시각 작업에 걸쳐 경쟁력 있는 결과를 제공한다. 예를 들어, 1.3G FLOPs를 가진 EfficientVMamba-S는 1.5G FLOPs의 Vim-Ti를 5.6% 높은 정확도로 ImageNet에서의 성능을 개선하였다.
- 연구에 사용된 코드는 https://github.com/TerryPei/EfficientVMamba에서 확인할 수 있다.

### [NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices](https://arxiv.org/abs/2403.10425)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.10425.png)

Vote: 2

Authors: Huaizu Jiang, Hanumant Singh, Zhiyong Zhang

- 실시간 고정밀도 광학 흐름 추정은 로봇의 위치 결정 및 매핑, 컴퓨터 비전에서의 객체 추적 및 활동 인식 등 다양한 응용 분야에서 중요한 구성 요소입니다.
- 기존의 학습 기반 광학 흐름 방법들은 높은 정확도를 달성하지만, 종종 많은 계산 비용을 요구합니다.
- 본 논문은 높은 정확도와 계산 비용 문제를 동시에 해결하기 위해 'NeuFlow'라는 효율적인 광학 흐름 구조를 제안합니다.
- 이 구조는 크게 두 단계, 즉 전역 매칭을 통한 초기 광학 흐름 추정과 경량 CNN 계층을 활용한 정확도 향상으로 이루어집니다.
- Jetson Orin Nano와 RTX 2080 같은 컴퓨팅 플랫폼에서 효율성 향상을 입증하여, 여러 최신 방법에 비해 10배에서 80배의 속도 향상을 달성하며, 비슷한 정확도를 유지하고 있습니다.
- 에지 컴퓨팅 플랫폼에서 약 30 FPS를 달성함으로써, 드론과 같은 소형 로봇에서 복잡한 컴퓨터 비전 작업을 배포하는 데에 있어 중요한 돌파구를 제시합니다.
- 전체 학습 및 평가 코드는 https://github.com/neufieldrobotics/NeuFlow 에서 확인할 수 있습니다.

