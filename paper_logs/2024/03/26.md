## Daily Papers (2024-03-26)

### [LLM Agent Operating System](https://arxiv.org/abs/2403.16971)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.16971.png)

Vote: 27

Authors: Shuyuan Xu, Yingqiang Ge, Ruosong Ye, Yongfeng Zhang, Kai Mei, Zelong Li

- 대규모 언어 모델(LLM) 기반 지능형 에이전트의 통합 및 배치는 스케줄링 최적화 미비, 리소스 할당 문제, 에이전트 간 상호작용 시 컨텍스트 유지 어려움, 다양한 에이전트의 통합 복잡성 등의 도전적 과제에 직면해 있다.
- 에이전트 수와 복잡성의 급격한 증가는 리소스의 비효율적 사용과 병목 현상을 야기한다.
- 이러한 문제를 해결하기 위해 'AIOS(Agent Operating System)'라는 LLM 에이전트 운영체제를 제안하며, 이는 대규모 언어 모델을 운영 시스템(OS)에 내장시켜 최적화하고 있다.
- AIOS는 리소스 할당 최적화, 에이전트 간 컨텍스트 전환 용이성, 에이전트의 동시 실행 지원, 에이전트를 위한 도구 서비스 제공, 에이전트의 접근 제어 유지 등을 설계 목표로 한다.
- 운영체제의 구조, 해결하고자 하는 핵심 도전 과제, 기본적인 설계 및 구현에 대해 논의한다.
- 여러 에이전트의 동시 실행에 대한 실험을 통해 AIOS 모듈의 신뢰성과 효율성을 입증한다.
- 이 프로젝트는 LLM 에이전트의 성능 및 효율성 향상뿐만 아니라 미래 AIOS 생태계 개발 및 배치를 위한 선구적인 역할을 목표로 하며, 오픈 소스로 제공된다.

### [Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation](https://arxiv.org/abs/2403.16990)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.16990.png)

Vote: 15

Authors: Or Patashnik, Daniel Cohen-Or, Kfir Aberman, Omer Dahary

- 텍스트-이미지 확산 모델은 다양하고 고품질의 이미지를 생성하는 능력을 가지고 있지만, 여러 주체를 포함한 복잡한 입력 프롬프트의 의도된 의미를 충실하게 포착하는데 어려움을 겪는다.
- 최근 사용자 제어를 향상시키기 위해 소개된 레이아웃-이미지 확장 모델은 특정 토큰으로 표현된 주제들을 지역화하지만, 특히 유사한 의미나 시각을 가진 여러 주체들을 다룰 때 의미적으로 부정확한 이미지를 자주 생성한다.
- 본 연구에서는 이러한 한계의 원인을 분석하고 연구하였고, 발견된 주된 문제는 잡음 제거 과정 중 주체들 사이에서 의도치 않은 의미의 유출로 밝혀졌다.
- 이 유출은 확산 모델의 주의력(attention) 계층이 다른 주제들의 시각적 특징들을 혼합하는 경향 때문에 발생한다.
- 이러한 문제에 대처하기 위해, 훈련 없이 샘플링 과정에서 정보 흐름을 제한하는 'Bounded Attention'이라는 방법을 소개한다.
- Bounded Attention은 주체들 간의 유해한 유출을 방지하고, 복잡한 여러 주제들의 조건을 충족시키면서 각각의 개별성을 촉진시키는 생성을 유도한다.
- 광범위한 실험을 통해, 우리의 방법이 제공된 프롬프트와 레이아웃에 더 잘 부합하는 다수의 주체들을 생성하는 데 기여함을 입증한다.

### [FlashFace: Human Image Personalization with High-fidelity Identity Preservation](https://arxiv.org/abs/2403.17008)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.17008.png)

Vote: 15

Authors: Wei Wang, Lianghua Huang, Shilong Zhang, Zhi-Fan Wu, Xi Chen, Yujun Shen, Ping Luo, Yifei Zhang, Yu Liu, Yutong Feng

- 본 연구는 사용자가 참조용 얼굴 이미지와 텍스트 프롬프트를 제공함으로써 실시간으로 자신의 사진을 개인화할 수 있는 실용적인 도구인 FlashFace를 제시합니다.
- 기존의 인간 사진 커스터마이징 방법과는 달리, FlashFace는 더 높은 충실도의 신원 유지와 더 나은 지시사항 이행이 가능한 것이 특징입니다.
- 첫번째로, 얼굴 신원을 단일 이미지 토큰으로 인코딩하는 대신 여러 개의 특징 맵으로 인코딩하여 모델이 참조 얼굴의 세부사항(예: 흉터, 문신, 얼굴 형태 등)을 더 잘 유지하도록 합니다.
- 두번째로, 텍스트와 이미지 유도 사이의 균형을 맞추기 위해 텍스트 대 이미지 생성 과정에서 신원 참조와 텍스트 프롬프트 사이의 충돌을 완화하는 별개의 통합 전략을 도입합니다.
- 다양한 응용 프로그램에서 실시된 광범위한 실험 결과는 얼굴 이미지 개성화, 언어 프롬프트가 있는 얼굴 교환, 가상 캐릭터를 실제 인물로 만드는 등의 분야에서 본 방법의 효과를 입증합니다.
- 프로젝트 페이지는 다음 링크에서 확인할 수 있습니다: https://jshilong.github.io/flashface-page.

### [SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions](https://arxiv.org/abs/2403.16627)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.16627.png)

Vote: 11

Authors: Zehao Sun, Yuda Song, Xuanwu Yin

- 확산 모델의 발전으로 이미지 생성 측면에서 뛰어난 성능을 보이고 있으나, 복잡한 구조와 계산량으로 인해 반복적 샘플링 과정에서 발생하는 상당한 지연 시간이 단점으로 지적되었습니다.
- 이러한 한계를 극복하기 위해, 모델의 크기를 줄이고 샘플링 단계를 감소하는 이중 접근 방식을 통해 모델의 대기 시간을 대폭 줄였습니다.
- 지식 증류를 활용하여 U-Net과 이미지 디코더 구조를 간소화하고, 특징 매칭 및 점수 증류를 이용한 혁신적인 단일 단계 DM 훈련 기법을 도입했습니다.
- 단일 GPU에서 SDXS-512는 약 100 FPS의 추론 속도로 (SD v1.5 대비 30배 빠름), SDXS-1024는 약 30 FPS의 추론 속도로(SDXL 대비 60배 빠름) 높은 성능을 달성했습니다.
- 또한, 우리의 훈련 접근 방식은 이미지 조건화 제어 분야에 유망한 응용을 제공하며, 효율적인 이미지 간 변환을 가능하게 합니다.

### [Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression](https://arxiv.org/abs/2403.15447)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15447.png)

Vote: 10

Authors: Chulin Xie, Zhangheng Li, Dan Hendrycks, Jinhao Duan, Bo Li, Junyuan Hong, Brian Bartoldson, Ajay Jaiswal, James Diffenderfer, Kaidi Xu, Chenhui Zhang, Dawn Song, Bhavya Kailkhura, Kelsey Lieberman, Zhangyang Wang

- 본 연구는 자원 효율적 추론을 위해 고성능 대형 언어 모델(LLMs)을 압축하는 전략이 널리 사용되는 가운데, 압축이 안전성과 신뢰성에 미치는 잠재적 위험을 최초로 철저히 평가합니다.
- 세 개의 선도적인 LLM을 대상으로 다섯 가지 최신 압축 기술을 활용하여 신뢰성의 여덟 가지 차원에서 실험을 수행했으며, 압축과 신뢰성 사이의 복잡한 상호작용을 밝혀냈습니다.
- 양자화가 가지치기보다는 효율성과 신뢰성을 동시에 달성하는 데 효과적인 접근법인 것으로 나타났으며, 예를 들어 4비트 양자화 모델은 원본 모델의 신뢰성을 유지하는 반면, 모델 가지치기는 50% 희소성에서도 신뢰성을 크게 저하시켰습니다.
- 중간 비트 범위 내에서의 양자화는 윤리성 및 공정성과 같은 특정 신뢰성 차원을 개선할 수 있으나, 매우 낮은 비트 수준(3비트)으로 가는 극한의 양자화는 신뢰성을 상당히 감소시킵니다.
- 이러한 증가된 위험은 양호한 성능만을 바라보는 것으로는 발견할 수 없으며, 이는 실전에서 포괄적인 신뢰성 평가의 필요성을 요구합니다.
- 연구 결과는 대형 언어 모델에서 높은 유용성, 효율성, 신뢰성을 동시에 달성하기 위한 실용적인 권장 사항으로 정리되며, 모델과 코드는 https://decoding-comp-trust.github.io/ 에서 확인할 수 있습니다.

### [TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models](https://arxiv.org/abs/2403.17005)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.17005.png)

Vote: 8

Authors: Yang Cao, Fuchen Long, Ting Yao, Zhongwei Zhang, Zhaofan Qiu, Tao Mei, Yingwei Pan

- 텍스트-비디오 생성의 최근 발전은 강력한 디퓨전 모델의 유용성을 입증했습니다.
- 이미지를 비디오로 애니메이팅하는 이미지-비디오 생성은 주어진 이미지와의 정확한 일치를 보존하면서 인접 프레임 간의 시간적 연속성을 추구해야 하므로 쉽지 않은 문제입니다.
- 이 문제를 완화하기 위해, 본 논문은 정적 이미지에서 파생된 이미지 노이즈 사전 지식을 활용하여 프레임 간 상호 관계 추론을 공동으로 촉진하고 시간적 잔차 학습을 통해 일관된 시간 모델링을 용이하게 하는 새로운 이미지-비디오 디퓨전 패러다임인 TRIP을 제시합니다.
- 기술적으로, 이미지 노이즈 사전 지식은 정적 이미지와 소음이 있는 비디오 잠재 코드를 기반으로 한 단계 역 디퓨전 과정을 통해 얻어집니다.
- 그 다음, TRIP은 두 가지 경로를 사용하는 잔차 형식의 듀얼-패스 구조로 노이즈 예측을 수행합니다: 1) 이미지 노이즈 사전을 각 프레임의 참조 노이즈로 직접 사용하는 단축 경로; 2) 3D-UNet을 사용하여 잠재 코드 상호 간 관계 추론을 가능하게 하는 잔차 경로.
- 각 프레임의 참조 노이즈와 잔차 노이즈는 최종 비디오 생성을 위해 주의 메커니즘을 통해 동적으로 합쳐집니다.
- WebVid-10M, DTDB 및 MSR-VTT 데이터셋에서의 광범위한 실험을 통해 우리의 TRIP이 이미지-비디오 생성에 효과적임을 입증합니다.
- 프로젝트 페이지 https://trip-i2v.github.io/TRIP/에서 더 자세한 정보를 확인할 수 있습니다.

### [RakutenAI-7B: Extending Large Language Models for Japanese](https://arxiv.org/abs/2403.15484)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15484.png)

Vote: 7

Authors: Ewa Szymanska, Connie Huang, Maksim Tkachenko, Aaron Levine, Justin Chiu, Karan Chopra, Maki Kubota, Keiji Shinzato, +, Miroku Lee, Rakuten Group, Lei Chen, Naoki Takahashi, Jean-François Pessiot, Hou Wei Chou, Lee Xiong, Hongyi Ding, Eduardo Batista, Johanes Effendi, Kai Torben Ohlhus, Prathyusha Jwalapuram, Chenguang Wang, Koji Murakami

- RakutenAI-7B는 일본어 대상의 대규모 언어 모델로, 일본어 LM Harness 벤치마크에서 오픈 7B 모델들 중 가장 뛰어난 성능을 달성하였습니다.
- 이 모델들은 기본 모델뿐만 아니라 지시(instruction) 조정 모델과 대화(chat) 조정 모델인 RakutenAI-7B-instruct와 RakutenAI-7B-chat을 포함합니다.
- RakutenAI-7B는 모든 모델들을 Apache 2.0 라이선스 하에 공개하여 사용이 가능하도록 제공합니다.

### [VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation](https://arxiv.org/abs/2403.17001)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.17001.png)

Vote: 6

Authors: Ting Yao, Yang Chen, Haibo Yang, Tao Mei, Yingwei Pan

- 최근 텍스트-3D 생성 분야의 혁신적인 기법 중 하나인 Score Distillation Sampling(SDS)은 2D 확산 모델에서 사전 지식을 직접 추출하여 암시적 3D 모델(NeRF)의 제로샷 학습을 가능하게 합니다.
- 현존하는 SDS 기반 모델은 복잡한 텍스트 프롬프트를 처리하기 어려워 종종 비현실적인 질감이나 뷰 간 일관성 문제를 가진 왜곡된 3D 모델을 생성합니다.
- 본 연구에서는 2D 시각적 프롬프트의 시각적 외모 지식을 명시적으로 활용하여 텍스트-3D 생성을 강화하는 새로운 시각 프롬프트 가이드 텍스트-3D 확산 모델(VP3D)을 소개합니다.
- VP3D는 텍스트 프롬프트를 통해서만 SDS를 지도하는 것이 아니라, 먼저 2D 확산 모델을 이용하여 입력 텍스트로부터 고품질 이미지를 생성하고, 이를 시각적 프롬프트로 활용하여 SDS 최적화를 시각적 외모에 대한 명시적 정보로 강화합니다.
- 또한, SDS 최적화를 시각적 프롬프트와 시각적 및 의미적으로 더 잘 일치하게 하는 3D 모델의 이미지 렌더링을 장려하는 추가적인 차별화된 보상 함수와 결합합니다.
- 광범위한 실험을 통해 우리의 VP3D 내의 2D 시각적 프롬프트가 3D 모델의 시각적 외형 학습을 크게 용이하게 하며, 이로 인해 더 세부적인 질감으로 높은 시각적 충실도를 달성함을 보여줍니다.
- 주어진 참조 이미지로 자가 생성된 시각적 프롬프트를 대체할 경우, VP3D는 스타일화된 텍스트-3D 생성이라는 새로운 작업을 유발할 수 있는 매력적인 점도 보여줍니다.
- 해당 프로젝트 페이지는 https://vp3d-cvpr24.github.io에서 확인할 수 있습니다.

