## Daily Papers (2024-06-27)

### [Adam-mini: Use Fewer Learning Rates To Gain More](https://arxiv.org/abs/2406.16793)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16793.png)

Vote: 22

Authors: Yinyu Ye, Yushun Zhang, Congliang Chen, Ziniu Li, Zhi-Quan Luo, Chenwei Wu, Ruoyu Sun, Tian Ding

- **What's New**: 새로운 옵티마이저 'Adam-mini'가 소개되었습니다. 이 옵티마이저는 LLMs(Large Language Models)를 훈련할 때 사용되는 메모리를 획기적으로 절감하는 것을 목표로 합니다. Adam-mini는 고전적인 Adam 옵티마이저의 v(모멘텀) 메커니즘을 간소화하여, 대규모 언어 모델에서도 비슷하거나 더 나은 성능을 유지하면서 메모리 사용량을 줄입니다.
- **Technical Details**: Adam-mini는 모델 파라미터를 헤시안(Hessian)의 블록 구조에 기반해 구분합니다. 이는 각 블록에 대해 평균화된 단일 학습률(learning rate)을 사용하는 방식입니다. 특히 Transformers의 헤시안 구조가 블록 대각선 구조를 가진다는 점을 활용하여, 각 블록마다 하나의 학습률만으로도 효과적인 학습이 가능하도록 설계되었습니다. 이렇게 하면 아담(Adam)의 다중 학습률 설정보다 메모리를 절감하면서도 비슷한 성능을 유지할 수 있습니다.
- **Performance Highlights**: Adam-mini는 90% 이상 Adam의 v를 감소시켜 전체 메모리 사용량을 45%에서 50%까지 절감할 수 있습니다. 또한, 다양한 언어 모델(125M에서 7B 규모)에서 AdamW와 동등하거나 더 나은 성능을 보여주었으며, 비언어 모델 작업들(예: training diffusion 모델, 비전 모델, 그래프 신경망)에서도 더 나은 성능을 기록했습니다. Adam-mini는 Llama2-7B의 사전 학습 시 AdamW 대비 49.6% 더 높은 처리량을 기록하며, 33.1%의 시간을 절약할 수 있었습니다.

### [CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs](https://arxiv.org/abs/2406.18521)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.18521.png)

Vote: 9

Authors: Richard Zhu, Xindi Wu, Mengzhou Xia, Haotian Liu, Zirui Wang, Kaiqu Liang, Sanjeev Arora, Luxi He, Sadhika Malladi, Danqi Chen, Howard Chen, Alexis Chevalier, Yitao Liu

- **What's New**: 최근 arXiv에 업로드된 논문은 새로운 딥러닝 아키텍처에 대한 내용을 다루고 있습니다. 이 논문은 기존 모델과의 비교를 통해 새로운 기술의 우수성을 강조하고 있습니다.
- **Technical Details**: 이 논문에서는 Transformer 모델을 기반으로 한 새로운 아키텍처를 도입했습니다. 특히 Self-Attention 메커니즘을 개선하여 더 효율적인 학습을 가능하게 했습니다. 또한, 데이터 전처리 과정에서 새로운 노이즈 제거 알고리즘이 사용되었습니다.
- **Performance Highlights**: 새롭게 제안된 모델은 여러 벤치마크 테스트에서 기존 최첨단 모델 대비 10% 이상의 성능 향상을 보였습니다. 특히 자연어 처리(NLP)와 이미지 인식 분야에서 탁월한 이점을 보여줍니다.

### [Octo-planner: On-device Language Model for Planner-Action Agents](https://arxiv.org/abs/2406.18082)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.18082.png)

Vote: 9

Authors: Wei Chen, Yikang Shen, Zhiyuan Li, Zhen Guo

- **What's New**: 최신 논문에서 소개된 Octo-planner는 엣지 디바이스에서 사용할 수 있는 계획 수립 에이전트로, 효율성, 적응력 및 자원 제약 문제를 해결합니다.
- **Technical Details**: Octo-planner는 Planner-Action 프레임워크를 사용하여 계획 수립과 실행을 두 개의 컴포넌트로 분리합니다. 이 기법은 특히 엣지 디바이스에 최적화되었으며, 프라이빗 모델인 Octopus를 통해 함수 호출을 수행합니다. 프레임워크는 GPT-4를 사용하여 계획 데이터를 생성하고 검증한 후, Phi-3 Mini로 최적화된 모델을 온디바이스에서 배포합니다. 모델의 효율성을 높이기 위해 Multi-LoRA 트레이닝 기법을 사용하여 여러 도메인에서의 복잡한 쿼리를 처리합니다.
- **Performance Highlights**: 온디바이스에서 벌크 기능을 수행할 수 있도록 설계된 Octopus V2 모델은 함수 호출 정확도 95%를 넘어섰고, 내부 테스트에서 플래닝 성공률 97%를 달성했습니다. 이는 사전에 정의된 기능에 대해 고도로 최적화된 성능을 보이며, 실제 응용 프로그램에서 AI 에이전트가 더욱 실용적이고 접근 가능하게 만듭니다.

### [EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records](https://arxiv.org/abs/2406.16341)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16341.png)

Vote: 6

Authors: Yeonsu Kwon, Gyubok Lee, Daeun Kyung, Tom Pollard, Jiho Kim, Edward Choi, Wonchul Cha, Alistair Johnson, Seongsu Bae

- **What's New**: 이번 연구는 새로운 태스크와 데이터셋인 EHRCon을 소개합니다. EHRCon은 임상 노트와 대규모 관계형 데이터베이스의 일관성을 검증하기 위해 고안되었습니다.
- **Technical Details**: EHRCon 태스크는 MIMIC-III 데이터셋을 사용하며, 관찰문진레지스터사업(OMOP) 공통 데이터 모델(CDM) 형태로도 제공됩니다. 또한, CheckEHR이라는 프레임워크를 도입하여 대형 언어 모델(LLM)의 추론 능력을 활용하여 일관성을 검증합니다. CheckEHR은 총 8단계로 구성되어 있으며, few-shot 및 zero-shot 설정에서 복잡한 태스크를 처리할 수 있습니다.
- **Performance Highlights**: few-shot 설정에서 CheckEHR은 MIMIC-III에서 61.06%, OMOP에서 54.36%의 리콜 성능을 보였으며, zero-shot 설정에서는 MIMIC-III에서 52.39%의 리콜 성능을 기록했습니다.

### [Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models](https://arxiv.org/abs/2406.17294)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17294.png)

Vote: 3

Authors: Roy Ka-Wei Lee, See-Kiong Ng, Yang Yang, Zhiqiang Hu, Lidong Bing, Junhua Liu, Wenhao Shi, Yi Bin

- **What's New**: 이번 연구는 새로운 다중모드 수학적 추론 데이터셋인 MathV360K를 제안하며, 이는 40K 개의 이미지와 360K 개의 질문-답변 쌍을 포함합니다. 이는 다양한 수학적 개념과 문제 유형을 포함하며, 기존 데이터셋보다 훨씬 더 폭넓고 깊이 있는 수학적 추론을 가능케 합니다.
- **Technical Details**: MathV360K 데이터셋은 24개의 공개 데이터셋에서 40K 고품질 이미지와 해당 질문-답변 쌍을 선택하여 구성되었으며, 여기에 기반하여 320K개의 추가 질문-답변 쌍을 합성했습니다. 데이터 선택 기준은 이미지의 명확성과 이해 복잡도이며, 다양한 수학적 개념을 포괄합니다. 이를 위해 LLaVA-1.5 모델을 기반으로 한 Math-LLaVA 및 Math-LLaVA-DS 모델이 개발되었습니다.
- **Performance Highlights**: 새로 생성된 Math-LLaVA 모델은 MathVista 벤치마크에서 LLaVA-1.5를 19% 초과하는 성능을 보여주었으며, MMMU 벤치마크에서도 향상된 일반화 성능을 입증했습니다. Math-LLaVA-DS 모델은 MathVista 벤치마크에서 10.6%의 성능 향상을 기록했습니다.

### [MatchTime: Towards Automatic Soccer Game Commentary Generation](https://arxiv.org/abs/2406.18530)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.18530.png)

Vote: 3

Authors: Jiayuan Rao, Haoning Wu, Chang Liu, Yanfeng Wang, Weidi Xie

- **What's New**: 이 논문은 축구 경기의 자동 해설 시스템 개발에 관한 연구를 다루고 있습니다. 특히 최근 시각-언어 모델의 발전을 바탕으로, 해설 데이터의 정렬 문제를 해결하여 더 나은 품질의 자동 해설을 생성하는 시스템을 제안합니다.
- **Technical Details**: 기존의 해설 데이터셋은 텍스트 해설과 비디오 클립 간의 불일치 문제가 자주 발생합니다. 이를 해결하기 위해 작성자는 수동으로 49개의 축구 경기 해설의 타임스탬프를 수정하여 새로운 벤치마크인 SN-Caption-test-align을 만들었습니다. 그런 다음 WhisperX를 사용하여 배경 오디오에서 내레이션 텍스트와 타임스탬프를 추출하고, LLaMA-3를 통해 이벤트 설명으로 요약합니다. 이러한 정보를 바탕으로 비디오와 해설을 더욱 정확하게 정렬하는 다단계 파이프라인을 제안합니다.
- **Performance Highlights**: 제안된 방법론을 통해 축구 경기 해설 데이터셋의 품질을 향상시켰으며, MatchVoice로 명명된 새로운 모델은 자동 축구 경기 해설 생성에서 최첨단의 성능을 보여주었습니다. 실험 결과, 정렬된 데이터셋을 사용하여 모델의 정밀도와 문맥적 관련성이 크게 개선되었습니다.

### [A Closer Look into Mixture-of-Experts in Large Language Models](https://arxiv.org/abs/2406.18219)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.18219.png)

Vote: 3

Authors: Ka Man Lo, Jie Fu, Zeyu Huang, Zihan Qiu, Zili Wang

- **What's New**: 최근 자연어 처리(NLP) 분야에서 큰 진전을 이루고 있는 대형 언어 모델(LLMs)의 개발입니다. Mixture-of-Experts(MoE) 아키텍처는 모델의 계산 효율성을 높이기 위해 도입된 새로운 접근 방식으로, 모델 스케일을 크게 늘리면서도 훈련 비용을 줄일 수 있는 혁신적인 솔루션입니다.
- **Technical Details**: MoE 모델은 원래의 피드 포워드 네트워크(FFNs)를 N개의 병렬 FFNs로 대체하고, 이를 라우터(router)에 연결하여 작동합니다. 이 방식은 입력을 여러 전문가(experts)에 할당함으로써 계산 효율성을 높이며, 이를 통해 더 유연하고 일반화 가능한 데이터 처리 및 작업이 가능해집니다. 라우터는 주로 간단한 선형 층과 소프트맥스(softmax) 및 Top-k 함수로 구성됩니다.
- **Performance Highlights**: 본 논문에서는 Mixtral 8x7B, DeepSeekMoE, Grok-1 모델을 연구하여 MoE 기반 모델들의 내부 메커니즘을 분석했습니다. 주요 관찰 결과로는 FFN 층의 뉴런이 미세한 전문가 역할을 하며, 게이트 임베딩과 게이트 프로젝션이 입력 텍스트에 따라 전문가들을 선택한다는 점입니다. 또한, 모델의 깊이 층이 증가할수록 전문가들 간의 유사성이 감소하지만, 마지막 층에서 다시 유사성이 증가하는 현상을 발견했습니다. 이를 통해 초기에 특정한 초기화 계획보다 훈련을 통해 전문가 다양성을 유지하는 것이 유리하다는 결론을 얻었습니다.

### [WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs](https://arxiv.org/abs/2406.18495)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.18495.png)

Vote: 3

Authors: Nathan Lambert, Bill Yuchen Lin, Nouha Dziri, Allyson Ettinger, Yejin Choi, Seungju Han, Kavel Rao, Liwei Jiang

- **What's New**: 새로운 연구에서 사용자와 언어 모델(LLM) 간의 상호작용 안전성을 평가하는 다목적 모더레이션 도구인 'WildGuard'가 소개되었습니다. 이 도구는 프롬프트의 유해성, 응답의 유해성 및 응답 거부 여부를 탐지하는 세 가지 주요 모더레이션 작업에 대한 종합적인 리소스를 제공합니다. WildGuard는 고비용의 API 모더레이션 도구에 비해 일관되고 경제적인 대안을 제공하며, 오픈 소스 기반 안전성 모더레이션 도구의 최첨단을 이끌고 있습니다.
- **Technical Details**: WildGuard는 92,000개의 레이블이 지정된 예시를 포함한 다양한 데이터셋으로 구성된 'WildGuardMix' 데이터셋을 통해 학습되었습니다. 이 데이터셋은 13개의 위험 범주를 포괄하며, 프롬프트 유해성과 거부/충족 여부를 균형 있게 다루고 있습니다. 또한 WildGuardTrain이라는 학습용 데이터셋(87,000개 예제)과 WildGuardTest라는 평가용 데이터셋(5,299개 인간 주석 항목)을 포함하고 있습니다. 이 데이터셋은 네 개의 주요 출처로부터 데이터를 추출하여 최대한의 커버리지를 보장하며, 다양한 유형의 거부와 충족 상황을 고려해 구성되었습니다.
- **Performance Highlights**: WildGuard는 기존의 오픈 소스 모더레이션 도구(Llama-Guard2, Aegis-Guard 등)를 능가하는 F1 점수를 기록했으며, 이는 최대 26.4%의 거부 탐지 개선을 포함합니다. 또한 GPT-4와 동등하거나 더 나은 성능을 보였는데, 특히 적대적 프롬프트 유해성 평가에서 최대 3.9%까지 우세한 성능을 나타냈습니다. WildGuard는 인간과 LLM 간의 상호작용에서도 성공률을 79.8%에서 2.4%로 감소시키면서도 안전한 요청에 과도하게 거부하지 않는 능력을 보였습니다.

### [Understanding and Diagnosing Deep Reinforcement Learning](https://arxiv.org/abs/2406.16979)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16979.png)

Vote: 2

Authors: Ezgi Korkmaz

- **What's New**: 이 논문은 심층 강화 학습(deep reinforcement learning) 정책이 학습한 표현 및 정책의 취약성을 이해하는 방법을 제안합니다. 표본의 룸 특정 방향에서의 공간 및 시간 상관성을 분석하는 체계적인 접근 방식을 바탕으로 하고 있으며, 다양한 시나리오에서 정책의 불안정성과 민감성을 자동으로 식별할 수 있는 진단 기법 개발의 필요성을 강조합니다.
- **Technical Details**: 논문에서는 마코프 결정 프로세스(Markov Decision Process, MDP)를 이용하여 강화 학습 에이전트가 현재 상태에서 다음 상태로 전이하는 과정 및 이를 통해 최적의 상태-행동 가치 함수(state-action value function)를 학습하는 방법을 설명합니다. 학습된 심층 강화 학습 정책에서 비강인(non-robust) 특징에 대한 체계적인 분석을 실시합니다.
- **Performance Highlights**: Arcade Learning 환경에서 고차원 상태 표현을 가진 신경망 정책을 훈련시키고, 최첨단 적대적 공격(Adversarial Attack) 기법들을 분석한 결과, 정책이 학습한 비강인 특징에 대한 정밀한 분석이 이루어졌습니다. 또한 분포 변동(distributional shift)이 심층 강화 학습 정책에 미치는 영향을 조사하여, 최첨단 인증 적대적 훈련 방법이 불연관되고 더 날카로운 취약한 표현을 학습하게 되는 것을 확인하였습니다.

### [MemServe: Context Caching for Disaggregated LLM Serving with Elastic Memory Pool](https://arxiv.org/abs/2406.17565)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17565.png)

Vote: 2

Authors: Jiang Xu, Junhao Hu, Yungang Bao, Cunchen Hu, Sa Wang, Xusheng Chen, Ninghui Sun, Yizhou Shan, Tao Xie, Heyang Huang, Chenxi Wang

- **What's New**: 이번 논문에서는 MemServe라는 새로운 시스템을 제안했습니다. MemServe는 대형 언어 모델(Large Language Models, LLMs) 서비스를 대규모로 최적화할 수 있도록 설계된 시스템입니다. 특히, 요청 간 및 요청 내 최적화(inter-request & intra-request optimizations)에 초점을 맞추고 있습니다. 이를 통해 분산된 인스턴스 간의 KV 캐시(Key-Value Cache)를 효율적으로 관리할 수 있는 능력을 갖추고 있습니다.
- **Technical Details**: MemServe는 세 가지 주요 구성 요소로 구성됩니다: 글로벌 스케줄러(Global Scheduler), 여러 유형의 추론 인스턴스(Inference Instances), 그리고 탄력적 메모리 풀(Elastic Memory Pool, MemPool)입니다. MemPool은 모든 클러스터 메모리(CPU DRAM 및 GPU HBM 포함)를 관리하기 위한 서브스트레이트로, 다양한 API를 제공합니다. MemServe는 글로벌 프로프트 트리(Global Prompt Trees)를 사용하는 지역 인식 정책(Locality-aware Policy)을 통해 베스트 에포트 라우팅을 구현합니다.
- **Performance Highlights**: MemServe는 다양한 설정에서 테스트를 수행하여 눈에 띄는 성능 향상을 보였습니다. 예를 들어, ShareGPT 워크로드 실행 시, MemServe의 분산된 추론(disaggregated inference) 방식은 전통적인 방식에 비해 최대 42%까지 JCT(Job Completion Time)를 개선했으며, 여기에 컨텍스트 캐싱을 추가하면 29% 더 향상됩니다. LooGLE 데이터셋에서는, 확장된 프롬프트와 짧은 생성 길이로 인해, 분산된 추론이 최대 10.8%, 추가적인 컨텍스트 캐싱이 최대 26.9%의 성능 향상을 이루었습니다.

### [Symbolic Learning Enables Self-Evolving Agents](https://arxiv.org/abs/2406.18532)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.18532.png)

Vote: 1

Authors: Long Li, Xiaohua Xu, Jialong Wu, Yixin Ou, Shengwei Ding, Tiannan Wang, Jiamin Chen, Ningyu Zhang, Wangchunshu Zhou, Huajun Chen, Shuai Wang, Yuchen Eleanor Jiang

- **What's New**: 본 논문은 언어 에이전트(Language Agent)의 자동 최적화 및 데이터 중심 학습(data-centric learning)을 위한 새로운 프레임워크를 제안합니다. 기존의 에이전트 개발은 엔지니어링 중심(engineering-centric)으로 복잡한 작업을 수동으로 세분화하고, 각각의 노드(node)에 맞춘 프롬프트(prompt)와 도구(tool)를 설계하는 과정이 필요했습니다. 본 연구는 이러한 한계를 극복하기 위해 에이전트 전체를 통합적으로 최적화하는 'Agent Symbolic Learning Framework'를 도입했습니다.
- **Technical Details**: 제안된 프레임워크는 뉴럴 네트워크(neural network)의 학습 절차(connectionist learning procedure)를 에이전트 학습에 적용한 것입니다. 에이전트의 파이프라인(pipeline)은 뉴럴 네트워크의 계산 그래프(computational graph)에 비유될 수 있으며, 각 노드는 레이어(layer)에 해당합니다. 이에 따라 우리는 언어 기반 손실(language-based loss), 그래디언트(language gradients), 가중치(weight) 업데이트를 활용한 역전파(backward propagation)를 구현했습니다. 학습 과정은 'forward pass(에이전트 실행)'로 시작하여 입력, 출력, 프롬프트 및 도구 사용 내용을 각 노드에 저장하고, 프롬프트 기반 손실 함수로 결과를 평가합니다. 이후 손실 값을 역전파하여 텍스트 분석과 반영을 통해 노드 내 상징적 요소를 업데이트합니다.
- **Performance Highlights**: 본 연구는 표준 LLM 벤치마크 및 복잡한 에이전트 과제에서 실험을 진행하였으며, 제안된 프레임워크가 프롬프트 및 도구를 최적화하고 전체 에이전트 파이프라인을 학습 데이터로부터 갱신하는 데 효과적임을 입증했습니다. 모든 코드와 프롬프트가 오픈 소스로 제공되어 향후 데이터 중심의 에이전트 학습에 대한 연구를 촉진할 것입니다.

### [ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of Text-to-Time-lapse Video Generation](https://arxiv.org/abs/2406.18522)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.18522.png)

Vote: 1

Authors: Xinhua Cheng, Li Yuan, Ruijie Zhu, Jinfa Huang, Yaoyang Liu, Yujun Shi, Yongqi Xu, Shenghai Yuan, Shaofeng Zhang, Jiebo Luo

- **What's New**: 최근 텍스트-비디오 (T2V) 생성 모델이 빠르게 발전하고 있으며, 이를 평가하기 위한 방법의 필요성이 제기되고 있습니다. 이에 따라 ChronoMagic-Bench라는 새로운 벤치마크를 도입하여, T2V 모델의 시간 경과 비디오(Time-lapse video) 생성 능력을 평가합니다. 또한, MTScore와 CHScore라는 자동 평가 지표를 개발하여 변형 진폭(metamorphic amplitude)과 시간적 일관성(temporal coherence)을 측정합니다.
- **Technical Details**: ChronoMagic-Bench는 생물학적, 인간이 만든, 기상, 물리적 비디오의 네 가지 주요 카테고리와 75개의 하위 카테고리를 포함하며, 총 1,649개의 프롬프트와 이에 해당하는 시간 경과 비디오를 갖추고 있습니다. 이를 통해 기존 벤치마크와 달리 높은 지속성(persistence)과 변형이 풍부한 비디오 생성을 강조합니다. 또한, ChronoMagic-Pro라는 새로운 대규모 T2V 데이터셋을 제공하여 커뮤니티가 시간 경과 비디오 생성을 연구할 수 있도록 돕습니다.
- **Performance Highlights**: ChronoMagic-Bench를 통해 거의 모든 공개 소스 T2V 모델을 평가한 결과, 대부분의 모델이 넓은 변화를 가지는 시간 경과 비디오를 생성하는 데 실패했으며, 프롬프트에 충실하지 못하고 일관된 결과를 위해 여러 번의 추론이 필요하며, 시간적 일관성이 부족한 점을 발견했습니다.

