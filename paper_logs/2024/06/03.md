## Daily Papers (2024-06-03)

### [Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality](https://arxiv.org/abs/2405.21060)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.21060.png)

Vote: 38

Authors: Albert Gu, Tri Dao

- 언어 모델링 분야에서 주로 사용되는 트랜스포머 아키텍처와 최근 소규모에서 중규모 범위에서 트랜스포머의 성능을 능가하는 것으로 나타난 상태 공간 모델(SSM), 예를 들어 Mamba의 이론적 연계성을 밝히는 연구입니다.
- 이 논문은 SSM과 트랜스포머 변형 간의 다양하고 깊은 이론적 관계를 탐구하며, 이들 관계는 구조화된 준분리행렬로 알려져 있는 행렬의 다양한 분해를 통해 연결됩니다.
- 또한, 상태 공간 이중성(State Space Duality, SSD) 프레임워크를 도입하여 Mamba의 선택적 SSM을 개선한 새로운 아키텍처 Mamba-2를 설계, 이는 언어 모델링에서 트랜스포머와 경쟁력을 유지하면서 2-8배 빠른 처리 속도를 제공합니다.

### [Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis](https://arxiv.org/abs/2405.21075)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.21075.png)

Vote: 11

Authors: Mengdan Zhang, Renrui Zhang, Zihan Wang, Xing Sun, Sirui Zhao, Chenyu Zhou, Tong Xu, Shuhuai Ren, Yanwei Li, Yondong Luo, Yuhan Dai, Yunhang Shen, Peixian Chen, Enhong Chen, Xiawu Zheng, Rongrong Ji, Shaohui Lin, Chaoyou Fu, Ke Li, Lei Li

- 인공 일반 지능에 대한 추구에서 다중 모달 대규모 언어 모델(MLLMs)이 최근 진전의 중심점으로 부상하였다.
- 진전은 주로 정적 이미지 이해 능력 개발에 초점을 맞추고 있으며, 연속적인 시각 자료를 처리하는 MLLMs의 잠재력은 아직 충분히 탐구되지 않았다.
- 본 논문에서는 비디오 분석에서 MLLMs를 평가하는 최초의 전 범위, 다중 모달 평가 벤치마크인 Video-MME를 소개한다.
- 이 평가는 1) 다양한 비디오 유형, 2) 시간적 차원의 지속성, 3) 다중 데이터 모달리티의 폭, 4) 주석의 품질 등 네 가지 주요 특징을 통해 기존 벤치마크와 구별된다.
- 총 256시간의 900개 비디오가 전문 평가자에 의해 수동으로 선택되고 주석이 붙여져, 2,700개의 질문-답변 쌍이 생성되었다.
- GPT-4 시리즈와 Gemini 1.5 Pro 같은 최신 MLLMs, 그리고 InternVL-Chat-V1.5와 LLaVA-NeXT-Video 같은 오픈소스 이미지 및 비디오 모델을 평가하였다.
- 실험 결과, Gemini 1.5 Pro가 가장 우수한 성능을 보여 오픈소스 모델들을 현저하게 능가했다.
- 이 데이터셋과 연구 결과는 더 긴 시퀀스와 다중 모달 데이터를 처리하는 데 있어서의 개선이 필요함을 강조한다.

### [Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models](https://arxiv.org/abs/2405.20541)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.20541.png)

Vote: 8

Authors: Max Marion, Kartik Sreenivasan, Zachary Ankner, Matthew L. Leavitt, Cody Blakeney, Mansheej Paul

- 이 연구에서는 소규모 언어 모델이 대규모 텍스트 데이터셋의 고품질 부분 집합을 결정하여 큰 언어 모델의 성능을 향상시킬 수 있는지를 조사합니다.
- 다양한 데이터셋 구성에서 사전 훈련 데이터의 난해도 기반 절삭이 하류 작업 성능을 상당히 향상시킬 수 있음을 시연합니다.
- 1억 2천 5백만 파라미터 모델로 계산된 난해도를 기반으로 데이터를 절삭하면, 30억 파라미터 모델의 하류 작업 평균 성능이 최대 2.04까지 향상되고, 동일한 기준 성능에 도달하기 위한 사전 훈련 단계가 최대 1.45배 줄어듭니다.
- 또한, 난해도 기반 데이터 절삭은 과다 훈련 및 데이터 제한 상태에서의 하류 성능 향상을 가져옵니다.

### [Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling](https://arxiv.org/abs/2405.21048)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.21048.png)

Vote: 8

Authors: Ying Shen, Navdeep Jaitly, Joshua M. Susskind, Jiatao Gu, Yizhe Zhang, Shuangfei Zhai

- 확산 모델은 텍스트 설명으로부터 고품질 이미지를 생성하는 강력한 도구로 부상하였으나, 높은 분류자 유도 가중치를 사용할 때 이미지 샘플의 다양성이 제한됩니다.
- 이러한 문제를 해결하기 위해, Kaleido는 원래 캡션을 인코딩하고 이미지 생성 과정을 지도하고 촉진하는 추상적이고 중간적인 표현을 생성하는 자기회귀 언어 모델을 통합하는 새로운 접근 방식을 제시합니다.
- 이 방법에서는 텍스트 설명, 탐지 경계 상자, 객체 블롭 및 시각적 토큰을 포함한 다양한 이산 잠재 표현을 탐구함으로써 입력 조건을 다양화하고 풍부하게 합니다.
- 실험 결과, Kaleido는 주어진 텍스트 설명에서 생성된 이미지 샘플의 다양성을 효과적으로 확장하는 동시에 높은 이미지 품질을 유지한다는 것을 보여줍니다.
- 또한 Kaleido는 생성된 잠재 변수에 의해 제공된 지침을 밀접하게 따름으로써 이미지 생성 과정을 효과적으로 제어하고 지시할 수 있는 능력을 입증합니다.

### [4Diffusion: Multi-view Video Diffusion Model for 4D Generation](https://arxiv.org/abs/2405.20674)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.20674.png)

Vote: 7

Authors: Xihui Liu, Yu Qiao, Haiyu Zhang, Yunhong Wang, Xinyuan Chen, Yaohui Wang

- 현재 4D 생성 방법은 고급 확산 생성 모델의 도움으로 주목할 만한 효과를 달성하고 있지만 다면체 시공간 모델링이 부족하고 여러 확산 모델로부터 다양한 선행 지식을 통합하는 데 어려움을 겪고 있습니다.
- 이 논문에서는 단안 비디오로부터 시공간적으로 일관된 4D 콘텐츠를 생성하기 위한 새로운 4D 생성 파이프라인인 4Diffusion을 제안합니다.
- 우리는 동결된 3D 인식 확산 모델에 학습 가능한 동작 모듈을 통합함으로써 다면체 비디오 생성을 위한 통합 확산 모델을 설계하여 다면체 시공간 상관관계를 포착했습니다.
- 특정 데이터 세트에서 훈련한 후에, 우리의 확산 모델은 합리적인 시간적 일관성을 획득하고, 3D 인식 확산 모델의 일반성과 공간적 일관성을 본질적으로 보존합니다.
- 이어서, 우리는 다면체 비디오 확산 모델을 기반으로 4D 인식 점수 증류 샘플링 손실을 제안하여 여러 확산 모델로 인해 발생하는 차이를 제거하고 시공간적으로 일관된 4D 콘텐츠를 생성할 수 있게 합니다.
- 또한, 동적 NeRF의 학습을 촉진하고 외관 세부 사항을 개선하기 위해 앵커 손실을 고안했습니다.
- 광범위한 정성적 및 정량적 실험을 통해 우리의 방범이 이전 방법들보다 우수한 성능을 달성함을 입증했습니다.

### [4-bit Shampoo for Memory-Efficient Network Training](https://arxiv.org/abs/2405.18144)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.18144.png)

Vote: 4

Authors: Jia Li, Pan Zhou, Hua Huang, Sike Wang

- 이 논문에서는 32비트 전처리기 상태를 저비트로 압축하여 메모리 사용을 줄이는 약속을 보여준다.
- 특히, 4-bit Shampoo라는 새로운 4비트 2차 최적화기를 제안하여, 전처리기의 고유 벡터 행레를 4비트로 양자화하는 것이 이론적으로나 실험적으로 전처리기 자체를 양자화하는 것보다 더 우수함을 보인다.
- 양자화된 고유 벡터 행렬의 직교성을 바로잡음으로써 전처리기의 고유 벡터 행렬 근사치를 향상시키고, 이는 그 역의 4승근 계산에도 도움이 된다.
- 또한, 2차 최적화기 상태를 양자화할 때 선형 제곱 양자화가 동적 트리 양자화보다 약간 더 우수한 성능을 보임을 발견했다.
- 다양한 네트워크와 이미지 분류 평가를 통해 4-bit Shampoo는 32-bit 버전과 비슷한 테스트 정확도를 달성하면서 더욱 메모리 효율적임을 보여준다.
- 관련 소스 코드는 공개될 예정이다.

