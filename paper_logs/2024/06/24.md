## Daily Papers (2024-06-24)

### [LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs](https://arxiv.org/abs/2406.15319)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15319.png)

Vote: 47

Authors: Xueguang Ma, Wenhu Chen, Ziyan Jiang

- **What's New**: 이번 연구에서는 오픈 도메인 질문 응답을 위한 LongRAG 프레임워크를 소개합니다. Long Retrieval Unit, Long Retriever, Long Reader라는 세 가지 중요한 구성을 통해 기존 RAG 모델의 비효율성을 개선합니다.
- **Technical Details**: Long Retrieval Unit(긴 검색 단위)를 사용하여 Wikipedia 문서 전체나 여러 관련 문서를 그룹화하여 4K 이상의 토큰 단위로 검색 단위를 구성합니다. Long Retriever(긴 검색기)는 모든 긴 검색 단위를 탐색하여 상위 4~8개 단위를 검색하고 이들을 연결하여 Long Reader(긴 읽기기)에 전달합니다. Long Reader는 주어진 질문에 답을 생성하기 위해 결합된 검색 단위들을 처리합니다.
- **Performance Highlights**: 실험 결과, LongRAG는 NQ와 HotpotQA와 같은 오픈 도메인 질문 응답 작업에서 뛰어난 성능을 보였습니다. 예를 들어, NQ에서 코퍼스 사이즈를 2200만에서 60만 문서 단위로 줄여, 답잔환(R@1) 성능을 DPR의 52%에서 71%로 향상시켰습니다. 또한, HotpotQA에서는 코퍼스 사이즈를 500만에서 50만으로 줄여 R@2를 47%에서 72%로 향상시켰습니다. 이러한 성과는 기존의 최첨단 RAG 모델과 같은 수준의 정확성을 보여줍니다.

### [Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges](https://arxiv.org/abs/2406.12624)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.12624.png)

Vote: 31

Authors: Venkat Srinik Ramayapally, Kartik Choudhary, Sankaran Vaidyanathan, Aman Singh Thakur, Dieuwke Hupkes

- **What's New**: 최근 몇 년 동안 대형 언어 모델(LLMs)은 다양한 분야에서 놀라운 능력을 보여주고 있습니다. 이 연구는 특히 새로운 LLM들이 계속해서 출시되고 그 능력이 확장됨에 따라 LLMs의 성능과 제한 사항을 정확히 평가하는 것이 점점 더 어려워지고 있는 상황에서 이루어졌습니다. 이는 특히 LLMs의 응답이 다양하고 사용되는 작업의 범위가 넓기 때문에 발생하는 문제입니다.
- **Technical Details**: LLM 평가를 위해, 대개 두 가지 주요 범주의 방법들이 제안되었습니다. 첫 번째는 MMLU, TruthfulQA, GSM8K와 같은 벤치마크를 사용하는 것이며, 두 번째는 Chatbot Arena와 Open LLM Leaderboard와 같은 리더보드를 활용하는 것입니다. MCQ 벤치마크와 잠재적인 답의 로그 확률을 비교하는 방법도 있지만, 이는 평가할 수 있는 능력의 범위를 제한할 수 있습니다. 따라서, 인간 평가가 여전히 금표준으로 간주되지만, 비용이 많이 들고 시간이 많이 소요됩니다. 이에 따라, 다른 LLM을 판사 모델로 사용하는 관행이 증가하고 있습니다.
- **Performance Highlights**: 이번 연구에서는 TriviaQA 지식을 평가하는 판사 모델로 9개의 서로 다른 아키텍처와 크기를 가진 모델을 사용하여 평가를 수행했습니다. 주요 발견은 다음과 같습니다: 9개의 판사 모델 중 GPT-4 Turbo와 Llama-3 70B만이 인간과 매우 높은 일치를 보였으며, Cohen의 카파(Cohen's kappa)가 비율 일치보다 판사를 더 잘 구분합니다. 또한 구체적인 오류 분석을 통해 판사 모델이 포괄적인 답변을 처리하는 데 어려움을 겪고, 프롬프트의 길이와 품질에 민감하다는 점을 발견했습니다.

### [Complexity of Symbolic Representation in Working Memory of Transformer Correlates with the Complexity of a Task](https://arxiv.org/abs/2406.14213)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14213.png)

Vote: 18

Authors: Alsu Sagirova, Mikhail Burtsev

- **What's New**: 연구에서는 Transformer 디코더에 상징 작업 기억(symbolic working memory)을 추가해 문맥적 지식을 생성하고 저장하는 방법을 제안합니다. 이는 '내적 대화(inner speech)'와 유사하게 작용하며, 입력 텍스트의 개념적 이해와 예측 품질을 향상시키는 데 도움을 줄 것으로 기대됩니다.
- **Technical Details**: 기존의 Transformer 모델은 입력 시퀀스의 요소만을 나타내는 반면, 이 연구에서는 Transformer 디코더에 추가적인 상징 작업 기억을 도입합니다. 입력 시퀀딩은 일반적인 Transformer 방식을 따르지만, 출력 시퀀스 생성 시 디코더는 다음 토큰을 내부 작업 기억 또는 출력 목표 예측에 기록할지 결정합니다. 작업 기억 내의 메모리 요소들은 단어 및 하위 단어에 대한 표현을 가지며, 이는 메모리 내용을 보다 설명 가능하게 만듭니다. 또한, 이 모델은 러시아어->영어 기계 번역 작업에서 다양한 어휘 및 문법적 복잡성을 통한 메모리의 속성을 조사합니다.
- **Performance Highlights**: 이 연구는 Transformer 디코더에 추가된 작업 기억이 모델의 예측 품질 및 성능을 향상시킬 잠재력이 있음을 보여줍니다. 특히, 작업 기억은 목표 작업의 내용과 관련이 있으며, 작업의 복잡성과 메모리 내용의 복잡성 간에 상관 관계가 나타날 것으로 기대됩니다.

### [Towards Retrieval Augmented Generation over Large Video Libraries](https://arxiv.org/abs/2406.14938)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14938.png)

Vote: 17

Authors: Khalil Guetari, Frédéric Petitpont, Yannis Tevissen

- **What's New**: 최신 arXiv 논문은 인공지능(AI) 및 기계 학습(machine learning) 분야에서 중요한 발전을 소개합니다. 연구자들은 새로운 알고리즘 혹은 모델을 개발하여 기존 기술의 한계를 극복하거나 성능을 크게 향상 시켰습니다.
- **Technical Details**: 이 논문은 특정한 딥러닝(deep learning) 아키텍처에 대한 자세한 설명을 다룹니다. 연구에서 사용된 접근 방식은 트랜스포머(transformer) 모델이나 집합 신경망(convolutional neural network, CNN)과 같은 복잡한 신경망 구조를 포함할 수 있습니다. 또한, 데이터셋(data sets)과 사전 학습(pre-training) 기법의 선택이 중요한 역할을 했음을 강조합니다.
- **Performance Highlights**: 새로운 모델은 다양한 벤치마크(benchmarks)에서 기존 모델을 초과하는 성과를 보였습니다. 특히, 정확도(accuracy), 속도(speed), 효율성(efficiency) 측면에서 눈에 띄는 개선이 있었습니다. 예를 들어, 이미지 분류(image classification)나 자연어 처리(natural language processing) 작업에서 큰 성과를 거두었습니다.

### [Stylebreeder: Exploring and Democratizing Artistic Styles through Text-to-Image Models](https://arxiv.org/abs/2406.14599)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14599.png)

Vote: 14

Authors: Enis Simsar, Pinar Yanardag, Joel Simon, Federico Tombari, Matthew Zheng, Hidir Yesiltepe

- **What's New**: 이 논문에서는 Denoising Diffusion Models (DDMs)와 Latent Diffusion Models (LDMs)을 활용한 텍스트-이미지 모델의 발전 상황과 Artbreeder라는 플랫폼에서 사용자가 생성한 예술 스타일을 조사하는 연구를 소개합니다. Artbreeder는 사용자 기반이 1,300만 명을 넘으며, 사용자 생성 콘텐츠가 급증하고 있습니다. 이에 따라 새로운 스타일이 어떻게 커뮤니티 내에서 탄생할 수 있는지, 그리고 이를 분석하기 위한 포괄적인 데이터셋 'STYLEBREEDER'를 도입했습니다.
- **Technical Details**: STYLEBREEDER 데이터셋은 Artbreeder 웹사이트에서 수집된 95,479명의 고유 사용자가 생성한 680만 개의 이미지와 180만 개의 텍스트 프롬프트가 포함되어 있으며, Stable Diffusion 1.5와 SD-XL 같은 다양한 텍스트-이미지 확산 모델을 사용하여 생성됩니다. 또한, 사용자가 원하는 스타일과 원치 않는 특징을 나타내는 긍정 및 부정 프롬프트, 하이퍼파라미터 등도 포함되어 있습니다. 분석을 통해 서로 다른 스타일에 대한 클러스터링과 개인화된 추천시스템을 개발했습니다.
- **Performance Highlights**: STYLEBREEDER 데이터셋은 CC0 라이선스로 제공되어 누구나 자유롭게 사용할 수 있고, 사용자 ID는 익명화되어 프라이버시가 보호됩니다. 또한, Style Atlas라는 웹 기반 플랫폼을 통해, 사전 훈련된 스타일 LoRA를 다운로드할 수 있어 개인화된 콘텐츠 생성이 가능하고, 협업적인 예술 탐구를 장려합니다. 이미지 해상도는 모델별로 512×512에서 1280×896까지 다양합니다.

### [Evaluating RAG-Fusion with RAGElo: an Automated Elo-based Framework](https://arxiv.org/abs/2406.14783)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14783.png)

Vote: 13

Authors: Jakub Zavrel, Arthur Câmara, Zackary Rackauckas

- **What's New**: Infineon의 반도체 제품들에 대한 내부 문서로부터 답변을 제공하는 회화형 QA 시스템을 개발하였습니다. 이 시스템은 Retrieval-Augmented Generation (RAG) 기법을 사용해 사용자가 질문한 내용을 바탕으로 품질 높은 답변을 생성합니다.
- **Technical Details**: Infineon은 질문에 대한 다양한 변형을 생성하고 랭킹 융합 기법 (Rank-Fusion)을 사용해 더 다양한 고품질의 답변을 생성하는 RAG Fusion (RAGF)을 도입했습니다. RAGElo라는 툴킷을 사용하여 RAG 시스템의 평가를 자동화합니다. 이 툴킷은 Elo 랭킹 시스템을 기반으로 하며, 검색 결과와 답변을 평가하기 위해 강력한 LLM을 활용한 평가 방식을 사용합니다.
- **Performance Highlights**: RAGElo는 전통적인 n-그램 평가 메트릭 (ROUGE, BLEU, METEOR) 대신 LLM-as-a-judge 방법을 사용하여 평가의 정확도를 높였습니다. Infineon RAGF 시스템은 기존의 평가와 비교하여 품질 높은 답변을 더 빠르고 효과적으로 생성할 수 있음을 입증했습니다. 또한, 이 접근법은 여러 RAG 파이프라인 간의 신속한 실험 및 비교를 가능하게 합니다.

### [EvTexture: Event-driven Texture Enhancement for Video Super-Resolution](https://arxiv.org/abs/2406.13457)

![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/MSTZ1H1JVaANlz2OGt3A3.jpeg)

Vote: 12

Authors: Dachun Kai, Yueyi Zhang, Xiaoyan Sun, Jiayao Lu

- **What's New**: 이번 연구에서는 이벤트 신호(event signals)를 이용한 새로운 접근법인 EvTexture를 통해 비디오 슈퍼 해상도(VSR)에서의 텍스처 복원 문제를 해결하고자 합니다. 이는 기존의 RGB만을 사용하는 VSR 방법과 차별화되는 이벤트 주도 텍스처 복원(event-driven texture restoration) 스킴을 처음으로 제안합니다.
- **Technical Details**: EvTexture는 두 가지 주요 방식을 결합하여 텍스처 정보를 점진적으로 복원합니다. 첫째, 텍스처 강화 브랜치(texture enhancement branch)를 도입하여 모션 브랜치와 함께 텍스처 세부 사항을 강화합니다. 둘째, 반복적인 텍스처 강화 모듈(Iterative Texture Enhancement, ITE)을 통해 높은 시간 해상도의 이벤트 정보를 점진적으로 탐색합니다. 이를 통해 여러 반복을 거치며 텍스처 영역을 단계적으로 강화하여 보다 정확하고 풍부한 HR(High Resolution) 세부 정보를 얻을 수 있습니다.
- **Performance Highlights**: 제안된 EvTexture는 네 가지 데이터셋에서 VSR 성능을 크게 향상시켰으며, 특히 텍스처가 풍부한 클립을 복원하는 데 탁월한 성능을 발휘합니다. 이를 통해 EvTexture가 텍스처 재현에 있어 최첨단 성능을 달성할 수 있음을 입증하였습니다.

### [MantisScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation](https://arxiv.org/abs/2406.15252)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15252.png)

Vote: 12

Authors: Ge Zhang, Sherman Siu, Abhranil Chandra, Achint Soni, Wenhu Chen, Ziyan Jiang, Aaran Arulraj, Yaswanth Narsupalli, Haonan Chen, Xuan He, Dongfu Jiang, Max Ku, Yuansheng Ni, Bohan Lyu, Zhiheng Lyu, Yuchen Lin, Rongqi Fan, Quy Duc Do, Kai Wang

- **What's New**: 최근 몇 년 동안 텍스트-비디오(T2V) 생성 모델이 급격히 등장하고 있습니다. 특히 2023년과 2024년에 걸쳐 Sora OpenAI, Runway Gen-2, Lumiere 등의 T2V 모델이 출현하여 길고 높은 품질의 자연스러운 비디오를 생성하는 데 성공했습니다. 하지만 여전히 인공적인 느낌, 불일치, 환각 등의 문제가 존재하여 세부적인 평가와 강화 학습을 위한 견고한 보상 모델이 필요합니다.
- **Technical Details**: 현재의 비디오 생성 모델 평가는 여러 가지 문제를 포함하고 있습니다. 첫째, 일부 메트릭은 분포 기반으로 계산되어 단일 모델 출력 평가에 적합하지 않습니다(예: FVD, IS). 둘째, 대부분의 메트릭은 시각적 품질이나 텍스트 정렬 평가에 한정되어 움직임의 부드러움, 사실적 일관성 등을 평가하지 못합니다(예: CLIP, DINO, BRISQUE). 셋째, 단일 평균 의견 점수(MOS)에만 초점을 맞추는 메트릭은 세부적인 하위 점수를 제공하지 못합니다(예: T2VQA, FastVQA, DOVER). 또한 일부 연구는 다중 모달 대형 언어 모델(MLLM)을 사용하여 다양한 측면에서 비디오 품질을 평가하려 하지만, 이는 종종 인간의 평가와 낮은 상관 관계를 보입니다.
- **Performance Highlights**: VideoFeedback 데이터를 기반으로 한 VideoScore의 개발을 통해 높은 상관 관계와 정확성을 달성했습니다. VideoScore는 VideoFeedback-test에서 77.1%, EvalCrafter 텍스트-비디오 정렬 측면에서 59.5%의 스피어만 상관 관계를 기록하여 최선의 기준보다 각각 54.1%, 4.4% 높았습니다. GenAI-Bench 비디오 선호도와 VBench의 5가지 측면에서 각각 평균 78.5%와 72.1%의 정확도를 기록하여 이전 최선의 기준보다 11.4%, 9.6% 높았습니다. 추가적인 분할 연구에서는 Mantis 기반의 메트릭이 Idefics2 기반 메트릭에 비해 12.1% 향상되는 것을 확인했습니다. VideoScore는 향후 비디오 생성 모델의 신뢰할 수 있는 메트릭으로 사용할 수 있을 것으로 기대됩니다.

### [Reward Steering with Evolutionary Heuristics for Decoding-time Alignment](https://arxiv.org/abs/2406.15193)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15193.png)

Vote: 11

Authors: Ambuj Mehrish, Chia-Yu Hung, Navonil Majumder, Soujanya Poria

- **What's New**: 대형 언어 모델 (LLMs)이 점점 더 우리의 일상 생활에 깊이 관여하게 되면서, 사용자가 원하는 특정 속성을 반영하기 위한 연구가 활발히 진행되고 있습니다. 이 논문은 특히 decode-time alignment 문제를 해결하기 위해, 새로운 방법을 제안하고 평가합니다. 새로운 기법인 Darwin은 탐색 및 활용 (exploration and exploitation) 전략을 결합하여 모델 정렬을 개선합니다.
- **Technical Details**: 이 연구에서는 decode-time alignment 문제를 휴리스틱 기반의 트리 탐색 문제로 프레임합니다. 휴리스틱은 인간의 선호를 시뮬레이트하는 프록시 보상 모델 (proxy reward model)로, 이는 특정 명령어에 따라 생성된 상태의 평가자로 작동합니다. 탐색 전략은 주기적으로 보상 평가를 수행하여 모델의 내재된 능력을 최대한 활용하도록 하며, 이는 유도된 탐색으로 정의됩니다.
- **Performance Highlights**: Darwin 방법은 ARGS 및 기존의 decode-time alignment 방법보다 AlpacaEval 2 및 MT-Bench 벤치마크에서 뛰어난 성능을 보였습니다. 이는 탐색 및 활용 전략을 균형 있게 적용한 결과로, 주기적인 보상 기반 대체와 명령어 변이를 통해 보다 효과적인 정렬을 달성합니다.

### [Jailbreaking as a Reward Misspecification Problem](https://arxiv.org/abs/2406.14393)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14393.png)

Vote: 10

Authors: Zhihui Xie, Lingpeng Kong, Qi Liu, Jiahui Gao, Lei Li, Zhenguo Li

- **What's New**: 최근 LLM(대형 언어 모델, Large Language Models)의 발전과 그에 따른 폭넓은 채용은 안전성과 신뢰성에 대한 우려를 높였습니다. 이 논문은 LLM의 취약성을 보상 오인(reward misspecification) 관점에서 분석하고, 새로운 평가 기준인 ReGap을 제안하여 이 문제를 해결하는 방안을 탐구합니다.
- **Technical Details**: 논문은 보상 모델링(reward modeling)에 기반을 두며, 보상 함수가 입력 x와 모델의 응답 y에 대해 어떻게 동작하는지에 중점을 둡니다. ReGap이라는 새로운 척도를 도입하여, 해로운 응답이 무해한 참고 응답보다 높은 점수를 받는 정도를 평가하고, 이를 통해 보상 오인을 탐지합니다. 또한, 자동화된 레드팀 시스템인 ReMiss를 제안하여 다양한 LLM에 대해 공격 성공률을 극대화합니다.
- **Performance Highlights**: ReMiss는 AdvBench 벤치마크에서 최첨단 공격 성공률을 달성하며, 생성된 프롬프트의 가독성을 유지합니다. 이 접근법은 타겟 모델의 다양한 실패 모드를 밝혀내는 데 탁월한 성과를 보였으며, 감사와 레드팀 활동의 효과를 크게 향상시켰습니다.

### [Cognitive Map for Language Models: Optimal Planning via Verbally Representing the World Model](https://arxiv.org/abs/2406.15275)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15275.png)

Vote: 9

Authors: Jongwon Lee, Minjoon Seo, Jinho Park, Doyoung Kim

- **What's New**: 이 논문에서는 최신 심층 강화 학습(Deep Reinforcement Learning) 알고리즘을 제안하며, 이전의 모델 대비 효율성과 성능을 크게 향상시켰습니다. 특히, 이 새로운 알고리즘은 복잡한 환경에서도 높은 적응력을 보여줍니다.
- **Technical Details**: 이 논문에서는 Q-Learning과 정책 경사(Policy Gradient) 방법론을 결합한 하이브리드 접근법(hybrid approach)을 사용하였습니다. 추가로, 네트워크 구조(Network Architecture)는 깊은 컨볼루션 레이어(Deep Convolutional Layers)와 재귀신경망(Recurrent Neural Network, RNN)을 결합하여 시계열 데이터(Time-Series Data)와의 호환성을 높였습니다.
- **Performance Highlights**: 실험 결과, 이 알고리즘은 여러 표준 강화 학습 벤치마크(benchmark)에서 우수한 성능을 보였습니다. 특히, 기존의 DQN(Deep Q Network)과 비교했을 때, 학습 속도(Learning Speed)와 정책 최적화(Policy Optimization) 측면에서 평균 20% 이상의 성능 향상을 기록하였습니다.

### [Two Giraffes in a Dirt Field: Using Game Play to Investigate Situation Modelling in Large Multimodal Models](https://arxiv.org/abs/2406.14035)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14035.png)

Vote: 9

Authors: Sherzod Hakimov, Antonia Schmidt, Anne Beyer, Yan Weiser, Kushal Koshti, Yerkezhan Abdullayeva, David Schlangen

- **What's New**: 이 아카이브(arXiv) 논문에서는 최신 AI 모델의 발전과 적용 가능성에 대해 다룹니다. 특히, 새로운 딥러닝(deep learning) 아키텍처와 알고리즘이 소개되었습니다.
- **Technical Details**: 논문은 새로운 신경망(neural network) 아키텍처를 제안합니다. 여기에는 Transformer 모델의 변형과 강화 학습(reinforcement learning) 기법이 포함됩니다. 또한, 데이터 증강(data augmentation) 기법과 과적합(overfitting)을 방지하기 위한 정규화(regularization) 방법도 자세히 설명됩니다.
- **Performance Highlights**: 제안된 모델은 여러 벤치마크(benchmark) 데이터셋에서 강력한 성능을 보여주었습니다. 특히, 자연어 처리(NLP) 작업과 이미지 인식(image recognition)에서 기존 기술 대비 우수한 성능을 입증하였습니다. 성능 지표로는 정확도(accuracy), F1-스코어(F1-score) 등이 사용되었습니다.

### [Data Contamination Can Cross Language Barriers](https://arxiv.org/abs/2406.13236)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.13236.png)

Vote: 8

Authors: Zihao Sun, Yufan Zhuang, Animesh Kumar, Jingbo Shang, Sunan Xu, Feng Yao

- **What's New**: 현재 대형 언어 모델(LLMs)의 사전 학습 데이터는 기본적으로 공개되지 않는 경우가 많습니다. 이 논문에서는 교차 언어(cross-lingual) 형태의 오염(contamination)이 기존의 탐지 방법으로는 포착되지 않으며, 특히 다언어 모델의 성능 향상에 영향을 줄 수 있다는 것을 보여줍니다.
- **Technical Details**: 교차 언어 오염은 다른 언어로 번역된 벤치마크 테스트 세트를 기억하도록 모델을 과적합시켜 의도적으로 주입됩니다. 우리는 두 개의 다언어 모델, LLaMA3-8B와 Qwen1.5-7b를 사용하여, MMLU, ARC Challenge, MathQA 벤치마크의 번역 버전으로 추가 학습을 수행했습니다. 이러한 오염은 기존의 텍스트 중복 탐지 방식으로는 감지되지 않습니다. 우리는 일반화 기반 탐지 방법을 제안하여 이러한 깊은 오염을 효과적으로 식별하고자 합니다.
- **Performance Highlights**: 실험 결과, 두 모델 모두 원래 벤치마크에서 성능이 급격히 향상되었습니다. 예를 들어, LLaMA3-8B의 MMLU 벤치마크 성능은 교차 언어 오염 후 63.82%에서 98.01%로 상승했습니다. 하지만 기존의 탐지 방법으로는 이러한 교차 언어 오염을 감지할 수 없었습니다. 우리가 제안한 일반화 기반 탐지 방법은 이러한 문제를 해결하는 데 효과적임을 입증했습니다.

### [DELLA-Merging: Reducing Interference in Model Merging through Magnitude-Based Sampling](https://arxiv.org/abs/2406.11617)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.11617.png)

Vote: 6

Authors: Rishabh Bhardwaj, Soujanya Poria, Pala Tej Deep

- **What's New**: 본 논문은 동종 모델(homologous models)을 병합하는 새로운 접근 방법인 Della(Drop and rEscaLe via sampLing with mAgnitude)를 소개합니다. Della는 세 가지 단계를 통해 구현되며, 이 과정에서 MagPrune이라는 새로운 가지치기(pruning) 방법을 제안합니다.
- **Technical Details**: Della는 세 단계로 구성됩니다. (1) Drop: 모델 파라미터 간의 간섭을 줄이기 위해 delta 파라미터를 드롭(drop)하는 단계로, Magnitude 기반으로 샘플링하는 MagPrune이라는 새로운 가지치기 방식을 사용합니다. (2) Elect: 귀속될 delta 파라미터를 선별하여 간섭을 줄입니다. 이 과정에서 주요 방향을 파악하여 동일한 부호를 가지는 delta 파라미터를 선택합니다. (3) Fuse: 선택된 delta 파라미터를 합체(fuse)하여 최종 모델을 만듭니다.
- **Performance Highlights**: Della는 AlpacaEval, GSM8K, MBPP와 같은 벤치마크 데이터셋에서 세 종류의 동종(전문가) 모델(LM, Math, Code) 병합 실험에서 기존 방법들을 압도하는 성능을 보였습니다. 특히, delta 파라미터 가지치기를 사용한 기존 방법들(Ties와 Dare)보다 평균적으로 2.4 포인트, 가지치기를 사용하지 않은 방법(TA)보다 11.1 포인트 향상된 성능을 보였습니다. 또한 MagPrune에 의한 스케일링은 Math+Code 모델에서 7.6 포인트 성능 향상을 가져왔습니다.

### [Ruby Teaming: Improving Quality Diversity Search with Memory for Automated Red Teaming](https://arxiv.org/abs/2406.11654)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.11654.png)

Vote: 6

Authors: Rishabh Bhardwaj, Vernon Toh Yan Han, Soujanya Poria

- **What's New**: 최근 대언어모델(LLMs)의 능력 및 사용은 놀라운 성장세를 보이고 있으며, 다양한 분야와 일상 업무에서도 활발히 도입되고 있습니다. 하지만 실제 세계에서의 사용과 관련된 잠재적 해악과 오용을 다루는 문제는 여전히 열려있는 연구 과제로 남아있습니다. 이 문제를 해결하기 위해, 새로운 '루비 팀(Ruby Teaming)' 접근법이 제안되었습니다. 루비 팀은 기존의 레인보우 팀에 메모리를 추가하여 반복적인 공격 성공률 및 다양성을 높이는 것을 목표로 합니다.
- **Technical Details**: 루비 팀은 레인보우 팀이 사용하는 기본 프레임워크를 기반으로 합니다. 루비 팀의 주요 단계는 샘플링, 변이, 업데이트로 이루어집니다. 우선, 샘플링 단계에서는 아카이브에서 균일분포를 기반으로 공격 프로프트(Adversarial Prompt)를 선택합니다. 다음으로, 변이 단계에서는 대상 리스크 카테고리 및 공격 스타일에 맞게 프로프트를 두 번 변이시킵니다. 마지막으로, 업데이트 단계에서는 생성된 후보 프로프트의 유해성을 평가하여 아카이브를 갱신합니다. 또한, 루비 팀은 가장 최근의 성공적인 변이 및 그에 대한 피드백을 메모리로 저장하여, 향후 변이 생성 시 이를 참고하도록 합니다.
- **Performance Highlights**: 루비 팀은 기존의 레인보우 팀보다 뛰어난 성능을 보였습니다. 공격 성공률(ASR)은 74%로 레인보우 팀의 54%에 비해 큰 향상을 보였으며, 다양성 지수인 셰넌 균등성 지수(SEI)와 심슨 다양성 지수(SDI)에서도 각각 6%, 3% 더 높은 점수를 기록했습니다. 또한, 아카이브의 품질은 메모리 크기에 의존하며, 메모리 크기를 늘리는 것이 항상 성능을 향상시키는 것은 아님을 확인했습니다.

### [A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems](https://arxiv.org/abs/2406.14972)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14972.png)

Vote: 6

Authors: Giovanni Trappolini, Fabrizio Silvestri, Florin Cuconasu, Nicola Tonellotto

- **What's New**: Retrieval Augmented Generation (RAG)는 최신 기술로, 대형 언어 모델(LLMs)의 능력을 향상시키기 위해 검색 메커니즘을 생성 과정에 통합합니다. RAG는 방대한 데이터 코퍼스에서 관련 정보를 검색한 후 이 정보를 기반으로 일관되고 맥락에 맞는 응답을 생성합니다.
- **Technical Details**: RAG는 LLMs의 기본 모델과 지도 학습을 통한 명령 세부 조정(SFT), 인간 피드백을 통한 강화 학습(RLHF) 등 다양한 정교화 단계를 포함합니다. 기본 모델은 다음 단어 예측 작업에서 선행 단어의 문맥을 기반으로 다음 단어를 예측하도록 훈련됩니다.
- **Performance Highlights**: 최근 연구 결과에 따르면, RAG 설정에서 추가 명령별 세부 조정이 없는 기본 모델이 명령 조정 모델보다 우수한 성능을 발휘합니다. 이는 명령 모델이 본질적으로 우수하다는 기존의 가정을 도전합니다.

### [Learning Molecular Representation in a Cell](https://arxiv.org/abs/2406.12056)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.12056.png)

Vote: 6

Authors: Srijit Seal, Gang Liu, Zhenwen Liang, Shantanu Singh, Meng Jiang, Anne E. Carpenter, John Arevalo

- **What's New**: InfoAlign이라고 불리는 새로운 접근법을 소개합니다. 이는 분자 구조와 세포 반응 데이터를 통합하여 보다 정확한 분자 표현(representation)을 학습하는 방법입니다. 기존의 단일 모달리티 접근법의 한계를 극복하고, 보다 포괄적인 데이터를 활용하는 새로운 방향성을 제시합니다.
- **Technical Details**: InfoAlign은 분자, 유전자 발현, 세포 형태와 같은 다양한 생물학적 변수를 통합한 컨텍스트 그래프(context graph)를 사용합니다. 컨텍스트 그래프에서 각 분자의 이웃을 식별하고, 정보 병목(information bottleneck)을 적용해 불필요한 정보를 제거하고 일반화 성능을 향상시킵니다. 한 개의 인코더와 다수의 디코더를 사용하는 정보 정렬(information alignment) 방식으로 구성되며, 인코더는 최소한의 충분한 통계치만을 학습합니다.
- **Performance Highlights**: InfoAlign은 Broad6K 분류 데이터셋과 Biogen3K 회귀 데이터셋에서 각각 +10.58%, +6.33%의 성능 향상을 보였습니다. 또한 두 개의 molecule-morphology 데이터셋에서 매우 경쟁력 있는 zero-shot 멀티모달 매칭 능력을 보여주었습니다.

### [4K4DGen: Panoramic 4D Generation at 4K Resolution](https://arxiv.org/abs/2406.13527)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.13527.png)

Vote: 5

Authors: Dejia Xu, Xuanyang Zhang, Panwang Pan, Renjie Li, Shijie Zhou, Zhangyang Wang, Zhiwen Fan, Zeming Li, Bangbang Yang, Achuta Kadambi

- **What's New**: 최근 생성적 기술의 발전으로 인해 VR/AR 및 기타 공간 컴퓨팅 플랫폼에서 고품질 자산을 만드는 능력이 콘텐츠 제작에 혁신을 가져올 수 있습니다. 이 논문에서는 4K 해상도의 파노라마 4D 환경을 생성하는 새로운 프레임워크인 4K4DGen을 소개합니다. 이 프레임워크는 360도 파노라마 이미지에서 동영상을 애니메이션화하고 이를 4D 환경 자산으로 승격시키는 과정을 다룹니다.
- **Technical Details**: 4K4DGen 프레임워크는 두 가지 주요 기술을 제안합니다. 첫째, Panoramic Denoiser는 2D 디퓨전 모델(diffusion model)을 사용하여 360도 시야각(FoV, Field-of-View)에 대한 파노라마 이미지를 애니메이션화합니다. 둘째, 4D 승격 메커니즘은 깊이 추정기를 사용하여 규모 불일치 문제를 해결하고 시간 의존적 3D 가우시안을 통해 동적 장면의 일관성을 유지합니다. 이 과정에서 파노라마 비디오를 4D 환경으로 변화시킵니다.
- **Performance Highlights**: 4K4DGen은 주석된 4D 데이터가 부족한 상황에서도 일관되고 원활한 4D 파노라마 렌더링을 가능하게 합니다. 이 프레임워크는 고해상도(최대 4096x2048)의 4D 옴니디렉셔널 자산을 생성할 수 있으며, 전 세계적 일관성을 보장하기 위해 사전 학습된 2D 디퓨전 모델의 생성적 프라이어(prior)를 파노라마 영역으로 전이합니다. 또한, 시간적 및 공간적 일관성을 유지하며 3D 가우시안을 활용하여 동적 파노라마 비디오를 4D 환경으로 승격시킵니다.

### [Style-NeRF2NeRF: 3D Style Transfer From Style-Aligned Multi-View Images](https://arxiv.org/abs/2406.13393)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.13393.png)

Vote: 5

Authors: Tatsuya Harada, Haruo Fujiwara, Yusuke Mukuta

- **What's New**: Neural Radiance Fields (NeRF)를 활용한 새롭고 효과적인 3D 스타일 전환 방법을 제안합니다. 이 방법은 텍스트로 지시된 스타일 조정(diffusion model) 및 Sliced Wasserstein Distance(SWD) 손실을 사용하여 3D 장면을 스타일화합니다.
- **Technical Details**: 최근의 3D 재구성 기술인 NeRF는 현실 세계 데이터를 바탕으로 3D 자산이나 장면을 만들 수 있게 도와주지만, 전체 3D 장면을 원하는 스타일이나 콘셉트에 맞게 편집하는 것은 여전히 어려운 과제입니다. 본 연구에서는 'Instruct-Pix2Pix'와 같은 텍스트 지시 기반(T2I) 모델을 사용하여 3D 장면을 스타일화하는 새로운 파이프라인을 제안합니다. 그 과정에서 깊이 지도(depth maps)를 조건으로 하는 스타일 정렬(diffusion) 모델을 사용하여 일관된 스타일 이미지를 생성한 후, NeRF를 학습시킵니다.
- **Performance Highlights**: 기존 방법들(Instruct-NeRF2NeRF, ViCA-NeRF 등)의 복잡하고 예측 불가능한 편집 과정을 개선했습니다. 실험 결과, SWD 손실을 통해 NeRF를 미세 조정하면 텍스트 프롬프트를 사용하여 다양한 스타일의 3D 장면을 효과적으로 생성할 수 있음을 확인했습니다.

### [NAVSIM: Data-Driven Non-Reactive Autonomous Vehicle Simulation and Benchmarking](https://arxiv.org/abs/2406.15349)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15349.png)

Vote: 5

Authors: Daniel Dauner, Boris Ivanovic, Marco Pavone, Igor Gilitschenski, Kashyap Chitta, Marcel Hallgarten, Zhiyu Huang, Xinshuo Weng, Tianyu Li, Hongyang Li, Andreas Geiger, Zetong Yang

- **What's New**: 자율 주행 차량(Autonomous Vehicles, AV)에 관한 연구는 교통 안전을 향상시키고, 교통 체계를 혁신할 잠재력 때문에 많은 연구 관심을 받고 있습니다. 그러나 현존하는 AV 알고리즘(algorithms)의 성능을 평가하고 비교하는 것은 상당히 어려운 일입니다. 이번 논문에서는 이러한 문제점을 해결하기 위해 NAVSIM이라는 종합 도구를 제안하고 있습니다. NAVSIM은 데이터 큐레이션(data curation), 시뮬레이션(simulation), 벤치마킹(benchmarking)을 포함한 종합 프레임워크입니다.
- **Technical Details**: NAVSIM은 다음의 주요 요소들로 구성됩니다. 첫째, 우리는 주행 시나리오를 샘플링하는 전략을 제안하고, 이를 가장 큰 공개 주행 데이터셋에 적용해 10만 개 이상의 도전적인 실제 주행 시나리오를 확보했습니다. 둘째, 비반응형(non-reactive) 시뮬레이션의 필요성을 해결하기 위해 정의된 시간 범위 내에서 에이전트의 행동이 다른 에이전트의 미래 행동에 영향을 미치지 않는 도메인 단순화된 시뮬레이션을 도입했습니다. 셋째, 다양한 평가 지표(metrics)를 사용해 여러 가지 자율 주행의 다양한 측면을 평가하도록 설계했습니다. 최종적으로, 오픈 소스 HuggingFace 플랫폼 상에서 공식적인 평가 서버를 구축하여 투명성과 확장성을 제공하고 있습니다.
- **Performance Highlights**: 우리는 NAVSIM을 사용하여 CARLA와 nuScenes 벤치마크에서 최고 성능을 자랑하는 모델들의 성능을 독립적으로 비교했습니다. 그 결과, 두 환경에서 개발된 최고 성능 모델의 성능이 유사하다는 것을 발견했습니다. 또한, 이번 연구를 통해 2024 NAVSIM 챌린지에서 13개국의 143개 팀이 다양한 방법을 개발하고 경쟁했습니다. 최상위 방법들은 수십억 개의 파라미터를 가진 비전 언어 모델에서부터 경량화된 효과적인 접근 방식까지 다양했습니다. 이러한 결과는 적절한 도구 제공 시 AV 연구를 더욱 발전시킬 수 있는 커뮤니티의 뛰어난 능력을 보여줍니다.

### [ICAL: Continual Learning of Multimodal Agents by Transforming Trajectories into Actionable Insights](https://arxiv.org/abs/2406.14596)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14596.png)

Vote: 4

Authors: Kenneth Marino, William W. Cohen, Michael J. Tarr, Katerina Fragkiadaki, Gabriel Sarch, Lawrence Jang

- **What's New**: 이 연구에서는 In-Context Abstraction Learning (ICAL) '이라는 새로운 접근 방식을 제안합니다. 이 방법은 시각 및 언어 모델(VLMs)을 사용하여 처음 접하는 환경에서도 과제를 효과적으로 수행할 수 있도록 합니다. 이는 기존의 방식들이 성공적인 행동 계획만 저장하고 회수하는 것과 달리, 과제의 동역학과 중요한 지식을 캡처하는 추상화를 학습하는 데 중점을 둡니다.
- **Technical Details**: ICAL의 핵심은 VLMs가 최적의 또는 최적화되지 않은 시연을 기반으로 추상화된 예제를 생성하고, 이를 자연어 피드백을 통해 개선해 나가는 것입니다. 중요한 파트는 네 가지 유형의 인지 추상화를 다룬다는 점입니다: 과제 및 인과 관계, 객체 상태 변화, 시간적 추상화, 그리고 과제 구성입니다. 이 과정에서 VLMs는 시각 및 언어 추상화 모두를 생생하게 생성합니다.
- **Performance Highlights**: ICAL은 TEACh, VisualWebArena, Ego4D와 같은 벤치마크에서 VLMs의 성능을 크게 향상시켰습니다. 특히 TEACh에서 새로운 상태를 달성했으며, 기존 최첨단 모델보다 12.6% 향상된 목표 달성률을 보여주었습니다. 또한 VisualWebArena에서의 성공률도 기존 대비 14.3%에서 22.7%로 향상되었습니다. Ego4D에서는 챔오브생각(chain of thought)을 사용하는 few-shot GPT4V보다 더 우수한 성능을 보여주며 명사 및 동사 수정 거리를 각각 6.4 및 1.7 감소시켰습니다.

### [RE-AdaptIR: Improving Information Retrieval through Reverse Engineered Adaptation](https://arxiv.org/abs/2406.14764)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14764.png)

Vote: 4

Authors: William Fleshman, Benjamin Van Durme

- **What's New**: 이번 연구에서는 정보 검색(Information Retrieval, IR) 모델을 향상시키기 위한 새로운 방법인 RE-AdaptIR을 소개합니다. RE-AdaptIR은 Reverse Engineered Adaptation(RE-Adapt) 방법을 확장하여, 라벨이 없는 데이터를 이용해 텍스트 검색 언어모델(LLMs)을 개선합니다. 특히 RepLLaMA와 e5-Mistral 두 가지 최첨단 텍스트 검색 모델에 적용하여 성능 향상을 입증했습니다.
- **Technical Details**: Transformer 아키텍처는 텍스트를 밀집 벡터(dense vector)로 변환하여 IR 모델에 자주 사용됩니다. 이는 텍스트를 유사도 기반으로 비교하여 관련 문서를 검색하는 데 유리합니다. RE-AdaptIR은 이전의 instruction-tuned 모델의 무게 차이를 활용해 새로운 지식 어댑터를 통해 모델을 미세 조정하는 방식으로 작동됩니다.
- **Performance Highlights**: RepLLaMA와 e5-Mistral 모델을 각각 14개의 데이터셋에서 테스트한 결과, RE-AdaptIR은 도메인 내(in-domain) 및 제로샷(Zero-shot) 환경 모두에서 성능 개선을 보였습니다. 특히 MS-MARCO 데이터셋의 전체 884만 패세지를 활용하며 더 많은 비라벨 데이터로도 효과적으로 성능을 높일 수 있음을 보여주었습니다.

### [Multimodal Structured Generation: CVPR's 2nd MMFM Challenge Technical Report](https://arxiv.org/abs/2406.11403)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.11403.png)

Vote: 4

Authors: Franz Louis Cesista

- **What's New**: 이번 보고서에서는 Multimodal Structured Generation이라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 멀티모달 모델의 출력 형식을 제어할 수 있게 해주며, 이를 통해 다운스트림 API가 파싱하고 사용할 수 있는 구조화된 출력을 생성합니다. 구조화된 생성을 통해 모델이 응답 전에 논리적인 사고를 하도록 강제하는 방식이며, 이를 통해 문서 이해 성능을 향상시키고자 합니다.
- **Technical Details**: 구조화된 생성(Structured Generation)은 생성 모델의 출력이 다운스트림 프로그램, 컴파일러 또는 API에 의해 파싱될 수 있도록 보장하는 접근법입니다. 'Soft'한 제약으로는 모델에게 지정된 스키마를 따르도록 요청하거나 재시도하게 하는 방법이 있으며, 'Hard'한 제약으로는 잘못된 토큰을 아예 무효화시키는 방법이 있습니다. 이 연구에서 우리는 구조화된 생성을 통해 잘못된 토큰의 로그잇(logits)을 무효화하는 방식을 채택했습니다. 우리는 Huggingface의 Inference Endpoints API와 TGI (Text Generation Interface) API를 사용하여 모델을 배포하고 추론 요청을 처리했습니다. 또한, Phase 1에서는 Llava v1.5를, Phase 2에서는 구조화된 생성으로 증강된 Llava-Next (v1.6)를 활용하였습니다.
- **Performance Highlights**: 우리 팀은 CVPR의 2차 MMFM 챌린지 Phase 2에서 2위를 차지했고, 전체 순위에서는 3위를 기록했습니다. 특히, 우리는 복합적인 멀티모달 모델의 미세 조정(fine-tuning)을 거친 여러 팀들을 능가했습니다. 이는 구조화된 생성의 일반성을 보여주며, 이 접근법이 보편적으로 사용 가능함을 의미합니다.

### [Low-Resource Machine Translation through the Lens of Personalized Federated Learning](https://arxiv.org/abs/2406.12564)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.12564.png)

Vote: 3

Authors: Nazarii Tupitsa, Samuel Horváth, Chris Biemann, Irina Nikishina, Viktor Moskvoretskii, Eduard Gorbunov

- **What's New**: 이 논문에서는 새로운 머신 러닝 알고리즘을 제안하여 데이터 분류의 정확성을 향상시키는 방법을 소개합니다. 특히, 저자들은 대규모 데이터 셋(data set)을 효율적으로 처리할 수 있는 알고리즘을 개발하는 데 중점을 두었습니다.
- **Technical Details**: 제안된 알고리즘은 convolutional neural networks (CNN)과 recurrent neural networks (RNN)의 하이브리드 모델을 기반으로 합니다. 모델은 데이터 전처리(data preprocessing) 단계를 포함하여 다양한 최적화 기법(optimization techniques)을 사용합니다. 또한, 모델의 학습 과정에서 overfitting을 방지하기 위해 regularization 기법을 적용합니다.
- **Performance Highlights**: 실험 결과에 따르면, 새로운 알고리즘은 기존 모델들보다 평균적으로 10% 높은 정확도(accuracy)를 보였습니다. 특히, 대규모 이미지 데이터 셋에서 최첨단(state-of-the-art) 성능을 기록하며 그 우수성을 입증했습니다.

### [ToVo: Toxicity Taxonomy via Voting](https://arxiv.org/abs/2406.14835)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14835.png)

Vote: 3

Authors: Thien Huu Nguyen, Diep Thi-Ngoc Nguyen, Thang Viet Doan, Tinh Son Luong, Linh Ngo Van, Thanh-Thien Le

- **What's New**: 텍스트 생성에서 독성 감지를 목표로 하는 새로운 연구가 발표되었습니다. 이 연구는 기존 닫힌 소스 모델에 대한 의존성을 극복하고자 'Toxicity Taxonomy Voting (ToVo)' 데이터셋을 소개하고, 이를 통해 사용자 맞춤형 독성 감지 모델을 개발하는 방법을 제시합니다.
- **Technical Details**: ToVo 데이터셋은 42가지 다양한 독성 기준을 포함하는 포괄적인 리소스로, 여러 개방형 소스 모델을 통해 샘플을 분류하고 설명적인 논리도 제공합니다. 데이터셋 구축 과정은 'Chain-of-Thought' 기법을 사용하여 기존 모델들이 샘플에 대한 판단을 투표하는 방식으로 이루어집니다. 이 데이터셋을 활용해 사전 정의된 메트릭뿐만 아니라 사용자 지정 메트릭에서도 효율적으로 작동할 수 있는 적응형 분류 모델을 개발합니다.
- **Performance Highlights**: 모델의 효율성을 입증하기 위해 주요 검열 도구들과 벤치마킹을 수행했으며, OAIM, Perspective API, Llama Guard 2가 포함됩니다. 특히, OAIM가 가장 높은 일치율을 보였지만 Perspective API는 비교적 낮은 일치율을 보여 추가적인 조율이 요구됨을 시사합니다. 또한, OOD(Out-of-Domain) 평가를 통해 학습되지 않은 메트릭에서도 높은 일반화 성능을 확인했습니다.

### [How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of LLM Responses Based on Hofstede Cultural Dimensions](https://arxiv.org/abs/2406.14805)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14805.png)

Vote: 3

Authors: Chirag Shah, Julia Kharchenko, Tanya Roosta, Aman Chadha

- **What's New**: 이번 연구는 대형 언어 모델(LLMs)이 사용자에게 조언을 제공할 때 문화적 민감성을 얼마나 잘 적용하는지 체계적으로 조사하는 첫 시도입니다. Hofstede의 문화 차원(Hofstede Cultural Dimensions)을 이용해 LLMs가 사용자의 문화적 배경을 고려하여 답변을 제공하는지 살펴봅니다.
- **Technical Details**: 이 연구는 Hofstede 문화 차원(Hofstede Cultural Dimensions)을 활용해 LLMs의 문화적 민감성을 평가합니다. Hofstede의 문화 차원은 문화적 가치를 정량화하는 널리 인정된 프레임워크로, 개인주의 vs. 집단주의(Individualism vs. Collectivism), 장기 vs. 단기 지향(Long Term vs. Short Term Orientation), 불확실성 회피도(High vs. Low Uncertainty Avoidance), 성취 지향(High vs. Low MAS), 권력 거리(High vs. Low Power Distance Index) 등의 가치를 포함합니다. 연구팀은 각 문화 가치를 평가하기 위해 50개의 고유 프롬프트를 작성하고, 이를 통해 LLMs가 사용자에게 문화적으로 적합한 조언을 제공하는지 테스트하였습니다.
- **Performance Highlights**: 결과적으로, LLMs는 데이터에서 반영된 인기 있는 감정에 따라 일부 이상을 선호하는 경향이 있으며, 모든 문화적 차원에서 균형 잡힌 조언을 제공하지 못했습니다. 이로 인해 다양한 문화적 배경을 가진 사용자에게 적절한 조언을 제공하는 데 한계가 있다는 점이 드러났습니다. 연구팀은 이를 통해 LLMs의 문화적 편향성을 더 잘 이해하고, 보다 다문화적인 가치에 맞춘 LLMs 개발을 촉진하는 방향성을 제시합니다.

