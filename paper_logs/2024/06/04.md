## Daily Papers (2024-06-04)

### [MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark](https://arxiv.org/abs/2406.01574)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.01574.png)

Vote: 28

Authors: Shiguang Guo, Kai Wang, Alex Zhuang, Xueguang Ma, Max Ku, Weiming Ren, Aaran Arulraj, Ge Zhang, Tianle Li, Abhranil Chandra, Ziyan Jiang, Yubo Wang, Yuansheng Ni, Xiang Yue, Wenhu Chen, Xuan He, Rongqi Fan

- 대규모 언어 모델 시대에 MMLU(Massive Multitask Language Understanding)와 같은 벤치마크는 다양한 분야에서 언어 이해와 추론 능력을 향상시키는 데 중요한 역할을 해왔습니다.
- 최근 모델의 성능 향상으로 이러한 벤치마크에서의 성능이 정체되기 시작하여 모델 간 차이를 구분하기 어렵게 되었습니다.
- 이 연구에서는 MMLU 벤치마크를 보완하고 더 도전적이고 추론 중심의 질문을 포함시키며 선택지를 네 개에서 열 개로 확장한 개선된 데이터셋인 MMLU-Pro를 소개합니다.
- MMLU-Pro는 기존 MMLU에 비해 난이도가 증가하여 정확도가 16%에서 33% 감소하였으멘, 다양한 프롬프트에 대한 안정성이 향상되었습니다.
- 24개의 다른 프롬프트 스타일을 테스트한 결과, 모델 점수의 프롬프트 변화에 대한 민감성이 MMLU에서 4-5%에서 MMLU-Pro에서 2%로 감소하였습니다.
- 사고의 연쇄(Chain of Thought, CoT) 추론을 활용한 모델은 MMLU-Pro에서 직접 대답하는 방식에 비해 더 나은 성능을 보였으며, 이는 MMLU-Pro가 더 복잡한 추론 질문을 포함하고 있음을 시사합니다.
- MMLU-Pro는 더 차별적이고 진보적인 이해를 추적하기 위한 벤치마크로서, 해당 분야에서의 진보를 더 잘 추적할 수 있습니다.

### [Learning Temporally Consistent Video Depth from Video Diffusion Priors](https://arxiv.org/abs/2406.01493)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.01493.png)

Vote: 12

Authors: Yujun Shen, Hongyu Zhou, Matteo Poggi, Yuanbo Yang, Yiyi Liao, Youmin Zhang, Jiahao Shao

- 이 연구는 비디오 깊이 추정의 도전을 다루며, 이는 단순한 프레임 당 정확성뿐만 아니라 훨씬 중요한 프레임 간 일관성을 요구합니다.
- 연구팀은 깊이 추정기를 처음부터 개발하는 대신, 조건부 생성 문제로 예측 작업을 재구성하여 기존 비디오 생성 모델에 내포된 사전 지식을 활용합니다.
- 공개된 Stable Video Diffusion(SVD)을 활용하여 비디오 입력에서 신뢰할 수 있는 깊이를 예측하기 위해 이미지 깊이와 비디오 깊이 데이터 세트의 혼합을 연구했습니다.
- 공간적 레이어의 SVD를 최적화한 다음, 공간적 레이어를 고정한 상태에서 시간적 레이어를 최적화하는 절차적 훈련 전략이 공간적 정확성과 시간적 일관성 측면에서 최상의 결과를 제공함을 실증적으로 확인했습니다.
- 임의 길이의 비디오에 대한 추론을 위해 슬라이딩 윈도우 전략을 검토하였고, 효율성과 성능 간의 트레이드오프를 관찰했으며, 한 프레임 겹침이 이미 유리한 결과를 제공한다고 밝혔습니다.
- 광범위한 실험 결과는 우리의 접근 방식인 ChronoDepth가 특히 추정된 깊이의 시간적 일관성 측면에서 기존 대안들을 능가함을 보여줍니다.
- 또한, 깊이 조건부 비디오 생성 및 새로운 시점 합성과 같은 두 가지 실용적인 응용 분야에서 일관된 비디오 깊이의 이점을 강조했습니다.
- 프로젝트 페이지는 https://jhaoshao.github.io/ChronoDepth/에서 확인할 수 있습니다.

### [Show, Don't Tell: Aligning Language Models with Demonstrated Feedback](https://arxiv.org/abs/2406.00888)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.00888.png)

Vote: 9

Authors: Joey Hejna, Diyi Yang, Omar Shaikh, Michael Bernstein, Michelle Lam, Yijia Shao

- 많은 사람들의 의견을 반영하여 만들어진 언어 모델은 특정한 누구의 기대에도 부합하지 않는 결과를 만들어낼 수 있습니다.
- 특정 상황에 맞춰 언어 모델을 조정하는 기존의 방식은 새로운 업무에 필요한 많은 데이터가 필요하다는 문제가 있습니다.
- 본 논문에서는 불과 10개 미만의 시연을 이용한 피드백을 활용하여 언어 모델을 특정 사용자의 행동에 맞추어 조정할 수 있는 새로운 방법을 제안합니다.
- 우리의 방법론인 DITTO (Demonstration ITerated Task Optimization)은 온라인 모방 학습의 아이디어를 기반으로 하여 사용자의 시연을 언어 모델 출력보다 선호하는 온라인 비교 데이터를 저렴하게 생성합니다.
- DITTO는 뉴스 기사, 이메일, 블로그 포스트 등 다양한 도메인에서 세밀한 스타일과 작업 조정 능력을 평가받았으며, 제한된 시연 만으로도 효과적인 맞춤화를 가능하게 합니다.
- 16명의 참가자들로부터 다양한 시연을 받은 사용자 연구를 통해, DITTO는 몇 번의 시연, 감독된 파인튜닝, 자기 게임 방식 등 다른 방법들보다 평균 19% 포인트 높은 승률을 보여주었습니다.

### [Artificial Generational Intelligence: Cultural Accumulation in Reinforcement Learning](https://arxiv.org/abs/2406.00392)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.00392.png)

Vote: 9

Authors: Chris Lu, Joel Z. Leibo, Edward Hughes, Jakob Foerster, Jonathan Cook

- 인간의 역사에 걸쳐 다양하고 끊임없는 능력의 발전을 이끄는 문화적 축적은 개인 탐험과 세대 간 정보 전달을 결합하여 지식과 기술의 확장하는 집합체를 구축합니다.
- 인공 학습 에이전트의 문화적 축적 능력은 널리 알려진 인간의 성공에도 불구하고 탐구가 미흡한 상태입니다. 특히, 강화 학습 접근법은 대체로 단일 생애에 걸친 개선에만 중점을 둡니다.
- 이미 사회적 학습을 수행할 수 있는 강화 학습 에이전트의 능력이 입증된 바, 독립적 학습과의 균형을 맞춘 훈련 설정은 문화적 축적을 초래하는 것으로 나타났습니다.
- 이러한 축적이 있는 에이전트는 동일한 누적 경험을 가진 단일 생애 동안 훈련된 에이전트보다 더 나은 성능을 보입니다.
- 우리는 문화적 축적이 발생하는 두 가지 모델을 구축했는데, 하나는 에피소드 세대에서의 맥락 내 학습을 통해, 또 다른 하나는 훈련 시간 세대에서의 가중치 내 학습을 통해 이루어집니다.
- 맥락 내와 가중치 내 문화적 축적은 각각 지식과 기술 축적에 비유될 수 있습니다.
- 최선의 지식으로는, 이 연구는 강화 학습에서 출현하는 문화적 축적을 달성하는 일반 모델을 처음으로 제시하며, 더 개방적인 학습 시스템으로 가는 새로운 길을 열고 인간 문화 모델링에 대한 새로운 기회를 제공합니다.

### [ZeroSmooth: Training-free Diffuser Adaptation for High Frame Rate Video Generation](https://arxiv.org/abs/2406.00908)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.00908.png)

Vote: 7

Authors: Xiaodong Cun, Ran He, Yong Zhang, Ying Shan, Shaoshu Yang

- 최근 몇 년간 비디오 생성 분야가 크게 발전하였으며, 특히 비디오 확산 모델의 도입으로 인해 진전이 이루어졌습니다.
- 대부분의 비디오 모델은 GPU 메모리의 한계와 다수의 프레임을 모델링하는 어려움으로 인해 낮은 프레임률의 비디오만 생성할 수 있습니다.
- 기존 방법들은 픽셀 공간에서 비디오 보간 모델을 후처리 단계로 학습하거나 특정 기본 비디오 모델의 잠재 공간에서 보간 모델을 학습하여 프레임률을 향상시켰습니다.
- 본 논문에서는 다양한 모델에 플러그 앤 플레이 방식으로 일반화 가능한 학습이 필요 없는 비디오 보간 방법을 제안합니다.
- 비디오 확산 모델의 특성 공간에서의 비선형성을 조사하고, 설계된 숨겨진 상태 교정 모듈을 통합하여 비디오 모델을 자체 캐스케이드 비디오 확산 모델로 변환합니다.
- 자체 캐스케이드 구조와 교정 모듈은 주요 프레임들과 보간된 프레임들 사이의 시간적 일관성을 유지하는 데 도움을 줍니다.
- 본 연구의 효과성은 여러 인기 있는 비디오 모델에 대한 광범위한 평가를 통해 입증되었으며, 특히 대규모 데이터셋과 큰 컴퓨터 자원을 요구하는 학습된 보간 모델과 비교할 수 있을 정도로 우수합니다.

### [$μ$LO: Compute-Efficient Meta-Generalization of Learned Optimizers](https://arxiv.org/abs/2406.00153)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.00153.png)

Vote: 3

Authors: Benjamin Thérien, Irina Rish, Eugene Belilovsky, Boris Knyazev, Edouard Oyallon, Charles-Étienne Joseph

- 학습된 최적화기(LO)는 신경망의 벽 시계 훈련 시간을 현저히 단축시켜 훈련 비용을 크게 절감할 수 있습니다.
- 그러나 이들은 메타 훈련 동안 보았던 것보다 큰 네트워크를 훈련할 때 메타 일반화가 부족한 문제가 종종 발생합니다.
- 이 문제를 해결하기 위해, 최근 제안된 최대 업데이트 파라미터화(muP)를 사용하여, 작은 모델에서 큰 모델로 최적화기의 하이퍼파라미터를 제로-샷 일반화할 수 있습니다.
- muP 이론을 학습된 최적화기에 적용하여, muP하의 학습된 최적화기를 찾는 것을 메타 훈련 문제로 취급합니다.
- muP로 메타 훈련된 LO는 표준 파라미터화(SP) 하에서 훈련된 LO에 비해 메타 일반화를 크게 향상시킵니다.
- 특히 큰 너비 모델에 적용될 때, 우리의 최고의 muLO는 4000 TPU-월의 계산으로 메타 훈련된 가장 큰 공개 학습된 최적화기인 VeLO의 성능에 맞거나 뛰어납니다.
- 또한, muLO는 SP 동료들에 비해 더 깊은 네트워크와 메타 훈련 동안 본 것보다 훨씬 더 긴 훈련 지평선(25배 더 길게)으로 일반화를 더 잘 보여줍니다.

