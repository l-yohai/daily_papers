## Daily Papers (2024-06-06)

### [Parrot: Multilingual Visual Instruction Tuning](https://arxiv.org/abs/2406.02539)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02539.png)

Vote: 24

Authors: Chao Yi, Qing-Guo Chen, Zhao Xu, Weihua Luo, Da-Wei Zhou, Kaifu Zhang, Yang Li, Shiyin Lu, De-Chuan Zhan, Han-Jia Ye, Hai-Long Sun

- GPT-4V와 같은 다중모달 대형 언어 모델(MLLMs)의 발전이 인공 일반 지능으로의 중요한 단계를 표시하였습니다.
- 기존 방법은 보통 시각 인코더를 지도 학습을 통해 LLM에 맞추어 다중모달 능력을 부여하나, 훈련 과정에서 다국어 능력이 점차 약화됩니다.
- 영어 중심의 이미지-텍스트 쌍이 주를 이루는 불균형 데이터셋 때문에 비영어 언어의 성능이 크게 감소하는 것으로 나타났습니다.
- 본 논문에서는 언어 수준에서 시각 토큰 정렬을 유도하는 텍스트 지침을 활용하는 새로운 방법, Parrot을 소개합니다.
- Parrot은 다양한 언어 입력에 따라 시각 토큰을 조건화하고, 다국어 토큰의 정렬을 촉진하기 위해 전문가 혼합(Mixture-of-Experts, MoE)을 사용합니다.
- 특히, 비영어 시각 토큰 정렬을 강화하기 위해 초기 시각 특징과 텍스트 임베딩을 사용하여 교차 주의를 계산하고, 이 결과를 MoE 라우터에 공급하여 가장 관련성 높은 전문가를 선택합니다.
- 선택된 전문가들은 초기 시각 토큰을 언어별 시각 토큰으로 변환합니다.
- 또한, 다국어 능력을 평가하기 위한 벤치마크 부족을 고려하여, 6개 언어, 15개 카테고리, 12,000개의 질문을 포함하는 Massive Multilingual Multimodal Benchmark(MMMB)를 수집하고 제공합니다.
- Parrot은 다양한 다중모달 작업에서 뛰어난 성능을 보이며, 다국어 MMBench와 MMMB에서 최고의 성능을 실현합니다.
- Parrot의 소스 코드와 훈련 데이터셋은 공개될 예정입니다.

### [Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration](https://arxiv.org/abs/2406.01014)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.01014.png)

Vote: 22

Authors: Fei Huang, Haitao Jia, Junyang Wang, Xi Zhang, Haiyang Xu, Ji Zhang, Ming Yan, Weizhou Shen, Jitao Sang

- 모바일 기기 작업을 위한 효율적인 다중 모달 AI 시나리오가 점차 인기를 끌고 있으멜, 현재의 다중 모달 대규모 언어 모델(MLLM)은 교육 데이터의 제한으로 인해 작업 보조원으로 효과적으로 기능하지 못합니다.
- 대신, 이러한 시나리오에 점차 적용되고 있는 MLLM 기반 에이전트는 도구 호출을 통해 기능을 강화합니다. 
- 그러나 기존 작업에서의 단일 에이전트 구조는 모바일 기기 운영 작업에서의 두 가지 주요 내비게이션 도전 과제인 작업 진행 내비게이션과 초점 콘텐츠 내비게이션을 복잡하게 만듭니다.
- 이는 긴 토큰 시퀀스와 중첩된 텍스트-이미지 데이터 형식 때문에 성능이 제한됩니다.
- 이러한 내비게이션 과제를 효과적으로 해결하기 위해, 우리는 모바일 기기 작업 보조를 위한 다중 에이전트 구조인 Mobile-Agent-v2를 제안합니다.
- 이 구조는 계통 에이전트, 의사 결정 에이전트, 반성 에이전트의 세 가지 에이전트로 구성됩니다.
- 계획 에이전트는 작업 진행을 생성하여 과거 작업의 내비게이션을 더욱 효율적으로 만듭니다.
- 초점 내용을 유지하기 위해, 우리는 작업 진행과 함께 업데이트되는 메모리 유닛을 설계했습니다.
- 또한, 반성 에이전트는 각 작업의 결과를 관찰하고 발생할 수 있는 오류를 적절히 처리합니다.
- 실험 결과에 따르면 Mobile-Agent-v2는 기존 Mobile-Agent의 단일 에이전트 구조에 비해 작업 완료율에서 30% 이상의 향상을 달성했습니다.
- 해당 코드는 https://github.com/X-PLUG/MobileAgent 에서 오픈 소스로 제공됩니다.

### [Block Transformer: Global-to-Local Language Modeling for Fast Inference](https://arxiv.org/abs/2406.02657)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02657.png)

Vote: 18

Authors: Sangmin Bae, Hyunjik Jo, Tal Schuster, James Thorne, Adam Fisch, Namgyu Ho, Yireun Kim, Se-Young Yun, Taehyeon Kim

- 이 논문은 계층적 글로벌-투-로컬 모델링을 채택한 Block Transformer 구조를 제시하여, 자기주의 변환기의 추론 병목 현상을 완화합니다.
- 전체 이전 시퀀스의 키-값(KV) 캐시를 모든 디코딩 단계에서 메모리에서 검색해야 하므로, KV 캐시 입출력이 배치 추론에서 중대한 병목이 됩니다.
- 글로벌 모델링의 비용이 많이 드는 부분을 하위 계층으로 조정하고, 상위 계층에서는 빠른 로컬 모델링을 적용합니다.
- 하위 계층에서 남은 비용을 완화하기 위해 입력 토큰을 고정 크기 블록으로 집계하고 이러한 거친 수준에서 자기주의를 적용합니다.
- 맥락 정보를 단일 임베딩으로 집계하여, 상위 계층이 전체 글로벌 주의 없이 다음 토큰 블록을 디코딩할 수 있게 합니다.
- 글로벌 주의의 병목 현상이 제거된 상위 계층은 계산 하드웨어를 완전히 활용하여 추론 처리량을 극대화할 수 있습니다.
- 글로벌 및 로컬 모듈을 활용한 Block Transformer 구조는 동일한 혼란도를 가진 기존 변환기에 비해 추론 처리량에서 10-20배의 성능 향상을 보여줍니다.
- 이 연구는 글로벌-투-로컬 모델링의 새로운 적용을 통해 언어 모델 추론을 최적화하는 새로운 접근 방식을 소개합니다.
- 관련 코드는 https://github.com/itsnamgyu/block-transformer에서 확인할 수 있습니다.

### [Ouroboros3D: Image-to-3D Generation via 3D-aware Recursive Diffusion](https://arxiv.org/abs/2406.03184)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.03184.png)

Vote: 14

Authors: Hao Wen, Yu Qiao, Lu Sheng, Xinyuan Chen, Yaohui Wang, Zehuan Huang

- 기존의 단일 이미지로부터 3D 생성 방법은 일반적으로 멀티뷰 이미지를 생성한 후 이를 활용하여 3D를 재구성하는 두 단계 과정을 포함합니다.
- 이 두 단계를 별도로 훈련하는 것은 추론 단계에서의 데이터 편향을 초래하며, 이는 재구성 결과의 품질 저하를 야기합니다.
- 우리는 Ouroboros3D라는 통합된 3D 생성 프레임워크를 도입하며, 이는 확산 기반의 멀티뷰 이미지 생성과 3D 재구성을 반복적인 확산 과정으로 통합합니다.
- 프레임워크 내의 두 모듈은 자체 조건 설정 메커니즘을 통해 공동으로 훈련되어 각각의 특성에 적응하며 강력한 추론을 가능하게 합니다.
- 멀티뷰 노이즈 제거 과정에서 멀티뷰 확산 모델은 이전 타임스탭에서 재구성 모듈에 의해 렌더링된 3D 인식지도를 추가적인 조건으로 사용합니다.
- 3D 인식 피드백을 통한 반복적인 확산 프레임워크는 전체 과정을 통일시키며 기하학적 일관성을 향상시킵니다.
- 실험 결과, 우리의 프레임워크는 이 두 단계를 분리한 경우와 추론 단계에서 결합하는 기존 방법들을 뛰어넘는 성능을 보여줍니다.
- 프로젝트 페이지: https://costwen.github.io/Ouroboros3D/

### [Searching Priors Makes Text-to-Video Synthesis Better](https://arxiv.org/abs/2406.03215)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.03215.png)

Vote: 7

Authors: Xiaofei He, Linxuan Xia, Qinglin Lu, Hengjia Li, Boxi Wu, Liang Peng, Yuepeng Hu, Haoran Cheng

- 텍스트에서 비디오로(T2V) 합성 분야의 진전에 비디오 확산 모델의 발전이 크게 기여하였지만, 기존의 T2V 합성 모델은 복잡한 동작 동역학을 정확하게 생성하는 데 어려움을 겪어 비디오의 사실성이 저하됩니다.
- 대규모 데이터 수집과 모델 훈련은 매우 비용이 많이 드는 방법이므로, 우리는 T2V 생성 과정을 검색 기반 생성 파이프라인으로 재구성하여 이 문제를 완화합니다.
- 주어진 프롬프트 입력에 대해 기존 텍스트-비디오 데이터셋에서 프롬프트 동작과 밀접하게 일치하는 텍스트 레이블이 있는 비디오를 검색하고, 객체 동작 특징을 강조하는 맞춤형 검색 알고리즘을 제안합니다.
- 검색된 비디오는 동작 사전으로 처리되어 사전 훈련된 기본 T2V 모델을 미세 조정하고 입력 프롬프트를 사용하여 원하는 비디오를 생성합니다.
- 검색된 비디오에서 얻은 사전을 활용함으로써 생성된 비디오의 동작 사실성을 향상시킵니다.
- 모든 작업은 단일 NVIDIA RTX 4090 GPU에서 완료될 수 있으멀로, 우리의 방법은 다양한 프롬프트 입력에 대해 최신 T2V 모델과 비교하여 검증되었습니다.
- 이 연구의 코드는 공개될 예정입니다.

### [Audio Mamba: Bidirectional State Space Model for Audio Representation Learning](https://arxiv.org/abs/2406.03344)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.03344.png)

Vote: 7

Authors: Mehmet Hamza Erol, Joon Son Chung, Jiu Feng, Arda Senocak

- 트랜스포머는 CNN 기반 방법보다 우수하여 오디오 분류에서 선호되는 선택이 되었습니다.
- 그러나 오디오 스펙트로그램 트랜스포머(AST)는 자기 주의(self-attention) 때문에 제곱 비율로 확장됩니다.
- 최근 언어 및 비전 작업에서 좋은 성능을 보여준 상태 공간 모델(SSM)인 Mamba를 이용하여 자기 주의 비용 문제를 해결하는 방향성이 제시되었습니다.
- 본 연구에서는 오디오 분류 작업에 자기 주의가 필수적인지 의문을 제기하며, 자기 주의를 사용하지 않는 순수 SSM 기반 첫 모델인 Audio Mamba (AuM)을 소개합니다.
- AuM은 다양한 오디오 데이터셋 및 여섯 가지 서로 다른 벤치마크에서 평가되었으멍, 기존의 AST 모델에 비해 비슷하거나 더 나은 성능을 달성하였습니다.

### [Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms](https://arxiv.org/abs/2406.02900)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02900.png)

Vote: 7

Authors: Joey Hejna, Bradley Knox, Chelsea Finn, Yaswanth Chittepu, Rafael Rafailov, Harshit Sikchi, Ryan Park, Scott Niekum

- 인간 피드백에서의 강화 학습(RLHF)은 대규모 언어 모델(LLM)의 발전에 중요하게 사용되었으나, 이 과정은 복잡하고 취약한 면이 있다.
- RLHF에서는 우선 보상 모델을 학습하여 인간의 선호도를 표현하고, 이를 바탕으로 온라인 강화 학습(RL) 알고리즘이 LLM을 최적화한다.
- 이 방법의 주요 문제는 보상 모델에 의한 성능은 향상되지만 실제 품질은 정체되거나 악화되는 보상 과잉 최적화 또는 해킹 문제이다.
- 보상 모델링 단계를 생략하고 직접적 선호 최적화와 같은 직접 정렬 알고리즘(DAAs)이 대안으로 등장했다.
- 그러나 DAAs는 별도의 대리 보상 모델을 사용하지 않음에도 불구하고 여전히 과잉 최적화로 인한 성능 저하가 발생한다.
- 높은 KL 예산을 사용할 때 DAA 알고리즘은 전통적인 RLHF 방법과 유사한 성능 저하 패턴을 보인다.
- 이 연구는 광범위한 경험적 실험을 통해 DAAs의 보상 과잉 최적화 문제를 정의하고 그 결과를 목표, 훈련 체제, 모델 규모에 걸쳐 탐구한다.

### [LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes](https://arxiv.org/abs/2406.02897)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02897.png)

Vote: 7

Authors: David Aponte, Trung Dang, Kazuhito Koishida, Dung Tran

- 이 연구에서는 신경 오디오 코드화를 통해 얻은 오디오 토큰을 사용하는 생성 언어 모델을 통해 제로-샷 텍스트-투-스피치를 구현하되, 저지연 상황에 적합하도록 개선한 LiveSpeech를 제시합니다.
- LiveSpeech는 완전 자동회귀 언어 모델을 기반으로 하며, 출력 오디오의 저지연 스트리밍을 가능하게 합니다.
- 각 프레임에서의 코드북 기여도를 고려하여 적응형 코드북 손실 가중치를 사용하고, 어려운 인스턴스에 집중하며, 코드북을 그룹화하고 그룹을 병렬로 처리하는 방법을 제안합니다.
- 제안된 모델은 내용의 정확성, 화자 유사성, 오디오 품질 및 추론 속도 측면에서 최신 기준 모델과 경쟁력 있는 결과를 달성함과 동시에 저지연 스트리밍에 적합합니다.

### [PosterLLaVa: Constructing a Unified Multi-modal Layout Generator with LLM](https://arxiv.org/abs/2406.02884)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02884.png)

Vote: 6

Authors: Zhongang Qi, Ying Shan, Yingmin Luo, Tao Yang, Chang Wen Chen, Yang Wu

- 자동 그래픽 디자인을 실현하기 위한 핵심인 레이아웃 생성은 다양한 멀티모달 디자인 요소의 위치와 크기를 시각적으로 만족스럽고 제약 조건을 준수하는 방식으로 배치하는 것을 요구합니다.
- 이 연구에서는 다양한 디자인 작업을 수용할 수 있는 멀티모달 대규모 언어 모델(MLLM)을 활용하여 자동 그래픽 레이아웃 생성을 위한 통합 프레임워크를 소개합니다.
- 본 연구의 데이터 기반 방법은 구조화된 텍스트(JSON 포맷)와 시각적 지시 튜닝을 활용하여 특정 시각적 및 텍스트 제약 조건, 사용자 정의 자연어 사양을 포함한 레이아웃을 생성합니다.
- 공개 멀티모달 레이아웃 생성 벤치마크에서 최고의 성능을 달성하여 방법의 효과를 입증한 광범위한 실험을 수행했습니다.
- 현실 세계의 그래픽 디자인의 복잡성을 포착하는 기존 데이터셋의 한계를 인식하고, 우리는 더 도전적인 작업(사용자 제약 생성 및 복잡한 포스터)을 위한 두 개의 새로운 데이터셋을 제안하여 모델의 실제 생활 환경에서의 유용성을 추가로 검증합니다.
- 이 접근 방식은 대규모 그래픽 디자인 작업을 더욱 자동화하는 데 있어 뛰어난 접근성과 적응성을 자랑합니다.
- 코드와 데이터셋은 https://github.com/posterllava/PosterLLaVA 에서 공개적으로 이용 가능합니다.

### [Xmodel-LM Technical Report](https://arxiv.org/abs/2406.02856)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02856.png)

Vote: 5

Authors: Xucheng Huang, Ling Jiang, Yang Liu, Yichuan Wang, Yu Yan

- Xmodel-LG는 2조 개 이상의 토큰에 대해 사전 훈련된 컴팩트하고 효율적인 11억 언어 모델을 소개합니다.
- 모델은 하류 작업 최적화를 기반으로 한국어 및 영어 말뭉치의 균형을 맞춘 자체 구축 데이터셋(Xdata)에서 훈련되었습니다.
- 작은 크기에도 불구하고 Xmodel-LM은 유사한 규모의 기존 오픈 소스 언어 모델을 뛰어넘는 뛰어난 성능을 보입니다.
- 모델 체크포인트와 코드는 GitHub에서 https://github.com/XiaoduoAILab/XmodelLM 에서 공개적으로 접근 가능합니다.

### [PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs](https://arxiv.org/abs/2406.02886)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02886.png)

Vote: 4

Authors: Feng Han, Chao Zhang, Tianqi Liu, Zhen Qin, Michael Bendersky, Rongzhi Zhang, Jialu Liu, Simon Baumgartner, Haorui Wang, Jiaming Shen

- 대규모 언어 모델(LLM)은 다양한 작업에서 인상적인 능력을 보여주었지만, 그 큰 매개변수 크기가 자원 제약 환경에서의 적용 가능성을 제한합니다.
- 지식 전달(KD)은 큰 교사 모델로부터 지식을 컴팩트한 학생 모델로 이전하는 유용한 해결책을 제공하지만, LLM에 적용할 때 특정 도전을 직면합니다.
- 이 논문에서는 PLaD라는 새로운 선호도 기반 LLM 축소 프레임워크를 제시합니다.
- PLaD는 학생 모델보다 교사 모델의 출력을 선호하는 의사 선호 쌍을 생성하여 교사-학생의 용량 차이를 활용합니다.
- 그 후, PLaD는 순위 손실을 활용하여 학생 모델의 시퀀스 가능성 추정을 재조정하고, 학생이 단순히 교사를 모방하는 대신 출력의 상대적인 질을 이해하는 데 집중하도록 유도합니다.
- PLaD는 교사 LLM의 내부 상태에 대한 접근 필요성을 우회하고, 학생의 표현력 제한을 다루며, 학생의 잘못된 보정 문제를 완화합니다.
- 두 가지 시퀀스 생성 작업과 다양한 LLM을 사용한 광범위한 실험을 통해 제안된 PLaD 프레임워크의 효과를 입증합니다.

### [Item-Language Model for Conversational Recommendation](https://arxiv.org/abs/2406.02844)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02844.png)

Vote: 4

Authors: Yanwei Song, Li Yang, Reza Mirghaderi, Vikram Aggarwal, Hardik Patel, Judith Yue Li, Anushya Subbiah

- 대규모 언어 모델(LLM)은 복잡한 대화 이해, 추론 및 코딩 작업에 매우 성공적이었으멀로 이러한 모델의 능력이 이미지, 오디오 및 비디오를 포함한 다양한 형식으로 확장되었습니다.
- 반면에 추천 시스템은 정보 검색과 항목 발견의 필수적인 도구로 활용되어 왔으며, 최근에는 LLM을 추천 시스템에 적용하려는 시도가 있었습니다.
- 현재의 도전 과제 중 하나는 LLM이 추천 시스템 데이터(주로 공개되지 않은 사용자 상호 작용 신호로 구성됨)로 훈련되지 않았다는 점입니다.
- 사용자 상호 작용 신호는 자연어 텍스트와 다른 패턴을 가지며, LLM 훈련 설정이 전통적인 추천 시스템 방법과 비교하여 상호 작용 신호에서 더 많은 비일상적 지식을 학습할 수 있는지 여부는 아직 불투명합니다.
- 또한, 다양한 사용 사례에 대해 여러 LLM을 훈련하고 추천 시스템 데이터로부터 학습할 때 원래의 언어 및 추론 능력을 유지하는 것이 어렵습니다.
- 이러한 세 가지 제한을 해결하기 위해, 사용자 상호 작용 신호를 인코딩하는 텍스트 정렬 항목 표현을 생성하는 항목 인코더와 사전 훈련된 지식을 유지하면서 해당 항목 표현을 이해할 수 있는 고정된 LLM으로 구성된 항목-언어 모델(ILM)을 제안합니다.
- 광범위한 실험을 통해 항목 인코더에서의 언어 정렬의 중요성과 사용자 상호 작용 지식이 입증되었습니다.

