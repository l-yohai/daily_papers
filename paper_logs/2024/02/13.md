## Daily Papers (2024-02-13)

### [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://arxiv.org/abs/2402.07827)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/aR8X_MSvrWIjgnjJprsTf.png)

Vote: 21

Authors: Wei-Yin Ko, Shivalika Singh, Shayne Longpre, Daniel D'souza, Phil Blunsom, Neel Bhandari, Marzieh Fadaee, Zheng-Xin Yong, Amr Kayid, Ahmet Üstün, Julia Kreutzer, Hui-Lee Ooi, Viraat Aryabumi, Niklas Muennighoff, Sara Hooker, Freddie Vargus, Gbemileke Onilude

- Aya 모델은 101개 언어, 그 중 50%가 자원이 적은 언어를 포함한, 지시에 따라 작동하는 대규모 다언어 생성 언어 모델입니다.
- 이 모델은 mT0 및 BLOOMZ보다 더 많은 수의 언어에서 다수의 과제에서 더 우수한 성능을 보였습니다.
- Aya 모델을 평가하기 위하여 99개 언어에 걸친 평가 도구를 새롭게 소개하고, 차별화 및 창조적 과제, 인간 평가, 그리고 분배 내 성능과 보류된 과제를 포함한 시뮬레이션 승률을 넓히는 면에서 최신 기준을 창출했습니다.
- 또한, 최적의 미세조정 믹스 구성, 데이터 가지치기 및 모델의 독성, 편향 및 안전성에 대한 세부 조사를 수행했습니다.
- 연구팀은 Aya 모델과 지시 데이터셋을 오픈소스로 제공하며, https://hf.co/CohereForAI/aya-101에서 접근 가능합니다.

### [OS-Copilot: Towards Generalist Computer Agents with Self-Improvement](https://arxiv.org/abs/2402.07456)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/SxYdJnpTgRcxA6y9lceFh.qt)

Vote: 16

Authors: Chengcheng Han, Zhenmin Weng, Shunyu Yao, Lingpeng Kong, Zichen Ding, Zhoumianze Liu, Zhiyong Wu, Tao Yu

- 컴퓨터와의 자율적 상호작용은 큰 잠재력을 가진 오랜 과제이며, 최근 대규모 언어 모델의 급속한 확산으로 디지털 에이전트 구축에 있어 진전이 있었습니다.
- 그러나 이러한 에이전트들은 특정 소프트웨어나 웹사이트와 같은 좁은 도메인과의 상호작용에 초점을 맞추고 있어, 일반 컴퓨터 작업에 대한 응용성이 제한됩니다.
- 이에 우리는 운영 체제(OS) 내의 다양한 요소들, 즉 웹, 코드 터미널, 파일, 멀티미디어, 그리고 여러 제3자 애플리케이션과 연동할 수 있는 범용 에이전트를 구축하기 위한 프레임워크인 OS-Copilot을 소개합니다.
- OS-Copilot을 사용하여, 일반 컴퓨터 작업을 자동화하기 위한 자체 개선이 가능한 실체화된 에이전트 FRIDAY를 개발했습니다.
- 범용 인공지능 비서 벤치마크인 GAIA에서 FRIDAY는 이전 방법들보다 35% 더 우수한 성능을 보이며, 이전 작업에서 축적된 기술을 통해 보이지 않는 응용 프로그램에 대한 강력한 일반화 능력을 보여줍니다.
- 또한, FRIDAY가 Excel과 Powerpoint 제어 및 자체 개선을 최소한의 감독으로 배우는 것에 대한 수치적이고 정량적인 증거를 제시합니다.
- 우리의 OS-Copilot 프레임워크와 실증적 결과는 보다 능력있고 범용적인 컴퓨터 에이전트를 향한 미래 연구를 위한 인프라와 인사이트를 제공합니다.

### [Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models](https://arxiv.org/abs/2402.07033)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/NXCf0dSZ_achMsQ6IaiiH.png)

Vote: 13

Authors: Baris Kasikci, Yile Gu, Kan Zhu, Keisuke Kamahori

- 대규모 언어 모델들은 Mixture-of-Experts(MoE) 아키텍처를 기반으로 다양한 작업에서 뛰어난 성능을 보여주고 있지만, GPU 메모리 자원이 제한된 환경에서 이러한 모델들을 실행하는 것은 그 크기 때문에 도전적입니다.
- 현재 시스템은 CPU 메모리로 모델 가중치를 오프로드하지만 CPU와 GPU 사이에 데이터를 자주 이동해야 하는 상당한 오버헤드에 직면합니다.
- 본 논문에서는 CPU-GPU 협업을 통한 자원 효율적인 추론 엔진인 Fiddler를 제안하며, 이는 CPU의 연산 능력을 활용하여 CPU와 GPU 사이의 데이터 이동을 최소화하는 것을 핵심 아이디어로 합니다.
- Fiddler 평가 결과를 통해, 90GB 이상의 매개변수를 가진 압축되지 않은 Mixtral-8x7B 모델을 단일 24GB 메모리 GPU에서 초당 3개 이상의 토큰을 생성하며, 기존 방법들에 비해 한 차원 높은 성능 향상을 보여주었습니다.
- Fiddler의 코드는 https://github.com/efeslab/fiddler 에서 공개적으로 이용 가능합니다.

### [PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs](https://arxiv.org/abs/2402.07872)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.07872.png)

Vote: 9

Authors: Jacky Liang, Karol Hausman, Kuang-Huei Lee, Tsang-Wei Edward Lee, Andy Zeng, Fei Xia, Ayzaan Wahid, Soroush Nasiriany, Annie Xie, Peng Xu, Wenhao Yu, Sean Kirmani, Zhuo Xu, Sergey Levine, Ted Xiao, Nicolas Heess, +, Tingnan Zhang, Danny Driess, Chelsea Finn, Yuke Zhu, Ishita Dasgupta, Quan Vuong

- 시각 언어 모델(VLMs)은 논리적 추론부터 시각 이해에 이르는 다양한 작업에서 인상적인 능력을 보여주며, 이는 로봇 제어와 같은 더 풍부한 세계와의 상호작용으로 이어질 수 있다.
- 그러나 VLMs는 텍스트 출력만을 생성하는 반면, 로봇 제어와 다른 공간적 작업은 연속 좌표, 행동 또는 궤적과 같은 출력을 요구한다.
- 본 논문에서는 VLMs가 과제 특정 데이터에 대한 미세 조정 없이 이러한 설정을 처리할 수 있는 새로운 시각 프롬프트 방법을 제안한다.
- '반복 시각 질문 응답'으로 작업을 변경하는 반복 시각 최적화 프롬프트(Prompting with Iterative Visual Optimization, PIVOT) 방법이 소개되며, 각 반복마다 이미지는 VLM이 참조할 수 있는 제안(예: 후보 로봇 동작, 위치 지정, 궤적 등)의 시각적 표현으로 주석이 달린다.
- VLM은 다음에 수행할 최선의 작업을 선택하며, 이러한 제안들은 반복적으로 세련되어 VLM이 최선의 답변에 궁극적으로 집중할 수 있도록 한다.
- 실제 세계 로봇 항법, 이미지를 통한 실제 조작, 시뮬레이션에서의 지시사항 이행, 위치 지정과 같은 추가 공간 추론 과제에서 PIVOT를 조사한다.
- 연구 결과로 볼 때, 놀랍게도 본 접근 방식이 어떠한 로봇 훈련 데이터 없이도 로봇 시스템의 제로샷 제어를 가능하게 하며 다양한 환경에서의 네비게이션 및 다른 기능을 가능하게 한다.
- 현재의 성능은 아직 완벽하지 않지만, 이 연구는 새로운 체제의 잠재력과 한계를 보여주며 로봇 및 공간 추론 영역에서의 인터넷 규모 VLMs를 위한 유망한 접근 방식을 보여준다.
- 관련 웹사이트와 HuggingFace에서 PIVOT 프로젝트 및 데모를 확인할 수 있다.

### [Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like](https://arxiv.org/abs/2402.07383)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/K4Q20sNjg0_4IZWn0GZzI.png)

Vote: 8

Authors: Yufei Xia, Naoyuki Kanda, Zhen Xiao, Sefik Emre Eskimez, Canrun Li, Zirun Zhu, Steven Tsai, Min Tang, Yanqing Liu, Xiaofei Wang, Michael Zeng, Sheng Zhao, Jinzhu Li, Manthan Thakker, Hemin Yang

- 인간의 말에 가장 표현력 있고 자연스러운 측면 중 하나인 웃음은 감정, 사회적 신호, 유머를 전달하지만, 대부분의 텍스트-투-스피치(TTS) 시스템은 현실감 있고 적절한 웃음 소리를 생성하는 기능이 부족하며, 이는 그들의 응용 프로그램과 사용자 경험을 제한합니다.
- 기존의 자연스러운 웃음을 생성하려는 연구가 있었으나, 생성되는 웃음의 타이밍과 다양성을 제어하는 데에는 한계가 있었습니다.
- 본 연구에서는 ELaTE라는 제로샷 TTS 기법을 제안하며, 이는 짧은 오디오 프롬프트를 기반으로 어떤 화자의 자연스러운 웃음이 담긴 말소리를 정확한 웃음 타이밍 및 표현 제어와 함께 생성할 수 있습니다.
- ELaTE는 목소리 특성을 모방하기 위해 오디오 프롬프트, 생성되는 말의 내용을 가리키는 텍스트 프롬프트, 그리고 웃음 표현의 시작과 끝 시간이나 모방하려는 웃음이 담긴 추가적인 오디오 프롬프트와 같은 입력을 통해 웃음 표현을 제어합니다.
- 웃음 탐지기에서의 프레임 레벨 대표를 추가 조건으로 사용하여 조건부 흐름-매칭 기반의 제로샷 TTS 모델을 기반으로 개발하고, 작은 규모의 웃음 조건 데이터와 대규모 사전 훈련 데이터를 혼합하는 단순한 방법으로 보여주게 됩니다.
- 사전 훈련된 제로샷 TTS 모델의 품질을 손실 없이 정확한 제어 가능성을 가진 자연스러운 웃음을 생성하기 위해 쉽게 정밀 조정될 수 있음을 입증합니다.
- 평가를 통해 ELaTE는 기존 모델들에 비해 상당히 높은 품질과 제어 가능성을 갖춘 웃음이 담긴 말소리를 생성할 수 있음을 보여줍니다.
- 데모 샘플은 https://aka.ms/elate/ 에서 확인할 수 있습니다.

### [A Tale of Tails: Model Collapse as a Change of Scaling Laws](https://arxiv.org/abs/2402.07043)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Xf_TL2ifeHRcf7dOGDMIU.png)

Vote: 8

Authors: Elvis Dohmatob, Pu Yang, Yunzhen Feng, Francois Charton, Julia Kempe

- 인공지능 모델의 크기가 증가함에 따라, 용량과 원본(인간 또는 자연) 훈련 데이터의 크기를 증가시킬 때 대형 모델의 개선을 예측하는 데 중요한 도구가 되는 신경 스케일링 법칙이 등장했습니다.
- 이 논문은 합성 데이터가 훈련 데이터에 통합될 때 스케일링 법칙이 어떻게 변할지, 미래 모델이 개선될지 아니면 완전한 모델 붕괴까지 퇴화할지 여부를 질문합니다.
- 저자들은 스케일링 법칙을 통해 모델 붕괴를 이론적인 프레임워크로 개발하였으며, 스케일링의 손실, 세대 수에 따른 스케일링의 변화, 기술의 "재학습" 상실 그리고 인간과 합성 데이터를 혼합할 때의 그로킹 현상을 분석했습니다.
- 이 이론은 산술 작업을 위한 변압기와 대규모 언어 모델 Llama2를 사용한 텍스트 생성에 대한 대규모 실험으로 검증되었습니다.

### [ChemLLM: A Chemical Large Language Model](https://arxiv.org/abs/2402.06852)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/X_eEIrEe7N3emj9pp368o.png)

Vote: 8

Authors: Qian Tan, Hang Yan, Jiatong Li, Shufei Zhang, Jingdan Chen, Wanli Ouyang, Mao Su, Yuliang Yan, Weiran Huang, Yuqiang Li, Di Zhang, Wei Liu, Dongzhan Zhou, Hansen Zhong, Xiangyu Yue

- 화학 응용 분야에서 인상적인 발전을 보여준 대형 언어 모델(LLMs)에도 불구하고, 화학 분야를 위한 대화 기반 모델은 부족하다.
- 대부분의 화학 데이터 및 과학 지식이 구조화된 데이터베이스에 저장되므로, 이러한 구조화된 데이터를 직접 사용하는 것은 모델의 일관된 대화 유지 능력을 저하시킨다.
- 이 문제를 해결하기 위해, 구조화된 지식을 일반 대화로 변환하는 새로운 템플릿 기반 지시 구성 방법을 개발하여 언어 모델 교육에 적합하게 만들었다.
- 이러한 접근 방식을 활용하여, 화학분야 전용의 첫 대형 언어 모델인 ChemLLM을 개발했으며, 이 모델은 화학 분야에서 다양한 작업을 원활한 대화 상호작용으로 수행할 수 있다.
- ChemLLM은 명명 변환, 분자 설명, 반응 예측 등 화학 분야의 세 가지 주요 작업에서 GPT-3.5를 능가하며, 이 중 두 가지 작업에서 GPT-4를 초과한다.
- 또한, 주로 화학 중심의 데이터로 훈련되었음에도 불구하고, 관련 수학 및 물리 작업에 대한 뛰어난 적응력을 보여준다.
- ChemLLM은 화학 내 전문적인 NLP 작업, 예를 들어 문헌 번역 및 cheminformatic 프로그래밍에서도 숙련도를 보여준다.
- ChemLLM은 화학 연구 내에서 새로운 탐색 방향을 열고, 구조화된 화학 지식을 대화 시스템에 통합하는 우리의 방법은 다양한 과학 분야에 걸쳐 LLM을 개발하는 새로운 분야를 설정한다.
- 코드, 데이터셋 및 모델 가중치는 hf.co/AI4Chem/ChemLLM-7B-Chat에서 공개적으로 접근할 수 있다.

### [Policy Improvement using Language Feedback Models](https://arxiv.org/abs/2402.07876)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/KA2nSHn2OVMnfQnKcvaJw.png)

Vote: 5

Authors: Dipendra Misra, Marc-Alexandre Côté, Xingdi Yuan, Victor Zhong

- 본 논문에서는 지시사항에 따라 원하는 동작(과제를 달성하는 데 도움이 되는 행동)을 식별하기 위한 언어 피드백 모델(LFMs)을 소개합니다.
- LFMs를 학습하기 위해, 대규모 언어 모델(LLMs)로부터 언어로 서술된 시각적 궤적에 대한 피드백을 얻습니다.
- LFMs를 이용하여 모방 학습에서 원하는 동작을 식별함으로써, Touchdown, ScienceWorld, ALFWorld라는 세 가지 언어 기반 환경에서 강력한 행동 복제 기준보다 더 높은 작업 완수율을 달성했습니다.
- LLMs를 직접 행동을 예측하는 전문가로 사용하는 것보다 토큰 수를 통제할 때 LFMs의 성능이 더 우수합니다.
- LFMs는 본보기 학습을 위한 원하는 행동에 대한 사람이 이해할 수 있는 피드백을 제공하여 성능 손실 없이 수정될 수 있으며, 이는 사람이 확인할 수 있게 합니다.
- 마지막으로, LFMs는 단 한 번의 적응을 통해 본 적 없는 환경에서 3.5-12.0%의 작업 완수율을 향상시키는 일반화 능력을 가집니다.

### [Scaling Laws for Fine-Grained Mixture of Experts](https://arxiv.org/abs/2402.07871)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/tfoNPxO6_eP5zZ76Lti4Z.png)

Vote: 5

Authors: Piotr Sankowski, Marek Cygan, Sebastian Jaszczur, Kamil Adamczewski, Kamil Ciebiera, Krystian Król, Jakub Krajewski, Maciej Pióro, Tomasz Odrzygóźdź, Michał Krutul, Jan Ludziejewski, Szymon Antoniak

- 대규모 언어 모델의 계산 비용을 줄이는 주요 솔루션으로서, 전문가 혼합(Mixture of Experts, MoE) 모델이 부상하고 있다.
- 이 연구에서는 확장된 범위의 변수를 고려하여 MoE 모델의 스케일링 속성을 분석한다.
- 특히, 전문가들의 크기를 정밀하게 조정할 수 있게 하는 새로운 하이퍼파라미터인 "세밀도"를 도입한다.
- 이를 바탕으로, 훈련 토큰의 개수, 모델 크기 및 세밀도를 고려한 미세조정 MoE의 스케일링 법칙을 수립한다.
- 이러한 법칙을 활용하여 주어진 계산 예산에 대한 최적의 훈련 구성을 도출한다.
- MoE 모델이 조밀한(dense) 트랜스포머보다 일관되게 뛰어난 성능을 보이며, 모델 크기와 훈련 예산이 증가함에 따라 MoE와 밀집 모델 간의 효율성 격차가 확대된다는 것을 발견한다.
- 또한, MoE에서 전문가의 크기를 피드-포워드 층의 크기와 동일하게 설정하는 일반적인 관행이 거의 모든 계산 예산에서 최적이 아니라는 것을 보여준다.

### [ODIN: Disentangled Reward Mitigates Hacking in RLHF](https://arxiv.org/abs/2402.07319)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/nNhbEB8zih6j60ulOZqtA.png)

Vote: 4

Authors: Jiuhai Chen, Lichang Chen, Tianyi Zhou, Heng Huang, Bryan Catanzaro, Chen Zhu, Tom Goldstein, Davit Soselia, Mohammad Shoeybi

- 본 연구는 강화 학습에서 인간의 피드백(RLHF)을 통해 언어 모델(LLM)의 반응 길이에 대한 보상 해킹 문제를 연구합니다.
- 잘 구성되었지만 덜 유용한 LLM의 반응이 고득점을 얻기 위해 LLM이나 심지어 인간 평가자를 속일 수 있다는 문제점을 분석했습니다.
- 다양한 훈련 하이퍼파라미터를 조정함으로써 LLM 평가 점수와 반응 길이 간의 균형을 조사하는 신뢰할 수 있는 평가 프로토콜을 개발했습니다.
- 이 평가를 기반으로 대규모 연구를 수행하여 강화 학습에서 길이 편향을 완화하는 하이퍼파라미터 및 트릭의 효과를 분석했습니다.
- 공유된 특징 표현에 기반한 두 개의 선형 헤드를 공동으로 학습시켜 하나는 길이와 상관관계가 있도록, 다른 하나는 길이와 무관하게 실제 내용에 더 집중하도록 만들어 보상 모델을 개선하는 방법을 제안했습니다.
- 길이에 따른 보상 해킹을 방지하기 위해 강화 학습에서 길이 헤드를 제거합니다.
- 실험 결과, 제안된 접근 방식이 길이와의 보상 상관관계를 거의 제거하고 정책의 성능을 크게 향상시킨 것으로 나타났습니다.

### [LiRank: Industrial Large Scale Ranking Models at LinkedIn](https://arxiv.org/abs/2402.06859)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06859.png)

Vote: 4

Authors: Jonathan Hung, Chen Zhu, Sathiya Keerthi, Siyu Zhu, Lei Le, Aman Gupta, Ruoyan Wang, Dan Liu, Hailing Cheng, Fengyu Zhang, Ganesh Parameswaran, Birjodh Tiwana, Yunbo Ouyang, Mingzhou Zhou, Mohit Kothari, +, Siddharth Dangi, Sheallika Singh, Qiang Xiao, Qingquan Song, Lars Hertel, Xiaochen Hou, Fedor Borisyuk

- LinkedIn의 LiRank는 최신 모델링 아키텍처와 최적화 방법을 적용한 대규모 순위 결정 프레임워크를 생산에 투입합니다.
- 해당 프레임워크는 유명한 DCNv2 아키텍처에 주의력(attention) 및 잔류 연결(residual connections)을 추가한 Residual DCN을 비롯한 여러 모델링 개선 사항들을 공개합니다.
- 고밀도 게이팅(Dense Gating), 트랜스포머(Transformers), Residual DCN 등 최신 아키텍처를 결합하고 조정하여 통합된 모델을 만드는 데 대한 통찰을 제공합니다.
- 모델 교정(calibration)을 위한 새로운 기법을 제안하고, 탐색/활용(explore/exploit) 방법에 기반한 딥러닝을 생산 환경에 적용하는 방법을 설명합니다.
- 대규모 순위 결정 모델의 효과적인 실제 환경에서의 서빙을 가능하게 하기 위해 양자화(quantization) 및 어휘(vocabulary) 압축을 이용하여 모델을 훈련하고 압축하는 방법에 대해 상세히 설명합니다.
- 피드 순위결정, 일자리 추천, 광고 클릭률(CTR) 예측의 대규모 사용 사례에 대한 배포 설정에 대한 정보를 제공합니다.
- 다양한 A/B 테스트로부터 얻은 지식을 요약하고, 가장 효과적인 기술 접근법을 밝힙니다.
- 이러한 아이디어들은 LinkedIn의 상대적 지표 개선에 기여했으며, 그 예로 피드의 회원 세션은 0.5%, 일자리 검색 및 추천을 위한 자격 있는 지원은 1.76%, 광고 CTR은 4.3% 향상되었습니다.
- 본 논문은 대규모 딥 랭킹 시스템을 활용하는 실무자들에게 실용적인 통찰과 솔루션을 제공하기를 희망합니다.

### [Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models](https://arxiv.org/abs/2402.07865)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/bjCh3kvei_P2tYMyiViy6.png)

Vote: 4

Authors: Percy Liang, Ashwin Balakrishna, Suraj Nair, Siddharth Karamcheti, Thomas Kollar, Dorsa Sadigh

- 시각적 조건부 언어 모델(VLMs)의 설계 공간을 조사하는 연구로, 이 분야에서 VLM이 점차 증가하는 적용을 받고 있음을 소개합니다.
- 연구는 이미지 전처리, 아키텍처 및 최적화와 같은 주요 설계 결정이 충분히 탐색되지 않아 모델 성능의 결정적 요인을 이해하는 데 어려움이 있다고 지적합니다.
- 이를 해결하기 위해 연구진은 시각적 질문 응답, 언어로부터의 객체 위치 및 환영 현상과 같은 특성을 측정하는 대상 챌린지 세트를 포함한 표준화된 평가 모음을 컴파일합니다.
- 이러한 평가를 통해 VLM의 능력에 대한 세밀하고 보정된 통찰력을 제공합니다.
- 연구진은 사전 훈련된 시각적 표현과 기본 대비 지시형 언어 모델을 사용하는 것의 이점 등, 중요한 설계 축을 따라 VLM을 철저히 조사합니다.
- 분석과 함께 연구진은 통합된 VLM 평가 프레임워크, VLM 훈련을 위한 최적화된 유연한 코드, 그리고 InstructBLIP 및 LLaVa v1.5를 능가하는 7-13B 규모의 VLM 계열의 체크포인트를 포함한 세 가지 자원을 제시합니다.

### [GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting](https://arxiv.org/abs/2402.07207)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/T4qXnmi2futgpHsOowBHV.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/T4qXnmi2futgpHsOowBHV.mp4" muted="false"></video></div>

Vote: 4

Authors: Xingjian Ran, Yajiao Xiong, Xiaoyu Zhou, Ming-Hsuan Yang, Jinlin He, Deqing Sun, Yongtao Wang, Zhiwei Lin

- GALA3D는 텍스트로부터의 복합적인 3D 장면 생성을 위한 새로운 방법으로, 레이아웃-안내형 제어를 통해 생성된 3D 가우시안(GAussians with LAyout-guided control)을 제시합니다.
- 대규모 언어 모델(Large Language Models, LLMs)을 활용하여 초기 레이아웃을 생성하고, 적응형 기하학적 제약조건을 가진 3D 컨텐츠 생성을 위해 레이아웃-안내형 3D 가우시안 표현을 도입합니다.
- 객체-장면 합성 최적화 메커니즘 및 조건부 확산(diffusion)을 제안하여, 다수의 객체 간 일관된 기하학, 질감, 규모 및 정확한 상호작용을 유지하면서 실감나는 3D 장면을 협력적으로 생성합니다.
- 동시에 생성된 장면과 일치하도록 LLM에서 추출된 초기 레이아웃 선행정보를 조정합니다.
- GALA3D는 장면 수준의 3D 컨텐츠 생성과 통제 가능한 편집을 위한 사용자 친화적인 종단간 프레임워크로, 장면 내 객체 수준의 높은 충실도를 보장합니다.
- 소스 코드와 모델은 https://gala3d.github.io/에서 확인할 수 있습니다.

### [Suppressing Pink Elephants with Direct Principle Feedback](https://arxiv.org/abs/2402.07896)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/OMA6eMGb247toBR8PDMha.png)

Vote: 4

Authors: Suraj Anand, Nathan Lile, Siddharth Verma, Louis Castricato, Stella Biderman, Hailey Schoelkopf

- 기존의 언어 모델 제어 방법들, 예를 들어 RLHF와 Constitutional AI는 어떤 LLM 행동이 바람직한지 결정하고 이를 언어 모델에 학습시키는 것에 집중합니다.
- 그러나 실제로는 다양한 맥락과 필요성을 가진 환경에서 추론 시간에 LLM을 제어할 수 있는 것이 바람직합니다.
- 이 연구에서는 "Pink Elephant Problem"을 예로 들어: LLM에게 특정 주제(‘핑크 코끼리’)에 대해 논의하지 말고 선호하는 주제(‘회색 코끼리’)에 대해서만 논의하도록 지시하는 문제를 다룹니다.
- 연구자들은 Constitutional AI의 신기술을 간소화한 Direct Principle Feedback(DPF)를 사용하여 응답 순위를 매기는 단계 없이 비판과 수정에 DPO를 직접 적용합니다.
- 합성된 Pink Elephants 데이터셋에서 DPF 미세조정을 거친 후, 13B 크기의 LLaMA 2 모델이 Llama-2-13B-Chat 모델과 촉구된 기준선보다 월등히 성능이 향상되었으며, Pink Elephant Problem을 평가하기 위해 준비된 테스트 세트에서 GPT-4와 동등한 성능을 보였습니다.

### [AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts](https://arxiv.org/abs/2402.07625)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hOx7D5_NVh-A-tY2F0e4h.png)

Vote: 3

Authors: Yang Yuan, Andrew Chi-Chih Yao, Yifan Luo, Yifan Zhang

- 본 연구는 기존의 감독된 미세조정이나 인간이 주석을 단 데이터를 사용하는 훈련된 분류기를 뛰어넘어 언어 모델의 수학적 추론 능력을 향상시키기 위해 태생적 데이터 선택 전략을 소개합니다.
- 제로 샷 검증자로 기능하는 메타-프롬프트 언어 모델을 활용하여 고품질의 수학 콘텐츠를 자율적으로 평가하고 선택하는 방법을 사용합니다.
- 연구팀은 200GB가 넘는 데이터를 포함하는 오픈 소스 AutoMathText 데이터셋을 공개하였습니다.
- 연구팀은 AutoMathText 데이터셋에서 7B 파라미터 Mistral 언어 모델을 지속적으로 사전 훈련하여 이전의 지속적 사전 훈련 작업에 비해 토큰의 양을 크게 줄이면서 MATH 데이터셋의 다운스트림 성능을 대폭 향상시켰습니다.
- 제시된 방법은 기존 기준과 비교하여 사전 훈련 토큰 효율성을 2배 향상시킴으로써 모델의 수학적 추론 능력 향상에 있어 우리 접근의 잠재력을 강조합니다.
- AutoMathText 데이터셋은 https://huggingface.co/datasets/math-ai/AutoMathText에서 이용 가능하며, 코드는 https://github.com/yifanzhang-pro/AutoMathText에서 확인할 수 있습니다.

### [Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping](https://arxiv.org/abs/2402.07610)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/qCHkU9JkZAOVMFeEQLUeg.png)

Vote: 3

Authors: Li Shen, Bingzhe Wu, Haoyu Wang, Tingyang Xu, Liu Liu, Zeyu Qin, Peilin Zhao, Yatao Bian, Zhong Zhang, Guozheng Ma, Ziqiao Meng, Xueqian Wang

- 자체 정렬은 인간의 주석 비용을 줄이면서도 모델의 유망한 능력을 보장하는 효과적인 방법입니다.
- 현재 방법들은 단일 라운드에서 데이터 수집 및 훈련 단계를 완료하지만, 자체 정렬 모델의 지속적으로 향상되는 능력을 간과할 수 있습니다.
- 이 논문에서는 자체 정렬을 부트스트래핑하는 것이 모델 성능을 향상시키거나 급격히 저하시키는지에 대한 탐색을 진행했습니다.
- 연구 결과, 부트스트래핑 자체 정렬 방식이 단일 라운드 접근 방식보다 눈에 띄게 우수하며, 인텍스트 학습(In-context learning)에서 데이터 다양성을 보장한다는 것을 발견했습니다.
- 부트스트래핑의 능력을 더욱 활용하기 위해, 데이터의 훈련 순서를 조사하고 조정하였고, 이는 모델의 성능을 향상시켰습니다.
- 이러한 발견을 바탕으로, 지속적으로 향상되는 few-shot 능력을 활용하여 zero 혹은 one-shot 성능을 증진시키는 Step-On-Feet Tuning (SOFT)를 제안합니다.
- 쉽게부터 어렵게까지의 훈련 레시피를 기반으로 하여, 자체 정렬 성능을 더욱 향상시키는 SOFT+를 제안합니다.
- SOFT (SOFT+)는 다양한 분류 및 생성 작업에서 효율성을 입증하며, 모델의 지속적인 정렬 성능 향상에 대한 부트스트래핑 자체 정렬의 잠재력을 강조합니다.

