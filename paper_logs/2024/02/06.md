## Daily Papers (2024-02-06)

### [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hj34x64Rwwu65IWHLS4eX.png)

Vote: 35

Authors: Daya Guo, Mingchuan Zhang, Y. K. Li, Runxin Xu, Y. Wu, Qihao Zhu, Peiyi Wang, Junxiao Song, Zhihong Shao

- 수학적 추론은 그 복잡하고 구조화된 특성으로 인해 언어 모델에 큰 도전이 되며, 이 논문에서는 Common Crawl에서 1200억 개의 수학 관련 토큰을 사용해 DeepSeek-Coder-Base-v1.5 7B를 추가 학습시킨 DeepSeekMath 7B를 소개합니다.
- DeepSeekMath 7B는 외부 도구나 투표 기법에 의존하지 않고 경쟁 수준의 MATH 벤치마크에서 51.7%라는 인상적인 성적을 달성했으며, 이는 Gemini-Ultra와 GPT-4의 성능 수준에 근접합니다.
- DeepSeekMath 7B로부터 64개의 샘플을 자체 일관성을 통해 검증했을 때 MATH에서 60.9%의 성능을 보여줍니다.
- DeepSeekMath의 수학적 추론 능력은 두 가지 주요 요소에 기인합니다: 첫 번째, 공개적으로 이용 가능한 웹 데이터의 잠재력을 최대한 활용하기 위한 세심하게 설계된 데이터 선택 파이프라인을 활용합니다.
- 두 번째, PPO(Proximal Policy Optimization)의 메모리 사용을 동시에 최적화하면서 수학적 추론 능력을 향상시키는 그룹 상대 정책 최적화(GRPO)라는 PPO의 변형을 도입합니다.

### [Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2402.03286)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/WuqBtMvZE5Y_iIk5b8d_r.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/WuqBtMvZE5Y_iIk5b8d_r.mp4" muted="false"></video></div>

Vote: 30

Authors: Rinon Gal, Omri Kaduri, Yoad Tewel, Yuval Atzmon, Yoni Kasten, Lior Wolf, Gal Chechik

- 자연어를 사용하여 이미지 생성 과정을 유도할 수 있는 Text-to-image 모델은 새로운 창의적 유연성을 제공하지만, 다양한 프롬프트에 걸쳐 동일한 주제를 일관되게 묘사하는 것은 여전히 어려움이 있습니다.
- 기존 방법들은 특정 사용자 제공 주제를 묘사하는 새로운 단어를 가르치기 위해 모델을 세밀하게 조정하거나 모델에 이미지 조건을 추가하는 데, 이러한 방법들은 주제별로 긴 최적화 과정이나 대규모 사전 훈련을 필요로 합니다.
- 기존 방법들은 문장 프롬프트와 생성된 이미지의 일치성을 맞추는데 어려움을 겪으며, 다수의 주제를 묘사할 때도 문제가 있습니다.
- 본 논문에서는 사전 훈련된 모델의 내부 활성화를 공유함으로써 주제의 일관성 있는 생성을 가능하게 하는 교육 없는 접근방식인 ConsiStory를 제시합니다.
- ConsiStory는 주제 주도 공유 주의 블록과 대응 기반 특징 주입을 도입하여 이미지 간의 주제 일관성을 증진시킵니다.
- 또한, 주제 일관성을 유지하면서 레이아웃 다양성을 장려하는 전략을 개발하였습니다.
- ConsiStory는 기존의 베이스라인들과 비교하여 주제 일관성과 텍스트 정렬에 있어 최신 성능을 보여주며, 단일 최적화 단계도 필요로 하지 않습니다.
- 최종적으로, ConsiStory는 다중 주제 시나리오로 자연스럽게 확장할 수 있으며, 일반적인 객체에 대한 교육 없는 개인화를 가능하게 합니다.

### [BlackMamba: Mixture of Experts for State-Space Models](https://arxiv.org/abs/2402.01771)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/_hCUha2m5Pn1dGEZGL_Ze.png)

Vote: 15

Authors: Paolo Glorioso, Quentin Anthony, Yury Tokpanov, Beren Millidge

- 최근 State-space model(SSM)은 큰 규모의 언어 모델링 벤치마크에서 트랜스포머와 경쟁력 있는 성능을 보이면서도 시퀀스 길이에 따라 선형 시간 및 메모리 복잡성을 달성했다.
- Mamba라는 최근 발표된 SSM 모델은 언어 모델링과 긴 시퀀스 처리 작업 모두에서 인상적인 성능을 보였다.
- 동시에, 전문가 혼합(Mixture-of-Expert, MoE) 모델들은 더 큰 메모리 사용에도 불구하고 계산 및 추론 비용을 크게 줄이면서 뛰어난 성능을 보여주고 있다.
- 본 논문에서는 Mamba SSM과 MoE를 결합한 새로운 구조인 BlackMamba를 소개하며, 이를 통해 두 가지 장점을 모두 얻을 수 있음을 보여준다.
- BlackMamba는 Mamba와 트랜스포머 베이스라인 모두에 대해 경쟁력 있는 성능을 보이며, 추론과 훈련에 있어서 FLOP에서 우수한 성능을 나타낸다.
- 연구팀은 300B 토큰의 맞춤 데이터셋에서 340M/1.5B 및 630M/2.8B 규모의 BlackMamba 모델을 전면 훈련시키고 그 결과를 오픈소스로 공개한다.
- BlackMamba는 SSM의 선형 복잡성 생성과 MoE의 저렴하고 빠른 추론의 이점을 결합하여 가지고 있다.
- 연구팀은 모든 가중치, 체크포인트 및 추론 코드를 오픈소스로 공개하며, 추론 코드는 https://github.com/Zyphra/BlackMamba에서 확인할 수 있다.

### [OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models](https://arxiv.org/abs/2402.01739)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ckrD-RyY0OSqFChHuqTxJ.png)

Vote: 14

Authors: Yao Fu, Yang You, Zian Zheng, Jinjie Ni, Fuzhao Xue, Wangchunshu Zhou, Zangwei Zheng

- 대규모 언어 모델(LLM)에 대한 이해를 높이기 위해, 650M에서 34B 매개변수에 이르는 다양한 OpenMoE 모델들을 훈련하고 코드를 완전히 공개했습니다.
- 1조 이상의 토큰으로 훈련된 OpenMoE는 MoE 기반의 LLM이 밀집 LLM보다 비용 대비 효율성 측면에서 더 매력적임을 보여줍니다.
- 이 연구는 OpenMoE 모델 내 라우팅 메커니즘에 대한 심층적 분석을 통해 세 가지 주요 발견을 도출했습니다: 맥락 독립적 전문화, 초기 라우팅 학습, 그리고 긴 시퀀스의 끝 부분에서 탈락 경향성.
- MoE 모델 내에서 토큰을 전문가에게 할당하는 결정은 토큰의 ID에 기반하며, 맥락과는 거의 관련이 없고 사전 훈련 초기에 결정되어 크게 변하지 않는 것으로 나타났습니다.
- 이러한 라우팅의 불완전성은 멀티턴 대화와 같이 시퀀스 후반부에 나타나는 토큰의 불필요한 도태로 인해 성능 저하를 일으킬 수 있습니다.
- 위의 관찰과 분석을 바탕으로, 우리는 향후 MoE LLM 설계를 개선하기 위한 전략을 제안하여 미래의 MoE LLM 개발을 돕고자 합니다.

### [LiPO: Listwise Preference Optimization through Learning-to-Rank](https://arxiv.org/abs/2402.01878)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/dhu1o2CJpvV0x7hP83VB2.png)

Vote: 12

Authors: Misha Khalman, Zhen Qin, Xuanhui Wang, Tianqi Liu, Mohammad Saleh, Peter J. Liu, Junru Wu, Simon Baumgartner, Jiaming Shen, Jialu Liu, Yao Zhao, Rishabh Joshi

- 언어 모델(LM)을 세심하게 큐레이션된 인간의 피드백과 일치시키는 것은 실제 응용 프로그램에서 그들의 행동을 제어하는데 필수적입니다.
- 최근의 정책 최적화 방법들, DPO와 SLiC와 같은 것들이 전통적인 인간 피드백으로부터의 강화 학습(RLHF) 접근 방식에 대한 유망한 대안들로 제시되었습니다.
- 실제로, 인간 피드백은 종종 프롬프트를 읽는 비용을 분산시키기 위해 여러 응답들에 대한 순위가 매겨진 목록의 형태로 자주 제공됩니다.
- 반응 목록에 직접 맞추는 연구는 부족함에도 불구하고, 여러 반응들은 보상 모델이나 AI 피드백에 의해 순위가 매겨질 수 있습니다.
- 본 연구에서는 언어 모델 정렬을 목록 순위 문제로 형식화하고, 프롬프트에서 주어진 가능한 반응들의 순위가 매겨진 목록으로부터 정책이 보다 효과적으로 배울 수 있는 가능성을 제시하는 목록 취향 최적화(Listwise Preference Optimization, LiPO) 프레임워크를 설명합니다.
- 이 관점은 학습-순위 매기기(Learning-to-Rank, LTR)에 명시적인 연결을 가져와, 대부분의 기존 선호 최적화 작업이 특히 쌍대적인 목표들에 매핑될 수 있는 것을 보여줍니다.
- 이 연결을 따라, 목록 크기가 두 개일 때 DPO와 SLiC이 특별한 경우로서 LM 정렬을 위해 잘 연구되지 않은 순위 결정 목표들을 검토합니다.
- 특히, 더 진보된 방식으로 각 선호 쌍을 가중치하는 최신 목록 순위 결정 목표를 활용하는 특정 방법인 LiPO-{\lambda}를 강조합니다.
- LiPO-{\lambda}가 두 선호 정렬 과제에서 DPO와 SLiC을 분명한 차이로 능가할 수 있다는 것을 보여줍니다.

### [Rethinking Interpretability in the Era of Large Language Models](https://arxiv.org/abs/2402.01761)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/zCyrEzGCycDNhiVmTu6J_.png)

Vote: 11

Authors: Rich Caruana, Chandan Singh, Jeevana Priya Inala, Jianfeng Gao, Michel Galley

- 최근 수년 간 해석 가능한 기계 학습은 거대 데이터셋과 심층 신경망의 발전으로 인해 크게 주목받아 왔습니다.
- 대규모 언어 모델(Large Language Models, LLMs)은 다양한 작업에서 뛰어난 능력을 보여, 기계학습 해석 가능성에 대한 새로운 기회를 제공합니다.
- LLM은 자연어로 설명할 수 있는 능력을 통해 인간에게 제공할 수 있는 패턴의 규모와 복잡성을 확장합니다.
- 그러나 허구의 설명이나 엄청난 계산 비용과 같은 새로운 도전 과제가 발생합니다.
- 이 위치 논문에서는 LLM 해석(LLM 해석과 설명을 위해 LLM 사용)의 새로운 분야에서 현재의 평가 방법들을 검토합니다.
- LLM의 한계에도 불구하고, LLM은 LLM 자체의 감사를 포함하여 많은 응용 프로그램에서 해석 가능성을 더욱 야심찬 범위로 재정의할 기회를 가지고 있다고 주장합니다.
- LLM 해석에 대한 두 가지 신흥 연구 우선 순위를 강조합니다: LLM을 사용하여 새로운 데이터셋을 직접 분석하고 상호 작용하는 설명을 생성합니다.

### [InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions](https://arxiv.org/abs/2402.03040)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/dj8_MC-W2B_xbE8Eh4KIm.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/dj8_MC-W2B_xbE8Eh4KIm.mp4" muted="false"></video></div>

Vote: 10

Authors: Xiangyu Yue, Xiaohan Ding, Zhixin Zhang, Yiyuan Zhang, Yuhao Kang, Sanyuan Zhao

- 'InteractiveVideo'는 사용자가 비디오 생성 과정 전체를 다양한 직관적인 메커니즘(텍스트 및 이미지 프롬프트, 페인팅, 드래그 앤 드롭 등)을 통해 동적으로 지시할 수 있게 해주는 사용자 중심 프레임워크를 소개합니다.
- 본 프레임워크는 사용자의 다중 모달 지시를 생성 모델에 원활하게 통합할 수 있게 하는 Synergistic Multimodal Instruction 메커니즘을 제안하여 사용자 입력과 생성 과정 간의 협력적이고 반응적인 상호작용을 촉진합니다.
- 이러한 접근법은 사용자의 정밀하고 효과적인 지시를 통해 비디오 생성 결과를 반복적이고 세밀하게 정교화할 수 있게 합니다.
- 사용자는 참조 이미지를 그리고, 의미를 편집하며, 비디오 움직임을 조절함으로써 비디오의 핵심 측면들을 상세하게 맞춤 설정할 수 있는 유연성을 제공받습니다.
- 코드, 모델 및 데모는 https://github.com/invictus717/InteractiveVideo 에서 사용할 수 있습니다.

### [V-IRL: Grounding Virtual Intelligence in Real Life](https://arxiv.org/abs/2402.03310)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/I08Yy40JIqlh-WArD50f_.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/I08Yy40JIqlh-WArD50f_.mp4" muted="false"></video></div>

Vote: 9

Authors: Jihan Yang, Runyu Ding, Saining Xie, Ellis Brown, Xiaojuan Qi

- 인간이 거주하는 지구와 현대 인공지능 에이전트가 만들어진 디지털 영역 사이에는 감각적인 차이가 존재한다.
- 실세계 설정에서 인간처럼 유연하게 감각하고, 생각하며, 행동할 수 있는 AI 에이전트를 개발하기 위해서는 디지털과 물리적 세계 간의 현실성 격차를 극복하는 것이 중요하다.
- 실제 하드웨어와 제어에 의해 부과되는 제약 없이, 우리가 거주하는 것과 같이 풍부하고 다양한 환경에서 에이전트를 구현할 방법은 무엇일까?
- 이러한 목적으로, 우리는 V-IRL이라는 플랫폼을 소개한다: 실세계와 상호작용할 수 있는 가상이지만 현실적인 환경에서 에이전트가 확장 가능하게 상호작용할 수 있는 플랫폼.
- V-IRL은 에이전트가 다양한 실용적인 작업을 수행할 수 있도록 개발하는 놀이터로서, 또한 인지, 의사결정, 전 세계 실제 데이터와의 상호작용 능력에 걸쳐 진전을 측정하는 광대한 시험대로서 기능한다.

### [Direct-a-Video: Customized Video Generation with User-Directed Camera Movement and Object Motion](https://arxiv.org/abs/2402.03162)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/zpslm6Me0oEd4poq2bC5n.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/zpslm6Me0oEd4poq2bC5n.mp4" muted="false"></video></div>

Vote: 9

Authors: Liang Hou, Pengfei Wan, Shiyuan Yang, Di Zhang, Xiaodong Chen, Jing Liao, Chongyang Ma, Haibin Huang

- 최근 텍스트를 이용한 비디오 생성 모델이 인상적인 발전을 이루었으며, 사용자들은 객체 모션과 카메라 움직임을 독립적으로 제어할 수 있는 능력을 종종 원합니다.
- 기존 방법들은 객체 모션과 카메라 움직임을 분리하여 제어하는 데 초점을 맞추지 않아 텍스트-비디오 모델의 제어 가능성과 유연성이 제한되었습니다.
- 본 논문에서는 Direct-a-Video 시스템을 소개하며, 이는 사용자가 비디오를 연출하는 것처럼 하나 또는 여러 객체의 움직임 및/또는 카메라 움직임을 독립적으로 지정할 수 있도록 합니다.
- 객체 모션은 모델의 고유한 사전 지식을 사용하여 공간적 교차 주의 조정을 통해 제어되며, 추가 최적화가 필요하지 않습니다.
- 카메라 움직임에 대해서는 정량적 카메라 움직임 매개변수를 해석할 수 있는 새로운 시간적 교차 주의 레이어를 도입했습니다.
- 이러한 레이어들은 소규모 데이터셋에서 자가 감독 학습 방식으로 훈련될 수 있으며, 명시적인 움직임 주석이 필요하지 않습니다.
- 두 구성 요소는 개별적으로 또는 결합하여 제어할 수 있으며, 개방형 시나리오에 일반화될 수 있습니다.
- 광범위한 실험을 통해 우리의 방법의 우수성과 효과를 입증하였습니다.
- 프로젝트 페이지: https://direct-a-video.github.io/.

### [Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization](https://arxiv.org/abs/2402.03161)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/miQWUWm-g3Zp120IwSUir.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/miQWUWm-g3Zp120IwSUir.mp4" muted="false"></video></div>

Vote: 8

Authors: Yang Jin, Yuliang Liu, Hao Jiang, Kun Gai, Quzhe Huang, Kun Xu, Yang Song, Zhicheng Sun, Yadong Mu, Di Zhang, Liwei Chen, Chengru Song

- 본 논문은 시공간 역학을 모델링하는 것이 도전적인 비디오에 대한 대규모 사전 학습을 효율적으로 수행하기 위해 핵심 프레임과 시간적 움직임으로 비디오를 분해하는 새로운 접근법을 제시합니다.
- 비디오 및 이미지의 시각적 정보와 시간적 정보를 적은 수의 토큰으로 이산화함으로써, 다양한 영상 콘텐츠 생성에 유용한 비디오, 이미지 및 텍스트의 통합 생성 사전 학습이 가능합니다.
- 사전 학습된 언어 모델은 추론 시 원본 연속 픽셀 공간으로 토큰을 정교하게 복원하여 이미지 및 비디오 콘텐츠 이해와 생성에서 경쟁력 있는 성능을 발휘함을 13가지 멀티모달 벤치마크를 통해 입증했습니다.
- 이 연구의 코드와 모델은 공식 웹사이트를 통해 공개될 예정입니다.

### [Shortened LLaMA: A Simple Depth Pruning for Large Language Models](https://arxiv.org/abs/2402.02834)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/9WG9Jjj3VuYe5iPRe1HPe.png)

Vote: 8

Authors: Bo-Kyeong Kim, Junho Shin, Geonmin Kim, Hyoung-Kyu Song, Tae-Ho Kim, Shinkook Choi, Thibault Castells

- 최신 대규모 언어 모델(LLMs)의 구조화된 가지치기가 높은 계산 요구를 줄이는 방법으로 등장하였으며, 너비 가지치기는 레이어 수는 유지하면서 프로젝션 가중치 행렬(예: 어텐션 헤드 제거)의 크기를 줄이는 반면, 깊이 가지치기는 레이어나 블록을 완전히 제거하면서 남은 가중치의 크기는 그대로 유지합니다.
- 대부분의 현재 연구는 너비만을 가지치기하거나 너비와 깊이 가지치기를 혼합하는데 초점을 맞추고 있지만, 두 단위(너비 대 깊이)가 LLM 추론 효율성에 미치는 영향에 대한 비교 분석은 많지 않습니다.
- 본 연구에서는 간단한 깊이 가지치기 접근 방식이 다양한 zero-shot 작업 성능에 있어 최근의 너비 가지치기 방법들과 경쟁할 수 있음을 보여줍니다.
- 특히 LLM 운영을 위해 제한된 배치 크기가 요구되는 메모리 제약 조건 하에서는 너비 가지치기가 비효율적인 반면, 우리의 가지치기 방법은 추론 속도를 향상시킵니다.
- 연구 결과는 대규모 언어 모델을 로컬 및 엣지 기기에 배포하는 데 도움이 될 것으로 기대됩니다.

### [Rethinking Optimization and Architecture for Tiny Language Models](https://arxiv.org/abs/2402.02791)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jQ4jwNpsjztuXE1JI2bGy.png)

Vote: 7

Authors: Shangling Jui, Yehui Tang, Zheyuan Bai, Yi-Qi Hu, Fangcheng Liu, Yunsheng Ni, Sichao Liu, Kai Han, Yuchuan Tian, Yunhe Wang

- 이 연구에서는 1B 매개변수를 가진 소형 언어 모델에 대한 연구를 바탕으로, 각 구성 요소의 영향을 분석하기 위해 일련의 경험적 연구를 신중하게 설계하였습니다.
- 세 가지 주요 관점인 신경 구조, 매개변수 초기화, 최적화 전략에 대해 논의되었습니다.
- 토크나이저 압축, 아키텍처 조정, 매개변수 상속, 다중 라운드 트레이닝 등 소형 언어 모델에 특히 효과적인 설계 공식이 실증적으로 증명되었습니다.
- 이러한 공식을 따라 PanGu-pi-1B Pro와 PanGu-pi-1.5B Pro를 1.6T 다국어 코퍼스에서 트레이닝 하여, 모델 최적화와 아키텍처를 개선했습니다.
- 실험 결과, PanGu-pi-1B Pro는 벤치마크 평가 세트에서 평균 8.87의 뚜렷한 성능 향상을 보였으며, PanGu-pi-1.5B Pro는 더 큰 모델 크기를 가진 다양한 SOTA 모델들을 능가하는 우수한 성능을 입증했습니다.
- 코드는 곧 공개될 예정이며 (https://github.com/YuchuanTian/RethinkTinyLM), 이는 소형 언어 모델에 대한 최적화와 아키텍처를 재고하기 위한 중요한 기여로 볼 수 있습니다.

### [Code Representation Learning At Scale](https://arxiv.org/abs/2402.01935)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/UTrwanKFD7-DrbqYNWT5S.png)

Vote: 6

Authors: Wasi Ahmad, Ramesh Nallapati, Hantian Ding, Ming Tan, Dejiao Zhang, Xiaofei Ma, Dan Roth, Bing Xiang

- 최근 연구들은 대규모로 훈련된 코드 언어 모델들이 코드 생성과 같은 다운스트림 작업에서 상당한 성능 향상을 보임을 보여주고 있으나, 기존의 코드 표현 학습 작업 대부분은 매우 제한된 사전학습 코퍼스를 사용하여 1억 개 매개변수 규모 모델을 훈련합니다.
- 본 연구는 두 단계 사전학습 방식을 통해 방대한 양의 코드 데이터를 통한 코드 표현 학습을 진행하며, 우선 무작위 마스킹 언어 모델링과 프로그래밍 언어의 구조 측면을 활용하여 인코더를 훈련시킵니다.
- 다음으로, 비지도 방식으로 구축된 어려운 부정 사례와 어려운 긍정 사례를 활용하여 대조 학습을 통해 표현 방법을 강화합니다.
- 이를 통해, 광범위한 다운스트림 작업에서 기존 모델들을 큰 차이로 지속적으로 능가하는 인코더 모델을 마련하였습니다.
- 성공적인 코드 표현 학습에 기여하는 요인들을 이해하기 위해, (i) 소스 코드에 대한 맞춤형이고 효과적인 토큰 레벨에서의 노이즈 제거 체계; (ii) 어려운 부정 사례와 어려운 긍정 사례의 중요성; (iii) 제안된 쌍방향 대조 학습이 어떻게 통합적인 의미 검색 성능을 향상시키는지; (iv) 사전학습 체계가 어떻게 모델 크기에 따라 다운스트림 작업 성능에 영향을 미치는지에 대해 상세한 실험을 진행하고 그 결과를 공유합니다.

### [Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities](https://arxiv.org/abs/2402.01831)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/B2LoHl9IZO_lH8OHEOGo5.png)

Vote: 6

Authors: Rohan Badlani, Wei Ping, Bryan Catanzaro, Zhifeng Kong, Rafael Valle, Arushi Goel

- 이 논문에서는 대화 형태를 포함한 비음성 소리와 비언어적 음성을 이해할 수 있는 강력한 오디오 이해 능력을 갖춘 '오디오 플라밍고'라는 새로운 오디오 언어 모델을 제안합니다.
- 모델은 상황 내 학습과 검색을 통해 본 적 없는 작업에 빠르게 적응할 능력을 갖추고 있습니다.
- 다양한 오디오 이해 작업에 대한 폭넓은 평가를 통해 우리의 방법이 효과적임을 확인하고, 새로운 최첨단 벤치마크를 설정합니다.
- 훈련 기법, 아키텍처 설계, 데이터 전략을 통해 모델이 위에 언급된 능력을 갖출 수 있도록 향상시켰습니다.
- 오디오 플라밍고는 강력한 멀티턴 대화 능력을 가지고 있으며, 이는 음성 및 음향 기반 실제 세계 응용 프로그램에 중요합니다.

### [DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing](https://arxiv.org/abs/2402.02583)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/PVfeWx6xlO06qMyfR25Sc.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/PVfeWx6xlO06qMyfR25Sc.mp4" muted="false"></video></div>

Vote: 5

Authors: Jiechong Song, Xintao Wang, Chong Mou, Jian Zhang, Ying Shan

- 대규모 텍스트-이미지(T2I) 확산 모델은 최근 몇 년 동안 이미지 생성 분야에 혁명을 가져왔지만 미세한 이미지 편집에 있어 여러 도전 과제가 남아 있다.
- 본 논문에서 제안하는 DiffEditor는 복잡한 시나리오에서 편집 정확성이 떨어지고 예기치 않은 아티팩트가 발생하는 문제, 편집 작업의 조화롭지 못한 유연성 부족을 해결한다.
- 이미지 프롬프트를 도입하여 텍스트 프롬프트와 협력함으로써 편집 내용을 더욱 잘 기술할 수 있게 하여 미세한 이미지 편집에 있어서의 성능을 높였다.
- 콘텐츠 일관성을 유지하면서 유연성을 증가시키기 위해, 확산 샘플링 과정에서 지역적으로 확률 미분 방정식(SDE)를 일반 미분 방정식(ODE) 샘플링에 결합하였다.
- 지역 점수 기반 그라디언트 가이드와 시간 여행 전략을 확산 샘플링에 추가함으로써 편집 품질을 더욱 향상시켰다.
- 단일 이미지 내 편집(예: 객체 이동, 크기 조정, 내용 드래그)과 이미지 간 편집(예: 외관 교체, 객체 붙여넣기)을 포함한 다양한 미세한 이미지 편집 작업에서 효율적으로 최신 성능을 달성할 수 있음을 방대한 실험을 통해 입증하였다.
- 소스 코드는 https://github.com/MC-E/DragonDiffusion에서 공개되었다.

