## Daily Papers (2024-02-16)

### [Chain-of-Thought Reasoning Without Prompting](https://arxiv.org/abs/2402.10200)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/SXhpWfFao_v5wL_5OMJM1.png)

Vote: 33

Authors: Xuezhi Wang, Denny Zhou

- 기존의 큰 언어 모델(LLMs)의 이성적 추론 능력 개선 연구는 주로 수작업의 프롬프트 엔지니어링을 필요로 하는 특정 프롬프트 기법, 예를 들어 few-shot 또는 zero-shot chain-of-thought (CoT) 프롬프트에 중점을 두었습니다.
- 우리의 연구는 새로운 접근 방식으로, LLMs가 프롬프트 없이 효과적으로 이성적 추론을 할 수 있는지에 대한 의문을 제기하였습니다.
- 연구 결과, 단순히 해독 과정을 변경함으로써 사전 훈련된 LLMs에서 CoT 추론 경로를 자극할 수 있다는 흥미로운 발견을 하였습니다.
- 우리는 전통적인 탐욕적 해석 대신, top-k 대체 토큰을 조사하여, 이러한 시퀀스에서 CoT 경로가 종종 내재하고 있는 것을 발견했습니다.
- 이 접근법은 프롬프트의 혼란 요소를 우회할 뿐만 아니라 LLMs의 본질적인 추론 능력을 평가할 수 있게 합니다.
- 또한, 해석 경로에 CoT가 존재하면 모델의 해석된 답변에 대한 신뢰도가 높아짐을 관찰하였으며, 이 신뢰도 지표는 CoT와 비-CoT 경로를 효과적으로 구분합니다.
- 다양한 이성적 추론 벤치마크에 대한 광범위한 경험적 연구는 제안된 CoT-디코딩이 표준 탐욕적 디코딩보다 훨씬 뛰어남을 보여줍니다.

### [Generative Representational Instruction Tuning](https://arxiv.org/abs/2402.09906)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/v8MPsPebHntTeIoX15NXP.png)

Vote: 19

Authors: Nan Yang, Amanpreet Singh, Niklas Muennighoff, Furu Wei, Tao Yu, Liang Wang, Hongjin Su, Douwe Kiela

- 모든 텍스트 기반 언어 문제는 생성 혹은 임베딩으로 축소될 수 있으며, 현재 모델들은 그 중 하나에서만 잘 작동합니다.
- 우리는 대규모 언어 모델을 사용하여 지시사항을 통해 생성 및 임베딩 작업을 구분하여 처리할 수 있도록 하는 생성적 표현 지시 조율(GRIT)을 소개합니다.
- GRIT을 사용한 결과, 우리의 GritLM 7B 모델은 Massive Text Embedding Benchmark(MTEB)에서 새로운 최첨단 기술을 세우고, 그 크기의 다른 모델보다 다양한 생성 작업에서 더 우수한 성능을 보였습니다.
- 더 나아가, GritLM 8x7B를 확장하여 시도한 모든 공개 생성 언어 모델을 능가하면서도 여전히 최고의 임베딩 모델 중 하나입니다.
- 중요하게, GRIT은 오직 생성 혹은 임베딩 데이터에만 훈련하는 것과 동일한 결과를 보이므로, 성능 손실 없이 두 가지를 통합할 수 있습니다.
- GRIT을 통한 통합은 별도의 검색 및 생성 모델이 필요하지 않아 긴 문서에 대한 검색-보강 생성(Retrieval-Augmented Generation, RAG)을 60% 이상 가속시키는 등의 이점이 있습니다.
- 모델, 코드 등은 https://github.com/ContextualAI/gritlm에서 무료로 이용할 수 있습니다.

### [A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/wLbt6phuvCPhbqe5nl0m6.png)

Vote: 14

Authors: John Canny, Kuang-Huei Lee, Hiroki Furuta, Ian Fischer, Xinyun Chen

- 현재의 대형 언어 모델들은 최대 문맥 길이 제한을 갖고 있으며 긴 입력 자료를 효율적으로 처리할 수 없는 단점이 있습니다.
- 이러한 제약을 극복하기 위해, 우리는 실험에서 효과적 문맥 길이를 최대 20배까지 확장시킨 ReadAgent, 즉 대형 언어 모델 기반 시스템을 제안합니다.
- ReadAgent는 사람이 긴 문서를 읽는 방식을 모방하여, 특정 내용을 어떻게 기억할지 결정하고, 이러한 기억을 짧은 에피소드 기억으로 압축하는 간략화 메모리 시스템으로 구현되었습니다.
- 또한, ReadAgent는 특정 작업을 완성하기 위해 원본 텍스트에서 관련 세부 정보를 상기시키기 위해 원문을 조회하는 작업을 수행합니다.
- QuALITY, NarrativeQA, QMSum과 같은 세 가지 긴 문서 독해 과제에서 기존 시스템보다 우수한 성능을 보이는 ReadAgent를 평가했습니다.
- 이 시스템은 효과적인 문맥 창을 3배에서 20배까지 확장하며 베이스라인을 능가하는 결과를 보여줍니다.

### [How to Train Data-Efficient LLMs](https://arxiv.org/abs/2402.09668)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/_ZlqeDheDmDWlrTukQ2T6.png)

Vote: 13

Authors: Jianmo Ni, Julian McAuley, Derek Zhiyuan Cheng, James Caverlee, Ed H. Chi, Lichan Hong, Benjamin Coleman, Noveen Sachdeva, Wang-Cheng Kang

- 대규모 언어 모델(LLM)의 훈련은 많은 비용이 들지만 본 연구에서는, 모델 품질과 훈련 자원/데이터 소비의 파레토 최전선을 최적화하는 데이터 효율적인 사전 훈련 접근 방식을 탐구한다.
- 훈련 데이터의 질을 평가하기 위해 계산 비용이 많이 드는 데이터 품질 추정과 기능 공간에서의 포괄성 및 다양성을 극대화하는 데이터 선택 루틴 간의 트레이드오프를 이해하고자 한다.
- 첫 번째 기술인 Ask-LLM은 지시어 기반으로 튜닝된 LLM의 제로샷 추론 기능을 이용하여 훈련 데이터 예시의 품질을 직접 평가한다.
- 포괄성을 목표로, Density 샘플링은 데이터 분포를 모델링하여 다양한 샘플을 선택한다.
- 19가지 샘플러를 비교하고 수백 개의 평가 작업 및 사전 훈련 실행을 통해, Ask-LLM과 Density가 각각의 범주에서 가장 효과적인 방법임을 발견했다.
- 포괄적 샘플링은 전체 데이터의 성능을 회복할 수 있으며, Ask-LLM 데이터로 훈련된 모델은 전체 데이터 훈련보다 일관되게 우수한 성능을 보이며, 원래 데이터셋의 90%를 거부하더라도 최대 70% 빠르게 수렴한다.

### [Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation](https://arxiv.org/abs/2402.10210)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/bTNIZh6e6_wDHe3H5IxpN.png)

Vote: 12

Authors: Quanquan Gu, Kaixuan Ji, Huizhuo Yuan, Zixiang Chen

- 확산 모델의 파인튜닝은 생성 인공지능 분야에서 아직 덜 탐구된 분야이며, 특히 대규모 언어 모델(LLM)의 놀라운 발전에 비해 더욱 그러하다.
- 최첨단 확산 모델인 Stable Diffusion (SD)과 SDXL은 감독된 파인튜닝에 의존하지만, 일정량의 데이터를 본 이후 성능이 정체하는 경향이 있다.
- 최근 인간의 선호도 데이터를 사용하여 확산 모델을 파인튜닝하기 위해 강화학습(RL)이 적용되었으나, 각 텍스트 프롬프트마다 최소한 두 개의 이미지(“이기는” 이미지와 “지는” 이미지)가 필요하다.
- 본 논문에서는 확산 모델이 이전 버전과 경쟁함으로써 반복적인 자가 개선 과정을 촉진하는 새로운 기법인 '셀프플레이 파인튜닝' 기술인 SPIN-Diffusion를 소개한다.
- 우리의 접근 방식은 전통적인 감독 학습 및 RL 전략에 대한 대안을 제시하며, 모델 성능과 정렬을 크게 향상시킨다.
- Pick-a-Pic 데이터셋에 대한 실험에서 SPIN-Diffusion은 첫 번째 반복부터 기존의 감독된 파인튜닝 방법보다 인간의 선호도 정렬 및 시각적 매력 측면에서 뛰어남을 보여준다.
- 두 번째 반복으로는 모든 메트릭에 걸쳐 RLHF 기반 방법보다 뛰어난 성능을 달성하며, 더 적은 데이터를 사용하여 이 결과를 달성한다.

### [BitDelta: Your Fine-Tune May Only Be Worth One Bit](https://arxiv.org/abs/2402.10193)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/H6sHy44ZNLAdD61WPi3y6.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/H6sHy44ZNLAdD61WPi3y6.mp4" muted="false"></video></div>

Vote: 10

Authors: Tri Dao, Kai Li, Guangxuan Xiao, Jason D. Lee, Song Han, Tianle Cai, James Liu

- 대규모 언어 모델(LLMs)은 대규모 인터넷 데이터셋에서 사전 학습 후, 다운스트림 태스크를 위해 파인튜닝 되는 두 단계로 훈련됩니다.
- 사전 학습에 비해 파인튜닝에서 새로운 정보가 상대적으로 작다고 가정, 이 연구는 파인튜닝이 모델에 추가하는 정보의 압축 가능성을 탐구합니다.
- 파인튜닝된 모델의 가중치를 사전 트레이닝된 구성 요소와 추가적인 델타 값으로 분해하고, 'BitDelta'라는 방법을 제안하여 성능 저하 없이 이 델타를 1비트로 양자화하는 데 성공했습니다.
- 비트델타의 발견은 파인튜닝 동안 추가되는 정보의 중복성 가능성을 제시하며, 파인튜닝된 모델의 멀티-테넌트 서비스 및 스토리지에 중요한 영향을 끼칩니다.
- 단일 고정밀 베이스 모델에 다수의 1비트 델타를 사용함으로써 GPU 메모리 요구 사항을 10배 이상 줄여주는데, 이는 멀티-테넌트 환경에서 세대 대기 시간을 향상시킬 수 있습니다.
- Llama-2 및 Mistral 모델 패밀리를 통한 실험과 70B 파라미터까지의 모델에서 비트델타를 검증하여 모든 테스트 설정에서 성능 저하가 최소화됨을 보여줍니다.

### [Zero-Shot Unsupervised and Text-Based Audio Editing Using DDPM Inversion](https://arxiv.org/abs/2402.10009)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2Lf17MZGJO_tBsmEfZOU2.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2Lf17MZGJO_tBsmEfZOU2.mp4" muted="false"></video></div>

Vote: 9

Authors: Hila Manor, Tomer Michaeli

- 최근 이미지 분야에서 큰 발전을 이룬 제로샷(Zero-Shot) 방식을 이용한 시그널 편집이 오디오 분야로 확장되지 못했었다.
- 본 논문에서는 사전 훈련된 확산 모델(Diffusion Models) 위에 DDPM(Denoising Diffusion Probabilistic Models) 인버전을 활용하여 오디오 신호를 편집하는 두 가지 제로샷 편집 기술을 탐구하였다.
- 첫 번째 방법은 이미지 분야에서 채택된 텍스트 기반 편집이며, 두 번째 방법은 감독 없이 의미 있는 편집 방향을 발견하는 새로운 접근법이다.
- 음악 신호에 적용했을 때, 이 방법은 특정 악기의 참여 조정부터 멜로디에 대한 즉흥 연주까지 음악적으로 흥미로운 수정을 가능하게 하였다.
- 오디오 편집 샘플은 https://hilamanor.github.io/AudioEditing/ 에서, 코드는 https://github.com/hilamanor/AudioEditing/ 에서 찾아볼 수 있다.

### [Data Engineering for Scaling Language Models to 128K Context](https://arxiv.org/abs/2402.10171)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ehuohhxYHTO_a2Y9CRP6j.png)

Vote: 9

Authors: Yao Fu, Rameswar Panda, Hao Peng, Xinyao Niu, Xiang Yue, Hannaneh Hajishirzi, Yoon Kim

- 연구에서는 128K까지의 언어 모델 컨텍스트 길이를 확장하기 위해 연속적인 사전 훈련 레시피에 중점을 두고 데이터 엔지니어링에 관해 다루었다.
- 연구팀은 대규모 사전 훈련을 통해 이미 획득된 장문의 컨텍스트 모델링 능력, 특히 임의의 입력 위치에서 정보를 활용하는 능력을, 적절한 데이터 혼합에 대한 가벼운 지속적 사전 훈련을 통해 훨씬 더 긴 컨텍스트(예: 4K에서 128K)로 쉽게 확장할 수 있다고 가설을 세웠다.
- 연속 사전 훈련을 위한 데이터의 양과 질에 대해 조사한 결과, 128K 컨텍스트 내에서 정보를 검색할 수 있도록 모델을 가능하게 하는 데는 5억 개에서 50억 개의 토큰이 충분하다는 것을 발견했다.
- 데이터의 질에 관한 연구 결과에서는 도메인 균형과 길이 업샘플링이 모두 중요한 것으로 강조되었으며, 특정 도메인에 대한 데이터를 무분별하게 업샘플링하는 기존 작업의 흔한 관행이 최적의 성능을 내지 못한다는 것을 밝혔다.
- 연구팀은 균형 잡힌 도메인 혼합 데이터 10억에서 50억 개 토큰에 전 모델을 지속적으로 사전 훈련시키는 방법이 언어 모델의 컨텍스트 길이를 128K까지 확장하기 위한 효과적이고 저렴한 전략임을 보여주었다.
- 이 레시피는 강력한 오픈 소스 장문 컨텍스트 모델을 능가하고 GPT-4 128K와 같은 최첨단 모델과의 격차를 좁힐 수 있는 성능을 입증하였다.

### [GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering](https://arxiv.org/abs/2402.10128)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/NN4_VR1-XmfJZkxrRBV9V.png)

Vote: 8

Authors: Abdullah Hamdi, Jinjie Mai, Bernard Ghanem, Ruoshi Liu, Guocheng Qian, Luke Melas-Kyriazi, Andrea Vedaldi, Carl Vondrick

- 이 논문은 3D 장면 모델링에 일반 지수 함수(GEF)를 활용한 새로운 표현 방식인 GES(Generalized Exponential Splatting)를 소개하며, 적은 수의 입자를 이용해 효과적으로 씬을 표현함으로써 기존의 가우시안 스플래팅 방법보다 효율성이 뛰어남을 보여준다.
- 가우시안 스플래팅의 대체 가능한 플러그 앤 플레이 능력을 갖추고 있으며, 주로 가우시안들이 낮은 통과 특성으로 정확히 표현하기 어려운 날카로운 에지를 가진 신호를 더 정확하게 재현할 수 있다.
- 이론적, 실증적인 검증을 통해 GEF가 자연스럽게 발생하는 신호(예: 사각형, 삼각형, 포물선 신호)를 가우시안보다 더 잘 적합시키며, 가우시안 스플래팅의 메모리 풋프린트를 증가시키는 다량의 분할 작업의 필요성을 감소시킴을 증명한다.
- 주파수 조절된 손실 함수를 도입하여 신규 시점 합성 벤치마크에서 경쟁력 있는 성능을 달성하면서도, 가우시안 스플래팅 필요 메모리의 절반 이하를 사용하고 렌더링 속도를 최대 39%까지 향상시킨다.
- 프로젝트 웹사이트 https://abdullahamdi.com/ges 에서 코드를 제공한다.

### [OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset](https://arxiv.org/abs/2402.10176)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/umTGWmecT4FPTVRA7AWl2.png)

Vote: 8

Authors: Ivan Moshkov, Shubham Toshniwal, Igor Gitman, Sean Narenthiran, Fei Jia, Daria Gitman

- 최근 인공지능 언어모델(Large Language Models, LLMs)을 훈련시키는데 생성된 데이터셋의 잠재력을 나타내는 연구가 보여졌으며, 특히 목표된 기술을 습득하는데 유용함을 보였다.
- 기존의 대규모 수학 지도 튜닝 데이터셋인 MetaMathQA와 MAmmoTH는 상용 라이선스를 가진 폐쇄소스 LLMs의 출력을 사용하여 구축되었다.
- 이제 오픈소스 LLMs의 수학 능력이 최고의 폐쇄소스 LLMs, 예를 들어 GPT-4에 비해 크게 떨어진다는 인식이 오픈소스 LLM 사용을 제한하는 주요 이유였다.
- 오픈소스 LLM의 최근 진전, 제안된 프롬프트의 새로움, 그리고 일부 무리한 확장에 기반하여, 저자들은 180만 개의 문제-해결 쌍으로 구성된 OpenMathInstruct-1이라는 수학 지도 튜닝 데이터셋을 구축했다.
- 이 데이터셋은 인기 있는 수학 추리 벤치마크인 GSM8K와 MATH를 위한 코드 인터프리터 해결책을 집합하여 Mixtral 모델을 이용해 생성되었다. Mixtral 모델은 최근 발표된 개방형 라이선스 모델이다.
- OpenMathInstruct-1의 하위세트로 훈련된 최고의 모델인 OpenMath-CodeLlama-70B는 GSM8K에서 84.6%, MATH에서 50.7%의 점수를 달성하여, 최고의 gpt-distilled 모델과 경쟁력이 있다.
- 저자들은 코드, 모델, 그리고 OpenMathInstruct-1 데이터셋을 상업적으로 허용하는 라이선스 하에 공개했다.

### [DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization](https://arxiv.org/abs/2402.09812)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/87E2ZReTwlLliM2vVWDj1.png)

Vote: 7

Authors: Jisu Nam, Heesu Kim, Siyoon Jin, Seungryong Kim, Seunggyu Chang, DongJae Lee

- 텍스트에서 이미지로의(T2I) 개인화의 목표는 사용자가 제공한 참조 개념을 맞춤화하여 텍스트 명령과 일치하는 다양한 이미지를 생성하는 것입니다.
- 기존의 방법들은 참조 개념을 고유한 텍스트 임베딩으로 표현하는데, 이는 종종 참조하는 외형을 정확하게 모방하는데 실패합니다.
- 이를 해결하기 위해, 참조 이미지를 타겟 이미지 복원 과정에 명시적으로 조건을 추가하고, 키-값 교체라는 방법인데, 이전 연구들은 미리 학습된 T2I 모델의 구조 경로를 방해한다는 단점이 있습니다.
- 우리는 T2I 개인화를 의미적 매칭으로 재정의하는 새로운 플러그인 방법인 DreamMatcher를 제안합니다.
- DreamMatcher는 의미적으로 매칭된 참조 값으로 타겟 값을 대체하며, 동시에 구조 경로는 변경하지 않아 다양한 구조를 생성할 수 있는 미리 학습된 T2I 모델의 다재다능한 기능을 유지합니다.
- 우리는 또한 개인화된 개념을 타겟 프롬프트로 인해 도입된 관련 없는 영역으로부터 격리시키는 의미론적으로 일관된 마스킹 전략을 도입합니다.
- 기존 T2I 모델들과 호환되며, DreamMatcher는 복잡한 시나리오에서 상당한 향상을 보여줍니다.
- 다양한 분석을 통해 우리의 방식이 효과적임을 입증합니다.

### [Rolling Diffusion Models](https://arxiv.org/abs/2402.09470)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/-uJZHbJolzim5xZ-WYbos.png)

Vote: 5

Authors: Emiel Hoogeboom, Jonathan Heek, Tim Salimans, David Ruhe

- 최근 확산 모델이 동영상, 유체 역학 시뮬레이션, 기후 데이터와 같은 시간적 데이터에 점차 적용되고 있다.
- 이러한 방법들은 일반적으로 확산 과정에서 연속되는 프레임들에 동등하게 노이즈의 양을 처리한다.
- 본 논문에서는 슬라이딩 윈도우 복원 과정을 사용하는 새로운 접근법인 Rolling Diffusion을 탐구한다.
- 이 방법은 시간이 지날수록 프레임에 점차 많은 노이즈를 할당함으로써, 확산 과정에서 시간에 따른 오염을 다르게 처리한다.
- 생성 과정이 전개됨에 따라 미래에 대한 불확실성이 증가함을 반영하여 뒤에 나타나는 프레임에 더 많은 노이즈를 지정한다.
- 실증적으로, 복잡한 시간적 역학을 가진 경우 Rolling Diffusion이 표준 확산 모델보다 우수함을 보여준다.
- 특히 이 결과는 Kinetics-600 동영상 데이터셋을 사용한 비디오 예측 작업과 혼돈 유체 역학 예측 실험에서 입증되었다.

### [Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling](https://arxiv.org/abs/2402.10211)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/CHFdZlOGxxn_XoJaKVOkc.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/CHFdZlOGxxn_XoJaKVOkc.mp4" muted="false"></video></div>

Vote: 4

Authors: Lerrel Pinto, Raunaq Bhirangi, Chenyu Wang, Tess Hellebrekers, Carmel Majidi, Abhinav Gupta, Venkatesh Pattabiraman

- 원시 센서 데이터의 연속적인 시퀀스로부터 추론하는 것은 의료 기기에서 로봇공학에 이르기까지 다양한 분야에 걸쳐 일반적인 문제입니다.
- 긴 센서 데이터 시퀀스를 사용하여 바람직한 물리적 양의 시퀀스를 예측하는 문제들은 종종 복잡하지만, 고전적 접근방식은 실제 센서 사용 시 충분하지 못합니다.
- 이러한 센서들은 대개 비선형적이고, 외부 변수의 영향을 받으며, 데이터 의존적 드리프트를 보입니다.
- 예측 작업은 정확한 라벨을 얻기 위해 비싼 장비가 필요하기 때문에 작은 레이블이 있는 데이터셋에서 더욱 복잡해집니다.
- 본 연구에서는 연속적인 순차 예측을 위한 새롭고 개념적으로 단순한 기술인 Hierarchical State-Space Models(HiSS)를 제시합니다.
- HiSS는 구조화된 상태 공간 모델을 서로 겹쳐 시간적 계층을 만듭니다.
- HiSS는 촉각 기반 상태 예측부터 가속도계 기반 관성 측정에 이르기까지 다양한 실제 센서 데이터셋에 걸쳐 최소 23% 이상의 평균제곱오차(MSE) 개선을 보인 상태의 최신 시퀀스 모델들을 능가합니다.
- 실험을 통해 HiSS는 작은 데이터셋으로의 효율적인 확장 가능성과 기존 데이터 필터링 기술과의 호환성을 보여줍니다.
- 연구에 사용된 코드, 데이터셋 및 동영상은 https://hiss-csp.github.io에서 확인할 수 있습니다.

