## Daily Papers (2024-02-14)

### [BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data](https://arxiv.org/abs/2402.08093)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/8T118RF8KcLYokCd6-LR-.png)

Vote: 25

Authors: Yang Li, Soledad López Gambino, Kayeon Yoo, Fan Yang, Haohan Guo, Fatih Beyhan, Álvaro Martín-Cortinas, Ammar Abbas, Elena Sokolova, Arnaud Joly, Thomas Drugman, Bartosz Putrycz, Sri Karlapati, Mateusz Łajszczak, Alexis Moinet, Arent van Korlaar, Ewa Muszyńska, Adam Michalski, Guillermo Cámbara

- 이 연구에서는 'Big Adaptive Streamable TTS with Emergent abilities'를 의미하는 BASE TTS라는 새로운 텍스트-음성 변환(TTS) 모델을 소개합니다.
- BASE TTS는 10만 시간 분량의 공개 도메인 음성 데이터로 훈련되었으며, 음성의 자연스러움 측면에서 새로운 기준을 세웠습니다.
- 10억 개의 매개변수를 가진 자기회귀 Transformer 모델은 원시 텍스트를 디스크리트 코드(“speechcodes”)로 변환하고, 이어서 컨볼루션 기반 디코더가 이 코드를 점진적이고 스트리밍 가능한 방식으로 파형으로 전환합니다.
- 특히, speechcodes는 speaker ID 분리와 바이트 쌍 인코딩을 이용한 압축을 특징으로 하는 새로운 음성 토큰화 기술을 사용하여 구축되었습니다.
- 대량의 데이터로 훈련시 큰 언어 모델에 보고된 '긴급 능력'처럼, BASE TTS는 10K 이상의 시간과 5억 개 이상의 매개변수를 갖춘 모델이 텍스트 복잡한 문장에 대한 자연스러운 억양을 내기 시작한다는 것을 보여줍니다.
- TTS의 이러한 '긴급 능력'을 측정하기 위해 특별히 만든 데이터셋을 설계하고 공유합니다.
- YourTTS, Bark 및 TortoiseTTS와 같은 공개적으로 사용 가능한 대규모 텍스트-음성 변환 시스템을 포함한 베이스라인과 비교하여 평가함으로써 BASE TTS의 상태-아트 자연성을 선보입니다.
- 모델이 생성한 오디오 샘플은 https://amazon-ltts-paper.com/에서 들을 수 있습니다.

### [Mixtures of Experts Unlock Parameter Scaling for Deep RL](https://arxiv.org/abs/2402.08609)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Cl2FukVC-wvmeieHi8fcU.png)

Vote: 19

Authors: Timon Willi, Gintare Karolina Dziugaite, Doina Precup, Pablo Samuel Castro, Johan Obando-Ceron, Clare Lyle, Jakob Foerster, Ghada Sokar, Jesse Farebrother

- 최근 감독 및 자기 감독 학습 모델의 빠른 진보는 경험적 스케일링 법칙에 의해 예측됩니다: 모델의 성능은 그 크기에 비례해 증가합니다.
- 그러나 강화 학습 분야에서는 모델의 매개변수 수를 증가시키면 최종 성능이 종종 저하되어 아날로그 스케일링 법칙을 찾기 어려웠습니다.
- 본 논문에서는 전문가의 혼합(MoE) 모듈, 특히 Soft MoE(Puigcerver et al., 2023)를 값 기반 네트워크에 결합하여 매개 변수 확장성이 더 높은 모델을 실현함을 보여줍니다.
- 다양한 훈련 체제와 모델 크기에서 크게 성능이 향상되어 이 작업이 강화 학습에 대한 스케일링 법칙을 개발하는 데 강력한 실증적 증거를 제공합니다.

### [World Model on Million-Length Video And Language With RingAttention](https://arxiv.org/abs/2402.08268)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2VIv4bRG5A9syqw3gFIoK.png)

Vote: 16

Authors: Wilson Yan, Pieter Abbeel, Hao Liu, Matei Zaharia

- 현재 언어 모델은 단어로 쉽게 설명되지 않는 세계의 측면을 이해하는 데 부족하며, 긴 형식의 복잡한 작업을 수행하는데 어려움이 있다.
- 비디오 시퀀스는 언어와 정적 이미지에 없는 소중한 시간 정보를 제공하기 때문에 언어와 함께 모델링하기에 매력적이다.
- 이러한 모델은 인간의 텍스트 지식과 물리적 세계에 대한 이해를 발전시킬 수 있으며, 인간을 돕는 더 넓은 AI 기능을 가능하게 할 수 있다.
- 천만 길이의 비디오와 언어 시퀀스에서 학습하는 것은 메모리 제약, 계산 복잡성 및 제한된 데이터셋으로 인해 도전적이다.
- 우리는 다양한 비디오와 책으로 구성된 대규모 데이터셋을 만들고, RingAttention 기술을 사용하여 긴 시퀀스에 대해 확장 가능한 학습을 수행하며, 컨텍스트 크기를 4K에서 100만 토큰까지 점진적으로 확대한다.
- 우리는 어려운 검색 작업 및 긴 비디오 이해에서 새로운 기준을 설정하는, 긴 비디오 및 언어 시퀀스에 대한 가장 큰 컨텍스트 크기 트랜스포머를 학습한다.
- 다른 시퀀스 길이 혼합을 위한 마스크 시퀀스 패킹 사용, 언어 및 비전의 균형을 맞추기 위한 손실 가중치, 긴 시퀀스 채팅을 위한 모델 생성 QA 데이터셋 등 비전-언어 학습 도전 과제를 극복하기 위한 솔루션을 제시한다.
- RingAttention, 마스크 시퀀스 패킹 등의 핵심 기능을 가진 수백만 길이의 멀티모달 시퀀스를 위한 최적화된 구현을 제공한다.
- 1M 토큰 이상의 긴 텍스트 문서(LWM-Text, LWM-Text-Chat)와 비디오(LWM, LWM-Chat)를 처리할 수 있는 7B 파라미터 모델의 패밀리를 완전히 오픈 소스화한다.
- 이 연구는 인간 지식과 멀티모달 세계를 이해하고, 더 넓은 기능을 개발하기 위해 긴 비디오와 언어의 대규모 데이터셋에서 학습할 방향을 제시한다.

### [Lumos : Empowering Multimodal LLMs with Scene Text Recognition](https://arxiv.org/abs/2402.08017)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/qeIznru3bcoGhrN5VvS98.png)

Vote: 13

Authors: Vikas Bhardwaj, Abhay Harpale, Ankit Ramchandani, Shicong Zhao, Pierce Chuang, Xin Luna Dong, Longfang Zhao, Debojeet Chatterjee, Anuj Kumar, Mohsen Moslehpour, Srihari Jayakumar, Di Xu, Yichao Lu, Ashish Shenoy

- 본 논문에서는 텍스트 이해 능력을 갖춘 최초의 다중모달 질문-응답 시스템인 Lumos를 소개합니다.
- Lumos의 핵심은 장면 텍스트 인식(Scene Text Recognition, STR) 구성 요소로, 1인칭 시점 이미지로부터 텍스트를 추출하고, 이를 다중모달 대규모 언어 모델(Multimodal Large Language Model, MM-LLM) 입력에 추가하여 강화합니다.
- 시스템을 구축하는 과정에서 STR 품질, 전체 대기 시간, 모델 추론과 관련된 여러 도전과제들을 마주쳤으며, 이에 대한 해결책을 논문에서 다룹니다.
- 논문은 시스템 아키텍처, 설계 선택, 그리고 이러한 장애물을 극복하기 위해 사용된 모델링 기술들을 상세히 설명합니다.
- 각 구성 요소에 대한 종합적인 평가를 제공하며, Lumos가 높은 품질과 효율성을 선보임을 보여줍니다.

### [Learning Continuous 3D Words for Text-to-Image Generation](https://arxiv.org/abs/2402.08654)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/YigL7HQEniGVMXOe4Blzh.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/YigL7HQEniGVMXOe4Blzh.mp4" muted="false"></video></div>

Vote: 7

Authors: Andrew Markham, Radomir Mech, Niki Trigoni, Ta-Ying Cheng, Matthew Fisher, Matheus Gadelha, Thibault Groueix

- 현재 확산 모델(예: 텍스트 또는 ControlNet을 통해)을 사용한 이미지 생성 작업은 조명 방향이나 비강체 모양 변화와 같은 추상적이고 연속적인 속성을 인식하는 데 한계가 있습니다.
- 이 논문에서는 텍스트 기반 이미지 모델 사용자들이 이미지의 여러 속성을 세밀하게 제어할 수 있는 방법을 제안합니다.
- 저자는 연속적으로 변형될 수 있는 특별한 입력 토큰 세트를 개발하고, 이를 '연속적인 3D 단어'라고 부릅니다.
- 이러한 속성들은 슬라이더로 표현되어 텍스트 프롬프트와 함께 이미지 생성에 대한 세밀한 제어를 가능하게 합니다.
- 단일 메시와 렌더링 엔진만으로, 저자의 접근법이 낮과 밤 조명, 새 날개 방향, 돌리줌 효과, 물체 포즈 등 3D 인식 속성에 대한 연속적인 사용자 제어를 제공할 수 있음을 보여줍니다.
- 이 방법은 여러 연속적인 3D 단어와 텍스트 설명을 동시에 이미지 생성에 조건을 부과하는 능력을 가지면서도, 생성 과정에 추가 부담을 주지 않습니다.
- 프로젝트 페이지: https://ttchengab.github.io/continuous_3d_words

### [ChatCell: Facilitating Single-Cell Analysis with Natural Language](https://arxiv.org/abs/2402.08303)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.08303.png)

Vote: 6

Authors: Xiaohui Fan, Yin Fang, Ningyu Zhang, Kangwei Liu, Mark Gerstein, Zhuo Chen, Penghui Yang, Xinle Deng, Huajun Chen, Xiangru Tang

- 대규모 언어 모델들이 빠르게 발전하면서 과학 분야, 특히 화학과 생물학에서 그 영향력이 점점 두드러지고 있습니다.
- 단일세포 생물학은 살아있는 유기체의 기본 구성 요소를 형성하는 분야임에도 불구하고 여전히 많은 도전에 직면해 있습니다.
- 현재 방법론에서의 높은 지식 장벽과 제한된 확장성은 대규모 언어 모델들이 단일세포 데이터를 마스터하는 것을 제한하고 있으며, 직접적인 접근성과 빠른 반복 작업을 방해합니다.
- 이러한 문제를 해결하기 위해 저희는 자연어를 통해 단일세포 분석을 용이하게 하는 ChatCell을 소개합니다.
- 어휘 적응 및 통합 시퀀스 생성을 활용하여, ChatCell은 단일세포 생물학에서 심오한 전문 지식을 습득하고 다양한 분석 작업을 수용할 수 있는 능력을 갖추었습니다.
- 광범위한 실험을 통해 ChatCell의 견고한 성능과 단일세포 통찰을 심화시킬 잠재력이 입증되었으며, 이 분야에서 더 접근하기 쉽고 직관적인 탐색의 길을 열어주었습니다.
- 우리의 프로젝트 홈페이지는 https://zjunlp.github.io/project/ChatCell 에서 확인할 수 있습니다.

### [UFO: A UI-Focused Agent for Windows OS Interaction](https://arxiv.org/abs/2402.07939)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/rZ5RrJd7pgF43Q5I9xm96.png)

Vote: 6

Authors: Saravan Rajmohan, Xu Zhang, Dongmei Zhang, Minghua Ma, Yu Kang, Shilin He, Liqun Li, Qingwei Lin, Chaoyun Zhang, Si Qin, Qi Zhang, Bo Qiao

- 'UFO'라는 새로운 사용자 인터페이스(UI)에 중점을 둔 에이전트는 GPT-Vision을 활용하여 Windows OS 상의 애플리케이션에 특화된 사용자 요청을 수행합니다.
- 이 에이전트는 그래픽 사용자 인터페이스(GUI)와 Windows 애플리케이션의 제어 정보를 세밀하게 관찰하고 분석하는 이중 에이전트 프레임워크를 사용합니다.
- UFO는 사용자의 요청을 단일 애플리케이션 내부뿐만 아니라 여러 애플리케이션을 걸쳐 자연스럽게 수행하고 조작할 수 있게 해줍니다.
- 제어 상호작용 모듈을 통해 사람의 개입 없이 행동을 구체화할 수 있으며, 완전히 자동화된 실행을 가능하게 합니다.
- 자연어 명령을 통해서만 시간이 많이 걸리는 과정을 간단한 작업으로 바꿀 수 있습니다.
- 9개의 인기 있는 Windows 애플리케이션을 대상으로 한 테스트로, UFO가 사용자의 일상 사용 시나리오를 반영하여 우수한 성능을 보임을 강조합니다.
- 정량적 지표와 실제 사례 연구를 통해 사용자의 요청을 충족시키는 데 있어 UFO의 효과성을 입증합니다.
- UFO는 Windows OS 환경 내 작업 완료를 위해 특별히 설계된 최초의 UI 에이전트로 알려져 있습니다.
- UFO의 소스 코드는 오픈 소스로 https://github.com/microsoft/UFO에서 제공됩니다.

### [Vision-Based Hand Gesture Customization from a Single Demonstration](https://arxiv.org/abs/2402.08420)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/HP7kIupBcdYjZF6j8lGFw.png)

Vote: 6

Authors: Gierad Laput, Soroush Shahi, Asaf Liberman, Abdelkareem Bedri, Cori Tymoszek Park, Oron Levy, Richard Kang, Jun Gong

- 카메라가 일상 기기에 널리 퍼지면서 손동작 인식은 인간-컴퓨터 상호작용의 중요한 모드가 되어가고 있습니다.
- 필드에 계속적인 진전에도 불구하고, 손동작 사용자 맞춤화는 종종 덜 조명되었는데, 이는 사용자가 더 자연스럽고 기억하기 쉽고 접근성이 높은 손동작을 정의하고 시연할 수 있기 때문에 중요합니다.
- 사용자 제공 데이터의 효율적 사용을 필요로 하는 맞춤화를 위해, 본 논문은 원시 카메라를 이용해 단 한 번의 시연을 통해 사용자 맞춤 손동작을 쉽게 설계할 수 있는 방법을 소개합니다.
- 이 방법은 변환기(transformers)와 메타 학습(meta-learning) 기술을 활용하여 적은 수의 학습 예시로 인한 도전을 해결합니다.
- 기존 연구와는 달리, 본 방법은 한 손, 양 손, 정적, 동적 등 모든 조합의 손동작과 다양한 시점을 지원합니다.
- 21명의 참가자로부터 수집한 20가지 손동작에 대한 사용자 연구를 통해 평가하여, 단 한 번의 시연으로 최대 97%의 평균 인식 정확도를 달성하였습니다.
- 우리의 작업은 시각 기반 손동작 맞춤화에 대한 실현 가능한 방향을 제공하며, 이 분야에서 미래의 발전을 위한 토대를 마련합니다.

### [IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation](https://arxiv.org/abs/2402.08682)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/HNtLrr1HCeHeDMcDx9KVT.png)

Vote: 6

Authors: Oran Gafni, Iro Laina, Christian Rupprecht, Filippos Kokkinos, Luke Melas-Kyriazi, Andrea Vedaldi, Natalia Neverova

- 대부분의 텍스트-투-3D 생성기는 수십억 개의 이미지에 대해 훈련된 기성 텍스트-투-이미지 모델에 기반을 두고 있으며, 이러한 생성기는 속도가 느리고 다소 불안정하며 아티팩트가 발생하기 쉬운 점수 증류 샘플링(SDS)의 변형을 사용합니다.
- 2D 생성기를 멀티뷰 인식이 가능하도록 미세 조정함으로써 증류 과정을 도울 수 있고, 이를 재구성 네트워크와 결합하여 직접적으로 3D 객체를 출력할 수 있습니다.
- 본 논문에서는 텍스트-투-3D 모델의 설계 공간을 더욱 탐구하여, 이미지 생성기 대신 비디오 생성기를 고려함으로써 멀티뷰 생성의 품질을 대폭 향상시킵니다.
- 가우시안 스플래팅을 사용하고 강건한 이미지 기반 손실을 최적화할 수 있는 3D 재구성 알고리즘과 결합하여 생성된 뷰로부터 직접적으로 고품질 3D 출력물을 생산합니다.
- 새로운 방법론인 IM-3D는 2D 생성 네트워크의 평가 횟수를 10-100배 감소시키므로, 훨씬 더 효율적인 파이프라인, 더 나은 품질, 더 적은 기하학적 불일치 및 사용 가능한 3D 자산의 높은 생산률을 제공합니다.

### [Graph Mamba: Towards Learning on Graphs with State Space Models](https://arxiv.org/abs/2402.08678)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/qHOVl6PvrYbp1qhXtF1MP.png)

Vote: 5

Authors: Farnoosh Hashemi, Ali Behrouz

- 그래프 뉴럴 네트워크(Graph Neural Networks, GNNs)는 그래프 표현 학습에서 높은 잠재력을 보였으나, 지역 메시지 전달과 장거리의존성 포착에 어려움을 겪고 있습니다.
- 최근, 계산 비용이 높고 그래프 구조에 대한 본질적인 이해 부족, 복잡한 위치/구조적 인코딩(Positional/Structural Encodings, PE/SE)에 의존하는 Graph Transformers(GTs)가 Message-Passing Neural Networks(MPNNs)의 대안으로 부상했습니다.
- 본 논문에서는 Transformer, 복잡한 메시지 전달, SE/PE 모두 실제 성능을 위해 충분하나 반드시 필요하지는 않음을 입증합니다.
- State Space Models(SSMs)를 활용한 새로운 GNNs 프레임워크인 Graph Mamba Networks (GMNs)를 제시하였고, 이를 통해 새로운 도전 과제를 논의하고 분류합니다.
- GMNs의 설계를 위한 다섯 가지 단계를 제안하며, 특히 이웃 토크나이제이션, 토큰 정렬, 양방향 선택적 SSM 인코더의 아키텍처, 지역 인코딩을 필수 단계로, PE 및 SE를 선택적 단계로 구분합니다.
- GMNs의 이론적 타당성을 제공하며, 실험을 통해 더 적은 계산 비용에도 불구하고 GMNs가 장거리, 소규모, 대규모 및 이질성 데이터셋에서 뛰어난 성과를 달성함을 시연합니다.

### [Tandem Transformers for Inference Efficient LLMs](https://arxiv.org/abs/2402.08644)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/glpMhmDzAmkJW7PVteCjx.png)

Vote: 4

Authors: Praneeth Netrapalli, Pranav Ajit Nair, Sanjiv Kumar, Prateek Jain, Yashas Samaga, Toby Boyd, Aishwarya P S

- 전통적인 대규모 언어 모델들(LLMs)은 토큰을 순차적으로 생성하는 자기회귀적 특성으로 인해 추론 속도에 한계가 있는데, 이를 해결하기 위해 Tandem Transformers라는 새로운 아키텍처가 제안되었다.
- 이 아키텍처는 작은 자기회귀 모델과 여러 토큰을 동시에 처리하는 대형 모델을 결합하여, 작은 모델이 대형 모델의 더 풍부한 표현력에 주목함으로써 예측 정확도를 크게 향상시켰다.
- PaLM2 사전 훈련 데이터셋에서, PaLM2-Bison과 PaLM2-Gecko의 Tandem 구조는 독립적인 PaLM2-Gecko보다 다음 토큰 예측 정확도가 3.3% 향상되고, 유사한 성능을 가진 PaLM2-Otter 모델에 비해 1.16배 빠른 속도를 보였다.
- 대형 모델이 작은 모델에서 생성한 토큰을 검증하는 구조인 'speculative decoding (SPEED)' 프레임워크에 Tandem 모델을 통합하여, PaLM2-Gecko를 단독으로 사용하는 것보다 약 1.14배 빠른 속도로 동일한 다운스트림 작업 정확도를 유지하며 더 큰 속도 향상을 달성했다.

### [NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs](https://arxiv.org/abs/2402.08622)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/QbU1j_pTH1wSy3UlxtgFn.png)

Vote: 3

Authors: Tobias Ritschel, Carl Marshall, Michael Fischer, Zhengqin Li, Thu Nguyen-Phuoc, Aljaz Bozic, Zhao Dong

- 신경 복사 필드(NeRF)는 특정 3D 기하학과 장면의 외모 간의 관계를 인코딩합니다.
- 본 연구는 원본 NeRF의 외모를 대상 3D 기하학에 의미 있게 전달할 수 있는지, 그 결과 새로운 NeRF가 대상 기하학을 유지하면서 원본 NeRF의 외모에 유사한지를 탐구합니다.
- 이를 위해, 2D 이미지에서의 클래식 이미지 아날로지를 NeRF로 확장하고, 의미론적 특징을 기반으로 상호 작용하는 대응 전달을 활용하여 다 관점 일관성 있는 외모 전달을 달성합니다.
- 방법론은 3D 기하학과 외모의 혼합 및 매치 가능성을 탐색할 수 있게 해줍니다.
- 이 방법이 전통적인 스타일 전달 방법들을 능가하며, 대다수 사용자가 기존의 전형적인 베이스라인들보다 본 방법을 선호함을 보여줍니다.

