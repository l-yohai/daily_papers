## Daily Papers (2024-02-26)

### [Genie: Generative Interactive Environments](https://arxiv.org/abs/2402.15391)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/bCTVh9dCqN6_e7TSeIsr2.qt)

Vote: 50

Authors: Yuge Shi, Sherjil Ozair, Yusuf Aytar, Sarah Bechtle, Nicolas Heess, Michael Dennis, Feryal Behbahani, Matthew Lai, Simon Osindero, Stephanie Chan, Aditi Mavalankar, Edward Hughes, +, Konrad Zolna, Scott Reed, Jack Parker-Holder, Ashley Edwards, Richie Steigerwald, Jeff Clune, Jingwei Zhang, Lucy Gonzalez, Chris Apps, Jake Bruce

- 저희는 무라벨 인터넷 비디오로부터 비감독 학습 방법으로 훈련된 최초의 생성적 인터렉티브 환경인 Genie를 소개합니다.
- 이 모델은 텍스트, 합성 이미지, 사진, 심지어 스케치를 통해 표현된 다양한 액션 제어가 가능한 가상 세계를 생성하도록 프롬프트할 수 있습니다.
- 11억 매개변수를 가진 Genie는 기초 월드 모델로 간주될 수 있으며, 공간시간 비디오 토크나이저, 자동 회귀 동역학 모델, 그리고 단순하고 확장가능한 잠재 액션 모델로 구성됩니다.
- Genie는 지상 진리 액션 라벨이나 세계 모델 문헌에서 일반적으로 찾아볼 수 있는 다른 도메인 특정 요구사항 없이도 훈련되었음에도 불구하고 사용자가 프레임 단위로 생성된 환경에서 행동할 수 있게 해줍니다.
- 또한 학습된 잠재 액션 공간은 본 적 없는 비디오에서 행동을 모방하는 에이전트를 훈련시키는 것을 용이하게 해, 미래의 보편적 에이전트 훈련을 위한 길을 연다는 잠재력을 보여줍니다.

### [MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases](https://arxiv.org/abs/2402.14905)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/SZoqAKLrSSD-cy5SreL4T.png)

Vote: 41

Authors: Yangyang Shi, Raghuraman Krishnamoorthi, Changsheng Zhao, Zechun Liu, Yuandong Tian, Liangzhen Lai, Igor Fedorov, Chen Lai, Vikas Chandra, Yunyang Xiong, Forrest Iandola, Ernie Chang

- 이 논문은 클라우드 비용 증가와 대기 시간 문제로 인해 모바일 기기 상의 효율적인 대형 언어 모델(Large Language Models, LLMs) 개발의 필요성을 다루고 있습니다.
- 모바일 배포에 적합한 수십억 개 미만의 파라미터를 가진 최고 품질의 LLM을 설계하는 것에 중점을 두었습니다.
- 데이터와 파라미터 양의 중요성 강조와 달리, 이 연구는 수십억 규모 미만 LLMs에서 모델 아키텍처의 중요성을 강조합니다.
- 심화되고 얇은 아키텍처를 활용하고 임베딩 공유 및 그룹화된 쿼리 주의 메커니즘을 도입하여, MobileLLM이라는 강력한 기반 네트워크를 설정하였으며, 기존의 125M/350M 최첨단 모델들에 비해 2.7%/4.3%의 정확도 향상을 달성했습니다.
- 모델 크기 증가 없이 소량의 추가 지연시간만을 가지고 즉시 블록별 가중치 공유 방법을 제안하였으며, 이로 인해 생긴 MobileLLM-LS 모델은 MobileLLM 125M/350M 모델 대비 각각 0.7%/0.8%의 정확도 향상을 보였습니다.
- MobileLLM 모델군은 채팅 벤치마크에서 이전 수십억 개 미만 모델들에 비해 상당한 향상을 보이며, API 호출 작업에서 LLaMA-v2 7B 모델에 근접한 정확도를 보여, 일반적인 모바일 기기 사용 사례에서 소형 모델의 가능성을 강조합니다.

### [Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition](https://arxiv.org/abs/2402.15504)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/384fXOREWdo-zNfQtHOxe.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/384fXOREWdo-zNfQtHOxe.mp4" muted="false"></video></div>

Vote: 16

Authors: Ta-Ying Cheng, Yi Ma, Andrew Markham, Niki Trigoni, Yubei Chen, He-Yen Hsieh, H. T. Kung, Chun-Hsiao Yeh, Chuan-En Lin

- 최근 텍스트-이미지 확산 모델은 수십 개의 예제만으로도 새롭고 개인화된 개념(예: 자신의 애완동물이나 특정 항목)을 학습하여 이미지를 합성할 수 있는 능력을 보여주고 있다.
- 본 논문은 텍스트-이미지 확산 모델의 개인화를 멀티 콘셉트로 확장할 때 발생하는 두 가지 상호 연결된 문제를 해결하고자 한다.
- 첫 번째 문제는 현재의 개인화 기술이 복잡한 장면과 사전 훈련 데이터셋(예: LAION)의 단순한 텍스트 설명 사이의 불일치로 인해 여러 개념으로의 신뢰할 수 있는 확장이 실패하는 점이다. 
- 두 번째 문제는 다양한 개인화 개념을 포함하는 이미지에 대해, 개인화된 개념들의 유사성뿐만 아니라 이미지에 모든 개념이 존재하는지, 그리고 전반적인 텍스트 설명을 정확하게 반영하는지를 평가할 수 있는 포괄적인 메트릭이 부족하다는 점이다.
- 이 두 가지 문제를 해결하기 위해, 저자들은 Gen4Gen이라는 반자동 데이터셋 생성 파이프라인을 소개하고, 이를 사용하여 복합적인 구성과 텍스트 설명을 결합한 MyCanvas라는 벤치마킹을 위한 데이터셋을 생성하였다.
- 또한, 멀티-개념, 개인화된 텍스트-이미지 확산 방법의 성능을 더 정확하게 측정하기 위해 두 점수(CP-CLIP 및 TI-CLIP)로 구성된 종합적인 메트릭을 설계하였다.
- 연구자들은 Custom Diffusion 모델 위에 구축된 간단한 베이스라인과 경험적 프롬프팅 전략을 제공하여 미래 연구자들이 MyCanvas에서 평가하도록 하였다.
- 데이터 품질과 프롬프팅 전략을 향상함으로써 모델 아키텍처나 훈련 알고리즘을 변경하지 않고도 멀티-개념 개인화 이미지 생성의 품질을 크게 향상시킬 수 있음을 보여주고 있다.

### [Orca-Math: Unlocking the potential of SLMs in Grade School Math](https://arxiv.org/abs/2402.14830)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/SNUBmAcBKlgg0OxeTRfvH.png)

Vote: 15

Authors: Arindam Mitra, Corby Rosset, Hamed Khanpour, Ahmed Awadallah

- 수학적 어휘 문제 해결은 작은 언어 모델(SLMs)에게 오랫동안 복잡한 과제로 인식되어 왔습니다.
- 최근 연구에 따르면 GSM8K 벤치마크에서 80% 이상의 정확도를 달성하기 위해 필요한 최소 모델 크기는 340억 매개변수라고 가정되었습니다.
- 더 작은 모델의 성능을 높이기 위해 연구자들은 종종 Python 코드 생성을 훈련하거나 계산 오류를 피하기 위한 도구들을 사용합니다.
- 또한, 여러 번의 모델 실행 결과를 결합하여 더 정확한 결과를 도출하는 앙상블 기법을 사용하며, 결과 선택은 합의, 다수결, 또는 별도의 검증 모델을 사용합니다.
- 본 연구에서 제시한 Orca-Math는 70억 매개변수의 SLM으로, 복잡한 앙상블, 검증기의 사용, 코드 실행 또는 기타 외부 도구 없이 GSM8k에서 86.81%의 정확도를 달성해냈습니다.
- Orca-Math의 접근 방식의 주요 요소는, (1) 에이전트들이 협력하여 데이터를 생성하는 다중 에이전트 설정을 사용하여 만든 20만개의 고품질 합성 수학 문제 데이터셋, (2) SLM이 문제를 해결하는 연습을 하고 그 해결책에 대한 피드백을 받으며 선호도 쌍을 통해 학습할 수 있는 반복 학습 기술입니다.
- 지도 학습만으로 훈련시 Orca-Math는 GSM8k의 pass@1 메트릭에서 81.50%의 정확도를 달성했으며, 반복 선호도 학습을 통해서는 86.81%를 달성했습니다.
- Orca-Math는 LLAMA-2-70B, WizardMath-70B, Gemini-Pro, ChatGPT-3.5와 같이 훨씬 더 큰 모델들의 성능을 뛰어넘을 뿐만 아니라, 훨씬 더 작은 데이터셋(수십만 개 대 수백만 개 문제)을 사용하면서도 다른 작은 모델들보다 월등한 성능을 보여주었습니다.

### [GPTVQ: The Blessing of Dimensionality for LLM Quantization](https://arxiv.org/abs/2402.15319)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/TD0kC_hrvKDrbzKZlz1RH.png)

Vote: 11

Authors: Eric Mahurin, Mart van Baalen, Tijmen Blankevoort, Paul Whatmough, Peter Couperus, Markus Nagel, Andrey Kuzmin, Cedric Bastoul

- 이 연구에서는 양자화 차원을 늘림으로써 신경망 양자화의 크기 대 정확도 트레이드오프를 크게 향상시킬 수 있음을 보여줍니다.
- GPTVQ 방법을 제안하는데, 이는 대용량 언어 모델(LLM)에 잘 확장되는 새로운 빠른 사후 학습 벡터 양자화(VQ) 방법입니다.
- 우리의 방법은 한 개 또는 그 이상의 열 양자화를 나머지 양자화되지 않은 가중치 업데이트와 교차하여, 계층별 출력 복원 MSE의 헤시안 정보를 사용합니다.
- 양자화 코드북은 효율적인 데이터 인식 버전의 EM 알고리즘을 사용하여 초기화됩니다.
- 코드북은 업데이트된 후 정수 양자화 및 SVD 기반 압축을 사용하여 더욱 압축됩니다.
- GPTVQ는 Llama-v2 및 Mistral과 같은 다양한 대규모 언어 모델에서 크기 대 정확도 트레이드오프에서 새로운 최고의 성능을 설정합니다.
- 또한, 우리의 방법은 효율적으로, 하나의 H100에서는 양자화 설정에 따라 Llamav2-70B 모델을 처리하는데 3시간에서 11시간이 걸립니다.
- 마지막으로, 모바일 CPU에서 VQ 디컴프레션을 위한 온디바이스 타이밍을 사용하여, VQ가 4비트 정수 포맷을 사용하는 것에 비해 향상된 지연 시간으로 이어진다는 것을 보여줍니다.

### [ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition](https://arxiv.org/abs/2402.15220)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/WOW9WqXM5dHIdKaVVO-gj.png)

Vote: 10

Authors: Yong Huang, Yang Li, Lu Ye, Ze Tao

- 셀프 어텐션은 대규모 언어 모델(Large Language Models, LLMs)에 필수적인 구성 요소이지만, 긴 시퀀스를 다룰 때 인퍼런스 지연을 가져오는 주된 원인입니다.
- 복수의 LLM 요청이 시스템 프롬프트의 접두사를 공유할 확률을 이용하여 셀프 어텐션의 계산 및 메모리 작업 비용을 최적화할 수 있습니다.
- 이 논문에서 우리는 ChunkAttention을 도입합니다. 이는 접두사에 대한 인식이 가능한 셀프 어텐션 모듈로, 여러 요청에서 매칭되는 프롬프트 접두사를 실시간으로 탐지하고 그들의 key/value 텐서를 메모리에서 공유함으로써 KV 캐시의 메모리 사용 효율을 개선합니다.
- 단일 key/value 텐서를 작은 청크로 나누고 이를 보조 접두어 트리에 구조화함으로써, 메모리에서 KV 캐시를 위한 효율적인 자료 구조를 구축합니다.
- 공유된 시스템 프롬프트의 존재 하에 셀프 어텐션 계산 중 데이터 지역성을 향상시키기 위해 이페이즈 분할 알고리즘을 적용한 효율적인 셀프 어텐션 커널을 설계합니다.
- 실험 결과는 ChunkAttention이 시스템 프롬프트의 길이가 1024부터 4096까지 범위일 때, 최신 구현 대비 셀프 어텐션 커널을 3.2-4.8배까지 가속화할 수 있음을 보여줍니다.

### [Divide-or-Conquer? Which Part Should You Distill Your LLM?](https://arxiv.org/abs/2402.15000)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hr_KNu9asHJ_Kk6XOb0ex.png)

Vote: 10

Authors: VG Vinod Vydiswaran, Aonan Zhang, Navdeep Jaitly, He Bai, Yizhe Zhang, Jiatao Gu, Zhuofeng Wu

- 이 논문에서는 추론 과제를 문제 분해 단계와 문제 해결 단계로 나누는 전략을 개발하여 단일 단계 해법보다 뛰어난 성능을 보이는 것을 제시합니다.
- 연구진은 문제 분해가 일반적인 문제 해결 전략을 배우는 것만을 필요로 하는 반면, 문제 해결은 많은 도메인 지식을 요구하기 때문에 전자가 후자보다 소규모 모델로 추상화하기에 더 용이하다고 가설을 세웁니다.
- 두 가지 능력을 추상화하는 방법을 제안하고, 이들이 추론 결과 및 추론 비용에 미치는 영향을 평가합니다.
- 연구 결과, 문제 분해 단계를 추상화할 수 있으며, 이를 통해 다양한 과제, 데이터셋 및 모델에 대해 좋은 일반화 성능을 달성할 수 있음을 확인합니다.
- 반면에 문제 해결 능력의 추상화는 성능 손실 없이는 어려우며, 추상화된 모델은 일반화에 어려움을 겪습니다.
- 이 결과들은 문제 분해를 위한 작고 추상화된 모델과 문제 해결을 위한 큰 LLM을 결합함으로써 비용 효율적인 추론과 지역적 적응을 달성할 수 있음을 시사합니다.

### [Watermarking Makes Language Models Radioactive](https://arxiv.org/abs/2402.14904)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/u16DqQGe68ALImF2qDgqK.png)

Vote: 10

Authors: Alain Durmus, Tom Sander, Matthijs Douze, Pierre Fernandez, Teddy Furon

- 본 연구는 언어 모델이 생성한 텍스트의 '방사성'을 조사하였는데, 이는 특정 입력이 훈련 데이터로 사용되었는지 탐지할 수 있는지의 여부를 의미합니다.
- 기존의 멤버십 추론과 같은 방법으로 탐지가 가능하지만, 워터마크가 삽입된 훈련 데이터는 이보다 훨씬 쉽고 믿을 수 있는 흔적을 남깁니다.
- 오염 수준은 워터마크의 견고성, 훈련 세트 내 비율, 그리고 미세 조정 과정과 연결됩니다.
- 특히, 훈련 데이터의 5%만이 워터마크 처리가 되었을 때에도, 워터마크가 있는 합성 지시사항에 대한 교육을 높은 신뢰도(p-값 < 1e-5)로 감지할 수 있음을 입증하였습니다.
- 기계 생성 텍스트를 감지하기 위해 설계된 워터마크 기술은 워터마크가 적용된 언어 모델의 출력이 다른 모델의 미세 조정에 사용되었는지 쉽게 식별할 수 있는 능력을 제공합니다.

### [Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models](https://arxiv.org/abs/2402.14848)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ddkmh05FqmK6CoS3gg6TZ.png)

Vote: 10

Authors: Yoav Goldberg, Alon Jacoby, Mosh Levy

- 이 논문은 대형 언어 모델(Large Language Models, LLMs)의 논리 추론 능력에 대한 입력 길이의 영향을 조사합니다.
- 최근 LLMs의 발전에도 불구하고 다양한 입력 길이에서의 성능 일관성이 잘 이해되지 않았습니다.
- 저자들은 입력 길이의 영향을 평가하기 위해 다양한 길이, 유형, 위치의 패딩으로 확장된 동일한 샘플의 다양한 버전을 사용하는 새로운 QA 추론 프레임워크를 도입했습니다.
- 연구 결과, LLMs의 추론 성능이 기술적 최대치보다 훨씬 짧은 입력 길이에서 눈에 띄게 저하되는 것으로 나타났습니다.
- 이러한 성능 저하 추세는 데이터셋의 모든 버전에서 발견되며, 각기 다른 정도로 나타났습니다.
- 또한, 전통적인 혼란 지수(perplexity metrics)가 긴 입력을 필요로 하는 추론 작업에서 LLMs의 성능과 상관관계가 없음을 밝혀냈습니다.
- 연구자들은 실패 모드를 분석하여 미래 연구를 위한 유용한 가이드를 제공하고, 관찰된 LLMs의 한계를 해결하기 위한 전략을 제시할 수 있는 정보를 제공합니다.

### [CLoVe: Encoding Compositional Language in Contrastive Vision-Language Models](https://arxiv.org/abs/2402.15021)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ZmOZf-Cz0FJDnW812B5pc.png)

Vote: 9

Authors: Avneesh Saluja, Rada Mihalcea, Amir Ziai, Zhuoning Yuan, Santiago Castro

- 최근 몇 년간 시각 및 언어 작업의 성능이 크게 향상되었으며, CLIP과 같은 기초 시각-언어 모델(VLMs)이 다양한 환경에서 활용되어 여러 작업에서 뛰어난 성능을 보였습니다.
- 이러한 모델들은 객체 중심 인식에서는 뛰어나지만 단어 순서에 불변하는 텍스트 표현을 학습하며, 알려진 개념을 새로운 방식으로 결합하는 데 실패할 수 있습니다.
- GPT-4V와 같은 대규모 단일 스트림 모델을 포함하여 어떤 VLM도 조합을 성공적으로 식별했다는 증거는 아직 없습니다.
- 본 논문에서는 기존 모델의 구성적 언어 인코딩 능력을 크게 향상시키는 프레임워크를 소개하며, 구성성 벤치마크에서 10% 이상의 절대적인 개선을 달성하는 한편, 표준 객체 인식 및 검색 벤치마크의 성능을 유지하거나 개선합니다.
- 저자들은 코드와 사전 훈련된 모델을 https://github.com/netflix/clove 에서 공개적으로 사용할 수 있도록 제공합니다.

### [Seamless Human Motion Composition with Blended Positional Encodings](https://arxiv.org/abs/2402.15509)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DP13-Sul2O6gMLP2ejUKc.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DP13-Sul2O6gMLP2ejUKc.mp4" muted="false"></video></div>

Vote: 7

Authors: Sergio Escalera, Cristina Palmero, German Barquero

- 가상 현실, 게임, 로봇공학과 같은 다양한 분야에서의 응용을 목표로 문자, 음악, 장면에 의해 안내되는 조건부 인간 동작 생성은 중요한 연구 주제입니다.
- 기존 연구들은 대체로 단기간에 한정된 동작 생성에 중점을 두었지만, 본 논문은 일련의 다양한 텍스트 설명에 의해 안내되는 긴 연속 동작 시퀀스의 생성을 다룹니다.
- 우리는 흐름 모델 기반인 FlowMDM을 제안했으며, 이는 후처리나 불필요한 노이즈 제거 단계 없이 이음새가 없는 인간 동작 구성(Human Motion Compositions, HMC)을 생성할 수 있는 최초의 모델입니다.
- 블렌디드 포지셔널 인코딩이라는 새로운 기술을 도입하여 데노이징 과정에서 절대 위치 인코딩과 상대 위치 인코딩을 모두 활용합니다.
- 본 연구의 방법으로 Babel과 HumanML3D 데이터셋에서 정확성, 사실성, 부드러움 측면에서 최신의 결과를 달성하였습니다.
- FlowMDM은 추론 시 변화하는 텍스트 설명에 강건함을 보이는 자세 중심의 Cross-Attention 덕분에 하나의 설명만으로도 훈련될 때 뛰어난 성능을 보입니다.
- 기존 HMC 평가 지표의 한계를 해결하기 위해 급작스러운 전환을 감지하는 새로운 메트릭 두 가지, 'Peak Jerk'와 'Area Under the Jerk'를 제안합니다.

### [AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning](https://arxiv.org/abs/2402.15506)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/KG3JHyjeTYWa-WhUm2R__.png)

Vote: 7

Authors: Zhiwei Liu, Tian Lan, Silvio Savarese, Rithesh Murthy, Liangwei Yang, Juntao Tan, Thai Hoang, Zuxin Liu, Jianguo Zhang, Huan Wang, Tulika Awalgaonkar, Yihao Feng, Caiming Xiong, Weiran Yao, Juan Carlos Niebles, Shelby Heinecke

- 대규모 언어 모델(LLMs)을 사용하는 자율 에이전트에 대한 연구가 주목을 받고 있으나 LLMs의 잠재력을 에이전트 기반 작업에 충분히 활용하는 것은 다양한 데이터 소스의 이질적인 성격 때문에 내재된 도전 과제가 있습니다.
- 이 논문에서는 AgentOhana라는 종합적인 솔루션을 소개하여 에이전트 궤적을 다양한 환경에서 수집하고 다양한 시나리오를 아우르는 표준화된 일관된 형식으로 통일하여 에이전트 훈련을 위한 범용 데이터 로더 생성을 간소화합니다.
- 데이터 통합을 활용하여, AgentOhana의 훈련 파이프라인은 다양한 데이터 소스 간의 균형을 유지하며 데이터셋 분할 및 모델 교육 중에 독립적 무작위성을 각 장치에서 보존합니다.
- 추가적으로, AI 에이전트에 맞춤화된 대형 행동 모델인 xLAM-v0.1을 제시하며, 이는 다양한 벤치마크에서 탁월한 성능을 입증합니다.

### [API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs](https://arxiv.org/abs/2402.15491)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/nUI5yLZekAUe9vO_fe-Av.png)

Vote: 7

Authors: Pavan Kapanipathi, Subhajit Chaudhury, Sadhana Kumaravel, Vinod Muthusamy, Maxwell Crouse, Ibrahim Abdelaziz, Luis A. Lastras, Soham Dan, Kinjal Basu, Asim Munawar

- 대용량 언어 모델(LLM)이 도구 및 외부 애플리케이션 프로그래밍 인터페이스(API)를 효과적으로 활용할 수 있는 능력이 점점 더 중요해짐에 따라, API 호출이 포함된 훈련 및 테스트 데이터의 충분한 양을 확보하는 방법에 관심이 증가하고 있습니다.
- 데이터를 합성 생성하는 기술에 초점을 맞춘 연구와 작업에 인접한 데이터셋을 큐레이션하여 API/도구 기반 작업으로 변환하는 데 초점을 맞춘 연구, 두 가지 주요 전략이 등장하였습니다.
- 본 논문은 기존 데이터셋을 식별, 큐레이션 및 변환하는 과제에 중점을 두고, API-BLEND라는 대규모 코퍼스를 소개하며, 이는 도구를 보강한 LLM의 훈련 및 체계적인 테스트를 위한 자료입니다.
- 이 데이터셋은 API 작업에 관련된 실제 시나리오를 모방하며, API/도구 탐지, 슬롯 채우기, 탐지된 API의 순서지정과 같은 작업을 포함합니다.
- API-BLEND 데이터셋이 훈련 및 벤치마킹 목적 모두에 유틸리티가 있음을 보여줍니다.

