## Daily Papers (2024-02-05)

### [StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback](https://arxiv.org/abs/2402.01391)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/q4A_lHCt7VHpMpcZaO-fW.png)

Vote: 28

Authors: Wei Shen, Tao Ji, Haoxiang Jia, Shihan Dou, Caishuang Huang, Yuhao Zhou, Yan Liu, Xiaoran Fan, Rui Zheng, Limao Xiong, Junjie Shan, Qi Zhang, Xuanjing Huang, Tao Gui, Enyu Zhou, Zhiheng Xi

- 커다란 언어 모델의 발전이 코드 생성 분야를 크게 진전시켰습니다.
- 이전 연구는 컴파일러 피드백과 함께 강화 학습을 통합하여 언어 모델의 출력 공간 탐색을 통해 코드 생성 품질을 향상시켰습니다.
- 복잡한 인간 요구에 대해 생성된 장문의 코드로 인해 강화 학습 탐색이 어려워지고, 단위 테스트로 복잡한 코드를 커버하지 못할 수도 있어 최적화가 비효율적입니다.
- 이러한 도전을 해결하기 위해, 우리는 코드 생성을 위한 새로운 강화 학습 프레임워크인 StepCoder를 소개합니다.
- StepCoder는 긴 코드 생성 작업을 '코드 완성 부분 과제로 구성된 교육'으로 나누어 탐색 문제를 해결하는 CCCS와 실행되지 않은 코드 세그먼트를 마스킹하여 '미세 조정 최적화'를 제공하는 FGO로 구성됩니다.
- 또한, 단위 테스트의 정확성을 수동으로 검증하여 강화 학습 훈련을 위한 APPS+ 데이터셋을 추가로 구축하였습니다.
- 실험 결과, 이 방법은 출력 공간 탐색 능력을 향상시키고 관련 벤치마크에서 최신 접근 방식을 능가하는 것으로 나타났습니다.

### [Specialized Language Models with Cheap Inference from Limited Domain Data](https://arxiv.org/abs/2402.01093)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/wyad9lOdT8rdndVwZgz7w.png)

Vote: 28

Authors: Awni Hannun, Pierre Ablin, David Grangier, Angelos Katharopoulos

- 이 작업은 대규모 언어 모델 적용이 어려운 제한된 추론 예산과 도메인 별 훈련 데이터가 충분하지 않은 상황에 대한 제약을 명확히 하고, 이를 네 가지 중요 변수로 구분합니다: 타겟 도메인이 알려지기 전에 이루어지는 사전 훈련 예산, 타겟 도메인이 알려진 후 특화 훈련을 위한 예산, 추론 예산, 그리고 도메인 내 훈련 데이터 세트의 크기.
- 머신러닝 문헌에서 다양한 접근 방식을 비교한 결과, 추론 비용에 제한이 있을 때, 매우 큰 바닐라 트랜스포머 모델 훈련이라는 기존의 방식보다 더 나은 대안을 발견했습니다.
- 특히, 사전 훈련 예산이 큰 경우 하이퍼네트워크와 전문가의 혼합이 더 낮은 혼란도를 보이는 동시에, 특화 훈련 예산이 큰 경우에는 중요도 샘플링된 데이터 세트에서 훈련된 작은 모델이 매력적인 대안임을 보여줍니다.

### [TravelPlanner: A Benchmark for Real-World Planning with Language Agents](https://arxiv.org/abs/2402.01622)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/nLutII5rfnrCLXiAWZTZC.png)

Vote: 20

Authors: Renze Lou, Kai Zhang, Yu Su, Yuandong Tian, Jiangjie Chen, Tinghui Zhu, Yanghua Xiao, Jian Xie

- 인공 지능(AI)의 핵심 추구 영역인 계획 수립은 대부분 제한된 환경에서 이루어졌으나, 최근 대규모 언어 모델(LLMs)의 언어 에이전트가 도구 사용과 추론과 같은 능력을 보여주었다.
- 본 연구에서는 실제 세계의 복잡한 여행 계획과 같은 시나리오에 집중하는 새로운 계획 벤치마크 'TravelPlanner'를 제안한다.
- TravelPlanner는 풍부한 샌드박스 환경, 거의 400만 개의 데이터 레코드에 접근할 수 있는 다양한 도구, 그리고 1,225개의 세심하게 큐레이션 된 계획 의도 및 참조 계획을 제공한다.
- 종합적인 평가에 따르면, 현재의 언어 에이전트들은 GPT-4가 성공률 0.6%를 달성하는 등 여전히 복잡한 계획 작업을 수행하는 데 능숙하지 않다.
- 언어 에이전트들은 작업 유지, 올바른 도구를 사용한 정보 수집 또는 여러 제약 조건의 추적에 어려움을 겪고 있다.
- 그러나 언어 에이전트가 이와 같이 복잡한 문제에 도전할 수 있는 자체가 중요한 진전임을 강조한다.
- TravelPlanner는 미래의 언어 에이전트를 위한 도전적이면서 의미 있는 테스트베드를 제공한다.

### [PokéLLMon: A Human-Parity Agent for Pokémon Battles with Large Language Models](https://arxiv.org/abs/2402.01118)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/1LGaxeviL-X5brLTNZhwm.png)

Vote: 20

Authors: Tiansheng Huang, Sihao Hu, Ling Liu

- PokéLLMon은 포켓몬 전투 게임에서 인간과 동등한 성능을 달성한 최초의 대규모 언어 모델(Large Language Models, LLM) 기반 에이전트로 소개됩니다.
- 이 에이전트는 실시간으로 텍스트 기반 피드백을 통해 정책을 지속적으로 개선하는 '인-콘텍스트 강화 학습', 외부 지식을 검색하여 환각 현상을 줄이고 적절한 시기에 적절한 행동을 취할 수 있게 하는 '지식-증대 생성', 및 강력한 상대에 직면했을 때 전투를 회피하고자 하는 급격한 전환 현상을 완화하는 '일관된 행동 생성'을 주요 전략으로 채택합니다.
- 온라인 포켓몬 배틀을 통해 PokéLLMon이 인간과 유사한 전략과 적시적인 결정을 내릴 수 있음을 보여주며, 래더 경쟁에서 49%의 승률과 초청 배틀에서 56%의 승률을 달성했습니다.
- PokéLLMon의 구현체와 플레이 가능한 전투 로그는 GitHub에서 제공되고 있습니다.

### [Boximator: Generating Rich and Controllable Motions for Video Synthesis](https://arxiv.org/abs/2402.01566)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/fmHpm1lA5tqy-BRkm_cVq.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/fmHpm1lA5tqy-BRkm_cVq.mp4" muted="false"></video></div>

Vote: 14

Authors: Jiawei Wang, Yan Zeng, Yuchen Zhang, Jiaxin Zou, Hang Li, Liping Yuan, Guoqiang Wei

- 동영상 합성에서 풍부하고 제어 가능한 움직임을 생성하는 새로운 접근 방식인 'Boximator'를 제안합니다.
- 사용자는 '하드 박스'로 조건부 프레임 내 객체를 선택하고, '하드 박스' 또는 '소프트 박스'를 사용하여 미래 프레임에서 객체의 위치, 모양, 또는 움직임 경로를 대략적으로 혹은 엄격하게 정의할 수 있습니다.
- 기존 비디오 확산 모델에 플러그인으로 작동되며, 기본 모델의 지식을 보존하기 위해 원래의 가중치를 고정하고 제어 모듈만을 학습합니다.
- 박스-객체 상관 관계 학습을 대폭 단순화하는 새로운 자기 추적 기법을 도입하여 교육 과정의 도전을 해결합니다.
- 하드 박스 및 소프트 박스 제약 조건을 포함시킨 후에 상태-예술 비디오 품질(FVD) 점수를 달성하고, 두 기본 모델에 비해 개선된 결과를 보여줍니다.
- 경계 상자 정렬 지표에서 급격한 증가를 통해 강력한 움직임 제어 가능성을 검증합니다.
- 인간 평가를 통해 사용자들이 기본 모델보다 Boximator 생성 결과를 선호함을 보여줍니다.

### [K-Level Reasoning with Large Language Models](https://arxiv.org/abs/2402.01521)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/LBXaeILP0s0oovBfXLQ6O.png)

Vote: 14

Authors: Man Lan, Xun Wang, Tao Ge, Shaoguang Mao, Yan Xia, Yadong Zhang, Furu Wei

- 대규모 언어 모델(LLMs)이 복잡한 추론 작업에서 능숙함을 보였지만, 경쟁적이면서 동적인 상호작용 시나리오에서는 성능이 덜 탐구되었습니다.
- 이 연구에서는 신속하게 변화하는 환경에서의 의사결정을 위한 LLM의 동적 추론 능력을 공식적으로 탐구합니다.
- 현실 세계의 동적 의사결정 복잡성을 반영하는 두 가지 게임 이론 기반의 파일럿 챌린지를 소개합니다.
- 이 챌린지들은 정의가 명확하여 LLM의 동적 추론 능력을 명확하고 제어 가능하며 정밀하게 평가할 수 있게 합니다.
- 광범위한 실험을 통해, 기존 추론 방법들이 역사적 정보를 바탕으로 한 k-수준 사고를 요구하는 동적 설정에서 취약함을 발견했습니다.
- 이에 대응하여, 경쟁자의 관점을 채택하고 반복적으로 k-수준 사고를 활용하는 새로운 추론 접근 방식인 “K-Level Reasoning”을 제안합니다.
- 이 접근 방식은 경쟁자의 후속 움직임 예측 정확도를 크게 향상시키고 전략적 의사결정에 관한 정보를 제공합니다.
- 해당 연구는 동적 추론의 견고한 정량적 벤치마크를 설정하는 동시에 동적 맥락에서 LLM의 숙련도를 뚜렷하게 증진시킵니다.

### [Repeat After Me: Transformers are Better than State Space Models at Copying](https://arxiv.org/abs/2402.01032)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/tIDlj9EG58UZBx74gENaf.png)

Vote: 12

Authors: David Brandfonbrener, Eran Malach, Sham M. Kakade, Samy Jelassi

- 변압기(Transformer)는 연속 모델링에 있어서 지배적인 구조체로 간주되나, 일반화된 상태 공간 모델(GSSM)이라고 불리는 고정된 크기의 잠재 상태를 사용하는 모델에 대한 관심이 증가하고 있습니다.
- 본 논문은 GSSM이 추론 시간에서의 효율성 측면에서 유망함을 보여주지만, 입력 컨텍스트에서 복제하는 작업에 관한 한 변압기 모델에 비해 한계가 있음을 보여줍니다.
- 이론적 분석을 통해 두 개의 레이어를 가진 변압기가 고정된 크기의 잠재 상태로 인해 근본적으로 제한되는 GSSM보다 지수 함수적 길이의 문자열 복사가 가능함을 증명했습니다.
- 경험적인 분석으로, 변압기는 컨텍스트를 복제하는 것을 요구하는 합성 작업에서 GSSM보다 효율성과 일반화 측면에서 우수하다는 것을 발견했습니다.
- 또한, 사전 훈련된 대형 언어 모델을 평가한 결과, 변압기 모델이 정보를 복사하고 컨텍스트에서 검색하는 데 있어서 상태 공간 모델보다 훨씬 뛰어남을 확인했습니다.
- 이러한 결과들은 실질적인 관심 분야에서 변압기와 GSSM 사이에 근본적인 차이가 있다는 것을 시사합니다.

### [Nomic Embed: Training a Reproducible Long Context Text Embedder](https://arxiv.org/abs/2402.01613)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Is-h2-Q72D6PLAYHBC0vB.png)

Vote: 7

Authors: Andriy Mulyar, Zach Nussbaum, Brandon Duderstadt, John X. Morris

- 이 기술 보고서는 완전 재현 가능한 첫 번째 오픈 소스, 오픈 웨이트, 오픈 데이터, 8192 컨텍스트 길이의 영문 텍스트 임베딩 모델인 'nomic-embed-text-v1' 학습에 대해 설명합니다.
- nomic-embed-text-v1은 OpenAI Ada-002와 OpenAI text-embedding-3-small 모델을 단문과 장문 컨텍스트 작업에서 모두 능가합니다.
- Apache 2 라이선스에 따라 훈련 코드와 모델 가중치를 공개합니다.
- 다른 오픈 소스 모델과 달리, nomic-embed-text-v1의 전체 복제를 가능하게 하는 2억 3500만 개의 선별된 텍스트 쌍을 포함하는 학습 데이터 로더를 공개합니다.
- 본 모델의 코드와 데이터는 https://github.com/nomic-ai/contrastors 에서 찾아서 복제할 수 있습니다.

### [EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks](https://arxiv.org/abs/2402.00892)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/0DldNeTa8j47JDrWkt4fA.png)

Vote: 7

Authors: Arun George Zachariah, Shijia Liao, Shiyi Lan

- 대규모 모델의 등장은 기계 학습에 새로운 시대를 열었으며, 방대한 데이터셋을 활용하여 복잡한 패턴을 포착 및 합성함으로써 작은 모델들보다 크게 우수한 성능을 보여줬습니다.
- 그럼에도 불구하고, 특히 오디오 생성 분야에서 규모 확장에 대한 탐구는 제한적이었고, 이전 노력들은 고음질(HiFi) 44.1kHz 도메인으로 확장되지 않았으며, 스펙트럼 불연속과 고주파 영역에서의 흐릿함, 그리고 도메인 외 데이터에 대한 견고성 부족 등의 문제점을 겪었습니다.
- 이러한 한계는 음악 및 노래 생성을 포함한 다양한 사용 사례로의 모델 적용성을 제한했습니다.
- 우리의 연구에서는 Enhanced Various Audio Generation via Scalable Generative Adversarial Networks (EVA-GAN)를 소개하며, 스펙트럼 및 고주파 재구성과 도메인 외 데이터 성능에서의 견고성 측면에서 이전 최고 기술 대비 큰 개선을 이루어냈습니다.
- EVA-GAN은 44.1kHz 오디오의 36,000시간에 달하는 방대한 데이터셋, 상황 인식 모듈, Human-In-The-Loop 아티팩트 측정 도구를 사용하여 HiFi 오디오 생성을 가능하게 하고, 모델을 약 2억 개의 매개변수로 확장했습니다.
- 우리의 작업 데모는 https://double-blind-eva-gan.cc에서 확인할 수 있습니다.

