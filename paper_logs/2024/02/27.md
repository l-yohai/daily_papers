## Daily Papers (2024-02-27)

### [ChatMusician: Understanding and Generating Music Intrinsically with LLM](https://arxiv.org/abs/2402.16153)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/WDMvwieajdGIJXfJ830Y0.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/WDMvwieajdGIJXfJ830Y0.mp4" muted="false"></video></div>

Vote: 36

Authors: Zeyue Tian, Ziyang Ma, Yizhi Li, Ge Zhang, Ruibo Liu, Liumeng Xue, Yinghao Ma, Tianhao Shen, Ziyu Wang, Qin Liu, Xiaowei Chi, Pengfei Li, Ziya Zhou, Shangda Wu, Cong Liu, Zili Wang, Tianyu Zheng, Ruibin Yuan, Hanfeng Lin, +, Yi Wang, Yiming Liang, Yuhang Wu

- 대규모 언어 모델(LLM)의 인상적인 텍스트 생성 능력에도 불구하고, 이러한 능력이 음악이라는 인류의 창의적 언어로 일반화되지 않았음을 발견하였습니다.
- ChatMusician은 본질적인 음악 능력을 통합하는 오픈 소스 LLM으로, 텍스트와 호환되는 음악 표기법인 ABC 악보를 기반으로 지속적인 사전 훈련과 라마2(LLaMA2)의 미세 조정을 기반으로 합니다.
- 이 모델은 외부의 다중 모달 신경 구조나 토크나이저 없이 순수한 텍스트 토크나이저를 이용해 음악을 이해하고 생성할 수 있습니다.
- 음악 능력을 부여하는 것이 언어 능력에 해를 끼치지 않으며, 심지어 약간 높은 MMLU 점수를 달성합니다.
- ChatMusician은 텍스트, 코드, 멜로디, 모티브, 음악 형태 등의 조건에 따라 구조화되고 전체 길이의 음악을 작곡할 수 있으며, GPT-4 베이스라인을 능가합니다.
- 제작한 대학 수준의 음악 이해 벤치마크인 MusicTheoryBench에서 ChatMusician은 LLaMA2와 GPT-3.5를 제로-샷 설정에서 뚜렷한 차이로 능가합니다.
- 연구는 LLM이 음악을 효과적으로 압축할 수 있음을 보여주지만 정복해야 할 중요한 영역이 남아 있다는 것을 밝힙니다.
- 4B 토큰 음악-언어 코퍼스인 MusicPile, 수집된 MusicTheoryBench, 코드, 모델, 그리고 GitHub에서의 데모를 공개합니다.

### [FuseChat: Knowledge Fusion of Chat Models](https://arxiv.org/abs/2402.16107)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/4O9EizBGqSgKw2ktFCplr.png)

Vote: 24

Authors: Fanqi Wan, Wei Bi, Longguang Zhong, Ziyi Yang, Xinting Huang, Xiaojun Quan

- 큰 언어 모델(LLMs)을 처음부터 훈련하는 것은 능력과 강점이 다양한 모델을 만들어낼 수 있지만, 이는 상당한 비용이 들고 역량에 중복이 생길 가능성이 있다.
- 존재하는 LLM을 합쳐 더욱 강력한 LLM을 만드는 것은 비싼 사전 훈련의 필요성을 줄일 수 있는 대안이다.
- 구조가 다른 LLM들로 인해, 직접적인 파라미터 결합은 실행이 불가능하다.
- 최근에 FuseLLM이 다양한 구조를 가진 여러 LLM의 지식을 대상 LLM으로 전달하여 경량 연속 훈련을 통해 지식 융합을 하는 개념을 도입했다.
- 본 보고서에서는 FuseLLM 프레임워크를 확장하여 채팅 LLM들의 융합을 실현하는 FuseChat을 제안한다.
- FuseChat은 먼저 구조와 규모가 다양한 소스 LLM들의 지식을 합쳐 동일한 구조와 크기를 가진 여러 대상 LLM에 경량 미세조정을 수행하는 단계로 구성된다.
- 그 다음, 이 대상 LLM들을 파라미터 공간 내에서 결합하며, 미세 조정 전후 파라미터 행렬의 변화 비율을 기반으로 결합 가중치를 결정하는 새로운 방법을 제안한다.
- 다양한 구조와 규모를 가진 세 개의 주요 채팅 LLM, 즉 NH2-Mixtral-8x7B, NH2-Solar-10.7B, 그리고 OpenChat-3.5-7B를 사용하여 접근법을 검증한다.
- 다양한 채팅 도메인을 포괄하는 실험 결과에서 FuseChat-7B는 7B와 34B 규모의 채팅 LLM 범위에서 우수한 성능을 나타내고, GPT-3.5 (3월)를 초과하고 Mixtral-8x7B-Instruct에 근접한 성능을 보여주었다.
- 코드, 모델 가중치, 데이터는 https://github.com/fanqiwan/FuseLLM 에서 공개적으로 접근 가능하다.

### [Multi-LoRA Composition for Image Generation](https://arxiv.org/abs/2402.16843)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/JvQHGGDcnlgggLFw0wiwh.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/JvQHGGDcnlgggLFw0wiwh.mp4" muted="false"></video></div>

Vote: 21

Authors: Yelong Shen, Yizhu Jiao, Yadong Lu, Siru Ouyang, Shuohang Wang, Weizhu Chen, Ming Zhong, Donghan Yu, Jiawei Han

- 낮은 랭크 적응(Low-Rank Adaptation, LoRA)은 특정 요소나 독특한 스타일과 같은 이미지 생성 시 정확한 묘사를 위해 텍스트-이미지 모델에서 널리 사용된다.
- 기존의 메소드들은 여러 LoRA를 효과적으로 조합하는 데 있어 어려움을 겪고 있으며, 특히 LoRA의 수가 증가할수록 복잡한 이미지 생성을 어렵게 한다.
- 본 논문에서는 디코딩 중심의 관점을 통해 다중 LoRA의 조합을 연구하고 있다.
- 'LoRA 스위치'는 각 탈잡음 단계마다 다른 LoRA 사이를 전환하는 훈련 없는 방법과 'LoRA 컴포지트'는 모든 LoRA를 동시에 통합해 더 조화로운 이미지 합성을 안내하는 방법을 제시한다.
- 이러한 접근법을 평가하기 위해 'ComposLoRA'라는 다양한 LoRA 카테고리와 480개의 조합 세트를 포함한 새롭고 포괄적인 테스트베드를 연구 내에 구축했다.
- GPT-4V를 기반으로 하는 평가 프레임워크를 사용하여, 우리의 방법이 특히 여러 LoRA를 조합할 때 현존하는 베이스라인보다 성능이 뚜렷이 향상됨을 보여준다.

### [Nemotron-4 15B Technical Report](https://arxiv.org/abs/2402.16819)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/4UrqVp4fu-hQ8cyPsNAd4.png)

Vote: 17

Authors: Jiwei Liu, Aastha Jhunjhunwala, Deepak Narayanan, James Maki, Jupinder Parmar, Ayush Dattagupta, Shrimai Prabhumoye, Sandeep Subramanian, Miguel Martinez, Ameya Mahabaleshwarkar, Denys Fridman, Mostofa Patwary, Patrick LeGresley, Vibhu Jawa, Dan Su, John Kamalu, Chen Zhu, Joseph Jennings, Jared Casper, Annika Brundyn, +, Osvald Nitski, Jiaxuan You

- Nemotron-4 15B는 총 8조 개의 텍스트 토큰을 학습한 150억 개의 파라미터를 가진 대규모 다국어 언어 모델을 소개합니다.
- 이 모델은 영어, 다국어, 코딩 작업을 평가할 때 강력한 성능을 보여주며, 비슷한 크기의 기존 공개 모델들 중 7개의 다운스트림 평가 분야 중 4개에서 모두 우수한 성능을 나타냅니다.
- 또한, Nemotron-4 15B는 동일한 크기의 모델 중에서는 물론이고, 4배 이상 크거나 다국어 작업을 위해 특별히 만들어진 모델들보다도 뛰어난 다국어 능력을 선보입니다.
- 나머지 평가 분야에서도 선도적인 공개 모델과 경쟁력 있는 성능을 달성함으로써, 다양한 언어적 작업에서의 사용 가능성을 시사합니다.

### [StructLM: Towards Building Generalist Models for Structured Knowledge Grounding](https://arxiv.org/abs/2402.16671)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/a0ikiPRfVdZK8OB7FBSrH.png)

Vote: 15

Authors: Stephen W. Huang, Weiming Ren, Xiang Yue, Wenhu Chen, Ge Zhang, Alex Zhuang, Jie Fu, Junjie Wang, Xinrun Du, Tianyu Zheng

- 대규모 언어 모델(LLM)이 일반 텍스트 처리에 탁월한 능력을 보여주고 있음에도 불구하고, 표, 그래프, 데이터베이스 같은 구조화된 데이터를 해석하고 활용하는데 있어서는 한계가 있음을 알 수 있다.
- ChatGPT와 같은 LLM이 최신 기술(SoTA) 수준의 모델에 비해 평균 35% 정도의 성능 차이를 보여 구조화된 데이터 처리에 있어 중요한 약점을 지니고 있음이 밝혀졌다.
- 구조화된 지식 연계(Structured Knowledge Grounding, SKG) 능력을 향상시키기 위해, 개발자들은 110만 개의 예시를 포함한 포괄적인 지시 튜닝 데이터셋을 개발했다.
- 이 데이터셋을 기반으로, Code-LLaMa 아키텍처를 사용하여 7B에서 34B 파라미터에 이르는 일련의 모델을 훈련시킨 결과, 이 모델들을 StructLM 시리즈라고 명명한다.
- StructLM 시리즈는 평가된 18개 데이터셋 중 14개에서 특정 작업에 맞춘 모델들을 능가했으며, 7개의 SKG 작업에서 새로운 최신 기술 수준(SoTA)을 달성했다.
- 또한 StructLM은 6개의 새로운 SKG 작업에서 뛰어난 일반화 능력을 보여주었다.
- 예상과 달리, 모델의 크기를 확장하는 것이 소폭의 이점만을 가져옴을 발견했으며, StructLM-34B가 StructLM-7B보다 약간의 개선만을 보임으로써 구조화된 지식 연계는 여전히 도전적인 작업임을 시사한다.
- 새로운 차원으로 나아가기 위해서는 구조화된 지식 연계에 더욱 혁신적인 설계가 필요함을 제안한다.

### [MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs](https://arxiv.org/abs/2402.15627)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/igMXMW43IYmaQwXQ7sz9h.png)

Vote: 15

Authors: Sun He, Ding Zhou, Qi Hou, Yinmin Zhong, Qi Huang, Yulu Jia, Yiyao Sheng, Haohan Xu, Hongmin Chen, Yangrui Chen, Zhuo Jiang, Haoran Wei, Zhi Zhang, Haibin Lin, Ziheng Jiang, Zhihao Bai, Cong Xie, Shibiao Nong, Shipeng Yan, Yanghua Peng, +, Xiang Li, Zhang Zhang

- 이 연구는 10,000개 이상의 GPU를 사용하여 대규모 언어 모델(Large Language Models, LLMs)의 훈련을 위해 설계되고 구현된 MegaScale이라는 시스템에 관한 설계 및 엔지니어링 경험을 제시합니다.
- 대규모로 언어 모델을 훈련할 때 효율성과 안정성에 전례 없는 도전이 발생하는 것으로, 이를 극복하기 위해 알고리즘과 시스템 구성 요소를 함께 디자인하는 전체 스택 접근 방식이 사용됩니다.
- 모델 블록과 최적화 도구 설계, 계산과 통신의 중첩, 연산자 최적화, 데이터 파이프라인, 그리고 네트워크 성능 튜닝을 통해 안정적인 고효율성을 유지합니다.
- 대규모 훈련에서 많은 안정성 문제가 타나날 수 있는데, 이를 해결하기 위해 시스템 구성과 깊은 스택 이벤트를 모니터링 하여 문제의 원인을 파악하고 효율적인 방식을 도출하는 진단 도구들을 개발했습니다.
- MegaScale은 12,288개의 GPU에서 175B LLM 모델을 훈련시킬 때 모델 플롭스 활용도(Model FLOPs Utilization, MFU)를 55.2%에 달하게 하여, Megatron-LM 대비 MFU를 1.34배 향상시켰습니다.
- 연구팀은 운영 경험을 공유하며, 실패와 지연 문제를 식별하고 수정하는 방법을 제시하여 미래의 대규모 언어 모델 시스템 연구에 영감을 줄 수 있기를 바랍니다.

### [MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT](https://arxiv.org/abs/2402.16840)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/InGhb9_Qq6r4NNWx8wHmL.png)

Vote: 12

Authors: Hisham Cholakal, Fahad Shahbaz Khan, Eric P. Xing, Omkar Thawakar, Tim Baldwin, Ashmal Vayani, Michael Felsberg, Rao M. Anwer, Salman Khan

- 최근의 큰 규모 언어모델(Large Language Models, LLMs) 개발 트렌드는 '더 크면 더 좋다' 였지만, 이러한 LLMs는 개인정보 보호, 보안, 지속 가능성 등을 중시하며 소형 기기에서의 처리, 에너지 효율성, 낮은 메모리 사용량 및 응답 효율성을 요구하는 시나리오에 적합하지 않습니다.
- 이 논문은 제한된 자원을 가진 장치들을 위해 정확하면서도 효율적인 소형 언어 모델(Small Language Models, SLMs)을 설계하는 도전과제를 다루며, "적을수록 좋다"는 패러다임을 탐구합니다.
- 주요 기여로, 저자들은 0.5B 파라미터 규모의 정확하고 완전히 투명한 오픈 소스 SLM인 MobiLlama를 소개합니다. 이는 자원 제한 컴퓨팅에 특화되어 성능을 향상시키며 자원 요구를 줄이고자 합니다.
- MobiLlama는 더 큰 모델에서 시작하여 주의 깊은 파라미터 공유 스킴을 적용함으로써 사전 훈련 및 배포 비용을 감소시키는 SLM 설계입니다.
- 이 연구는 SLMs의 개방형 소스 부족을 해결하고 모델의 완전한 투명성을 보장하고자 하는 노력을 하였으며, 훈련 데이터 파이프라인, 훈련 코드, 모델 가중치 및 평가 코드뿐만 아니라 300개 이상의 체크포인트를 https://github.com/mbzuai-oryx/MobiLlama 에서 제공합니다.

### [Towards Open-ended Visual Quality Comparison](https://arxiv.org/abs/2402.16641)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2NTei4Nfrczk-iko1v9JF.png)

Vote: 11

Authors: Hanwei Zhu, Haoning Wu, Chaofeng Chen, Guangtao Zhai, Shiqi Wang, Xiaohong Liu, Annan Wang, Zicheng Zhang, Chunyi Li, Wenxiu Sun, Liang Liao, Qiong Yan, Erli Zhang, Weisi Lin

- 이미지 품질 평가(IQA)를 위한 연구에서 비교 설정을 널리 채택하고 있으며, 이는 관찰자 간 평가 기준을 표준화하고 분명한 답변을 얻을 수 있게 해준다.
- 이 연구에서는 대규모 멀티 모달 모델(LMM)의 발전을 활용하여, 열린 범위의 질문에 답할 수 있으며, 직접적인 답변을 넘어서 상세한 이유를 제공할 수 있는 개방형 시각 품질 비교로 확장했다.
- 이를 위해 Co-Instruct라는 모델을 제안하며, 이를 학습시키기 위해 LMM이 통합한 단일 이미지 품질 설명과 GPT-4V "교사"의 응답으로부터 데이터를 수집한 Co-Instruct-562K 데이터셋을 구축했다.
- 또한 LMM에 대한 멀티 이미지 비교 벤치마크인 MICBench를 최초로 제안하여 이 새로운 설정을 더 잘 평가하기 위한 기준을 마련했다.
- Co-Instruct는 기존의 최신 개방형 LMM들보다 30% 높은 정확도를 달성할 뿐만 아니라, 교사 모델인 GPT-4V를 현재 관련 벤치마크와 제안된 MICBench 양쪽에서 모두 뛰어넘는 성능을 보였다.
- 연구 모델은 https://huggingface.co/q-future/co-instruct에 공개되어 있다.

### [Do Large Language Models Latently Perform Multi-Hop Reasoning?](https://arxiv.org/abs/2402.16837)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Az5DrQf0hQpNDciaF5taj.png)

Vote: 10

Authors: Elena Gribovskaya, Nora Kassner, Mor Geva, Sebastian Riedel, Sohee Yang

- 본 연구는 대형 언어 모델(Large Language Models, LLMs)이 "Superstition을 부른 가수의 어머니는"과 같이 복잡한 프롬프트에 대해 다단계 추론(multi-hop reasoning)을 수행하는지 여부를 분석한다.
- 연구팀은 LLM이 첫째로 "Superstition을 부른 가수"를 스티비 원더로 내재적으로 식별하고, 둘째로 스티비 원더의 어머니에 대한 지식을 활용하여 프롬프트를 완성하는 추론 경로를 찾는다.
- 첫 번째 단계로, 다른 엔티티가 아닌 가교 엔티티(bridge entity)를 간접적으로 언급하는 프롬프트의 변경이 LLM의 가교 엔티티 인출(internal recall)을 높이는지 테스트한다.
- 두 번째 단계로는 이러한 인출이 LLM이 가교 엔티티에 대한 지식을 얼마나 잘 활용하는지를 측정한다.
- 특정 관계 유형에 대한 프롬프트에서는 다단계 추론을 수행하는 경로가 80% 이상에서 관찰되는 강력한 증거가 발견되었으나, 그 활용은 프롬프트의 유형에 따라 매우 상황적이었다.
- 전반적으로 첫 번째 단계에 대한 증거는 상당하지만, 두 번째 단계와 전체 다단계 추론 경로에 대한 증거는 보통 수준이었다.
- 모델 크기 증가에 따른 추론의 첫 번째 단계에 대한 명확한 스케일링 경향이 있었지만, 두 번째 단계에 대해서는 그러한 경향이 나타나지 않았다.
- 실험 결과는 LLM의 미래 개발 및 응용에 있어 잠재적인 도전 과제와 기회를 보여준다.

### [Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts](https://arxiv.org/abs/2402.16822)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/gwUY2uHyoFs3RkbQ0PMnV.png)

Vote: 9

Authors: Jack Parker-Holder, Andrei Lupu, Aram H. Markosyan, Sharath Chandra Raparthy, Mikayel Samvelyan, Jakob Foerster, Tim Rocktäschel, Manish Bhatt, Minqi Jiang, Roberta Raileanu, Eric Hambro, Yuning Mao

- 대형 언어 모델(LLMs)의 강건성을 이해하고 향상시키는 것이 점점 중요해지면서, 사용자의 가해적 프롬프트에 대한 대응방법을 발견하는 것이 중요해졌습니다.
- 기존의 메서드는 특정 영역에 집중하거나 다양성이 부족하고, 방대한 인간의 주석이 필요했습니다.
- 이러한 한계를 극복하기 위해, Rainbow Teaming으로 불리는 새로운 접근 방식을 제시합니다; 이는 가해적 프롬프트 생성을 품질과 다양성 문제로 보고, 효과적이며 다양한 프롬프트를 생성하기 위해 개방형 탐색을 활용합니다.
- Rainbow Teaming은 안전성, 질의응답, 사이버보안을 포함한 다양한 영역에서 모델의 취약점을 밝혀냅니다.
- Rainbow Teaming으로 생성된 합성 데이터에 대한 미세조정이 최신 LLMs의 안전성을 개선하면서도 일반적인 능력과 도움이 되는 기능을 해치지 않음을 입증합니다.
- 이 접근 방식은 개방형 자기개선의 길을 제시합니다.

