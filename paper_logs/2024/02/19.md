## Daily Papers (2024-02-19)

### [Linear Transformers with Learnable Kernel Functions are Better In-Context Models](https://arxiv.org/abs/2402.10644)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/wPg9SdNuwev7cc7JCIvWQ.png)

Vote: 47

Authors: Boris Shaposhnikov, Alexey Gorbatovski, Yaroslav Aksenov, Daniil Gavrilov, Sofia Maria Lo Cicero Vaina, Nikita Balagansky

- 자연어 처리 분야에서 하위 제곱 구조의 언어 모델링(Linear Transformers) 공학의 전선을 나아가는 것이 중요합니다.
- 최근 혁신 모델 중 State Space Models은 언어 모델링 작업에서 Transformer의 성능을 뛰어넘었지만, In-Context Learning 능력에서 결점을 드러내었습니다.
- "Based" 모델은 Linear Transformer와 exponential 함수의 테일러 전개에서 영감을 얻은 커널을 결합하고 컨벌루셔널 네트워크를 통해 보강하여 생겨났으며, In-Context 학습에서 Transformer에 필적하는 성능을 보여주었습니다.
- 본 연구에서는 Based 커널에 단일하면서 우아한 변경을 제안하여 Multi-Query Associative Recall 작업 및 Pile 데이터셋에서의 전체적인 언어 모델링 과정에서 In-Context Learning 능력을 크게 향상시켰습니다.

### [In Search of Needles in a 10M Haystack: Recurrent Memory Finds What LLMs Miss](https://arxiv.org/abs/2402.10790)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Put7Y4YOMN1HqP7JPDK2L.png)

Vote: 19

Authors: Mikhail Burtsev, Yuri Kuratov, Artyom Sorokin, Aydar Bulatov, Dmitry Sorokin, Petr Anokhin

- 이 논문은 긴 문서를 처리하는 과제에 대해 다루며, 생성적 변환 모델인 '트랜스포머 모델'을 사용하여 연구합니다.
- 새로운 벤치마크인 'BABILong'을 도입하여, 광범위한 텍스트 내에서 분산된 사실을 추출하고 처리하는 모델의 능력을 평가합니다.
- GPT-4와 RAG를 포함한 벤치마크 평가는 일반적인 방법들이 10^4개 요소까지의 시퀀스에서만 효과적임을 밝혀냈습니다.
- 반면, 반복적 메모리 증강을 통해 GPT-2를 미세 조정함으로써, 최대 10^7개 요소를 다루는 과제를 처리할 수 있는 능력을 부여하였습니다.
- 이러한 성과는 지금까지 공개된 신경망 모델이 처리한 가장 긴 입력으로, 긴 시퀀스를 처리하는 능력에서 중요한 향상을 보여주었습니다.

### [DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://arxiv.org/abs/2402.10379)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/pf74Rwj_v_MqRmTwjxaGP.png)

Vote: 13

Authors: Chris Callison-Burch, Ajay Patel, Colin Raffel

- 대규모 언어 모델(LLM)은 NLP 연구자들에게 다양한 작업에서 중요하고 지배적인 도구가 되었습니다.
- 연구자들은 합성 데이터 생성, 태스크 평가, 파인튜닝, 모델 축소 등 모델 중심 연구 워크플로우에 LLM을 사용하지만 이러한 모델의 규모, 폐쇄 소스 성격, 표준화되지 않은 도구의 부재로 인해 도전과제에 직면합니다.
- 이러한 모델의 급격한 부상과 독특한 도전과제들은 공개 과학과 이를 사용하는 작업의 재현 가능성에 즉각적인 부정적 영향을 미쳤습니다.
- 본 논문에서는 연구자들이 강력한 LLM 워크플로우를 구현하기 위해 간단한 코드를 작성할 수 있게 하는 오픈 소스 파이썬 라이브러리인 DataDreamer를 소개합니다.
- DataDreamer는 연구자들이 공개 과학과 재현 가능성을 장려하기 위해 우리가 제안하는 모범 사례를 준수할 수 있도록 도와줍니다.
- 라이브러리와 문서는 https://github.com/datadreamer-dev/DataDreamer 에서 이용할 수 있습니다.

### [GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object with Gaussian Splatting](https://arxiv.org/abs/2402.10259)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2a4v22ryVq9NxluHAy7gf.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2a4v22ryVq9NxluHAy7gf.mp4" muted="false"></video></div>

Vote: 10

Authors: Xiaopeng Zhang, Lingxi Xie, Ruofan Liang, Wei Shen, Qi Tian, Chen Yang, Sikuang Li, Jiemin Fang

- 매우 희소한 시점에서 3D 객체를 재구성하고 렌더링하는 것은 3D 비전 기술의 응용을 촉진하고 사용자 경험을 개선하는데 중요합니다.
- 희소한 시점의 이미지들은 제한된 3D 정보만을 포함하므로, 멀티뷰 일관성 구축과 불충분한 시점 커버리지로 인한 객체 정보의 부분 생략이나 과도한 압축과 같은 두 가지 주요 도전 과제가 있습니다.
- 이러한 도전과제를 극복하기 위해, 우리는 단 네 개의 입력 이미지만을 사용해 고화질 렌더링을 달성하는 가우시안 스플래팅을 이용하여 3D 객체를 표현하고 렌더링하는 프레임워크인 GaussianObject를 제안합니다.
- 구조적 특혜를 초기 최적화 과정에 명시적으로 주입하여 멀티뷰 일관성을 구축하는 것을 돕는 시각적 선체(visual hull)와 플로터 제거(floater elimination) 기술을 소개합니다. 이로 인해 조잡한 3D 가우시안 표현이 생성됩니다.
- 생략된 객체 정보를 보완하기 위해, 가우시안을 더 세밀하게 다듬는 과정에서 확산 모델에 기반한 가우시안 수리 모델을 구축합니다.
- 수리 모델 훈련을 위한 이미지 쌍을 얻기 위한 자기생성 전략을 설계합니다.
- GaussianObject는 MipNeRF360, OmniObject3D, OpenIllumination 등과 같은 도전적인 데이터셋에서 평가되었으며, 단 4개의 시점만으로도 강력한 재구성 결과를 달성하여 이전의 최신 기술들을 크게 능가했습니다.

### [LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models](https://arxiv.org/abs/2402.10524)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/rbEs5kCsYN0kLfgA2yCDJ.png)

Vote: 10

Authors: Michael Terry, Minsuk Chang, Michael Xieyang Liu, Minsuk Kahng, Ian Tenney, Mahima Pushkarna, Krystal Kallarackal, Lucas Dixon, James Wexler, Emily Reif

- 대형 언어 모델(LLMs)의 응답 품질을 비교 평가하는 새로운 접근법인 자동 나란히 비교 평가가 주목받고 있지만, 이를 분석하는 과정에서 확장성과 해석가능성에 도전이 되고 있다.
- 본 논문에서는 자동 나란히 비교 평가 결과를 상호작용적으로 분석할 수 있는 새로운 시각 분석 도구인 LLM Comparator를 제안한다.
- 이 도구는 사용자들이 모델의 성능이 기준 모델보다 더 좋거나 나쁜 경우를 이해하고, 두 모델의 응답이 질적으로 어떻게 다른지를 파악하는 인터랙티브한 워크플로우를 지원한다.
- 연구원과 엔지니어들과 긴밀히 협력하여 이 도구를 반복적으로 설계하고 개발했으며, 이 논문은 사용자 도전 과제 식별, 도구의 설계 및 개발, 그리고 모델 평가를 정기적으로 수행하는 참가자들과의 관찰 연구에 대해 상세하게 설명한다.

### [LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing](https://arxiv.org/abs/2402.10294)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/_tC90Q7sH6FSSQmNDFFZf.png)

Vote: 9

Authors: Yan Xu, Bryan Wang, Haijun Xia, Yuliang Li, Zhaoyang Lv, Raj Sodhi

- 비디오 편집에 대한 전문성과 노력은 입문자들에게 장애물이 되곤 하는데, 본 논문에서는 비디오 편집 작업 흐름에 대규모 언어 모델(LLMs)의 통합을 통해 이러한 장벽을 줄이는 방법을 탐구하고 있음.
- 이 논문은 LAVE라는 새로운 시스템을 통해 사용자의 비디오에 대해 자동으로 언어 설명을 생성하며, 이를 바탕으로 LLM이 비디오 처리 및 편집 작업 지원을 가능하게 함.
- 사용자가 편집 목표를 제공하면, 에이전트는 이를 충족시키기 위해 관련된 행동을 계획하고 실행함.
- 또한, LAVE는 사용자가 에이전트 또는 직접 UI 조작을 통해 비디오를 편집할 수 있게 하여 유연성을 제공하고, 에이전트 행동에 대한 수동 수정을 가능하게 함.
- 초보자부터 숙련된 편집자에 이르기까지 여덟 명의 참가자를 포함하는 사용자 연구를 통해 LAVE의 효과성을 입증함.
- 연구 결과는 제안된 LLM 지원 편집 패러다임에 대한 사용자 인식과 사용자 창의성과 공동 창작에 대한 영향에 대한 통찰을 제공함.
- 이러한 결과를 바탕으로, 에이전트 지원 콘텐츠 편집의 미래 발전을 위한 디자인 시사점을 제시함.

### [Large Language Models as Zero-shot Dialogue State Tracker through Function Calling](https://arxiv.org/abs/2402.10466)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/BJoUN-XNlzrZSoiNWoGfm.png)

Vote: 8

Authors: Xin Luna Dong, Seungwhan Moon, Paul A. Crook, Xifeng Yan, Adithya Sagar, Mike Ross, Zhiyu Zoey Chen, Patrick Huber, Zekun Li, Zhaojiang Lin

- 일반적인 대화 시스템에서 뛰어난 이해력과 생성 능력을 발휘하는 대규모 언어 모델(LLMs)의 활용이 증가하고 있지만, 특정 작업 및 도메인 내에서 효과적인 대화 상태 추적(DST)이 필요한 작업 지향 대화(TOD)에서는 효과가 덜 만족스러움을 보여왔다.
- 본 연구에서는 기능 호출을 통해 LLMs로 DST 문제를 해결하는 새로운 접근 방식 FnCTOD를 제안하며, 이 방법은 광범위한 도메인에 걸쳐 대량의 데이터 수집이나 모델 조정 없이 제로샷 DST에 적응할 수 있도록 개선한다.
- 실험 결과는 개방형 소스 및 독점 LLMs를 사용하여, 단순한 맥락 프롬프트를 통해 기존 ChatGPT가 달성한 최신 기술(SOTA)을 7B 또는 13B 파라미터 모델로 넘어서고, ChatGPT의 성능을 5.6% 평균 JGA로 향상시켜 SOTA를 능가함을 보여준다.
- GPT-3.5와 GPT-4에 대해 개별 모델의 결과는 각각 4.8% 및 14% 향상되었다.
- 또한, 다양한 작업 지향 대화에 대한 소규모 튜닝을 통해, 특히 13B 파라미터를 가진 LLaMA2-Chat 모델에게 기능 호출 능력과 ChatGPT 수준의 DST 성능을 장착함으로써 채팅 기능을 유지하면서 성능을 높일 수 있음을 보여준다.
- 연구진은 실험 코드 및 모델을 오픈소스로 공개할 계획임을 밝혔다.

### [Make a Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation](https://arxiv.org/abs/2402.10491)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/1DHxfNjujX1orJGY07sTt.png)

Vote: 8

Authors: Lanqing Guo, Siyu Huang, Qifeng Chen, Xintao Wang, Yufei Wang, Yingqing He, Haoxin Chen, Yong Zhang, Xiaodong Cun, Bihan Wen, Menghan Xia, Ying Shan

- 확산 모델은 이미지 및 비디오 생성에 매우 효과적인 것으로 입증되었지만, 단일 규모의 훈련 데이터로 인해 다양한 크기의 이미지 생성 시 구성의 어려움을 직면하고 있습니다.
- 본 논문에서는 결정된 저해상도 모델에서 얻은 풍부한 지식을 활용하여 고해상도 이미지 및 비디오 생성에 빠르게 적응할 수 있는 새로운 자체 캐스케이드 확산 모델을 제안합니다.
- 이 모델은 조정 없는 튜닝 또는 저비용 업샘플러 튜닝 패러다임을 사용하여 고성능으로 빠르게 고해상도에 적응 가능합니다.
- 다중 규모 업샘플러 모듈의 시퀀스를 통합함으로써, 자체 캐스케이드 확산 모델은 원래의 구성 및 생성 능력을 보존하면서 고해상도로 효율적으로 적응할 수 있습니다.
- 추론 과정을 가속화하고 지역적인 구조적 세부사항을 개선하기 위해 피벗 가이드 잡음 재조정 전략을 제안합니다.
- 전체 미세조정에 비해, 저희의 방법은 5배 빠른 훈련 속도를 달성하며, 추가적인 튜닝 파라미터는 0.002M만을 요구합니다.
- 광범위한 실험을 통해 10k 스텝만으로 빠르게 고해상도 이미지 및 비디오 합성으로 적응할 수 있으며, 추가적인 추론 시간은 거의 들지 않음을 입증하였습니다.

### [Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots](https://arxiv.org/abs/2402.10329)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/x2YQTAWluHL8R2FuC-smL.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/x2YQTAWluHL8R2FuC-smL.mp4" muted="false"></video></div>

Vote: 6

Authors: Siyuan Feng, Shuran Song, Benjamin Burchfiel, Eric Cousineau, Russ Tedrake, Chuer Pan, Zhenjia Xu, Cheng Chi

- 우리는 'Universal Manipulation Interface (UMI)'라는 데이터 수집 및 정책 학습 프레임워크를 제시하며, 이를 통해 야외 환경에서의 인간 데모를 직접 로봇 정책에 전송할 수 있습니다.
- UMI는 휴대가능하고 저비용이며 정보가 풍부한 데이터 수집을 위해 손으로 들 수 있는 그리퍼와 신중한 인터페이스 설계를 활용합니다.
- 이 프레임워크는 추론 시간 대기 시간 일치 및 상대적 궤적 작업 표현을 사용하여 실제 정책을 학습하기 위한 정책 인터페이스를 포함합니다.
- UMI를 통해 배워진 정책들은 하드웨어에 구애 받지 않고 다양한 로봇 플랫폼에서 배치 및 사용할 수 있습니다.
- UMI는 새로운 로봇 조작 기능을 가능하게 하여, 각 작업에 대해 오직 훈련 데이터만 변경함으로써 동적이고 양손을 사용하는 정교하고 장기적인 행동을 일반화할 수 있습니다.
- UMI의 다양성과 효과는 실제 세계에서의 실험을 통해 입증되었으며, 다양한 인간 데모에 대한 훈련을 받은 정책들이 새로운 환경과 객체에 대해 zero-shot 일반화를 성공적으로 보여줍니다.
- UMI의 하드웨어 및 소프트웨어 시스템은 https://umi-gripper.github.io에서 오픈소스로 제공됩니다.

### [SPAR: Personalized Content-Based Recommendation via Long Engagement Attention](https://arxiv.org/abs/2402.10555)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/MlAPkYoYJ909473ZqXaIZ.png)

Vote: 6

Authors: Ning Yao, Bo Long, Rong Jin, Chiyu Zhang, Jie Lei, Muhammad Abdul-Mageed, Sinong Wang, Jun Chen, Yifei Sun, Sem Park

- 사용자의 장기적인 참여 이력을 활용하는 것은 개인화된 콘텐츠 추천에 있어 필수적입니다.
- 자연어 처리(NLP)에서 사전 학습된 언어 모델(PLMs)의 성공으로 인해 사용자 이력 및 후보 항목 인코딩에 그들이 사용되며, 콘텐츠 추천을 텍스트 의미 매칭 작업으로 구성합니다.
- 그러나 기존의 작업들은 매우 긴 사용자 역사적 텍스트 처리와 불충분한 사용자-아이템 상호작용에 어려움을 겪고 있습니다.
- 본 논문에서는 사용자 참여 이력으로부터 전체적인 사용자 관심사를 효과적으로 추출하는 새로운 콘텐츠 기반 추천 프레임워크인 SPAR을 소개합니다.
- SPAR는 PLM, 폴리-어텐션 층, 주의 집중 희소성 메커니즘을 이용하여 사용자의 역사를 세션 기반 방식으로 인코딩합니다.
- 사용자와 아이템 측의 특징이 참여 예측을 위해 충분히 결합되면서, 효율적인 실용 모델 배치를 위해 양측이 독립적인 대표성을 유지합니다.
- 또한, SPAR는 대규모 언어 모델(LLM)을 활용하여 사용자 참여 이력으로부터 전역적인 관심사를 추출함으로써 사용자 프로파일링을 강화합니다.
- 두 벤치마크 데이터셋에서 실시한 광범위한 실험은 SPAR 프레임워크가 기존의 최신 기법(SoTA)들보다 우수한 성능을 나타내는 것을 증명합니다.

### [PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter](https://arxiv.org/abs/2402.10896)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Vmk0-ZL_1yyaBEp_f9Txb.png)

Vote: 5

Authors: Shen Yan, Junfei Xiao, Alan Yuille, Boyu Wang, Zheng Xu

- 이 논문은 점진적으로 정렬된 언어 모델을 사용하여 고정된 비전 인코더와 큰 언어 모델(Large Language Models, LLM) 사이를 효과적으로 연결할 수 있음을 보여줍니다.
- 기존의 비전 인코더와 LLM의 기본 구조와 사전 학습 방법이 광범위하게 연구되었지만, 시각-언어 어댑터의 구조와 훈련 전략은 최근 연구마다 크게 달라집니다.
- 연구자들은 최첨단의 perceivers resampler 구조를 철저히 조사하고 강력한 기준선을 설정했지만, perceivers resampler을 사용한 시각-언어 정렬은 직접적인 지도 부족으로 인해 수렴 속도가 느리고 확장성이 제한되었다는 점을 발견했습니다.
- 이러한 문제를 해결하기 위해 저자들은 PaLM2-VAdapter라는 새로운 방법을 제안하며, 이는 진보적으로 정렬된 언어 모델을 시각-언어 어댑터로 활용합니다.
- perceivers resampler를 사용한 강력한 기준선과 비교하여, PaLM2-VAdapter는 더 빠른 수렴, 더 높은 성능 및 강화된 확장성을 경험적으로 보여줍니다.
- 다양한 시각적 질문 응답(VQA) 작업과 이미지 및 비디오에 대한 캡셔닝 작업에서 광범위한 실험을 통해, 우리의 모델은 최첨단 시각적 이해 및 다중 모달 추론 능력을 나타낸다는 것을 보여줍니다.
- 특히, 우리의 방법은 기존의 대형 시각-언어 모델보다 30~70% 적은 매개변수를 사용하면서 이러한 발전을 달성하여 상당한 효율성 향상을 표시합니다.

### [RLVF: Learning from Verbal Feedback without Overgeneralization](https://arxiv.org/abs/2402.10893)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/sNQ7y9jsYQIdogVCENsVw.png)

Vote: 5

Authors: Archit Sharma, Alexander Khazatsky, Annie S Chen, Eric Mitchell, Sheryl Hsu, Chelsea Finn, Moritz Stephan

- 대규모 언어 모델(Large Language Models, LLMs)을 다양한 맥락에서 배포할 때, 사용자의 세밀한 요구사항과 선호도에 맞게 모델의 기본 행동을 수정하거나 맞춤화해야 할 수 있는 능력이 필요합니다.
- 고수준 언어 피드백을 이용하여 모델 조정을 명시하는 인터페이스는 매우 편리하지만, 모델에 대한 간단한 피드백 유도로 인해 피드백이 적용되지 않아야 할 상황에서도 일반화가 이루어지는 문제가 있습니다.
- 이러한 과도한 일반화 문제를 해결하기 위해 연구진은 '문맥화된 비판을 통한 제한된 선호도 최적화(Contextualized Critiques with Constrained Preference Optimization, C3PO)'이라는 새로운 방법을 제안하였습니다.
- C3PO는 고수준 피드백을 이용하여 그 피드백이 어떻게 적용되어야 하고 적용되지 말아야 하는지 명시하는 작은 합성 선호도 데이터셋을 생성합니다.
- 이 방법은 피드백이 적용되지 않는 맥락에 있는 프롬프트에 대해 원래 모델로부터의 발산을 최소화하면서 모델을 합성 선호도 데이터에 따라 미세 조정합니다.
- 실험 결과, C3PO은 관련 시나리오에 대해 효과적으로 언어적 피드백을 적용하는 동시에 기타 맥락에 대한 기존 행동을 유지하는 것으로 나타났습니다.
- 인간과 GPT-4가 생성한 고수준 피드백 모두에서, C3PO은 맥락 내 기준선에 비교해 피드백을 준수하면서 과도한 일반화를 30% 감소시켰습니다.

