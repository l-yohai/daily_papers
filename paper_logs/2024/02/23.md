## Daily Papers (2024-02-23)

### [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://arxiv.org/abs/2402.14658)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/J9Z7fBm_fC6eQV8-yjdmk.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/J9Z7fBm_fC6eQV8-yjdmk.mp4" muted="false"></video></div>

Vote: 32

Authors: Tianhao Shen, Wenhu Chen, Jie Fu, Xiang Yue, Bill Yuchen Lin, Ge Zhang, Tianyu Zheng, Xueling Liu

- 대규모 언어 모델의 도입으로 코드 생성이 크게 발전하였으나, 오픈소스 모델은 GPT-4 코드 해석기의 실행 능력과 반복적인 미세 조정 기능이 종종 부족합니다.
- 이러한 문제를 해결하기 위해, OpenCodeInterpreter는 코드를 생성하고 실행하며 반복적으로 세부 조정하는 일련의 오픈소스 코드 시스템으로 소개됩니다.
- 68K 회의 멀티 턴 인터랙션을 특징으로 하는 Code-Feedback 데이터셋을 지원하며, OpenCodeInterpreter는 실행 및 인간의 피드백을 통합하여 동적 코드 세부 조정을 가능하게 합니다.
- HumanEval, MBPP 및 EvalPlus에서 개선된 버전을 포함한 주요 벤치마크에서 OpenCodeInterpreter의 종합적인 평가는 뛰어난 성능을 나타냈습니다.
- 특히, OpenCodeInterpreter-33B는 HumanEval과 MBPP의 평균(및 플러스 버전)에서 83.2(76.4)의 정확성을 달성하며, GPT-4의 84.2(76.2)에 매우 근접하며, GPT-4에서 합성된 인간의 피드백을 통해 91.6(84.6)으로 더욱 향상됩니다.
- OpenCodeInterpreter는 오픈 소스 코드 생성 모델과 GPT-4 코드 인터프리터와 같은 독점 시스템 간의 격차를 좁힙니다.

### [Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping](https://arxiv.org/abs/2402.14083)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/vil4JnUKWuwKa_SWYPFps.png)

Vote: 24

Authors: Michael Rabbat, Sainbayar Sukhbaatar, Paul Mcvay, Lucas Lehnert, Yuandong Tian

- 트랜스포머(Transformer)는 여러 응용 분야에서 큰 진보를 이루었지만 복잡한 의사결정 과제를 해결하는 데 있어 전통적 기호 플래너(symbolic planners)에 뒤쳐지고 있다.
- 본 연구에서는 트랜스포머를 이용하여 복잡한 계획 작업을 해결하기 위한 훈련 방법을 소개하며, 'Searchformer'라는 모델을 제시하여 이전에 접하지 않은 Sokoban 퍼즐을 93.7%의 확률로 최적으로 해결한다.
- Searchformer는 A* 탐색 동적을 예측하기 위해 훈련된 인코더-디코더 트랜스포머 모델로, A* 탐색보다 최대 26.8% 적은 탐색 단계를 사용한다.
- 이 모델은 전문가의 반복을 통해 미세 조정되어 여전히 최적의 계획을 생성하면서 A* 탐색보다 적은 탐색 단계를 수행한다.
- A*의 탐색 동적은 기호 계획 중 탐색 트리에 작업 상태가 추가되고 제거되는 순간을 개요하는 토큰 시퀀스로 표현되며, 이것을 훈련 방법에 사용된다.
- 미로 탐색에 대한 본 연구의 소거 연구(ablation studies)에서 Searchformer는 최적의 계획을 직접 예측하는 베이스라인을 크게 능가하며 모델 크기는 5-10배 작고 훈련 데이터셋은 10배 작다.
- 또한 Searchformer는 Sokoban과 같은 더 크고 복잡한 의사결정 과제에 적용될 때 작업 해결 비율의 향상과 탐색 동적의 감소를 보여준다.

### [PALO: A Polyglot Large Multimodal Model for 5B People](https://arxiv.org/abs/2402.14818)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/IMt4llXcK4PR5xna7mnFY.png)

Vote: 11

Authors: Tim Baldwin, Fahad S. Khan, Salman Khan, Rao M. Anwer, Muhammad Maaz, Abdelrahman Shaker, Hisham Cholakal, Hanoona Rasheed, Michael Felsberg

- 이 연구는 영어, 중국어, 힌디어, 스페인어, 프랑스어, 아랍어, 벵골어, 러시아어, 우르두어, 일본어 등 10개 주요 언어로 시각 추론 능력을 제공하는 대규모 다언어 다모달 모델인 PALO를 소개합니다.
- 이 모델은 전 세계 인구의 약 65%에 해당하는 약 50억 명을 대상으로 서비스를 제공합니다.
- 본 연구는 세밀하게 조정된 대규모 언어 모델을 이용하여 영어로 된 다모달 지시 데이터셋을 대상 언어로 번역하는 반자동 번역 접근 방식을 사용하고, 소규모의 수동 작업으로 확장성을 가능하게 하면서 언어적 충실도를 확보하였습니다.
- 다양한 언어의 지시 세트를 포함시킴으로써 특히 힌디어, 아랍어, 벵골어, 우르두어와 같은 소수 대표 언어에서 전반적인 성능이 향상됩니다.
- 모델들은 일반화 및 확장성을 보여주기 위해 세 가지 규모(17억, 70억 및 130억 파라미터)에서 훈련되었으며, 강력한 베이스라인에 비해 상당한 개선이 관찰되었습니다.
- 또한, 언어별 시각 언어 추론 능력을 평가하기 위해 다국어 다모달 벤치마크를 처음으로 제안합니다.
- 코드는 https://github.com/mbzuai-oryx/PALO에서 제공됩니다.

### [Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis](https://arxiv.org/abs/2402.14797)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2z9ydIkorw1KI1SgxlMya.png)

Vote: 11

Authors: Elisa Ricci, Sergey Tulyakov, Jian Ren, Ivan Skorokhodov, Ekaterina Deyneka, Anil Kag, Aliaksandr Siarohin, Tsai-Shien Chen, Yuwei Fang, Aleksei Stoliar, Willi Menapace

- 현대 이미지 생성 모델들은 높은 품질과 다양성을 보이지만, 연구 커뮤니티에서 비디오 생성을 위해 단순히 이미지 모델을 차용하는 것은 비디오의 운동성과 시각적 품질을 저하시키는 문제가 있다는 주장이 제기됩니다.
- 본 연구에서는 비디오 생성을 위한 video-first 모델인 Snap Video를 개발하여 이러한 도전을 체계적으로 해결합니다.
- 우선, 공간적 및 시간적으로 중복되는 픽셀을 고려하고 비디오 생성을 자연스럽게 지원하는 EDM 프레임워크를 확장합니다.
- 이미지 생성의 주요 도구인 U-Net이 비디오 생성 시에 규모가 확장되기 어렵고 상당한 계산 오버헤드가 필요하다는 것을 보여줍니다.
- 대신, 훈련 속도가 U-Net보다 3.31배 빠르고 추론 시에는 약 4.5배 빠른 새로운 트랜스포머 기반 아키텍처를 제안합니다.
- 이를 통해, 수십억 개의 파라미터를 가진 텍스트-투-비디오 모델을 효율적으로 훈련하고, 벤치마크에서 최고 성과를 달성하며, 품질과 시간 일관성, 운동의 복잡성이 크게 향상된 비디오를 생성할 수 있습니다.
- 사용자 연구에서 우리의 모델이 가장 최근의 방법들을 크게 앞선 것으로 나타났습니다.
- 더 많은 정보는 https://snap-research.github.io/snapvideo/ 웹사이트에서 확인할 수 있습니다.

### [Subobject-level Image Tokenization](https://arxiv.org/abs/2402.14327)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/pJEqG_9vQ3fFROGSN0X8i.png)

Vote: 9

Authors: Delong Chen, Samuel Cahyawijaya, Jianfeng Liu, Pascale Fung, Baoyuan Wang

- 변형 기반 시각 모델은 일반적으로 고정 크기의 사각형 패치를 이미지 입력 단위로 사용하여 이미지 내용에 적응력이 떨어지고 픽셀 그룹화 구조를 간과합니다.
- 언어 모델에서 널리 사용되는 서브워드 토큰화에 영감을 받아, 본 연구는 세그멘테이션 모델(예: 세그먼트 에니싱 모델)을 통해 얻어진 의미 있게 의미있는 이미지 분할로 표현되는 서브오브젝트 수준의 이미지 토크나이저를 제안합니다.
- 서브오브젝트 토큰화에 기반한 학습 시스템을 구현하기 위해, 먼저 다양한 크기와 형태의 서브오브젝트 세그먼트를 압축된 임베딩 벡터로 압축하는 순차적 자동 인코더(SeqAE)를 도입했습니다.
- 그 후, 서브오브젝트 임베딩을 대규모 언어 모델에 입력하여 비전 언어 학습을 진행합니다.
- 실증적 결과로서 본 연구의 서브오브젝트 수준 토큰화는 기존의 패치 수준 토큰화와 비교하여 이미지를 객체 및 속성 설명으로 번역하는 효율적인 학습을 현저히 촉진시킴을 보여주었습니다.
- 연구의 코드와 모델은 https://github.com/ChenDelong1999/subobjects에서 오픈 소스로 제공될 예정입니다.

### [AgentScope: A Flexible yet Robust Multi-Agent Platform](https://arxiv.org/abs/2402.14034)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/OQ6FyQzJ0TnZ-v3Nii3dn.png)

Vote: 9

Authors: Yaliang Li, Zitao Li, Bolin Ding, Dawei Gao, Lin Zhu, Liuyi Yao, Zhijian Ma, Hongzhu Shi, Jingren Zhou, Daoyuan Chen, Bingchen Qian, Xuchen Pan, Chen Cheng, Weirui Kuang

- 대규모 언어 모델(LLMs)의 빠른 발전으로 다중 에이전트 응용 프로그램이 상당한 진보를 이루었음에도 불구하고, 에이전트 협력 조정과 LLMs의 변덕스러운 성능은 다중 에이전트 애플리케이션 개발에 있어 눈에 띄는 도전 과제로 남아있다.
- 이러한 도전 과제를 해결하기 위해 메시지 교환을 주요 통신 메커니즘으로 하는 개발자 중심의 다중 에이전트 플랫폼인 AgentScope를 제안한다.
- AgentScope는 풍부한 구문 도구, 내장 자원, 사용자 친화적 상호작용과 함께 개발 및 이해의 장벽을 크게 낮추는 커뮤니케이션 메커니즘을 포함한다.
- 내장형 및 사용자 정의 오류 허용 메커니즘을 통해 강인하고 유연한 다중 에이전트 애플리케이션을 제공하며, 멀티모달 데이터 생성, 저장, 전송을 위한 시스템 수준의 지원을 갖추고 있다.
- 또한, 로컬 및 분산 배포 간의 쉬운 전환과 추가적인 노력 없이 자동 병렬 최적화를 가능하게 하는 액터 기반 분산 프레임워크를 설계했다.
- AgentScope는 개발자가 지능형 에이전트의 잠재력을 실현할 수 있는 애플리케이션을 구축하는 데 도움을 주며, https://github.com/modelscope/agentscope 에서 AgentScope를 공개하여 이 빠르게 진화하는 분야에서의 더 넓은 참여와 혁신을 촉진한다.

### [TinyLLaVA: A Framework of Small-scale Large Multimodal Models](https://arxiv.org/abs/2402.14289)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jLTorjcBFaqWNxe8v34Xc.png)

Vote: 7

Authors: Ji Wu, Jie Luo, Junlong Jia, Xien Liu, Lei Huang, Ying Hu, Baichuan Zhou, Xi Weng

- 작은 규모의 대형 다중 모달 모델(Large Multimodal Models, LMMs) 설계 및 분석을 위한 통합적 관점을 제공하는 TinyLLaVA 프레임워크를 소개합니다.
- 다양한 비전 인코더, 연결 모듈, 언어 모델, 학습 데이터 및 학습 레시피의 영향을 실증적으로 연구하였습니다.
- 더 나은 데이터 품질과 학습 레시피를 결합함으로써, 작은 LMM들이 큰 LMM들에 비해 동등한 성능을 꾸준히 달성할 수 있음을 실험을 통해 보여주었습니다.
- 이 프레임워크 하에 우리는 일련의 소규모 LMM들을 학습시켰고, 그중 TinyLLaVA-3.1B 모델은 기존의 7B 모델들, 예를 들어 LLaVA-1.5와 Qwen-VL과 비교하여 더 나은 전체적 성능을 달성했습니다.
- 본 논문의 발견이 데이터 스케일링, 학습 설정 및 모델 선택과 관련된 미래 연구의 기준점으로 작용하기를 바랍니다.
- 모델 가중치와 코드는 공개될 예정입니다.

### [OmniPred: Language Models as Universal Regressors](https://arxiv.org/abs/2402.14547)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ijyBcI4TRzqJmU2GlTOwr.png)

Vote: 6

Authors: Sagi Perel, Bangding, Daiyi Peng, Chansoo Lee, Xingyou Song, Oscar Li, Yutian Chen, Yang

- 실험 설계의 넓은 분야에서 회귀 분석은 특정 파라미터 집합이 주어질 때 시스템이나 모델의 결과 메트릭을 정확하게 예측하는 강력한 도구였으나, 전통적으로 특정 작업에만 적용 가능한 방법으로 제한되어왔습니다.
- 본 논문에서는 다양한 실제 실험에서의 (x,y) 평가 데이터를 사용하여 언어 모델을 범용적으로 끝에서 끝까지(end-to-end) 회귀 분석하는 프레임워크인 OmniPred를 제안합니다.
- 구글 Vizier에서 수집한 데이터를 사용한 광범위한 실험에서 수학적 파라미터와 값의 텍스트 표현만을 사용하여 언어 모델이 매우 정밀한 수치 회귀를 수행할 수 있음을 보여줍니다.
- 또한, 여러 작업에 걸쳐 훈련할 기회가 주어질 경우, 언어 모델이 전통적인 회귀 모델을 크게 능가하는 성능을 나타낼 수 있음을 입증합니다.

### [LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons](https://arxiv.org/abs/2402.14086)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/y3cPKihXT2Fu_4eXA02jl.png)

Vote: 6

Authors: Cristina Menghini, Zheng-Xin Yong, Stephen H. Bach

- 저자원 언어를 위한 데이터 부족 문제를 양자어 사전을 이용한 고자원 언어의 레이블이 있는 데이터의 단어 대 단어 번역으로 해결하려는 시도는 제한된 어휘 일치로 인해 번역 범위와 사전 활용도가 떨어진다.
- LexC-Gen은 양자어 사전과 큰 언어 모델을 활용하여 저자원 언어의 분류 작업 데이터를 대규모로 생성하는 방법으로, 양자어 사전의 고자원 언어 단어를 사용하여 사전과 호환 가능한 작업 데이터를 먼저 생성한 다음 이를 단어 번역을 통해 저자원 언어로 번역한다.
- LexC-Gen을 사용하여 생성된 데이터는 17개의 극저자원 언어에서 전문 번역된 골드 데이터와 경쟁력이 있으며, 정서 분석 및 주제 분류 작업에서 기존 사전 기반 단어 번역 방법보다 평균적으로 5.6점과 8.9점의 성능 향상을 보였다.
- 양자어 사전에 조건을 달아 생성하는 것이 LexC-Gen의 관건이라는 것을 입증하였으며, 단일 GPU만으로 대규모 데이터를 생성할 수 있어 실용적이다.
- LexC-Gen은 오픈 액세스 큰 언어 모델과 함께 잘 작동하며, GPT4 기반 다국어 데이터 생성 비용의 1/5에 불과하다.

### [T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching](https://arxiv.org/abs/2402.14167)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/c16yygP36a4XQ4Wu9Ju9_.png)

Vote: 5

Authors: Zhiding Yu, Jianfei Cai, Anima Anandkumar, Zizheng Pan, Weili Nie, Chaowei Xiao, De-An Huang, Bohan Zhuang

- 이 논문은 높은 품질의 이미지 생성을 위한 확산 확률 모델(DPMs) 샘플링이 종종 비용이 많이 드는 문제를 해결하기 위해 T-Stitch(트레젝토리 스티칭)라는 새롭고 효율적인 기술을 소개합니다.
- T-Stitch는 큰 DPM을 전체 샘플링 경로에 단독으로 사용하는 대신, 초기 단계에서는 작은 DPM을 큰 DPM의 저렴한 대체제로 사용하고 후반 단계에서 큰 DPM으로 전환합니다.
- 핵심 통찰은 다른 확산 모델이 같은 훈련 데이터 분포에서 비슷한 인코딩을 학습하며, 작은 모델이 초기 단계에서 좋은 전역 구조를 생성할 수 있다는 것입니다.
- T-Stitch는 훈련 없이도 다양한 구조의 모델에 적용 가능하고, 속도와 품질 사이의 유연한 조절이 가능한 기존의 빠른 샘플링 기술과도 잘 결합됩니다.
- 예를 들어, DiT-XL에서 초기 타임스텝의 40%를 성능 저하 없이 10배 더 빠른 DiT-S로 안전하게 대체할 수 있습니다.
- 본 방법은 인기 있는 사전 훈련된 안정된 확산(SD) 모델의 가속화 뿐 아니라, 공개 모델 동물원에서 스타일리시한 SD 모델의 프롬프트 배치를 개선하는 데에도 사용될 수 있습니다.
- 코드는 https://github.com/NVlabs/T-Stitch에서 공개되어 있습니다.

### [GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion](https://arxiv.org/abs/2402.14810)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/wwLwrz8tXVgFmPhnk5Sde.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/wwLwrz8tXVgFmPhnk5Sde.mp4" muted="false"></video></div>

Vote: 4

Authors: Li Yi, Xueyi Liu

- 본 연구는 잘못된 손-물체 상호작용(HOI) 시퀀스를 정제하여 상호작용 결함을 제거하고 현실적인 시퀀스를 생성하는 것을 목표로 하는 어려운 손-물체 상호작용 잡음 제거 문제를 다룬다.
- 신규 접근 방식인 GeneOH Diffusion는 손-물체 접촉 중심의 HOI 표현인 GeneOH와 새로운 도메인 일반화 가능한 잡음 제거 기법을 포함한다.
- 이 접촉 중심 표현 방식인 GeneOH는 다양한 HOI 시나리오에서 일반화 능력을 향상시키는데 기여한다.
- 새로운 잡음 제거 기법은 화이트닝된 잡음 공간에서 부정확한 데이터 샘플을 깨끗한 데이터 매니폴드로 투영하는 표준 잡음 제거 모델을 훈련시키고, 다양한 잡음 패턴을 가진 입력 경로를 처리하기 위해 확산 후 잡음 제거 전략을 사용한다.
- 네 가지 벤치마크에서 상당한 도메인 변이를 통해 수행된 광범위한 실험은 저희 방법의 우수한 효과를 입증한다.
- GeneOH Diffusion은 또한 다양한 하류 응용 프로그램에서 잠재적으로 유망함을 보여준다.
- 프로젝트 웹사이트: https://meowuu7.github.io/GeneOH-Diffusion/.

### [GaussianPro: 3D Gaussian Splatting with Progressive Propagation](https://arxiv.org/abs/2402.14650)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DoTO-vmhmEZ46b1NEJMX7.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DoTO-vmhmEZ46b1NEJMX7.mp4" muted="false"></video></div>

Vote: 4

Authors: Xiaoxiao Long, Kai Cheng, Yao Yao, Yuexin Ma, Xuejin Chen, Wenping Wang, Kaizhi Yang, Wei Yin

- 3D Gaussian Splatting (3DGS)은 신경 렌더링 분야에 혁명을 가져오며 실시간 속도로 고품질 렌더링을 가능하게 했으나, 구조에서 모션 (SfM) 기술이 초기화한 포인트 클라우드에 크게 의존한다.
- 텍스처가 없는 표면이 포함된 대규모 장면에서 SfM 기술은 충분한 포인트를 생성하지 못하며 이로 인해 3DGS의 최적화가 어렵고 렌더링 품질이 낮다.
- 본 논문에서는 고전적인 멀티 뷰 스테레오 (MVS) 기술에서 영감을 받아, 기존에 복원된 장면의 지오메트리 정보와 패치 매칭 기법을 활용하여 GaussianPro라는 새로운 방법을 제안한다.
- GaussianPro는 정확한 위치와 방향성을 가진 새로운 가우스 분포를 생성하기 위해 점진적인 전파 전략을 적용한다.
- 기존 3DGS의 단순 분할 및 복제 전략에 비해, 우리의 방법은 대규모와 소규모의 장면 모두에서 우수한 효과를 검증하였으며, Waymo 데이터셋에서 PSNR 측면에서 1.15dB의 개선을 보여주는 것으로 나타났다.

### [Scaling Up LLM Reviews for Google Ads Content Moderation](https://arxiv.org/abs/2402.14590)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/VEVFFh0-Bk8BGY9EvOs_g.png)

Vote: 4

Authors: Tushar Dogra, Enming Luo, Chih-Chun Chia, Wei Qiao, Otilia Stretcu, Ariel Fuxman, Mehmet Tek, Fangzhou Wang, Dongjin Kwon, Chun-Ta Lu, Yuan Wang, Ranjay Krishna, Yu-Han Lyu, Tiantian Fang

- 구글 광고 콘텐츠 심사를 위한 대규모 언어 모델(LLM)의 확장 방안에 대해 연구한 논문입니다.
- 대규모 데이터셋에서 LLM을 활용할 때 발생하는 추론 비용과 지연 시간 문제를 해결하기 위해 휴리스틱을 사용하여 후보를 선정하고 중복을 제거합니다.
- 광고 클러스터를 생성하고 각 클러스터당 대표 광고를 선별하여 이를 대상으로만 LLM 심사를 수행합니다.
- 이 방법은 대표 광고의 LLM 판단을 클러스터에 전파하여 리뷰의 수를 3단계 이상 감소시키면서 비-LLM 모델 대비 2배의 검색률을 달성합니다.
- 클러스터링 및 라벨 전파에 사용된 표현 방식이 접근법의 성공에 크게 영향을 미치며, 단일 모드 대신 교차 모드 유사성 표현이 더 나은 결과를 가져옵니다.

### [Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming](https://arxiv.org/abs/2402.14261)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DT1GZteSe00AqW0yXx_nw.png)

Vote: 4

Authors: Roshanak Zilouchian Moghaddam, Aaron Chan, Anisha Agarwal, Jinu Jang, Neel Sundaresan, Shubham Chandel, Yevhen Mohylevskyy, Shaun Miller, Michele Tufano

- 대규모 언어 모델(LLMs)을 통합 개발 환경(IDEs)에 적용하는 것은 현대 소프트웨어 개발의 핵심적인 이슈가 되었다.
- LLMs 예로 OpenAI GPT-3.5/4 및 Code Llama는 인텔리전트한 채팅 주도 프로그래밍 어시스턴트로서 개발자 생산성을 대폭 증진시킬 잠재력을 지니고 있다.
- 본 논문에서는 다양한 프로그래밍 시나리오와 언어를 포함한 LLM 가이드 IDE 상호작용을 평가하기 위한 데이터와 도구 세트인 'Copilot evaluation harness'를 소개한다.
- 기존 평가 시스템보다 강력하고 정보 밀도가 높은 평가를 위해 새로운 메트릭을 제안한다.
- 이 메트릭들은 코드 생성(생성), 코드로부터 문서 생성(문서), 테스트 케이스 생성(테스트), 버그 수정(수정), 작업 공간 이해와 질의 해결(작업 공간) 등 개발자 작업의 넓은 범위를 포괄하는 시나리오에 대한 정적 및 실행 기반 성공 지표를 설계하고 산출한다.
- 제안된 성공 메트릭은 주어진 IDE 내의 LLM의 성능을 평가하기 위해 설계되었으며, 이는 각각의 시스템이 최적의 성능을 보장하기 위해 LLM을 특정 휴리스틱 집합에 맞춰 조정해야 함을 의미한다.
- 이러한 메트릭을 사용하여 평가된 세 가지 일반적인 LLM의 평가 결과는 LLM 가이드 IDE 상에서 미래 시나리오의 개발 및 검증을 알릴 수 있다.

### [CyberDemo: Augmenting Simulated Human Demonstration for Real-World Dexterous Manipulation](https://arxiv.org/abs/2402.14795)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/gRbuAWso9SyWQ_FgTVndc.png)

Vote: 3

Authors: Xiaolong Wang, Hao Su, Yigit Korkmaz, Akhilan Gurumoorthy, Jun Wang, Kaiming Kuang, Yuzhe Qin

- CyberDemo는 모방 학습을 위한 새로운 접근 방식으로 실제 세계 과제에 적용할 수 있는 시뮬레이션된 인간 데모를 활용합니다.
- 이 방식은 시뮬레이션 환경에서 광범위한 데이터 증강을 통합함으로써, 다양한 물리적 및 시각적 조건에서 기존의 실제 세계 데모보다 더 우수한 성능을 나타냅니다.
- CyberDemo는 데이터 수집의 편리성에도 불구하고, 다양한 작업에서 성공률 측면에서 베이스라인 방법들을 능가합니다.
- 또한, 인간의 시연이 삼방 밸브만을 다루었음에도 불구하고, 새롭게 접하는 사방 밸브와 오방 밸브를 회전할 수 있는 일반화 능력을 보여줍니다.
- 이 연구는 시뮬레이션된 인간 데모가 실제 세계의 민첩한 조작 작업에 대한 매우 큰 잠재력을 갖고 있음을 보여 줍니다.
- 추가 세부 사항은 https://cyber-demo.github.io 웹사이트에서 확인할 수 있습니다.

### [BeTAIL: Behavior Transformer Adversarial Imitation Learning from Human Racing Gameplay](https://arxiv.org/abs/2402.14194)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/n9u_flt9xZmD8FDqCbkQk.png)

Vote: 3

Authors: Wei Zhan, Chen Tang, Masayoshi Tomizuka, Ce Hao, Catherine Weaver, Kenta Kawamoto

- 모방 학습은 핸드메이드 보상 기능 없이 데몬스트레이션으로부터 정책을 학습하며, 자율주행 레이싱과 같은 로봇 과제에서 복잡한 환경 역학과 인간 의사 결정을 모델링해야 합니다.
- 동작 시퀀스의 복잡한 패턴을 포착하는데 효과적인 시퀀스 모델링은 새로운 환경 또는 로봇 과제에서 일반적인 분포 변화에 적응하는데 어려움이 있습니다.
- 이에 반해, 적대적 모방 학습(Adversarial Imitation Learning, AIL)은 이러한 영향을 완화할 수 있으나, 복잡한 동작 패턴을 다루는데 비효율적입니다.
- 그래서 이 논문은 BeTAIL(행동 변압기(Transformer) 적대적 모방 학습)을 제안하여, 인간의 데모에서 BeT(Beavior Transformer) 정책과 온라인 AIL를 결합합니다.
- BeTAIL은 BeT 정책에 AIL 잔여 정책을 추가해 인간 전문가의 연속적인 의사결정 과정을 모델링하고 분포 밖의 상태나 환경 역학의 변화를 수정합니다.
- 본 연구는 실제 인간 게임 플레이의 전문가 수준 데몬스트레이션을 포함하는 그란 투리스모 스포츠에서 BeTAIL을 세 가지 도전 과제로 테스트했습니다.
- 제안된 잔여 BeTAIL은 환경 상호 작용을 줄이고, BeT가 다운스트림 학습과 다른 트랙에서 미리 학습되더라도 레이싱 성능과 안정성을 향상시킵니다.
- 관련 비디오와 코드는 학술 출판 웹사이트에 제공됩니다.

### [MVD$^2$: Efficient Multiview 3D Reconstruction for Multiview Diffusion](https://arxiv.org/abs/2402.14253)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/pZ5BFUNmq6Eqyg6owNVhb.png)

Vote: 3

Authors: Xin-Yang Zheng, Yang Liu, Xin Tong, Hao Pan, Yu-Xiao Guo

- 다시 보기 어려운 3D 객체 이미지를 생성하는 다중 시점 확산(MVD)에 대한 연구가 주목받고 있으며, 이 기법은 일반화, 품질 및 효율성면에서 이점을 갖고 있습니다.
- 본 논문에서는 프로젝션과 컨볼루션을 통해 이미지 특징을 3D 특징 볼륨에 집계한 후, 3D 메쉬로 디코드하는 효율적인 MVD$^2$ 3D 재구성 방법을 제시합니다.
- 3D 형상 컬렉션과 3D 형상의 렌더링 뷰로 프롬프트된 MVD 이미지로 MVD$^2$를 훈련시켜, 생성된 다중 시점 이미지와 3D 형상의 실제 뷰 간의 차이를 극복하고자 합니다.
- 간단하면서도 효율적인 시점 의존적 훈련 방식을 설계하여, MVD의 3D 생성 품질을 향상시키고, 다양한 MVD 방법에 대해 빠르고 강인하게 대응합니다.
- 훈련 후 MVD$^2$는 한 초 이내에 다중 시점 이미지로부터 3D 메쉬를 효율적으로 디코드할 수 있습니다.
- MVD$^2$는 Zero-123++ 및 ObjectVerse-LVIS 3D 데이터셋을 사용하여 훈련되었으며, 합성 및 실제 이미지 모두를 프롬프트로 사용하여 다양한 MVD 방법으로부터 생성된 다중 시점 이미지를 이용한 3D 모델 생성에서 우수한 성능을 입증하였습니다.

### [Linear Transformers are Versatile In-Context Learners](https://arxiv.org/abs/2402.14180)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ffL5P53UVpEM2XbJjUFUY.png)

Vote: 2

Authors: Johannes von Oswald, Mark Sandler, Max Vladymyrov, Rong Ge

- 최근 연구에 따르면 트랜스포머, 특히 리니어 어텐션 모델들이 추론 단계 동안 문맥에서 제공된 데이터에 대해 그래디언트 디센트(경사 하강)와 유사한 알고리즘을 암묵적으로 실행하는 것으로 나타났습니다.
- 본 논문에서는 모든 리니어 트랜스포머가 암묵적인 선형 모델을 유지하며 사전 조건부 그래디언트 디센트의 변형을 수행한다는 것을 증명합니다.
- 연구진은 또한 다양한 노이즈 수준으로 오염된 훈련 데이터를 다루는 까다로운 시나리오에서 리니어 트랜스포머의 사용을 조사했습니다.
- 놀랍게도, 이 문제에 대해 리니어 트랜스포머는 복잡하면서도 매우 효과적인 최적화 알고리즘을 발견해 여러 합리적인 기준들의 성능을 능가하거나 일치했습니다.
- 연구진은 이 알고리즘을 역공학하여, 노이즈 수준을 기반으로 한 모멘텀과 적응적 재조정을 포함하는 새로운 접근법임을 밝혔습니다.
- 이 발견은 리니어 트랜스포머조차도 복잡한 최적화 전략을 발견할 수 있는 놀라운 능력을 가지고 있음을 보여줍니다.

### [Consolidating Attention Features for Multi-view Image Editing](https://arxiv.org/abs/2402.14792)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/-4na-GRPXDJonefyY3jmQ.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/-4na-GRPXDJonefyY3jmQ.mp4" muted="false"></video></div>

Vote: 2

Authors: Daniel Cohen-Or, Jun-Yan Zhu, Fernando De la Torre, Rinon Gal, Or Patashnik

- 대규모 텍스트-투-이미지 모델을 활용한 이미지 편집 기술은 텍스트 프롬프트 또는 공간적 제어를 사용하여 다양한 방식으로 이미지를 편집할 수 있지만, 이 기술을 단일 장면을 묘사하는 다중 시점 이미지에 적용할 경우 3D 일관성이 없는 결과를 초래한다.
- 본 연구에서는 공간적 제어 기반의 기하학적 조작에 초점을 맞추고, 다양한 시점에서의 편집 과정을 통합하는 방법을 소개한다.
- 생성 과정 동안 일관된 특징을 유지하는 것이 다중 시점 편집의 일관성을 달성하는 데 도움이 되며, 자기 주의(self-attention) 층의 쿼리들이 이미지 구조에 영향을 미친다는 두 가지 인사이트에 기반을 두고 있다.
- 쿼리의 일관성을 강화함으로써 편집된 이미지의 기하학적 일관성을 개선하기 위해, 편집된 이미지의 내부 쿼리 특징에 대하여 훈련된 신경 복사장치(QNeRF)를 도입한다.
- QNeRF가 훈련되면 3D-일관된 쿼리를 렌더링할 수 있으며, 이 쿼리들을 생성 과정 동안 자기 주의 층에 부드럽게 주입하여 다중 시점 일관성을 크게 향상시킨다.
- 프로세스를 개선하기 위해 확산 단계에 걸쳐 쿼리를 더욱 잘 통합하는 점진적이고 반복적인 방법을 정제한다.
- 제안된 방법은 기존 기술과 비교하여 더 나은 다중 시점 일관성과 입력 장면에 대한 높은 충실도를 달성할 수 있음을 보여주며, 이러한 이점으로 인하여 타겟 기하학과 더 잘 정렬된, 시각적 아티팩트가 적은 NeRFs를 훈련할 수 있다.

