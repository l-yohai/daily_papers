## Daily Papers (2024-02-15)

### [Magic-Me: Identity-Specific Video Customized Diffusion](https://arxiv.org/abs/2402.09368)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/cIloux0EbGcqvPWwoptmU.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/cIloux0EbGcqvPWwoptmU.mp4" muted="false"></video></div>

Vote: 18

Authors: Xue-She Wang, Jiashi Feng, Ze Ma, Zhen Dong, Xiuyu Li, Daquan Zhou, Huanrui Yang, Kurt Keutzer, Chun-Hsiao Yeh

- 특정 신분(ID)을 대상으로 하는 콘텐츠 제작은 생성 모델 분야에서 상당한 관심을 받고 있으며, 이미지 내 ID 제어가 가능한 텍스트-이미지 생성(T2I)에서 큰 진전을 이루었습니다.
- 이러한 접근을 비디오 생성으로 확장하는 것은 아직 잘 탐구되지 않았습니다.
- 본 연구에서는 몇 장의 이미지로 정의된 특정 주체 ID를 가지는 비디오 생성 프레임워크인 Video Custom Diffusion (VCD)를 제안합니다.
- VCD는 신원 정보 추출을 강화하고 초기화 단계에서 프레임 간 상관관계를 주입하여 정체성을 크게 보존한 안정적인 비디오 결과물을 제공합니다.
- 높은 품질의 ID 보존을 위해 3가지 새로운 요소를 제안합니다: 1) 프롬프트-투-세그먼테이션을 통해 크롭된 신원으로 ID 모듈을 훈련시켜 정확한 ID 토큰 학습을 위한 ID 정보와 배경 잡음을 분리시키는 기술, 2) 프레임 간 일관성을 향상시키기 위한 3D 가우시안 노이즈 프라이어를 가진 텍스트-투-비디오(T2V) VCD 모듈, 그리고 3) 얼굴을 선명하게 하고 비디오를 고해상도로 확장시키기 위한 비디오-투-비디오(V2V) 페이스 VCD와 타일드 VCD 모듈.
- 본 연구는 VCD가 선택된 강력한 기준들을 뛰어넘어 안정적이고 고품질의 비디오를 ID와 함께 더 잘 생성할 수 있다는 것을 광범위한 실험을 통해 입증했습니다.
- 또한, ID 모듈의 전이 가능성 덕분에 퍼블릭하게 이용 가능한 세부 조정된 텍스트-이미지 모델들과 잘 작동하여 사용 편의성을 향상시킵니다.
- 해당 코드는 https://github.com/Zhen-Dong/Magic-Me에서 확인할 수 있습니다.

### [Premise Order Matters in Reasoning with Large Language Models](https://arxiv.org/abs/2402.08939)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/TJjo8qFrgsLh972-ksi2q.png)

Vote: 10

Authors: Xinyun Chen, Ryan A. Chi, Denny Zhou, Xuezhi Wang

- 대규모 언어 모델(LLMs)은 다양한 분야에서 놀라운 추론 성능을 달성했으나, 추론 작업 영역에서 그들은 전제 순서에 매우 민감한 것으로 나타났다.
- 특히, 추론 과정에서 필요한 맥락과 일치할 때 전제를 순서대로 제시하는 것이 LLMs의 정확도를 크게 향상시켰다.
- 연구팀은 다양한 대규모 언어 모델을 대상으로 전제 순서가 연역적 추론에 미치는 영향을 조사했으며, 전제 순서를 변경하는 것이 성능을 30% 이상 떨어뜨릴 수 있다는 것을 발견했다.
- 또한, 수학 문제 해결을 위한 순서 효과를 평가하기 위해 GSM8K 기반의 벤치마크 R-GSM을 개발했으며, 여기서도 원래의 GSM8K 벤치마크에 비해 정확도가 크게 저하되는 것을 관찰했다.

### [Computing Power and the Governance of Artificial Intelligence](https://arxiv.org/abs/2402.08797)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hvrM7se1cTeAoT4nQHDOe.jpeg)

Vote: 9

Authors: Markus Anderljung, Gillian K. Hadfield, Robert F. Trager, Richard Ngo, Konstantin Pilz, Julian Hazell, Janet Egan, Yoshua Bengio, Haydn Belfield, Girish Sastry, Sarah Shoker, Lennart Heim, Emma Bluemke, Miles Brundage, Shahar Avin, Adrian Weller, Diane Coyle, George Gor, Cullen O'Keefe

- 컴퓨팅 파워는 인공지능(AI) 개발 및 배치에 있어 중요하며, 정부와 기업들이 AI 거버넌스를 위해 컴퓨팅 파워를 활용하고 있다.
- 정부는 국내 컴퓨팅 능력에 투자하고, 경쟁국에 대한 컴퓨팅 파워의 흐름을 통제하며, 특정 분야에 컴퓨트 접근을 보조하는 등의 조치를 취하고 있다.
- AI에 대한 다른 주요 입력(데이터 및 알고리즘)과 비교할 때, AI 관련 컴퓨팅 파워는 관리의 중대한 지점이 될 수 있으며, 이는 탐지 가능하고, 배제 가능하며, 양적으로 측정 가능하며, 매우 집중된 공급망을 통해 생산된다.
- 이러한 특성들은 컴퓨팅 파워를 통한 거버넌스가 AI의 안전한 사용을 보장하는 등의 공통된 정책 목표를 달성하는 데 기여할 수 있음을 나타낸다.
- 정책 입안자들은 규제의 가시성을 높이고, 유익한 결과를 촉진하기 위한 자원을 할당하며, 무책임하거나 악의적인 AI 개발 및 사용에 대한 제한을 시행하기 위해 컴퓨팅 파워를 활용할 수 있다.
- 컴퓨팅 기반 정책과 기술은 이 분야를 돕기 위한 잠재력이 있지만, 실제로 구현되기까지 준비 상태에는 상당한 차이가 존재한다.
- 일부 아이디어는 현재 시범적으로 진행되고 있지만, 기본 연구가 필요한 영역에 제약이 따른다.
- 또한, 컴퓨트 거버넌스에 대한 순진하거나 범위가 너무 좁은 접근 방식은 프라이버시, 경제적 영향, 권력 중앙집중화 등의 영역에서 상당한 위험을 안고 있다.
- 연구는 이러한 위험을 최소화하기 위한 안전장치를 제안함으로써 마무리된다.

### [L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects](https://arxiv.org/abs/2402.09052)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/RvHaz3lRvPfB5VetZAQJh.png)

Vote: 8

Authors: Yejin Choi, Jack Hessel, Ilker Yildirim, Yuchen Lin, Yutaro Yamada, Khyathi Chandu

- DALL-E 3 등의 확산 기반 이미지 생성 모델은 현실적이고 독특한 구성의 이미지를 만드는 능력을 갖고 있지만, "다섯 개의 다리가 있는 의자"와 같은 비전통적인, 분포를 벗어난 설명에 대해서 물리적 및 공간 구성을 정확하게 추론하는 데에는 약점이 있습니다.
- 본 논문은 비전통적 객체의 부분 기반 3D 메쉬 생성에 대해 추론할 수 있는 언어 에이전트인 L3GO(chain-of-3D-thoughts)를 제안, 기존 데이터 기반 확산 모델이 어려워하는 문제를 해결하기 위한 추론 시간 접근법을 소개합니다.
- 큰 언어 모델을 에이전트로 사용해 3D 시뮬레이션 환경 내에서 시행착오를 통해 원하는 객체를 구성하며, 언어 에이전트가 API 호출을 통해 원자적 구성 요소를 빌드하고 조합할 수 있는 Blender 기반의 SimpleBlenv 래퍼 환경과 UFO(Unconventionally Feasible Objects) 벤치마크를 개발했습니다.
- 인간 및 자동 GPT-4V 평가에서, L3GO 방식은 ShapeNet에서의 3D 메쉬 생성에 있어 표준 GPT-4 및 다른 언어 에이전트들(예: ReAct, Reflexion) 보다 뛰어난 것으로 나타났습니다.
- UFO 벤치마크에 대한 테스트에서는, 인간 평가를 바탕으로 텍스트-투-2D 이미지 및 텍스트-투-3D 모델들을 포함한 현존하는 최고의 방법들을 능가하는 성능을 보였습니다.

### [GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency](https://arxiv.org/abs/2402.08855)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/7gnibLgKaq-LwCltfd_p7.png)

Vote: 7

Authors: Andy Huntington, Rachel Ng, Catherine Yeh, Gonzalo Ramos, Richard Banks

- 대규모 언어 모델(LLMs)이 글쓰기 보조 수단으로 널리 사용되고 있지만, 개인 맞춤화와 제어의 한계로 사용자의 불만을 초래할 수 있습니다.
- 특히 경험이 부족한 사용자들은 프롬프트 엔지니어링을 통해 이러한 문제를 해결하는 데 어려움을 겪을 수 있습니다.
- 이러한 도전 과제를 해결하기 위해 'GhostWriter'라는 이름의 인공지능(AI)이 가미된 글쓰기 디자인 프로브를 소개합니다.
- GhostWriter는 사용자가 글을 쓰면서 의도한 글쓰기 스타일을 묵시적으로 배우고, 수동 스타일 편집 및 주석을 통해 명시적인 가르침의 순간을 제공합니다.
- 18명의 참가자가 두 가지 다른 글쓰기 작업에 GhostWriter를 사용해보면서, 이 시스템이 개인화된 텍스트 생성을 돕고 시스템의 글쓰기 스타일을 제어하는 다양한 방법을 제공함으로써 사용자에게 권한을 부여한다는 것을 관찰했습니다.
- 이 연구를 통해 인공지능 지원 글쓰기와 사람들의 관계에 대한 인사이트를 제공하고, 미래 연구를 위한 디자인 권고안을 제시합니다.

### [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://arxiv.org/abs/2402.08714)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/IOO8o6C1NxdT8HcTyWrs9.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/IOO8o6C1NxdT8HcTyWrs9.mp4" muted="false"></video></div>

Vote: 6

Authors: Tingbo Hou, Qifei Wang, Wei Wei, Fei Deng, Matthias Grundmann

- 보상 파인튜닝은 기초 모델을 다운스트림 목표와 일치시키는 유망한 접근 방식으로 등장했으며, 특히 사람의 선호를 반영하는 보상을 최대화하기 위해 강화 학습(RL)을 사용하여 언어 분야에서 놀라운 성공을 거두었습니다.
- 그러나 비전 분야에서는 기존의 RL 기반 보상 파인튜닝 방법들이 대규모 훈련에서 불안정함으로 인해 복잡하고 보지 못한 프롬프트에 일반화하는 데 한계가 있습니다.
- 본 논문에서는 Proximal Reward Difference Prediction (PRDP)을 제안하여, 100K 이상의 프롬프트가 있는 대규모 프롬프트 데이터셋에서 처음으로 확산 모델에 대한 안정적인 블랙박스 보상 파인튜닝을 가능하게 합니다.
- 핵심 혁신은 Reward Difference Prediction (RDP) 목표로, RL 목표와 동일한 최적 해결책을 가지면서 더 나은 훈련 안정성을 제공합니다.
- RDP 목표는 확산 모델이 생성된 이미지 쌍의 노이즈 감소 궤적에서 보상 차이를 예측하는 감독된 회귀 목표입니다.
- 완벽한 보상 차이 예측을 하는 확산 모델이 RL 목표의 최대화 자임을 이론적으로 증명하였습니다.
- 또한 RDP 목표를 안정적으로 최적화하기 위해 근사치 업데이트와 함께 온라인 알고리즘을 개발하였습니다.
- 실험을 통해, PRDP는 소규모 훈련에서 잘 알려진 RL 기반 방법의 보상 최대화 능력에 필적한다는 것을 보여주었습니다.
- 더 큰 규모의 훈련을 통해, Human Preference Dataset v2 및 Pick-a-Pic v1 데이터셋의 텍스트 프롬프트로 PRDP는 복잡하고 보지 못한 프롬프트 세트에서 다양한 우수한 생성 품질을 달성하는 반면, RL 기반 방법은 완전히 실패하였습니다.

### [Transformers Can Achieve Length Generalization But Not Robustly](https://arxiv.org/abs/2402.09371)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/guy11n8ESAiCLOa_LX6q-.png)

Vote: 6

Authors: Xinyun Chen, Xuezhi Wang, Uri Alon, Denny Zhou, Yongchao Zhou, Rishabh Agarwal

- 길이 일반화란 언어 모델이 짧은 훈련 시퀀스에서 긴 테스트 시퀀스로 외삽하는 능력을 의미하며, 대규모 Transformer에서도 언어 모델에는 여전히 중대한 도전이다.
- 본 논문에서는 두 정수의 덧셈이라는 간단한 작업을 사용하여 Transformer의 길이 일반화 능력을 테스트한다.
- 데이터 형식과 위치 인코딩 유형과 긴밀히 연관되어 있음을 보여줌으로써, 적절한 데이터 형식과 위치 인코딩 조합을 사용하여 표준 Transformers가 입력 길이의 2.5배까지 시퀀스 길이로 외삽할 수 있음을 처음으로 입증한다.
- 그러나 분배 내 일반화와 달리 길이 일반화는 무작위 가중치 초기화와 훈련 데이터 순서와 같은 요인에 의해 크게 영향을 받아, 다양한 무작위 시드에서 큰 변동성을 보인다.
- 이러한 길이 일반화의 성공은 비록 표준 Transformer가 가능하다는 것을 보여주지만, 이 일반화는 견고하지 않다는 것을 시사한다.

### [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://arxiv.org/abs/2402.09126)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/PUwl9AMbDHedtTawn2SF4.png)

Vote: 5

Authors: Tal Kadosh, Guy Tamir, Vy A. Vo, Timothy Mattson, Mihai Capotă, Abdul Wasay, Yuval Pinter, Gal Oren, Niranjan Hasabnis, Nadav Schneider, Nesreen Ahmed, Ted Willke, Neva Krien

- 본 연구에서는 MPI(Message Passing Interface) 기반 병렬 프로그램 생성을 위한 최신 언어 모델들의 성능을 조사하였습니다.
- 대중적인 모델들인 GPT-3.5와 PolyCoder 같은 다중 언어 코드 모델들은 일반 프로그램 생성에 비해 MPI 기반 프로그램 생성 시 성능 저하를 겪는 것으로 밝혀졌습니다.
- 반면, C와 C++로 이루어진 MPI 관련 프로그래밍 언어에 대해 사전 학습된 MonoCoder와 같은 도메인 특화 모델들이 더 큰 모델들을 능가하는 성능을 보였습니다.
- 이에 MonoCoder를 HPCorpusMPI를 사용하여 미세 조정을 거친 MPI 기반 프로그램 생성을 위한 전용 과제를 소개하며, 이를 MPIrigen이라 명명했습니다.
- 코드 전체를 관찰한 후에만 완성을 허용하는 새로운 전처리를 제안하여 보다 넓은 컨텍스트에서 더 나은 완성을 가능하게 하였습니다.
- HPC(High-Performance Computing) 지향 평가 방법을 사용하여 GPT-3.5의 제로샷 성능과 비교 분석을 실시한 결과, MPIrigen은 함수 위치 및 기능 예측에서 최대 0.8의 정확도를, 인자 예측에서 0.9 이상의 정확도를 보이며 뛰어난 성능을 나타냈습니다.
- 이 맞춤형 해결책의 성공은 병렬 컴퓨팅 코드 생성을 위한 언어 모델 최적화에서 도메인 특화 미세 조정의 중요성을 강조하며, 자동 병렬화 도구의 새로운 세대를 위한 길을 열어줍니다.
- 이 연구의 소스 코드는 GitHub MPIrigen 저장소(https://github.com/Scientific-Computing-Lab-NRCN/MPI-rigen)에서 확인할 수 있습니다.

### [Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers](https://arxiv.org/abs/2402.08958)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/tKVPL6pmc64H7JKVJKO0X.png)

Vote: 2

Authors: Kyungphil Park, Yongkweon Jeon, Ho-young Kim, Joonyoung Kim, Chungman Lee, Junhan Kim

- 기존의 사후 훈련 양자화(Post-Training Quantization, PTQ) 방법은 모바일 기기나 TV와 같은 엣지 디바이스에 하이퍼스케일 모델을 배치하는데 유망한 솔루션으로 부상했지만, 상당한 시간과 자원을 소모합니다.
- 실제 상황에서 자주 발생하는 모델 업데이트와 다수의 하이퍼파라미터 조정 시에 기존 방법이 병목 현상을 야기할 수 있으므로, 원-샷(One-shot) PTQ 방식이 제안되었지만 성능이 제한적입니다.
- 트랜스포머의 주요 특징인 주목 모듈 내의 계층 간 의존성을 고려하지 않는 것이 이들 방식의 성능 제한 요인임을 지적합니다.
- 이 논문에서는 정확성과 효율성을 균형 있게 달성하는 새로운 PTQ 알고리즘인 'aespa'를 제안하고 있습니다.
- 'aespa'는 양자화를 계층별로 효율적으로 수행하는 동시에 주목 점수를 유지하기 위해 계층 간 의존성을 고려하는 것이 핵심 아이디어입니다.
- 다양한 언어 모델에 대한 광범위한 실험과 복잡성 분석을 통해 'aespa'가 트랜스포머 모델을 양자화하는 데 있어 정확하고 효율적임을 입증합니다.

