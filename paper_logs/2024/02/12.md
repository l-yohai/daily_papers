## Daily Papers (2024-02-12)

### [Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning](https://arxiv.org/abs/2402.06619)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06619.png)

Vote: 12

Authors: Daniel Dsouza, Laura OMahony, Mike Zhang, Aisha Alaagib, Abinaya Mahendiran, +, Irem Ergün, Freddie Vargus, Dominik Krzemiński, Zaid Alyafeai, Ifeoma Okoh, Luisa Souza Moura, Hakimeh Fadaei, Joseph Wilson, Jay Patel, Deividas Mataciunas, Shivalika Singh, Börje F. Karlsson, Ramith Hettiarachchi, Wei-Yin Ko, Herumb Shandilya, Oshan Mudannayake, Marina Machado

- 인공지능의 주요 발전에 기여하는 데이터셋의 중요성을 강조하고, 자연어 처리(NLP)의 최근 성과는 다양한 작업에 대해 미세 조정된 프리트레인드 모델로 설명됩니다.
- 특히, 지시 사항을 따르는 데이터셋 구축이 필요한데, 기존 자료는 대부분 영어로 제한되어 있었습니다.
- 이 연구는 기존의 언어 격차를 메우기 위해 전 세계의 유창한 언어 사용자와 협력하여 65개 언어에 걸친 인간 큐레이팅 지시 사항 데이터셋을 생성했습니다.
- 기존 데이터셋을 템플레이팅 및 번역하는 방식으로 총 513백만 개의 인스턴스를 포함하는 지금까지 가장 광범위한 다국어 컬렉션을 창출했습니다.
- Aya Annotation Platform, Aya Dataset, Aya Collection, Aya Evaluation Suite를 개발 및 오픈소스화함으로써 네 가지 주요 자원을 기여했습니다.
- 119개국의 협력자들이 참여한 Aya 프로젝트는 참여 연구의 중요한 사례로, 자원의 격차를 메우려는 미래 연구 협업에 대한 유용한 틀을 제시합니다.

### [HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting](https://arxiv.org/abs/2402.06149)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06149.png)

Vote: 11

Authors: Yi Yang, Hehe Fan, Zhenglin Zhou, Fan Ma

- HeadStudio는 텍스트 프롬프트로부터 현실적이고 애니메이터블한 아바타를 생성하는 새로운 프레임워크입니다.
- 이 방법은 중간 FLAME 표현을 통해 유연하고 실현 가능한 외모를 생성할 수 있는 3D 가우시안 스플래팅을 활용합니다.
- FLAME 기반 3D 가우시안 스플래팅은 FLAME 메쉬에 각 포인트를 링킹함으로써 3D 가우시안 포인트를 드라이브합니다.
- FLAME 기반 점수 추출 샘플링은 FLAME 기반의 세밀한 제어 신호를 사용하여 텍스트 프롬프트에서 점수 추출을 안내합니다.
- 광범위한 실험을 통해 HeadStudio가 텍스트 프롬프트에서 애니메이터블 아바타를 생성하는 효과를 입증하였으며, 시각적으로 매력적인 외모를 전시합니다.
- 생성된 아바타는 1024 해상도에서 초당 40프레임(geq 40 fps) 이상의 고품질 실시간 노벨 뷰 렌더링이 가능합니다.
- 또한, 이들 아바타는 실제 세계의 음성 및 비디오로 부드럽게 제어될 수 있습니다.
- 연구자들은 HeadStudio가 디지털 아바타 생성을 발전시키길 바라며, 이 방법이 다양한 분야에 널리 적용될 수 있기를 희망합니다.

### [ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://arxiv.org/abs/2402.06118)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06118.png)

Vote: 10

Authors: Siming Yan, Xiong Zhou, Min Bai, Qixing Huang, Li Erran Li, Weifeng Chen

- 최근의 대형 시각 언어 모델들은 자연 언어 이해와 이미지 인식을 결합하여 실세계에서의 추론 능력을 발휘하고 있지만, 시각적 입력에 대한 부정확한 근거로 인해 종종 오류를 범합니다.
- 이러한 문제를 해결하기 위해, 저자들은 세밀한 보상 모델링을 이용하는 새로운 프레임워크인 ViGoR를 소개하여 기존에 사전 학습된 기준들보다 더 나은 시각적 근거 능력을 향상시킬 수 있음을 보였습니다.
- 이 방법은 완전한 감독 없이 훨씬 저렴한 인간 평가와 자동화된 방법을 사용하여 효율적으로 개선을 달성합니다.
- 연구팀은 여러 벤치마크에서 수많은 측정 기준을 통해 접근 방식의 유효성을 입증했습니다.
- 또한, 대형 시각 언어 모델의 시각적 근거 능력을 검증하기 위해 설계된 광범위하고 도전적인 데이터셋을 구축했습니다.
- 마지막으로, 약 16,000개의 이미지와 생성된 텍스트 쌍에 대한 세밀한 평가를 포함한 인간 주석을 공개하여 관련 연구 커뮤니티에 기여할 계획입니다.

### [MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models](https://arxiv.org/abs/2402.06178)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06178.png)

Vote: 8

Authors: Yukara Ikemiya, Gus Xia, Yuki Mitsufuji, Marco Martínez, Naoki Murata, Yixiao Zhang, Simon Dixon, Wei-Hsiang Liao

- 최근 텍스트를 활용한 음악 생성 모델의 발전은 음악 창작에 새로운 방향을 제시했지만, 생성된 음악을 수정하는 과정은 여전히 중요한 도전 과제로 남아있습니다.
- 본 논문에서 소개하는 MusicMagus 방법론은 장르, 분위기, 악기와 같은 특정 속성들을 수정할 수 있게 하면서, 다른 측면은 그대로 유지하는 음악 편집 방식을 새롭게 제안합니다.
- 이 방식은 텍스트 수정 작업을 잠재 공간 조작으로 변환하고 일관성을 유지하기 위한 추가적인 제약을 도입하는 방식으로 작동합니다.
- 기존에 사전 훈련된 텍스트에서 음악으로의 확산 모델과 원활하게 결합하며, 추가적인 훈련 없이도 통합할 수 있습니다.
- 실험 결과는 스타일과 음색 변화 평가에서 기존의 제로샷 방법과 일부 지도 학습 기반의 기준들을 능가하는 우수한 성능을 보여주었습니다.
- 또한, 실제 음악 편집 시나리오에서 본 접근법의 실용적인 적용 가능성을 보여줍니다.

### [InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning](https://arxiv.org/abs/2402.06332)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06332.png)

Vote: 7

Authors: Zhaoye Fei, Songyang Zhang, Hang Yan, Yichuan Ma, Yunfan Shao, Kai Chen, Xipeng Qiu, Ziyi Wang, Zhejian Zhou, Shuo Zhang, Hongwei Liu, Wenwei Zhang, Jiayu Wang, Yudong Wang, Shuaibin Li, Linyang Li, Dahua Lin, Huaiyuan Ying, Zijian Wu, Kuikun Liu, Jiawei Hong, Fengzhe Zhou

- 이 논문은 추상적 추론 능력을 나타내는 대규모 언어 모델의 수학 능력에 초점을 맞추고, InternLM2에서 계속 예비 학습된 수학 추론 대규모 언어 모델(이하 InternLM-Math)을 소개하고 오픈 소스로 공개합니다.
- 연쇄적 사고 추론, 보상 모델링, 형식적 추론, 데이터 증강, 코드 인터프리터를 통합 seq2seq 형식으로 통합하고, 모델을 다재다능한 수학 추론자, 검증자, 증명자 및 증강자로 감독하여 훈련합니다.
- InternLM-Math는 인컨텍스트 학습, 감독된 미세 조정, 코드 지원 추론 등 다양한 비공식 및 공식 벤치마크를 포함하여 최신 오픈 소스 성능을 달성했습니다.
- 미세 조정 없이 MiniF2F 테스트 세트에서 30.3의 성능을 내는 사전 훈련된 모델을 보유하고 있습니다.
- 이 논문은 또한 LEAN을 사용하여 수학 문제를 해결하는 방법을 탐구하고, 수학에서 문제를 해결하고 증명하기 위한 통합 플랫폼으로 LEAN 사용 가능성을 보여주는 다중 과제 학습 설정에서의 성능을 연구합니다.
- 해당 모델, 코드, 데이터는 https://github.com/InternLM/InternLM-Math 에서 공개적으로 이용할 수 있습니다.

### [Keyframer: Empowering Animation Design using Large Language Models](https://arxiv.org/abs/2402.06071)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06071.png)

Vote: 7

Authors: Jeffrey Nichols, Ruijia Cheng, Tiffany Tseng

- 대규모 언어 모델(LLM)이 창의적 분야에 영향을 미칠 잠재력을 가지고 있으나, 애니메이션 분야에서의 LLM 적용은 아직 덜 탐구되어 있고, 자연어로 동작을 효과적으로 묘사하는 방법 등 새로운 도전 과제들이 존재합니다.
- 이 논문에서는 자연어를 통해 정적 이미지(SVG)를 애니메이션화할 수 있는 디자인 도구인 Keyframer를 제시하고 있습니다.
- 전문 애니메이션 디자이너 및 엔지니어와의 인터뷰를 바탕으로, Keyframer는 사용자가 프롬프트 지정 및 생성된 결과에 대한 직접 편집을 통해 애니메이션을 탐색하고 개선할 수 있도록 지원합니다.
- 이 시스템은 또한 사용자가 디자인 변형을 요청하고 비교 및 아이디어 발산을 지원할 수 있게 합니다.
- 13명의 참가자와 함께 진행된 사용자 연구를 통해, 생성된 출력에 대응하여 그들의 목표를 지속적으로 적응하는 '분해된' 프롬프트 스타일을 포함한 사용자 프롬프트 전략과 동작을 묘사하는 데 사용되는 의미론적 프롬프트 유형의 분류를 제시하고 있습니다.
- 직접 편집과 프롬프트 지정을 결합한 접근 방식이 오늘날 생성 도구에서 흔히 볼 수 있는 일회성 프롬프트 인터페이스를 넘어선 반복 작업을 가능하게 한다고 설명합니다.
- 이 연구를 통해, LLM이 어떻게 다양한 사용자들이 애니메이션 창작에 참여할 수 있게 하며, 이를 강화시킬 수 있는지에 대한 제안을 하고 있습니다.

### [SubGen: Token Generation in Sublinear Time and Memory](https://arxiv.org/abs/2402.06082)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06082.png)

Vote: 4

Authors: Amin Karbasi, Vahab Mirrokni, Insu Han, Amir Zandieh

- 대규모 언어 모델(Large Language Models, LLMs)은 장문의 토큰 생성에 있어서 상당한 메모리 요구로 데플로이먼트에 도전적 문제를 제시한다.
- LLM 디코더의 주요 메모리 사용량은 기-값(Key-Value, KV) 캐싱으로 인해 주목 모듈에 이전 토큰들을 모두 저장해야 한다는 요구 때문에 발생한다.
- 본 연구는 KV 캐시의 효율적인 압축 기술 개발에 집중하며, 주목 모듈 내의 키 임베딩에서 뚜렷한 클러스터링 경향을 실험적으로 보여준다.
- 이 핵심 통찰을 바탕으로, 온라인 클러스터링을 통한 키 토큰 및 온라인 ell_2 샘플링을 활용하는 하위 선형 복잡도를 가진 새로운 캐싱 방법을 고안했다.
- 이로써 우리는 SubGen이라고 명명된 증명 가능한 정확하고 효율적인 주목 디코딩 알고리즘을 제시한다.
- SubGen은 하위 선형 메모리 사용량과 하위 선형 시간 복잡도를 보장할 뿐만 아니라 접근법에 대한 엄격한 에러 범위도 설정한다.
- 장문의 질문-응답 과제에 대한 실험 평가는 SubGen이 성능과 효율성 면에서 기존 및 최신의 KV 캐시 압축 방법들을 현저히 능가함을 보여준다.

### [DeAL: Decoding-time Alignment for Large Language Models](https://arxiv.org/abs/2402.06147)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06147.png)

Vote: 4

Authors: Dan Roth, Saab Mansour, Katrin Kirchoff, Arshit Gupta, Sailik Sengupta, Daniele Bonadiman, Nikolaos Pappas, James Y. Huang, Yi-an Lai

- 현재 대규모 언어 모델(Large Language Models, LLMs)들은 인간의 선호도와 일치하는 컨텐츠 생성이 기대되는 바, 이를 위한 정렬(alignment)은 주로 모델 학습 시간의 기술에 초점을 맞추고 있으며, 인간 피드백을 활용한 강화학습(Reinforcement Learning with Human Feedback, RLHF) 등의 기법을 사용한다.
- 그러나 이러한 방법들이 모델에 정렬 목표를 교육하기에 효과적인 선택인지는 불분명하며, 단일 보상 체계에만 의존하고 모델 개발자가 보는 보편적이고 정적인 원칙에 기반하는 점이 주요 한계로 지적된다.
- 또한 교육 과정에서 남아 있는 격차들과 이러한 접근법의 신뢰성에 대한 의문(예를 들어 안전 교육 후에도 발생하는 'jail-breaking' 취약성)도 존재한다.
- 이러한 문제들을 해결하기 위해, 저자들은 사용자가 보상 함수를 맞춤화할 수 있고, LLMs의 정렬을 디코딩 시간에 가능하게 하는 프레임워크인 DeAL(Decoding-time Alignment for Large Language Models)을 제안한다.
- DeAL의 핵심은 디코딩을 휴리스틱(heuristic) 가이드 탐색 과정으로 보고, 다양한 정렬 목표를 적용하는 것을 용이하게 한다.
- 실험에서는 키워드와 길이 제약과 같은 프로그램적 제약뿐만 아니라 해로움과 유용성 같은 추상적 목표들을 다루며, 이를 통해 미세한 균형 조정이 가능하고, LLMs의 정렬 목표 준수를 개선하고 남아 있는 격차를 해결할 수 있음을 보여준다.
- 마지막으로 DeAL은 RLHF 및 프롬프트 기술과 효과적으로 결합될 수 있지만, 디코딩 속도가 느려지는 일반성 때문에 향후 작업을 위한 최적화 문제는 남아있다.

### [Animated Stickers: Bringing Stickers to Life with Video Diffusion](https://arxiv.org/abs/2402.06088)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06088.png)

Vote: 4

Authors: Luxin Zhang, Ankit Ramchandani, Dingkang Wang, Krishna Narni, Ali Thabet, Licheng Yu, Amy Bearman, Winnie Zhang, David Yan, Edgar Schoenfeld, Lawrence Chen, Guan Pang, Miao Liu, Albert Pumarola, Elliot Blanchard, Yaqiao Luo, Anmol Kalia, Peter Vajda

- 본 연구에서는 텍스트 프롬프트와 정적 스티커 이미지를 기반으로 애니메이션을 생성하는 비디오 확산 모델인 애니메이티드 스티커를 소개합니다.
- 기존의 최신 Emu 텍스트-이미지 모델을 기반으로 하여 움직임을 모델링하기 위한 시간적 레이어가 추가되었습니다.
- 자연스러운 비디오를 생성하는 데 능숙한 모델이 스티커 도메인의 시각적 스타일 및 움직임 차이로 인해 생생한 비디오 생성에 어려움을 겪었습니다.
- 이러한 도메인 차이를 해결하기 위해 부분적으로 관련 있는 데이터로 먼저 파인튜닝을 진행한 후, 'ensemble-of-teachers'라고 이름 붙인 인간-루프(HITL) 전략을 사용하였습니다.
- 이 전략은 다수의 '선생님' 모델들의 최고의 특징들을 보다 작은 '학생' 모델로 흡수시켜서 스틱의 스타일을 유지하면서도 움직임의 질을 목표로 한 특정한 개선을 가능하게 합니다.
- 추론 최적화를 통해 모델은 1초 미만의 시간에 고품질이며 흥미롭고 관련 있는 움직임을 포함하는 8프레임 비디오를 생성할 수 있습니다.

### [Model Editing with Canonical Examples](https://arxiv.org/abs/2402.06155)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06155.png)

Vote: 3

Authors: Edward Adams, Percy Liang, Christopher D. Manning, John Hewitt, Lanruo Lora Xie, Sarah Chen

- 본 논문에서는 모델 편집 및 캐논니컬 예제를 도입하여, 각각의 바람직한 행동에 대해 단일 학습 예제를 제공하고, 완전히 분포 밖에서 평가를 수행하며, 초기 모델로부터의 편차를 엄격히 제한하는 새로운 설정을 제시하였다.
- 캐논니컬 예제는 우수한 행동(예: 모리셔스의 수도는 포트루이스이다) 또는 부적절한 행동(예: 연구원의 한 측면은 냉정하다)의 단순한 사례로, 평가 세트는 각 행동의 더 복잡한 예(예: 모리셔스의 수도가 언급된 문단)를 포함한다.
- 지식 기반 개선, 사회적 편견 완화 및 구문론적 경계사례를 다루는 세 개의 데이터세트를 생성하고 있으며, 이를 통해 캐논니컬 예제로 모델 편집을 가능하게 한다.
- Pythia 언어 모델로 실험한 결과, LoRA가 전체 파인튜닝(finetuning) 및 MEMIT보다 우수한 성능을 보였다.
- 대상 맞춤 개선을 용이하게 하는 Backpack 언어 모델 아키텍처에 초점을 맞추었으며, Backpack은 각 단어의 다양한 사용을 분해한 방대한 의미 벡터 은행을 정의한다.
- 캐논니컬 예제에 대해 소수(약 10개)의 의미 벡터를 선택하고 파인튜닝하는 '의미 파인튜닝(sense finetuning)'을 제안하며, 이 방법이 기타 파인튜닝 방법들보다 뛰어난 성능을 보임(예: 4.8% 대 0.3% 개선)을 확인했다.
- 마지막으로, GPT-J-6B를 35배 더 작은 Backpack 모델의 '의미 파인튜닝'에서 변경된 부분만을 이용한 추론 시간 앙상블로 개선하여, 일부 설정에서 GPT-J 자체 편집을 뛰어넘는 성능을 보였다(4.1% 대 1.0%).

### [Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss](https://arxiv.org/abs/2402.06187)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06187.png)

Vote: 3

Authors: Furong Huang, Shuang Ma, Praveen Palanisamy, Ruijie Zheng, John Langford, Hal Daumé III, Huazhe Xu, Yongyuan Liang, Kalyan Shankar Basu, Xiyao Wang

- Premier-TACO는 순차적 의사결정 작업에서 적은 수의 예제 학습 효율성을 향상시키기 위해 설계된 멀티태스크 기능 표현 학습 접근법을 제시합니다.
- 이 방법은 중요한 환경 동역학을 포착하는 일반적 기능 표현을 사전 훈련하기 위해 멀티태스크 오프라인 데이터 세트의 부분집합을 활용하고, 최소한의 전문가 데몬스트레이션을 사용하여 미세 조정합니다.
- 시각적 제어 작업에서 최고의 결과로 알려진 시간적 행동 대조 학습(TACO) 목표를 개선하고, 대규모 멀티태스크 오프라인 사전 훈련을 실현할 수 있는 새로운 부정적 예시 샘플링 전략을 도입합니다.
- 다양한 연속 제어 벤치마크인 Deepmind Control Suite, MetaWorld 및 LIBERO에서의 광범위한 경험적 평가를 통해 Premier-TACO가 시각적 표현 사전 훈련에 효과적이며, 새로운 작업의 적은 수의 예제 학습 성능을 크게 향상시킴을 입증합니다.
- 관련 코드, 사전 훈련 데이터 및 사전 훈련된 모델 체크포인트는 'https://github.com/PremierTACO/premier-taco'에서 배포될 예정입니다.

### [Real-World Fluid Directed Rigid Body Control via Deep Reinforcement Learning](https://arxiv.org/abs/2402.06102)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2402.06102.png)

Vote: 2

Authors: Markus Wulfmeier, Martin Riedmiller, Michael Neunert, Abbas Abdolmaleki, Arunkumar Byravan, Thomas Lampe, Mohak Bhardwaj, Jonas Buchli, Francesco Romano

- 실제 적용분야에서 강화 학습(RL)의 최근 진전은 대규모 시스템을 정확히 시뮬레이션할 수 있는 능력에 의존하고 있으나, 유체 역학 시스템과 같은 영역은 복잡한 동적 현상을 높은 통합 속도로 시뮬레이션하기 어려워 현대적 심화 RL 알고리즘의 직접적인 적용을 제한한다.
- 이 연구에서는 'Box o Flows'라는 새로운 벤치탑 실험 제어 시스템을 도입하여 동적 실제 상황에서 RL 알고리즘을 체계적으로 평가한다.
- 'Box o Flows'의 주요 구성 요소를 설명하고, 일련의 실험들을 통해 최신 모델-프리 RL 알고리즘이 단순한 보상 명세를 통해 다양한 복잡한 행동을 합성할 수 있음을 보여준다.
- 이외에도, 과거 경험을 재사용함으로써 오프라인 RL이 데이터-효율적인 가설 검증에 있어서의 역할을 탐구한다.
- 이러한 초기 연구에서 얻은 통찰력과 'Box o Flows'와 같은 시스템의 가용성은 복잡한 동적 시스템에 일반적으로 적용될 수 있는 체계적인 RL 알고리즘을 개발하기 위한 방향을 지원한다고 믿는다.
- 실험의 보충 자료와 비디오는 https://sites.google.com/view/box-o-flows/home에서 확인할 수 있다.

