## Daily Papers (2024-09-12)

### [PingPong: A Benchmark for Role-Playing Language Models with User Emulation and Multi-Model Evaluation](https://arxiv.org/abs/2409.06820)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.06820.png)

Vote: 45

Authors: Ilya Gusev

- **What's New**: 이 논문에서는 오락을 목적으로 특정 캐릭터나 페르소나를 유지하면서 사용자를 즐겁게 할 수 있는 역할극(language models)의 평가를 위한 새로운 벤치마크를 소개합니다. 이러한 역할극 모델은 LLMs (Large Language Models)의 엔터테인먼트 능력을 직접적으로 평가하는 첫 단계로 사용자와의 다중 턴 상호 작용을 자동으로 평가하는 시스템을 제안합니다. 사례별 평가 점수와 함께 모든 결과, 프롬프트, 스크립트가 온라인에 공개되어 있습니다.
- **Technical Details**: 우리의 방법론은 세 가지 주요 구성 요소로 구성됩니다: 사용자 역할(plater model)을 맡는 모델, 사용자 행동을 시뮬레이션하는 조사자 모델(interrogator model), 대화 품질을 평가하는 심판 모델(judge model)이 그것입니다. 이 시스템은 비대칭적으로 설계되었지만, 대칭적으로도 수정 가능하여 다양한 도메인에 활용될 수 있습니다. 평가 기준에는 캐릭터 일관성(character consistency), 오락 가치(entertainment value), 언어 유창성(Language fluency)이 포함됩니다.
- **Performance Highlights**: 우리는 제안된 심판(judges) 모델들이 인간 평가와 높은 상관관계를 가지는지를 확인하기 위해 실험을 진행했습니다. 여러 소유 및 오픈 언어 모델 가족(Claude, GPT-4o, Llama 3.1 등)을 테스트했으며, 각각의 메트릭에 대한 평균과 대화 거절 비율을 보고했습니다. 수동 평가와 자동 평가 간의 상관 관계는 스피어만 상관(Spearman correlation)을 사용해 계산되었습니다.

### [MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications](https://arxiv.org/abs/2409.07314)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.07314.png)

Vote: 32

Authors: Nada Saadi, Hamza Javed, Clément Christophe, Shadab Khan, Praveen K Kanithi, Svetlana Maslenkova, Tathagata Raha, Nasir Hayat, Ronnie Rajan, Marco AF Pimentel

- **What's New**: 새로운 연구에서는 대규모 language model(언어 모델)의 학습 방법에 대한 혁신적인 접근법을 제안하고 있습니다. 특히, 이 연구는 모델의 학습 효율성을 대폭 개선하는 다양한 전략을 포함하고 있습니다.
- **Technical Details**: 이 연구에서 소개된 주요 개념 중 하나는 gradient accumulation(그라디언트 누적) 기법입니다. 이는 메모리 효율성을 높이기 위해 mini-batch(미니 배치)를 나누는 방식으로, GPU 자원을 더 효율적으로 사용할 수 있게 합니다. 또 다른 중요한 점은 mixed precision training(혼합 정밀도 학습) 전략의 사용입니다. 이는 계산 속도를 높이면서도 정확도 손실을 최소화할 수 있는 방법입니다.
- **Performance Highlights**: 실험 결과, 제안된 기술들을 적용한 모델이 기존의 모델들과 비교해 학습 속도가 1.5배 이상 향상된 것을 확인할 수 있었습니다. 또한, 메모리 사용량도 약 40% 줄어드는 등 전반적인 자원 효율성도 크게 향상되었습니다.

### [Agent Workflow Memory](https://arxiv.org/abs/2409.07429)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.07429.png)

Vote: 14

Authors: Daniel Fried, Jiayuan Mao, Graham Neubig, Zora Zhiruo Wang

- **What's New**: 최근 언어 모델(LM) 기반 에이전트들이 디지털 작업을 다루는 능력이 급격히 향상되었습니다. 그러나 현재 에이전트들은 주어진 예제들을 고정된 세트로 통합하여 학습할 뿐, 과거의 성공과 실패에서 배워 적응하는 능력은 부족합니다. 이를 해결하기 위해, 본 논문에서는 에이전트 워크플로우 메모리(AWM)라는 새로운 모델을 제안하였습니다.
- **Technical Details**: AWM은 에이전트의 경로에서 재사용 가능한 루틴을 추출하여 워크플로우를 유도하고, 이 워크플로우를 에이전트 메모리에 통합해 향후 작업 해결에 활용합니다. 워크플로우는 주어진 작업 경로에서 공통 루틴을 추출한 목표를 나타내며, 이를 통해 더 복잡한 작업을 성공적으로 해결하기 위해 필요한 필수 기술을 효과적으로 포착합니다. AWM은 기본적 내장 액션 세트를 시작으로 스트리밍 방식으로 새로운 작업을 해결하고, 계속해서 새로운 경험과 이전에 획득한 워크플로우를 바탕으로 더 복잡한 워크플로우를 구축합니다.
- **Performance Highlights**: AWM은 두 가지 웹 탐색 벤치마크(WebArena와 Mind2Web)에서 탁월한 성능을 보였습니다. WebArena에서는 상위 자율 메서드 대비 상대 성공률 51.1% 증가를, Mind2Web에서는 교차 작업 결과를 24.6% 개선했습니다. 또한, WebArena에서 크로스 템플릿 하위 집합과 Mind2Web의 교차 웹사이트 및 도메인 테스트 분할에서도 우수한 성과를 보이며, 작업, 웹사이트, 도메인 간의 일반적인 적응력을 입증했습니다.

### [Gated Slot Attention for Efficient Linear-Time Sequence Modeling](https://arxiv.org/abs/2409.07146)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.07146.png)

Vote: 13

Authors: Yiqiao Wang, Freda Shi, Yue Zhang, Songlin Yang, Bailin Wang, Wei Bi, Guohong Fu, Bolun Wang, Yu Zhang, Ruijie Zhu, Leyang Cui, Peng Zhou

- **What's New**: 최근 Transformer가 시퀀스 모델링 작업에서 우세한 아키텍처로 자리잡은 반면, 소프트맥스 기반 표준 어텐션(Softmax Attention)의 이차 복잡성으로 인해 긴 시퀀스를 모델링하는 데 어려움이 있습니다. 이를 해결하기 위해 제안된 새로운 모델, Gated Slot Attention(GSA)는 둡니다.
- **Technical Details**: 기존 Attention with Bounded-Memory Control(ABC) 모델을 개편하여 Softmax 연산을 포함하는 방식으로 재구성하였으며, 이는 T2R(Transformer to RNN) 컨텍스트에서 유리합니다. 또한, 하드웨어 효율적인 조각별(Chunkwise) 구현을 통해 더 효율적인 훈련을 가능하게 합니다.
- **Performance Highlights**: GSA는 언어 모델링과 이해 과제에서 성능을 유지하면서도, 대용량 상태 크기가 필요하지 않은 상태에서 다른 선형 모델을 능가합니다. 특히, Mistral-7B를 GSA로 미세조정할 경우, 여타 선형 모델 및 다른 T2R 방법보다 우수한 성능을 보였습니다. 훈련 속도는 GLA와 유사하지만, 상태 크기가 작아 추론 속도는 더 빠릅니다.

### [Hi3D: Pursuing High-Resolution Image-to-3D Generation with Video Diffusion Models](https://arxiv.org/abs/2409.07452)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.07452.png)

Vote: 8

Authors: Ting Yao, Yang Chen, Tao Mei, Haibo Yang, Yingwei Pan, Chong-Wah Ngo, Zhineng Chen

- **What's New**: 이 논문은 Image-to-3D (이미지를 3D 이미지로 변환) 문제에 대한 혁신적인 접근법을 제안합니다. 기존의 2D diffusion 모델 대신, 비디오 diffusion 모델을 사용하여 3D 인지 일관성을 강화하고 고해상도 다중 뷰 생성의 안정성을 높이는 새로운 방법을 도입합니다. 이 방법은 Hi3D (High-resolution Image-to-3D model)로 명명됩니다.
- **Technical Details**: 논문은 두 단계의 비디오 diffusion 기반 패러다임을 제안합니다. 첫 번째 단계에서는 사전 학습된 비디오 diffusion 모델을 카메라 포즈 조건과 함께 리 모델링하여 단일 뷰 이미지를 저해상도의 3D 인지 순차적 이미지(512×512 해상도의 궤도 비디오)로 변환합니다. 두 번째 단계에서는 이 저해상도 궤도 비디오를 3D 인지 비디오-to-비디오 정제기에 추가 깊이 조건과 함께 입력하여, 고해상도 궤도 비디오(1,024×1,024)로 변환하며 세부 텍스처를 향상시킵니다. 최종적으로 3D Gaussian Splatting을 사용하여 새로운 뷰를 추가하여 고품질의 3D 메쉬를 생성합니다.
- **Performance Highlights**: 제안된 Hi3D 모델은 소설 뷰 합성과 단일 뷰 재구성 작업에서 최첨단 성능을 입증합니다. 실험 결과, Hi3D 모델은 기존 방법보다 높은 3D 인지 일관성과 고해상도의 3D 메쉬 생성을 달성하며, VR 및 3D 영화 제작과 같은 고해상도 텍스처를 요구하는 실제 시나리오에서의 적용 가능성을 높였습니다.

### [VMAS: Video-to-Music Generation via Semantic Alignment in Web Music Videos](https://arxiv.org/abs/2409.07450)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.07450.png)

Vote: 7

Authors: Gedas Bertasius, Yu Tian, Yan-Bo Lin, Linjie Yang, Heng Wang

- **What's New**: 최근 몇 년간 자동 비디오 배경 음악 생성 방법에 대한 수요가 증가하고 있으며, 이를 통해 콘텐츠 제작자들은 수작업을 줄일 수 있습니다. 이전의 방법들에서는 한정된 표현력과 장르 다양성을 가진 symbolic music annotations(MIDI 등)을 사용해왔으나, 본 연구에서는 대규모 웹 기반 비디오 컬렉션을 활용하여 다양한 음악 장르를 포괄하는 효과적인 비디오-음악 생성 모델을 제안합니다.
- **Technical Details**: 우리의 접근 방식은 VMAs(Video-Music Alignment Scheme)라 불리는 프레임워크를 개발하는 것입니다. VMAs는 생성적 비디오-음악 Transformer와 새로운 비디오-음악 정렬 스킴을 결합합니다. 우리는 생성적인 목표를 통한 현실적인 음악 생성과 대조를 목표로 함으로써 비디오의 고수준 내용(예: 장르)과 생성된 음악 간의 정렬을 촉진합니다. 또한, 저수준의 시각적 단서(예: 장면 전환, 동적 사람 움직임)와의 조화를 유도하는 비디오-리듬 정렬 스킴을 도입합니다.
- **Performance Highlights**: 우리의 새로운 DISCO-MV 데이터셋을 통해 훈련된 우리의 모델은 MusicCaps와 DISCO-MV 테스트 세트에서 우수한 품질의 음악을 생성합니다. 인간 평가에서도, 우리의 생성된 음악이 기존 방법 대비 음악 품질과 비디오-음악 정렬 모두에서 일관되게 더 선호되었습니다.

### [gsplat: An Open-Source Library for Gaussian Splatting](https://arxiv.org/abs/2409.06765)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.06765.png)

Vote: 7

Authors: Jeffrey Hu, Zhuoyang Pan, Angjoo Kanazawa, Brent Yi, Matias Turkulainen, Matthew Tancik, Vickie Ye, Justin Kerr, Otto Seiskari, Jianbo Ye, Ruilong Li

- **What's New**: Kerbl 등(2023)이 제안한 Gaussian Splatting은 고해상도의 3D 장면 재구성과 새로운 시점 합성에 대한 빠르게 발전하는 연구 분야입니다. 이 논문에서는 Gaussian Splatting을 기반으로 한 효율적이고 사용자 친화적인 오픈 소스 프로젝트인 gsplat을 소개합니다. gsplat은 최신 연구 기능을 지원하며, PyTorch 기반 프로젝트에서 쉽게 사용할 수 있는 API를 제공합니다. 2023년 10월 첫 출시 이후 gsplat은 GitHub에서 39명의 기여자와 1.6k 이상의 별점을 받았습니다.
- **Technical Details**: gsplat은 Windows와 Linux 플랫폼에서 PyPI를 통해 설치할 수 있으며, PyTorch 인터페이스를 제공합니다. CUDA 커널을 최적화하여 많은 작업을 처리하며, Python 바인딩을 통해 개발자에게 노출됩니다. gsplat은 간단한 인터페이스를 제공하여 외부 프로젝트에서 Gaussian Splatting 기능을 쉽게 통합할 수 있도록 설계되었습니다. 예제 코드와 테스트 케이스 및 온라인 문서화가 잘 갖춰져 있어 새로운 연구자들에게 교육 자료로도 유용합니다.
- **Performance Highlights**: MipNeRF360 데이터셋에서 gsplat과 원본 구현과의 성능을 비교한 결과, gsplat이 메모리를 적게 사용하면서도 훈련 시간을 상당히 단축시켰습니다. 추가적인 정량적 평가와 기능별 성능 분석은 부록에서 확인할 수 있습니다.

### [Self-Harmonized Chain of Thought](https://arxiv.org/abs/2409.04057)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.04057.png)

Vote: 7

Authors: Wei Lu, Ziqi Jin

- **What's New**: 새로운 체인 오브 소트 (Chain-of-Thought, CoT) 프롬프팅을 활용하여, 자동화된 합리적 시연 생성을 통해 대형 언어 모델(LLMs)의 복잡한 추론 작업 해결 능력을 개선했습니다. 이 접근법은 Auto-CoT와 달리, 시연들의 다양성을 통일하여 추론 패턴을 정제하는 ECHO(Self-Harmonized Chain of Thought) 방법을 제안합니다.
- **Technical Details**: ECHO 방법은 다음 단계로 구성됩니다: (1) 데이터셋을 유사성에 따라 여러 클러스터로 나눕니다. (2) 각 클러스터에서 대표 질문을 선택하고 Zero-shot-CoT를 사용하여 그 질문에 대한 합리적 추론 체인을 생성합니다. (3) 동적 프롬프팅 메커니즘을 사용하여 시연들을 서로 참조해가며 지속적으로 개선합니다. Sentence-BERT 및 k-means 클러스터링 모델이 이 과정에 사용됩니다.
- **Performance Highlights**: ECHO는 다양한 추론 도메인에서 +2.8%의 개선된 성능을 보였습니다. 이 방법은 산술, 상식 및 기호 추론 영역에서 다른 기준보다 우수한 성과를 입증하였습니다. 또한, 다양성을 통일함으로써 전반적인 성능 향상이 이루어졌음을 포괄적인 연구로 입증했습니다.

### [MVLLaVA: An Intelligent Agent for Unified and Flexible Novel View Synthesis](https://arxiv.org/abs/2409.07129)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.07129.png)

Vote: 6

Authors: Ke Lu, Xing Lan, Hanyu Jiang, Guohong Hu, Jian Xue

- **What's New**: MVLLaVA는 다양한 태스크를 통합하는 지능형 에이전트로, LLaVA (Large Language model in Visual-Audio tasks)와 다수의 멀티뷰 확산 모델(multi-view diffusion models)을 결합하여 새로운 뷰 생성(novel view synthesis)을 위한 획기적인 솔루션을 제안합니다.
- **Technical Details**: MVLLaVA는 LLaVA의 미세 조정(fine-tuning)을 통해 뷰 기반 명령 템플릿(instruction templates)을 개발하고, 입력을 지능적으로 해석하여 적절한 하위 모델을 선택하여 멀티뷰 이미지를 생성합니다. 다섯 가지 템플릿 유형이 있으며, 이는 각각 다양한 멀티뷰 확산 모델에 대응하는 세 가지 주요 그룹으로 분류됩니다. LLaVA의 미세 조정을 위해 LoRA (Low-Rank Adaptation)을 사용하여 GPU 자원 절약과 효율적인 최적화를 달성합니다.
- **Performance Highlights**: MVLLaVA는 Objaverse 데이터셋 부분을 사용하여 훈련 및 테스트되었으며, 다양한 어플리케이션 시나리오에서 성능이 검증되었습니다. 이 모델은 다양한 입력과 사용자 요구에 효과적으로 대응할 수 있는 유연성과 확장성을 제공합니다.

### [Can Large Language Models Unlock Novel Scientific Research Ideas?](https://arxiv.org/abs/2409.06185)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.06185.png)

Vote: 5

Authors: Tirthankar Ghosal, Asif Ekbal, Vinayak Goyal, Sandeep Kumar

- **What's New**: 최근에 발표된 논문에서 LLM (Large Language Models)의 퓨처 리서치 아이디어(Future Research Ideas) 생성 능력을 분석하는 새로운 연구가 발표되었습니다. 이 연구는 컴퓨터 공학, 물리학, 화학, 경제학, 의학 등의 다양한 분야에 걸쳐 LLM이 제안하는 아이디어의 참신성과 관련성을 평가합니다. 이를 위해 연구팀은 2022년 이후에 출판된 논문들로부터 데이터를 수집하고, 아이디어 정렬 점수(IAScore)와 아이디어 독창성 지표(Idea Distinctness Index)를 제안하였습니다.
- **Technical Details**: 연구팀은 다섯 개의 특정 분야에서 2022년 이후 출간된 논문들을 수집하여 데이터를 생성하였고, 이를 통해 LLM이 생성하는 아이디어의 품질을 평가했습니다. 다양한 프롬프트(prompt)를 사용해 아이디어를 생성하고, 인용의 참신성과 관련성을 평가하기 위해 IAScore와 Idea Distinctness Index를 제안했습니다. 이러한 평가 지표를 통해 LLM, 특히 Gemini, Claude-2, GPT-3.5 및 GPT-4 모델의 성능을 분석했습니다.
- **Performance Highlights**: 연구 결과, LLM이 생성한 아이디어는 일정 수준의 참신성과 관련성을 지니고 있었으며, 이를 통해 LLM이 실제 연구에서 유용하게 활용될 가능성을 확인했습니다. 인간 평가를 통해 460개의 컴퓨터 과학 아이디어를 분석한 결과, 상당한 참신성과 관련성, 실행 가능성을 보여주었습니다.

### [Instant Facial Gaussians Translator for Relightable and Interactable Facial Rendering](https://arxiv.org/abs/2409.07441)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.07441.png)

Vote: 5

Authors: Dafei Qin, Jun Saito, Lan Xu, Qixuan Zhang, Kaichun Qiao, Jingyi Yu, Longwen Zhang, Hongyang Lin, Zijun Zhao, Taku Komura

- **What's New**: 새로운 연구는 디지털 트윈(Digital Twins)과 혼합 현실(MR, Mixed Reality) 디바이스의 발전에 따라 3D 자산의 품질과 렌더링 효율에 대한 기대를 변화시키고 있습니다. 얼굴 아바타는 감정과 의도를 전달하는 중심 역할을 하기 때문에 매우 정확하게 렌더링되어야 합니다. 연구진은 TransGS라는 새로운 기술을 도입하여, CG-친화적인 얼굴 자산을 실시간으로 고품질의 3D Gaussian Splatting(3DGS) 표현으로 번역할 수 있는 번역기를 제안했습니다.
- **Technical Details**: 이 연구의 핵심 설계는 얼굴 자산에 맞춘 Gaussian 표현인 GauFace입니다. GauFace는 Gaussian splatting과 얼굴 자산의 강력한 기하학 및 텍스처 사전 정보를 연결합니다. 구체적으로, Gaussian 행볼과 얼굴 메시에 부착하여 메시에 기반한 애니메이션을 자연스럽게 지원하고, 변형에 따른/무관한 셰이딩 효과를 해독하는 새로운 셰이딩 벡터를 도입했습니다. TransGS는 Diffusion transformer (DiT) 아키텍처를 채택하여 3D 얼굴 자산과 GauFace 대본 사이의 복잡한 일대다 관계를 모델링합니다. 트레이닝 데이터셋으로, 143개의 물리 기반 얼굴 자산과 134개의 HDR 환경 맵을 이용하여 총 1,023개의 조합을 만들고, 각 조합에 대해 1,071개의 고품질 렌더링 이미지를 준비했습니다.
- **Performance Highlights**: TransGS는 기존의 온라인 렌더링 도구보다 우수한 렌더링 결과를 제공하며, 오프라인 렌더링 기술과 비슷한 수준의 품질을 보여줍니다. 또한 PC, 휴대폰, VR 헤드셋 등 다양한 플랫폼에 통합되어, 재조명(relighting), 편집(editing) 및 애니메이션 제어와 같은 전통적인 세지(CG) 파이프라인의 기능을 제공합니다.

### [ProteinBench: A Holistic Evaluation of Protein Foundation Models](https://arxiv.org/abs/2409.06744)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.06744.png)

Vote: 4

Authors: Yan Wang, Yiming Ma, Lihao Wang, Zaixiang Zheng, Quanquan Gu, Yuning Shen, Dongyu Xue, Xiangxin Zhou, Fei Ye, Xinyou Wang

- **What's New**: 최신 연구는 단백질 생성 모델의 성능을 평가하기 위한 최초의 벤치마크인 ProteinBench를 소개합니다. 이 벤치마크는 단백질 설계와 구조 예측을 포함한 다양한 생물학적 도메인을 아우르는 포괄적인 평가 프레임워크를 제공합니다.
- **Technical Details**: ProteinBench는 다음 네 가지 주요 구성 요소를 포함합니다: (1) 단백질 도메인에서 주요 생성 과제를 아우르는 분류 체계, (2) 품질, 신선함, 다양성, 견고성을 평가하는 다차원 평가 접근법, (3) 다양한 사용자 목표에 대한 심층 분석, (4) 공개된 리더보드 및 코드 프레임워크. 이 벤치마크는 신경망 모델의 구조적 성능과 데이터 특성의 영향을 분석하고, 표준화된 벤치마크를 통해 모델들 간의 비교를 돕습니다.
- **Performance Highlights**: ProteinBench는 단백질 설계와 구조-동역학 관련 과제를 평가하며, 품질, 신선함, 다양성, 견고성의 네 가지 핵심 차원에서 모델 성능을 평가합니다. 이를 통해 모델의 다양한 기능 메커니즘을 포괄적으로 측정할 수 있습니다.
- **Datasets**: 평가는 다양한 생물학적 도메인을 아우르는 데이터셋을 사용하여 진행되었습니다. 특히, 자연적 진화 분포를 포착하는 새로 나온 PDB 구조와 de novo 단백질 설계를 포함한 목표를 가진 데이터셋이 사용되었습니다.

### [Generative Hierarchical Materials Search](https://arxiv.org/abs/2409.06762)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.06762.png)

Vote: 4

Authors: Sherry Yang, Alexander L. Gaunt, Ekin D. Cubuk, Danilo J. Rezende, Muratahan Aykol, Ruiqi Gao, Igor Mordatch, Simon Batzner, Dale Schuurmans, Brendan McMorrow

- **What's New**: 현대 기술은 반도체, 태양 전지, 리튬 배터리 등의 재료 개발에 크게 의존하고 있습니다. 이 논문은 기존 재료 과학 지식을 기반으로 사전 훈련된 대규모 생성 모델의 일반화 능력을 활용하여 후보 결정 구조(crystal structure)를 제안할 수 있는 가능성에 대해 탐구하고 있습니다.
- **Technical Details**: GenMS(Generative Hierarchical Materials Search)는 다음과 같은 3단계로 구성된 엔드 투 엔드 언어-구조 생성 프레임워크를 제안합니다: 1) 인터넷에서 고급 재료 과학 지식을 사전 훈련한 대규모 언어 모델(LLM). 2) 전문적인 결정 구조 데이터베이스에서 학습된 확산 모델(diffusion model). 3) 속성 예측을 위한 그래프 신경망(GNN). 언어 명령을 기반으로 화학 공식 생성, 구조 샘플링, 속성 예측을 통해 다중 목표 최적화를 수행합니다.
- **Performance Highlights**: GenMS는 언어 명령으로부터 결정 구조를 생성하는 능력을 평가받았으며, 주요 구조 패밀리에서 사용자 요구 사항을 80% 이상 충족하는 구조를 성공적으로 생성했습니다. 기존의 사전 훈련된 LLM과 비교하여 0%의 성공률을 기록한 반면, GenMS는 복잡한 구조 생성에서도 우수한 성과를 보였습니다. 또한, GenMS의 결정 구조 컴팩트 표현(compact representation)은 DFT 수렴률을 50% 향상시켰습니다.

### [SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories](https://arxiv.org/abs/2409.07440)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.07440.png)

Vote: 1

Authors: Tushar Khot, Erin Bransom, Peter Clark, Ashish Sabharwal, Kejuan Yang, Kyle Richardson, Shashank Gupta, Ben Bogin

- **What's New**: 이번 연구에서는 LLM(Large Language Models)이 좀 더 낮은 프로필의 연구 리포지토리에서 연구 실험을 설정하고 실행하는 작업을 자동화할 수 있는지를 평가하기 위해 새로운 벤치마크인 \\mlee를 도입했습니다. \\mlee는 특히 문서화가 잘 되어있지 않은 오픈 소스 리포지토리를 대상으로 하고 있습니다.
- **Technical Details**: 벤치마크는 세 가지 문제 세트로 구성됩니다: 전문가 세트(Expert set), 마스크 세트(Masked set), 그리고 자동 생성 세트(Auto set). 전문가 세트는 전문가에 의해 수작업으로 작성된 45개의 문제로 이루어져 있고, 마스크 세트는 코드 마스킹(Code Masking) 메커니즘을 통해 전문가 세트에서 파생된 152개의 서브 문제로 구성됩니다. 자동 생성 세트는 다양한 리포지토리와 문제를 포함하는 604개의 자동 생성된 작업을 포함합니다.
- **Performance Highlights**: Benchmark를 통해 평가된 Propietary와 오픈 소스 LLM들은 많은 문제를 해결하는 데 어려움을 겪었습니다. 가장 강력한 Agent도 마스크 서브 문제의 46.1%만을 해결할 수 있었으며, 전체 연구 작업의 16.3%만을 완벽하게 처리할 수 있었습니다. 이 결과는 LLM 기반 실험 실행 시스템이 직면한 주요 과제를 강조합니다.

