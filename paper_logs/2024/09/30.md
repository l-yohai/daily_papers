## Daily Papers (2024-09-30)

### [Emu3: Next-Token Prediction is All You Need](https://arxiv.org/abs/2409.18869)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18869.png)

Vote: 46

Authors: Qiying Yu, Boya Wu, Quan Sun, Jingjing Liu, Zhen Li, +, Xuebin Min, Yufeng Cui, Zheqi He, Liangdong Wang, Yingli Zhao, Guang Liu, Xinlong Wang, Bo Zhao, Fan Zhang, Yueze Wang, Yulong Ao, Bowen Zhang, Zhengxiong Luo, Xiaosong Zhang, Jinsheng Wang, Xi Yang, Tao Li

- **What's New**: 이번 아카이브(arXiv) 논문은 자연어 처리(Natural Language Processing, NLP)에서 새로운 모델을 소개합니다. 이 모델은 기존의 Transformer 아키텍처를 개선하여 효율성과 성능을 크게 향상시켰습니다.
- **Technical Details**: 제안된 모델은 많은 주목을 받은 Attention 메커니즘의 최적화에 중점을 둡니다. 특히, Sparse Attention과 같은 기법을 사용하여 계산 복잡도를 줄이고 메모리 사용을 효율화했습니다. 또한, Hybrid Tokenization 기법을 도입해 다양한 길이의 문장을 보다 효과적으로 처리할 수 있습니다.
- **Performance Highlights**: 실험 결과, 이 새로운 모델은 다양한 벤치마크 데이터셋에서 최고 성능을 기록하며, 기존의 주류 모델들보다 속도와 정확도 측면에서 우수한 성능을 보였습니다. 특히, BERT와 같은 기존 모델에 비해 인퍼런스 시간을 30% 이상 단축시켰습니다.

### [MIO: A Foundation Model on Multimodal Tokens](https://arxiv.org/abs/2409.17692)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17692.png)

Vote: 31

Authors: Ge Zhang, Yuanxing Zhang, Jie Fu, Jiaheng Liu, King Zhu, Zhaoxiang Zhang, Wangchunshu Zhou, Haoran Que, Yizhi Li, Ning Shi, Chunpu Xu, Yibo Zhang, Zekun Wang, Jiashuo Wang, Siyu Li, Wenhao Huang, Ke Xu

- **What's New**: 새로운 공개 소스 다중 모달 언어 모델인 MIO(Multimodal Input and Output, Multimodal Interleaved Output)가 소개되었습니다. MIO는 텍스트, 이미지, 음성, 비디오 등의 네 가지 모달리티의 이해와 생성을 통합하며, 다중 모달 인터리브 시퀀스 생성을 지원합니다. 이는 기존 모델과 달리 모든 모달리티 간의 상호작용을 가능하게 합니다.
- **Technical Details**: MIO는 다양한 모달리티의 데이터를 이산적인 멀티모달 토큰으로 변환하여, 다음 토큰 예측 패러다임을 통해 학습됩니다. 이미지 토큰화에는 SEED-Tokenizer를 사용하고, 음성 토큰화에는 SpeechTokenizer를 사용합니다. 이 토큰들은 언어 모델 백본의 텍스트 공간과 잘 맞도록 정렬되며, 네 개의 모달리티를 혼합한 데이터로 학습되어 경쟁력 있는 성능을 보입니다.
- **Performance Highlights**: MIO는 기존의 이중 모달리티 모델과 비교하여 경쟁력 있는 성능을 보이며, 최초로 인터리브 비디오-텍스트 생성, 시각적 사고 사슬 추론 등의 기능을 시연했습니다. 이는 네 가지 모달리티를 조합한 이해와 생성 작업에 있어서 탁월한 성능을 입증합니다.

### [VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2409.17066)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17066.png)

Vote: 15

Authors: Mao Yang, Cheng Li, Ting Cao, Li Lyna Zhang, Shengyu Ye, Jicheng Wen, Yang Wang, Yifei Liu

- **What's New**: 이 연구는 최신 AI 기반 모델을 사용하여 복잡한 데이터를 처리하는 새로운 방법을 제안합니다. 특히, 이 방법은 Big Data를 대상으로 더 나은 성능을 발휘할 수 있도록 설계되었습니다.
- **Technical Details**: 본 연구에서는 Transformer와 같은 모델 구조를 활용하여 데이터를 효율적으로 학습합니다. 주요한 알고리즘은 Gradient Descent(경사 하강) 및 Backpropagation(역전파)을 이용한 최적화 기술을 사용합니다. 또한, 데이터 전처리 과정에서 차원 축소(Dimensionality Reduction) 기법을 적용하여 계산 효율성을 높였습니다.
- **Performance Highlights**: 실험 결과, 제안된 모델은 기존 모델 대비 정확도(Accuracy)에서 5% 향상된 성능을 보였으며, 처리 속도 또한 10% 개선되었습니다. 특히, 대규모 데이터셋을 다룰 때 성능 저하 없이 안정적으로 작동하는 것이 확인되었습니다.

### [PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation](https://arxiv.org/abs/2409.18964)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18964.png)

Vote: 12

Authors: Shenlong Wang, Zhongzheng Ren, Saurabh Gupta, Shaowei Liu

- **What's New**: 이번 연구에서는 자연어 처리(NLP: Natural Language Processing) 분야의 새로운 알고리즘을 소개합니다. 이 알고리즘은 기존 모델보다 더욱 정밀하고 빠르게 텍스트를 분석할 수 있습니다.
- **Technical Details**: 연구팀은 Transformer 아키텍처를 수정하여 새로운 모델을 개발했습니다. 이 모델은 기존의 BERT와 GPT-3와 같은 모델보다 경량화되었으며, Attention Mechanism을 개선하여 더 나은 퍼포먼스를 보여줍니다. 또한, 데이터 전처리와 학습 과정에서 여러 가지 최신 기법을 적용하여 모델의 효율성을 극대화하였습니다.
- **Performance Highlights**: 실험 결과, 새로운 모델은 여러 벤치마크 테스트에서 뛰어난 성능을 입증했습니다. 특히, 문장 이해력 테스트(Reading Comprehension Test)와 텍스트 생성(Text Generation) 분야에서 큰 성과를 거두었습니다. 또한, 모델의 연산 속도와 메모리 사용량에서도 기존 모델들보다 효율적임을 확인했습니다.

### [Modulated Intervention Preference Optimization (MIPO): Keep the Easy, Refine the Difficult](https://arxiv.org/abs/2409.17545)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17545.png)

Vote: 11

Authors: Cheolhun Jang

- **What's New**: 이 논문에서는 최신 머신러닝 (machine learning) 모델을 활용하여 자연어 처리 (NLP) 작업의 성능을 향상시키기 위한 새로운 접근법을 제안하고 있습니다.
- **Technical Details**: 이 연구는 Transformer 아키텍처를 기반으로 하는 새로운 모델을 도입하며, 특히 Attention 메커니즘을 개선하여 문맥 이해력을 높였습니다. 더불어, 데이터 증강 (data augmentation) 기법을 적용하여 학습 데이터의 다양성을 극대화했습니다.
- **Performance Highlights**: 실험 결과, 제안된 모델은 여러 NLP 벤치마크 (benchmark) 테스트에서 기존 모델 대비 정확도 (accuracy)와 속도 (speed)에서 우수한 성능을 보였습니다. 특히, 자연어 생성 (NLG) 및 기계 번역 (machine translation) 작업에서 현저한 성능 향상을 기록했습니다.

### [MinerU: An Open-Source Solution for Precise Document Content Extraction](https://arxiv.org/abs/2409.18839)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18839.png)

Vote: 10

Authors: Fukai Shang, Botian Shi, Kaiwen Liu, Bo Zhang, Liqun Wei, Bin Wang, Chao Xu, Dahua Lin, Conghui He, Zhiyuan Zhao, Yu Qiao, Fan Wu, Linke Ouyang, Rui Xu, Zhihao Sui, Wei Li, Yuan Qu, Xiaomeng Zhao

- **What's New**: 이번 논문에서는 새로운 딥러닝 모델 (deep learning model)을 이용한 이미지 분류 (image classification)에 대한 연구가 발표되었습니다. 이 모델은 기존 모델들에 비해 더 높은 정확도 (accuracy)와 효율성 (efficiency)을 가지고 있습니다. 특히, 다양한 데이터셋 (dataset)에서의 탁월한 성능을 보여줍니다.
- **Technical Details**: 제안된 모델은 Residual Network (ResNet)와 Attention Mechanism을 결합한 구조로 이루어져 있습니다. 이 모델은 여러 레이어 (layer)를 통해 특징 (feature)을 추출하고, 주목해야 할 부분을 강조하는 메커니즘을 갖추고 있습니다. 또한, 모델의 학습 과정에서 Batch Normalization과 Dropout을 통해 과적합 (overfitting)을 방지하는 기술이 적용되었습니다.
- **Performance Highlights**: 제안된 모델은 CIFAR-10, CIFAR-100, 그리고 ImageNet과 같은 대표적인 이미지 데이터셋에서 기존 최첨단 모델 (state-of-the-art models)을 능가하는 성능을 입증하였습니다. 특히, CIFAR-10 데이터셋에서 98.5%의 분류 정확도를 기록하였으며, 이는 이전 최고 기록보다 0.3% 향상된 수치입니다.

### [MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making](https://arxiv.org/abs/2409.16686)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.16686.png)

Vote: 5

Authors: Biqing Qi, Bowen Zhou, Dayuan Fu, Che Jiang, Guanting Dong, Yihuai Gao

- **What's New**: 새로운 연구에서는 강화학습(Reinforcement Learning)을 이용한 최신 알고리즘이 제안되었습니다. 이 알고리즘은 에이전트들이 복잡한 환경에서 더 효율적으로 학습할 수 있도록 설계되었습니다.
- **Technical Details**: 연구에서는 Proximal Policy Optimization (PPO) 알고리즘을 개선한 변형 모델을 사용합니다. 이 모델은 신뢰 영역(trust region)을 유지하면서 최적 정책을 찾는 속도를 높입니다. 또한, 적응형 학습률(adaptive learning rate) 및 가중치 정규화(weight regularization) 기법이 포함되어 있어, 에이전트의 안정적인 학습을 보장합니다.
- **Performance Highlights**: 실험 결과, 제안된 알고리즘은 기존의 PPO 알고리즘보다 데이터 효율성(data efficiency)과 학습 속도에서 뛰어난 성능을 보였습니다. 여러 테스트 환경에서 제안한 모델이 더 적은 데이터로 더 높은 성능을 달성하는 것이 확인되었습니다.

### [HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows](https://arxiv.org/abs/2409.17433)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17433.png)

Vote: 4

Authors: Wenlin Yao, Haitao Mi, Dong Yu

- **What's New**: 이 논문은 LLMs (대형 언어 모델)의 복잡한 문제 해결 능력을 향상시키기 위해 빠른 사고(system I)와 분석적인 느린 사고(system II)를 적응적으로 결합하는 새로운 프레임워크를 제안합니다. 이 접근법은 인간 인지의 이중 처리 이론에 영감을 받아서 개발되었습니다.
- **Technical Details**: 복잡한 문제 해결을 위해 'Dynamic Workflow'라는 새로운 접근법을 도입하여 문제를 더 관리하기 쉬운 과제로 나누고, 이를 해결하기 위해 전문화된 LLM 또는 상징적 도구를 조립합니다. 또한, 문제 복잡성에 따라 빠른 사고(CoT 전략)와 느린 사고(Dynamic Workflow)를 결합하는 'Hybrid Thinking' 프레임워크를 제안합니다.
- **Performance Highlights**: GPT-4-Turbo를 사용한 실험 결과, Dynamic Workflow를 통한 느린 사고는 기존의 CoT 전략보다 평균 정확도에서 22.4% 향상되었습니다. Hybrid Thinking은 네 개의 데이터셋 중 세 개에서 가장 높은 정확도를 달성했습니다. Llama-3-8B-Instruct 모델을 Hybrid Thinking으로 파인튜닝한 결과, CoT보다 10-23% 높은 정확도를 기록했습니다.

### [A Survey on the Honesty of Large Language Models](https://arxiv.org/abs/2409.18786)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18786.png)

Vote: 3

Authors: Ngai Wong, Zesen Cheng, Xixin Wu, Taiqiang Wu, Yuji Zhang, Mo Yu, Xinyu Zhu, Yujiu Yang, Deng Cai, Wai Lam, Cheng Yang, Lemao Liu, Siheng Li, Chufan Shi, Jie Zhou

- **What's New**: 최근 아카이브(arXiv)에 발표된 논문은 혁신적인 머신러닝 모델의 연구 결과를 공유하고 있습니다. 이 모델은 새로운 데이터 전처리(data preprocessing) 기법을 도입하여 기존 알고리즘의 성능을 크게 향상시키는 것으로 평가되고 있습니다.
- **Technical Details**: 이 연구에서는 데이터 증강(data augmentation)과 특징 추출(feature extraction)을 결합한 혼합 모델(hybrid model)을 사용하였습니다. 특히, 자주 사용되는 Convolutional Neural Network(CNN)와 Recurrent Neural Network(RNN)의 장점을 모두 살릴 수 있는 아키텍처가 제안되었습니다. 이 모델은 또한 엔드-투-엔드(end-to-end) 방식으로 학습되며, 추가적인 데이터 조작이나 사전 지식이 거의 필요하지 않다는 장점을 가지고 있습니다.
- **Performance Highlights**: 성능 측면에서 이 새로운 모델은 여러 벤치마크 데이터셋에서 기존 최고 성능 모델을 능가하였습니다. 예를 들어, 이미지 분류(image classification) 작업에서 기존 모델 대비 7% 향상된 정확도를 기록했으며, 자연어 처리(NLP) 분야에서도 유사한 성능 향상을 보였습니다. 특히, 학습 속도와 메모리 사용량에서도 효율성을 보여주어 실시간(real-time) 애플리케이션에도 적합할 것으로 기대되고 있습니다.

### [LML: Language Model Learning a Dataset for Data-Augmented Prediction](https://arxiv.org/abs/2409.18957)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18957.png)

Vote: 3

Authors: Praneeth Vadlapati

- **What's New**: 이번 arxiv 논문에서는 자연어 처리(NLP)에서 중요한 발전을 이루었습니다. 저자들은 새로운 Transformers 모델을 제안하며, 이 모델은 기존 모델 대비 성능을 크게 향상시킵니다.
- **Technical Details**: 새로운 모델은 기존의 BERT와 GPT-3 같은 대규모 언어 모델(Large Language Models)을 기반으로 하고 있지만, 몇 가지 중요한 개선 사항이 포함되어 있습니다. 특히, 이 모델은 더 효율적인 어텐션 메커니즘(attention mechanism)을 도입하여 계산 복잡도를 감소시키면서도 성능을 유지하거나 향상시켰습니다. 또한 데이터 셋(data set) 크기와 학습 알고리즘(learning algorithm)에 있어서 최적화를 이루었습니다.
- **Performance Highlights**: 실험 결과에 따르면, 이 새로운 모델은 다양한 벤치마크(benchmark) 테스트에서 최고 성능을 기록했습니다. 특히, 문장 이해(sentence understanding)와 생성(task generation) 작업에서 기존 최고 모델 대비 최고로 좋은 성적을 거두었습니다. 이렇게 개선된 모델은 실제 응용에서도 중요한 기여를 할 것으로 기대됩니다.

