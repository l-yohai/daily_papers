## Daily Papers (2024-09-27)

### [MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models](https://arxiv.org/abs/2409.17481)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17481.png)

Vote: 25

Authors: Greg Heinrich, Pavlo Molchanov, Saurav Muralidharan, Xinchao Wang, Jeff Pool, Jan Kautz, Hongxu Yin, Gongfan Fang

- **What's New**: 최근 발표된 연구는 대형 언어 모델(LLMs)의 메모리 및 연산 효율성을 개선하는 방법으로 N:M 희소패턴을 도입한 'MaskLLM'이라는 학습 가능한 방식을 제안합니다. MaskLLM은 대규모 데이터를 통한 엔드 투 엔드 학습을 통해 LLM 희소성을 최적화하고, 프루닝(pruning)으로 인한 손실을 줄이는 것이 목표입니다.
- **Technical Details**: MaskLLM은 프루닝을 위한 마스크 선택 문제를 확률적 관점으로 접근하며 Gumbel Softmax를 이용해 차별화할 수 있는 샘플링 과정을 도입합니다. 이를 통해 각 후보 마스크의 확률을 최적화하고, 그래디언트 디센트를 활용해 마스크 분포를 학습합니다. 2:4 희소패턴을 중심으로 하여, 최적의 바이너리 마스크를 학습함으로써 대규모 데이터 세트의 정보를 유지하고, LLM의 언어 모델링 손실을 최소화합니다.
- **Performance Highlights**: 여러 대형 언어 모델(LLaMA-2 7B, LLaMA-2 13B, Nemotron-4 15B 등)을 대상으로 한 실험에서, MaskLLM은 SparseGPT에 비해 LLaMA-2 7B 모델에서 perplexity(PPL)를 10.42에서 6.72로 개선했습니다. 또한, 특정 도메인에서 손실 없는 압축을 실현하여 LLMs의 성능을 크게 향상시켰습니다.

### [LLaVA-3D: A Simple yet Effective Pathway to Empowering LMMs with 3D-awareness](https://arxiv.org/abs/2409.18125)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18125.png)

Vote: 21

Authors: Jiangmiao Pang, Chenming Zhu, Tai Wang, Wenwei Zhang, Xihui Liu

- **What's New**: 최근 대형 멀티모달 모델 (Large Multimodal Models, LMMs)의 발전은 시각적 및 언어적 입력에 대한 이해와 추론 능력을 크게 향상시켰습니다. 그러나 이러한 모델은 주로 가상적 상호작용에 제한되어 있으며, 물리적 세계와의 상호작용 능력이 부족합니다. 이를 해결하기 위해 LLaVA-3D라는 새로운 프레임워크가 제안되었습니다. LLaVA-3D는 기존의 2D LLaVA 모델을 확장하여 3D 공간 지능을 갖추도록 하였습니다.
- **Technical Details**: LLaVA-3D의 핵심 혁신은 3D Patch라고 불리는 새로운 3D 표현을 도입한 것입니다. 2D 패치 특징에 3D 위치 임베딩을 추가하여 복잡한 처리를 거치지 않고 3D 표현을 생성합니다. 여러 입력 프레임에 걸쳐 3D 패치 특징을 압축하는 다양한 풀링 전략을 탐구하여 LLM에 입력하기 전에 최적화합니다. 이 모델은 3D 비전-언어 데이터셋에서 미세 조정되며 빠르게 3D 공간 이해 및 그라운딩 능력을 획득합니다.
- **Performance Highlights**: LLaVA-3D는 다양한 3D 태스크 및 벤치마크 (예: 3D 캡셔닝, 3D 질의응답, 3D 그라운딩)에서 최첨단 성능을 달성합니다. 기존 3D LMM들보다 훨씬 적은 훈련 시간과 에포크로 뛰어난 성능을 발휘합니다. 또한, 2D 이미지 이해, 추론, 대화에서도 강력한 성능을 유지합니다.

### [EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions](https://arxiv.org/abs/2409.18042)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18042.png)

Vote: 19

Authors: Yu Zhang, Weike Jin, Kuo Yang, Daxin Tan, Xiaodan Liang, Kun Xiang, Runhui Huang, Haoyuan Li, Haoli Bai, Kai Chen, Chunwei Wang, Yunhao Gou, Zhili Liu, Yi Zhu, Jianhua Han, Xiaohui Li, Yihan Zeng, Dingdong Wang, James T. Kwok, Jing Xu, Hengshuang Zhao, +, Nian Xie

- **What's New**: OpenAI가 발표한 GPT-4o는 모든 모달리티(omni-modal)에서 작동하는 인공지능 비서에 대한 관심을 다시 불러일으켰습니다. 특히, 시각, 언어, 음성 능력을 동시에 가진 모델의 필요성이 대두되고 있습니다.
- **Technical Details**: 기존 모델들은 주로 Vision-Language 또는 Speech-Language에 집중했으나, EMOVA는 고급 시각 디테일을 캡처할 수 있는 지속적인 비전 인코더와, 시맨틱-음향 분리된 말(tokenizer)을 통해 다양한 음성 스타일을 제어할 수 있습니다. EMOVA는 분리된 시맨틱 내용과 음성 스타일을 LLM에 정렬하여 다양한 감정 표현과 피치를 지원하는 가벼운 스타일 모듈을 도입하였습니다.
- **Performance Highlights**: EMOVA는 이미지-텍스트 및 음성-텍스트 데이터를 통해 모든 모달리티를 정렬하여, 동시대 최상위 비전-언어 및 음성 기준 성능을 달성합니다. 또한, 소량의 혼합 모달리티 샘플만으로도 원하는 형식의 응답을 가르칠 수 있습니다.

### [Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction](https://arxiv.org/abs/2409.17422)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17422.png)

Vote: 13

Authors: Yifei Ming, Xuan-Phi Nguyen, Shafiq Joty, Zhenmei Shi, Yingyu Liang

- **What's New**: 이번 연구에서는 Large Language Models(LLMs)의 긴 컨텍스트(컨텍스트) 입력 처리 능력을 향상시키기 위한 새로운 최적화 방식인 GemFilter를 제안합니다. 이 방법은 초기 레이어의 주의(attention) 행렬을 활용하여 필터링 레이어를 통해 필요한 정보를 추출하고, 이를 통해 시간이 많이 소요되는 프롬프트 계산 단계를 최적화합니다.
- **Technical Details**: 기존의 KV 캐시(KV cache) 압축 방식인 H2O와 SnapKV는 프롬프트 계산 단계의 비효율성을 개선하지 못했습니다. 이에 비해 GemFilter는 초기 레이어에서 주의 행렬을 이용해 필터링 레이어를 정의하고, 이를 통해 입력 토큰을 압축하여 프롬프트 계산에 필요한 시간을 단축하고 GPU 메모리 사용량을 줄입니다. 알고리즘 1(GemFilter)은 초기 레이어가 필요한 정보를 요약하는 능력을 이용해 이를 필터링하여 목표 토큰 수로 줄이는 과정입니다.
- **Performance Highlights**: GemFilter는 프롬프트 계산 단계에서 SnapKV/H2O 및 기존의 표준 주의 메커니즘보다 빠르게 실행되며, GPU 메모리 사용량도 줄어듭니다. 테스트 결과, 'Needle in a Haystack' 벤치마크에서 표준 주의 및 SnapKV 모두를 능가하는 성능을 보였고, LongBench 벤치마크에서도 SnapKV/H2O와 유사한 성능을 보였습니다.

### [Lotus: Diffusion-based Visual Foundation Model for High-quality Dense Prediction](https://arxiv.org/abs/2409.18124)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18124.png)

Vote: 12

Authors: Kaiqiang Zhou, Hongbo Liu, Wei Yin, Leheng Li, Ying-Cong Chen, Jing He, Haodong Li, Yixun Liang, Bingbing Liu

- **What's New**: Lotus는 밀도 예측(dense prediction)을 위한 새로운 확산 모델(diffusion model)을 제안합니다. 기존의 확산 모델이 이미지 생성에 최적화되었지만, Lotus는 밀도 예측에 더욱 적합한 방식으로 설계되었습니다.
- **Technical Details**: Lotus는 표준 노이즈 예측 방식을 피하고 직접 주석(annotation)을 예측하도록 훈련되었습니다. 또한, 순차적인 디노이징을 한 단계로 단순화하여 모델의 수렴을 촉진하고 최적화 성능을 향상시킵니다. 타스크 스위처(task switcher)를 통해 디테일 보존을 개선합니다.
- **Performance Highlights**: Lotus는 제로샷 단안 깊이 추정(zero-shot monocular depth)과 표면 노멀 예측(surface normal estimation)에서 SoTA 성능을 달성했습니다. 기존의 생성적 접근법보다 더 높은 정확도와 효율성을 보여주며, 특히 Marigold보다 빠르게 수행됩니다.

### [Pixel-Space Post-Training of Latent Diffusion Models](https://arxiv.org/abs/2409.17565)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17565.png)

Vote: 11

Authors: Christina Zhang, Jialiang Wang, Matthew Yu, Ji Hou, Zijian He, Felix Juefei-Xu, Sam Tsai, Peter Vajda, Simran Motwani

- **What's New**: 새로운 연구에서는 화학분야의 인공지능 모델 효율성을 극대화하기 위한 혁신적인 접근법을 제안합니다. 이 연구는 분자(분자, molecule)의 특성과 반응성을 더욱 정확하게 예측할 수 있는 방법을 소개합니다.
- **Technical Details**: 연구팀은 기계 학습 (machine learning) 알고리즘의 일종인 그래프 신경망 (Graph Neural Networks, GNNs)을 활용하여 분자 구조를 더욱 정밀하게 분석하였습니다. 또한, 이 접근법은 다양한 분자들 간의 상호작용을 고려한 하이퍼그래프 모델 (Hypergraph Model)을 채택하였습니다.
- **Performance Highlights**: 제안된 모델은 기존의 방법들과 비교하여 예측 정확도와 계산 효율성에서 큰 성과를 보였습니다. 특히, 대규모 분자 데이터셋(data set)을 다룰 때에도 우수한 성능을 유지하며, 이는 실제 화학 연구와 약품 개발에 큰 기여를 할 수 있을 것으로 보입니다.

### [Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling](https://arxiv.org/abs/2409.14683)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.14683.png)

Vote: 7

Authors: Griffin Adams, Antoine Chaffin, Benjamin Clavié

- **What's New**: 이번 연구에서는 Token Pooling이라는 새로운 방법을 소개합니다. 이 방법은 특정한 트레이닝이나 파이프라인 수정 없이도 문서를 표현하는 벡터의 수를 줄일 수 있습니다. Token Pooling은 심플한 클러스터링 접근법을 사용하여 토큰 표현을 평균 풀링(mean pooling)합니다.
- **Technical Details**: Token Pooling은 문서 내 토큰 벡터의 수를 효과적으로 줄이기 위해 클러스터링 방법을 적용하는 두 단계 시스템입니다. 첫 번째 단계에서는 개별 벡터를 그룹화하며, 세 가지 클러스터링 방법(Sequential Pooling, K-Means 기반 풀링, 계층적 클러스터링 기반 풀링)을 사용합니다. 두 번째 단계에서는 평균 풀링을 적용하여 클러스터의 평균 표현을 계산합니다. 그 결과 생성된 풀링된 벡터들은 새로운 멀티 벡터 문서 표현으로 사용됩니다.
- **Performance Highlights**: 다양한 평가 데이터셋에서 Token Pooling 방법은 최대 50%의 저장 비용 감소와 평균 성능 저하 없이 좋은 성과를 보였습니다. 더 나아가, ColBERTv2 모델뿐만 아니라 일본어 데이터와 JaColBERTv2 모델에서도 강력한 성과를 나타냈습니다. 특히, 최대 66%의 저장 비용 감소와 3% 미만의 성능 저하를 달성했습니다.

### [Instruction Following without Instruction Tuning](https://arxiv.org/abs/2409.14254)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.14254.png)

Vote: 5

Authors: Christopher D. Manning, Nelson F. Liu, Percy Liang, John Hewitt

- **What's New**: 이 논문에서는 언어 모델이 명시적으로 설계되지 않았음에도 불구하고 지시를 따를 수 있다는 개념을 탐구합니다. 이는 이전의 명령어 튜닝(instruction tuning) 접근법에 비해 한 단계 더 나아간 것입니다. 연구팀은 두 가지 형태의 적응(response tuning과 single-task finetuning)이 명시적 명령어 튜닝 없이도 충분히 지시를 따를 수 있다는 것을 발견했습니다.
- **Technical Details**: 1. Response tuning: 단순히 응답(response)만을 가지고 훈련하여 명령어와의 매핑(mapping) 없이도 지시를 따를 수 있습니다. 2. Single-task finetuning: 특정 작업(예: Python 코드 생성 또는 시 생성)만을 위한 데이터로 훈련하더라도 다양한 지시를 따를 수 있습니다. 실험에서는 Llama-2-7B 및 OLMo-7B-Feb2024 모델을 활용하여 두 방식의 효과를 검증했습니다.
- **Performance Highlights**: Response tuning 접근법은 명령어 튜닝된 모델에 비해 약 43%의 승률을 보였고, single-task finetuning은 모델이 특정 작업을 위해 훈련되었음에도 불구하고 일반적인 지시를 따르는 행동을 보였습니다. 예를 들어, 시 생성 작업만을 위해 튜닝된 모델은 약 23.7%의 승률을 보였습니다. 또한, 간단한 규칙 기반 접근법으로도 언어 모델이 지시를 따르도록 만들 수 있는 것을 확인했습니다.
- **Implications**: 이 연구는 특정 목적을 위해 언어 모델을 적응시키는 동안 모델이 광범위한 지시를 따르는 범용 모델로 작동할 수 있음을 시사합니다. 또한, 매우 간단한 조건 분포의 변화로도 언어 모델이 지시를 따를 수 있다는 점을 보여줍니다.

### [Robot See Robot Do: Imitating Articulated Object Manipulation with Monocular 4D Reconstruction](https://arxiv.org/abs/2409.18121)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18121.png)

Vote: 4

Authors: Mingxuan Wu, Ken Goldberg, Chung Min Kim, Justin Kerr, Qianqian Wang, Brent Yi, Angjoo Kanazawa

- **What's New**: 새로운 논문인 'Robot See Robot Do'는 인간의 단일 시연에서 로봇이 움직이는 물체의 3D 동작을 모방하는 개체 중심의 방법을 제안합니다. 이는 기존의 방법들과 달리, 스마트폰으로 쉽게 캡처할 수 있는 정적 다중 뷰 객체 스캔과 단안 인간 상호작용 비디오를 통해 이루어집니다.
- **Technical Details**: 이 논문에서는 4D-Differentiable Part Models (4D-DPM)라는 방법을 도입하여 단안 비디오에서 개체와 그 부분의 3D 동작을 복구합니다. 4D-DPM은 3D Gaussian Splat[2]을 사용하여 개체를 부분으로 분할하고, 각 부분에 DINO[3] feature fields를 내장하여 단안 비디오에서 객체의 동작을 추적합니다. 이러한 방식은 사전 학습된 대형 모델의 0-shot 성능을 활용하여 다양한 객체를 추적할 수 있게 합니다.
- **Performance Highlights**: 본 연구에서는 다양한 9개의 관절 물체에 대해 RSRD의 유연성을 평가하였으며, 이 중 여러 시연이 양손을 사용하여 물체를 완전히 들어 올리는 작업을 포함합니다. RSRD는 평균 7.5mm의 추적 오차를 달성했으며, 실제 로봇 실험에서 초기 자세 등록의 성공률이 94%, 이동 경로 계획이 87%를 기록했습니다. 또한 초기 잡기와 동작 실행에서 각각 83%와 85%의 성공률을 보였으며, 초기 위치의 60%에서 성공적인 모방을 달성했습니다.

### [Disco4D: Disentangled 4D Human Generation and Animation from a Single Image](https://arxiv.org/abs/2409.17280)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17280.png)

Vote: 4

Authors: Zhongang Cai, Lei Yang, Tianwei Zhang, Ziwei Liu, Shuai Liu, Hui En Pang

- **What's New**: 최근 다양한 증강 및 가상 현실 응용 분야에서 고품질의 3D 디지털 인간 모델의 개발이 중요해지고 있습니다. 이러한 디지털 아바타를 쉽게 구할 수 있는 이미지에서부터 생성하기 위해 많은 연구가 이루어졌습니다. 하지만, 기존의 모델은 단일 레이어로 렌더링되어 애니메이션 및 사용자 정의에 적합하지 않는 문제점이 있었습니다. 이를 해결하기 위해, 본 논문은 4D 복장을 분리하여 인간과 의류 요소를 구분하는 새로운 방법인 Disco4D를 제안합니다.
- **Technical Details**: Disco4D는 SMPL-X (parametric model)를 사용하여 인간의 신체를 표현하고, Gaussian 모델을 사용하여 의류 및 머리카락, 액세서리 등의 요소를 표현합니다. 이를 통해 디지털 아바타의 인간 신체와 의류를 분리하여 개별적으로 학습할 수 있습니다. 또한 occluded된 부분을 모델링하기 위해 diffusion models을 사용하였습니다.
- **Performance Highlights**: Disco4D는 다음과 같은 장점을 제공합니다. (1) Reconstruction fidelity 향상: SMPL-X 바디를 안정적인 앵커로 사용하여 의류의 정밀한 지오메트리와 세부 묘사를 달성. (2) Fine-grained categorization: 각 의류 Gaussian을 분리하여 개별 의류 자산의 복구 및 활용 가능. (3) Extensive editing capabilities: 특정 항목 제거, 색상이나 소재 변경 등의 수정 기능을 지원. (4) Improved animation capabilities: SMPL-X 모델에서 정의된 변형을 따르면서도 의류의 실제 물리적 특성을 반영하여 의류 행동을 조정 가능.

### [The Imperative of Conversation Analysis in the Era of LLMs: A Survey of Tasks, Techniques, and Trends](https://arxiv.org/abs/2409.14195)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.14195.png)

Vote: 3

Authors: Haiyang Yu, Fei Huang, Longze Chen, Minzheng Wang, Xinghua Zhang, Yongbin Li

- **What's New**: 대규모 언어 모델(LLMs)의 발전과 함께 자연어 대화 인터페이스(Language UI)로의 시스템 상호작용이 빠르게 진화하고 있습니다. 이런 변화는 대량의 자연어 상호작용 로그를 생성하게 만들어, 시스템 최적화, 고객 운영, 수요 통찰력 등의 여러 새로운 응용 프로그램으로 연결됩니다.
- **Technical Details**: 대화 분석(CA)은 대화 데이터에서 중요한 정보를 추출하고 분석하여 고객 프로필, 구매 의도, 감정 변화, 판매 기술 등 비즈니스 인사이트와 의사 결정을 돕고자 합니다. 작은 언어 모델(SLMs) 시대에는 대화 데이터 기반 분석이 체계화되지 않았지만, LLMs의 등장으로 대화 속에서 보다 상세하고 다각적인 분석이 가능해졌습니다. CA는 장면 재구성(Scene Reconstruction), 인과 분석(Causality Analysis), 기술 향상(Skill Enhancement), 대화 생성(Conversation Generation)의 네 가지 주요 절차로 나뉩니다.
- **Performance Highlights**: LLMs는 이전의 SLMs와 비교하여 세계 지식을 풍부하게 포함하고 있어, 대화 속에서 실제 장면 요소를 추론하고 더 정확한 비즈니스 인사이트를 제공할 수 있습니다. 그러나, CA는 여전히 정의, 데이터, 방법, 적용면에서 도전에 직면하고 있습니다. 이 연구는 CA의 향후 방향성을 조명하며, 체계적인 과업 정의 및 최적화 목표, 풍부한 데이터 리소스, 통찰력 있는 논의 등을 제공합니다.

### [Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study](https://arxiv.org/abs/2409.17580)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17580.png)

Vote: 2

Authors: Pål Halvorsen, Zahra Sepasdar, Sushant Gautam, Michael A. Riegler, Cise Midoglu

- **What's New**: 디지털 콘텐츠의 빠른 확산과 더불어, 복잡한 자연어 쿼리를 처리하고 관련 정보를 효과적으로 검색하는 시스템의 필요성이 증가하고 있습니다. 기존의 Retrieval-Augmented Generation (RAG) 프레임워크를 넘어, GraphRAG는 지식 그래프(KGs)를 통합하여 검색 프로세스를 개선하고 더 정교하고 상황에 맞는 응답을 제공합니다. 구조화된 데이터를 활용하는 Structured-GraphRAG 프레임워크가 도입되었습니다.
- **Technical Details**: GraphRAG는 지식 그래프(KGs)를 이용하여 복잡한 쿼리를 더 잘 이해하고 연결된 데이터를 바탕으로 보다 정교한 정보를 제공합니다. 이 프레임워크는 KGs를 생성하고 이를 기반으로 자연어 쿼리를 Cypher 쿼리로 번역해, 그래프 데이터베이스를 탐색하여 필요한 정보를 검색합니다. 생성된 데이터를 다시 LLM에 입력하여 상세하고 정확한 답변을 제공합니다. Structured-GraphRAG는 SQL 기반 데이터를 자동으로 그래프 형태로 변환하여 폭넓은 사용자들이 그래프 이론에 대한 전문가가 아니더라도 쉽게 데이터를 분석할 수 있게 합니다.
- **Performance Highlights**: Structured-GraphRAG는 기존 RAG 메서드와 비교하여 정밀도와 처리 속도에서 우수한 성능을 보였습니다. Soccernet 데이터셋을 활용한 실험 결과, 구조화된 지식 그래프는 LLM의 환각(Hallucination) 발생을 크게 줄였고, 빠른 데이터 검색과 응답 시간을 가능하게 했습니다. 또한, 그래프 기반 접근법이 데이터 간의 세부적 연결성을 강화하여 보다 정확하고 신뢰할 수 있는 출력을 제공했습니다. 이러한 성능은 디지털 콘텐츠 생성, 뉴스 생성, 챗봇과 같은 도메인에서 큰 이점을 제공합니다.

