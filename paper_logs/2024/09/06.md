## Daily Papers (2024-09-06)

### [Guide-and-Rescale: Self-Guidance Mechanism for Effective Tuning-Free Real Image Editing](https://arxiv.org/abs/2409.01322)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.01322.png)

Vote: 71

Authors: Aibek Alanov, Dmitry Vetrov, Alexandra Ivanova, Vadim Titov, Madina Khalmatova

- **What's New**: 최근 몇 년간, diffusion models(확산 모델)은 높은 생성 품질 덕분에 급속도로 발전하고 있습니다. 이들은 텍스트-이미지 생성 모델(text-to-image generative models)의 기본 모델로 활발히 사용되고 있습니다. 하지만, 이러한 모델을 실제 이미지 편집에 적용하는 것은 여전히 어려운 과제입니다. 본 논문에서는 실제 이미지 편집 문제를 해결하기 위한 가이던스(guidance) 기법을 탐구하고, 새로운 에너지 함수(energy functions)인 가이더스(guiders)를 제안합니다.
- **Technical Details**: 기존의 접근법들은 세 가지 주요 그룹으로 나눌 수 있습니다: 최적화 기반 방법, 확산 모델의 내부 표현을 활용하는 방법, 그리고 인버전(inversion)을 개선하는 방법. 본 논문에서는 인버전 과정에서 저장된 UNet의 내부 표현을 활용하는 기존의 튜닝 없는(tuning-free) 접근법이 실제 특징과 삽입된 특징 간의 불일치 문제를 야기한다는 점에 주목했습니다. 이를 해결하기 위해, 새로운 에너지 함수인 가이더스(guiders)가 제안되었습니다. 이 함수는 원본 이미지의 전체 구조와 편집되지 않은 로컬 영역을 보존하도록 설계되었습니다. 추가적으로, 노이즈 재스케일링(noise rescaling) 자동 메커니즘을 도입하여, 노이즈 트래젝토리와 확산 샘플링 간의 불일치를 방지합니다.
- **Performance Highlights**: 본 논문은 Stable Diffusion 모델에 제안된 방법을 적용하고, 다양한 실험을 통해 다른 방법들과 비교 평가를 진행했습니다. 다양한 편집 유형에 대해 CLIP/LPIPS 점수 측면에서 편집의 품질과 원본 이미지 구조 보존 간의 균형을 잘 맞춘 것으로 나타났습니다. 예를 들어, 일반적인 이미지 변환 문제(예: 개에서 고양이)에서도 제안된 방법이 기존의 기법들보다 더 나은 성능을 보였습니다. 또한, 사용자 연구를 통해 제안된 접근법이 인간 평가에서 가장 선호되는 것으로 나타났습니다.

### [Attention Heads of Large Language Models: A Survey](https://arxiv.org/abs/2409.03752)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.03752.png)

Vote: 55

Authors: Yuxin Huang, Feiyu Xiong, Zhiyu Li, Yezhaohui Wang, Zifan Zheng, Shichao Song, Bo Tang

- **What's New**: 최근 연구는 대형 언어 모델(LLMs) 내부의 주목(head) 메커니즘을 이해하는 데 중점을 두었습니다. 특히 BERT와 GPT 모델의 LLM 추론 단계에서 주목 메커니즘의 역할을 탐구하고 있습니다.
- **Technical Details**: 이 논문은 LLM의 여러 단계에서 주목(head)이 어떻게 작동하는지 분류하고, 각 단계에서 협력하는 방식에 대해 설명합니다. 논문 구조는 다음과 같이 구성됩니다: 문제 배경(Section 2), 인지신경과학 관점에서 인간 사고 과정을 유추한 LLM 추론 프레임워크(Section 3), 주목 메커니즘 실험 방법론(Section 4), 평가 기준 및 벤치마크(Section 5), 피드포워드 네트워크(FFNs)와 기계적 해석 가능성 연구(Section 6), 연구 현황과 향후 연구 방향(Section 7).
- **Performance Highlights**: 이 논문은 주목(head) 메커니즘을 이해하고, 이를 통해 모델 성능을 향상시키는 데 기여할 수 있는 방안을 제시합니다. 기존 연구와 달리 최신 LLM을 중심으로 한 연구로, 인간 사고 단계를 유추한 혁신적인 네 단계 프레임워크를 제시합니다.

### [FuzzCoder: Byte-level Fuzzing Test via Large Language Model](https://arxiv.org/abs/2409.01944)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.01944.png)

Vote: 35

Authors: Yuwei Yin, Ge Zhang, Jian Yang, Guanglin Niu, Linzheng ChaI, Jiaxin Ma, Jiaheng Liu, Liqun Yang, Wanxu Xia, Zhoujun Li, Yunli Wang, Shun Zhang, Hongcheng Guo, Junran Peng, Liang Sun, Chaoren Wei

- **What's New**: 본 연구는 코드 기반 LLM(Code Large Language Models)을 활용하여 소프트웨어 테스트 기법인 퍼징(fuzzing) 테스트 입력 변이 과정을 개선하는 새로운 프레임워크를 제안합니다. 퍼징 테스트를 시퀀스 생성 모델(sequence-to-sequence modeling)로 공식화하고, 코드 LLM을 활용해 입력 바이트 시퀀스를 변이된 바이트 시퀀스로 출력합니다. 이 모델은 새로운 코드 커버리지 또는 충돌(crash)를 유발한 것들을 기록하는 휴리스틱 퍼징 도구로부터 퍼징 인스트럭 데이터셋(Fuzz-Instruct)을 통해 학습됩니다.
- **Technical Details**: 퍼징 테스트는 예상치 못한 입력을 주입하여 소프트웨어 결함을 찾는 강력한 소프트웨어 테스트 기법입니다. 본 연구에서는 퍼징 변이 과정이 시퀀스-투-시퀀스 모델링(sequence-to-sequence modeling) 방식으로 공식화됩니다. 코드 LLM은 바이트 수준 시퀀스를 입력으로 받아 변이된 바이트 시퀀스를 출력합니다. 이를 위해 Fuzz-Instruct라는 데이터셋을 수집하고, 성공적인 변이 히스토리를 바탕으로 모델을 미세 조정(fine-tuning)합니다. 그리고 이 접근법을 AFL(American Fuzzy Lop) 퍼징 프레임워크에 적용하여 랜덤 변이를 통해 새로운 입력 파일을 큐에 추가하는 과정을 최적화했습니다.
- **Performance Highlights**: 제안된 방법론은 벤치마크 Fuzz-Bench에서 평가되었으며, 이 벤치마크는 NM_ELF, READ_ELF, OBJDUMP_ELF, LINT_XML, MP3GAIN_MP3, IMAGEMAGICK_GIF, SPLIT_TIFF, 그리고 TRAN_JPEG 프로그램으로 구성되었습니다. FuzzCoder는 기존 강력한 베이스라인보다 라인 커버리지(line coverage)와 브랜치 커버리지(branch coverage)를 유의미하게 향상시켰으며, 특히 새로운 코드 경로를 더 많이 발견하고 더 자주 코드 블록을 탐지했습니다.

### [CDM: A Reliable Metric for Fair and Accurate Formula Recognition Evaluation](https://arxiv.org/abs/2409.03643)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.03643.png)

Vote: 16

Authors: Bo Zhang, Fan Wu, Linke Ouyang, Rui Zhang, Renqiu Xia, Conghui He, Bin Wang, Zhuangcheng Gu

- **What's New**: 새로운 평가 메트릭인 CDM(Character Detection Matching)이 도입되었습니다. 이 메트릭은 기존의 텍스트 기반 평가 방식인 BLEU와 Edit Distance의 한계를 극복하고, 이미지 기반 평가로 전환하여 수식 인식의 정확성과 공정성을 높입니다.
- **Technical Details**: CDM은 예측된 LaTeX 및 실제 LaTeX 수식을 이미지로 변환한 후 각 문자를 독립적인 객체로 취급하여 시각적으로 일치 여부를 평가합니다. 이는 다양한 수식 표현 방식을 보다 정확하게 처리하고 인간의 주관적인 평가 기준과 더 잘 맞추도록 설계되었습니다.
- **Performance Highlights**: CDM은 기존의 BLEU와 Edit Distance에 비해 수식 인식 성능을 더 잘 평가할 수 있음을 다양한 모델들과 데이터셋을 통해 입증하였습니다. CDM은 특히 도메인 간의 데이터 분포 차이로 인해 발생할 수 있는 평가 편향을 줄이고, 인간의 직관적 인식과 더 잘 맞는 평가 결과를 제공합니다.

### [mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding](https://arxiv.org/abs/2409.03420)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.03420.png)

Vote: 16

Authors: Qin Jin, Liang Zhang, Jingren Zhou, Haiyang Xu, Fei Huang, Jiabo Ye, Anwen Hu, Ji Zhang, Ming Yan

- **What's New**: 이번 연구에서는 고해상도 문서 이미지를 처리할 수 있는 새로운 압축 아키텍처인 High-resolution DocCompressor를 제안합니다. 이 모델은 문서 이미지를 더 적은 시각적 토큰으로 압축하면서 레이아웃 및 텍스트 정보를 유지합니다.
- **Technical Details**: 제안된 아키텍처는 Layout-aware Compressing Architecture로, 전체 레이아웃 정보를 잘 포착할 수 있는 글로벌 저해상도 이미지를 압축 가이드(query)로 사용합니다. 각 쿼리는 원본 이미지의 동일한 상대 위치에 있는 고해상도 기능 그룹을 압축 대상으로 선택합니다. 여기서 주목할 점은 V2T(vision-to-text) 모듈 이후, DocOwl 1.5 아키텍처를 기반으로 한 High-resolution DocCompressor를 배치하여 텍스트 의미를 더 잘 유지할 수 있게 한 것입니다.
- **Performance Highlights**: DocOwl2 모델은 Multi-page Document 이해 벤치마크에서 최초 토큰 지연 시간이 50% 미만으로 매우 뛰어난 성능을 보여줍니다. 또한, 싱글 이미지 문서 벤치마크 10개 중 20% 미만의 시각적 토큰으로 유사 크기의 모델과 비교하여 경쟁력 있는 성능을 나타냅니다.

### [WildVis: Open Source Visualizer for Million-Scale Chat Logs in the Wild](https://arxiv.org/abs/2409.03753)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.03753.png)

Vote: 14

Authors: Yuntian Deng, Claire Cardie, Wenting Zhao, Xiang Ren, Jack Hessel, Yejin Choi

- **What's New**: WildVis는 대규모 대화 로그를 탐색하기 위한 새로운 도구로, 연구자들이 특정 기준에 따라 대화를 찾아내고 주제 분포를 이해하며 유사한 대화를 탐색할 수 있도록 합니다. 이를 통해 대화 데이터 세트의 패턴과 이상 현상을 효율적으로 분석할 수 있습니다.
- **Technical Details**: WildVis는 두 가지 주요 컴포넌트로 구성됩니다: 정확한 필터 기반 검색 시스템과 임베딩(embedding) 기반 시각화 모듈입니다. 필터 기반 검색 시스템은 키워드, 지리적 위치, IP 주소 등의 10가지 사전 정의된 필터를 사용하여 검색을 정제할 수 있게 합니다. 반면, 임베딩 기반 시각화 모듈은 대화를 2D 평면에 점으로 표시하며 유사한 대화는 가까이 위치하게 합니다. 이 컴포넌트들은 수백만 개의 대화를 처리할 수 있도록 설계되었습니다.
- **User Interface**: WildVis는 필터 기반 검색 페이지와 임베딩 시각화 페이지, 그리고 대화 세부 페이지로 구성됩니다. 필터 기반 검색 페이지에서는 사용자가 키워드를 입력하여 관련 대화를 찾고, 10가지 필터 중 하나를 사용해 결과를 좁힐 수 있습니다. 임베딩 시각화 페이지에서는 유사한 대화가 가까이 배치된 2D 평면에서 대화를 탐색할 수 있습니다. 각 대화는 점으로 표시되며, 점 위로 마우스를 올려놓으면 대화 미리보기가 표시되고 클릭 시 대화 세부 페이지로 이동합니다.
- **System Implementation**: WildVis는 대규모 대화 데이터를 효율적으로 처리할 수 있도록 설계되었습니다. Flask와 Elasticsearch를 사용해 백엔드를 구축하였고, Deck.gl을 사용해 대규모의 인터랙티브 임베딩 시각화를 구현했습니다. 적절한 최적화 전략을 통해 사용자들이 데이터를 원활하게 탐색할 수 있도록 지원합니다.

### [From MOOC to MAIC: Reshaping Online Teaching and Learning through LLM-driven Agents](https://arxiv.org/abs/2409.03512)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.03512.png)

Vote: 13

Authors: Chaojun Xiao, Linlu Gong, Jie Cao, Jianxiao Jiang, Haoxuan Li, Yuanchun Wang, Rui Miao Li, Hanming Li, +, Haohua Wang, Nianyi Lin, Yisi Zhan, Xuan Yan, Fei Qin, Daniel Zhang-li, Shangqing Tu, Jinchang Zhou, Zhanxin Hao, Jiayin Lin, Zheyuan Zhang, Xusheng Dai, Lijun Deng, Jifan Yu

- **What's New**: 새로운 시대의 도래와 함께 온라인 교육 패러다임에 혁신을 가져올 MAIC(Massive AI-empowered Course)가 소개되었습니다. MAIC는 대형 언어 모델(Large Language Models, LLMs)과 다중 에이전트 시스템(Multi-Agent Systems)을 활용하여 코스 준비, 교육, 분석 등 다양한 단계에서 온라인 학습의 확장성과 적응성을 조화롭게 통합합니다.
- **Technical Details**: MAIC는 LLM-driven 에이전트 시스템을 통해 교육 자료 준비, 강의 노트 생성, 학습 리소스 최적화 등을 자동화합니다. 학생들의 개별 요구에 맞춘 학습 경로 계획(Learning Path Planning), 코스 추천(Course Recommendation), 지능형 튜터링(Intelligent Tutoring) 등의 AI 기술이 적용되었습니다. GPT-4와 LLaMA 같은 모델들은 지식 구조 추출(Knowledge Structure Extraction)과 다중 모달 이해(Multimodal Understanding)를 포괄하여 효율적인 학습 환경을 제공합니다.
- **Performance Highlights**: MAIC는 학생과 교사에게 직관적이고 사용자 친화적인 솔루션을 제공하며, 과정 분석 및 MAIC 코스 예제 구축을 지원하는 다양한 지능형 에이전트와 툴들을 통합합니다. 또한, 학습 데이터를 신속하게 접근하고, 아카데믹 결과를 예측하며, 인터뷰 및 평가 등의 작업을 자동화하는 학습 분석 툴을 제공합니다. 중국의 최고 대학 중 하나인 칭화대학교(Tsinghua University)에서 500명 이상의 학생 자원봉사자들과 약 3개월 간 두 과정을 통해 새로운 학습 모델을 탐구하였으며, 100,000건 이상의 행동 기록을 수집하였습니다.

### [Geometry Image Diffusion: Fast and Data-Efficient Text-to-3D with Image-Based Surface Representation](https://arxiv.org/abs/2409.03718)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.03718.png)

Vote: 12

Authors: Slava Elizarov, Simon Donné, Ciara Rowles

- **What's New**: 3D 객체 자동 생성은 비디오 게임 제작, 영화, 제조업, 건축 등 다양한 분야에서 큰 이점을 제공합니다. GIMDiffusion은 텍스트 프롬프트에서 3D 객체를 생성하기 위해 Collaborative Control 기법과 3D 표면의 2D 표현인 기하학적 이미지를 사용합니다. 이는 데이터 부담과 비용을 현저히 줄이며 텍스트-이미지 모델을 활용할 수 있게 합니다.
- **Technical Details**: 기하학적 이미지(Geometry images)는 3D 표면을 이미지 형식으로 표현하는 방법으로, 텍스처 및 UV 맵을 생성하는 데 적합합니다. Collaborative Control 기법을 통해 사전 훈련된 텍스트-이미지 모델의 잠재력을 최대한 활용하면서 매우 제한된 3D 학습 데이터에서 우수한 일반화를 달성합니다.
- **Performance Highlights**: GIMDiffusion은 이미지 기반 아키텍처를 활용함으로써 모델 설계와 훈련을 단순화하고, 물리적으로 기반한 렌더링(PBR) 재료를 사용하여 그래픽 파이프라인 내에서 재조명할 수 있는 객체를 생성합니다. 10초 이내에 잘 정의된 3D 메시를 생성할 수 있으며, 생성된 객체를 구체적으로 구분된 부분으로 만들어 쉽게 조작하고 편집할 수 있습니다.

### [FrozenSeg: Harmonizing Frozen Foundation Models for Open-Vocabulary Segmentation](https://arxiv.org/abs/2409.03525)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.03525.png)

Vote: 9

Authors: Hongxun Yao, Haosen Yang, Sheng Jin, Xiatian Zhu, Xi Chen

- **What's New**: 최신 연구인 FrozenSeg는 널리 알려진 Vision Language (ViL) 모델 CLIP와 지역적 특성을 보완하기 위해 SAM 모델을 통합하여 개방형 어휘 분할(open-vocabulary segmentation) 문제를 해결합니다. 이를 통해 기존 모델의 미세 픽셀 수준 정렬 문제를 극복하고, 더욱 일반화된 마스크 예측 성능을 확보합니다.
- **Technical Details**: FrozenSeg는 세 가지 주요 모듈로 구성됩니다. 첫째, Query Injector는 SAM에서 공간적 특성을 받아와 관련 마스크 영역에 학습할 수 있는 질의로 변환합니다. 둘째, Feature Injector는 각 픽셀의 CLIP 특성에 SAM의 전역적 공간 정보를 통합해 강화합니다. 셋째, OpenSeg Ensemble Module은 SAM에서 얻은 제로샷 마스크 제안을 기반으로 마스크 예측 품질을 향상시킵니다.
- **Performance Highlights**: CityScapes 데이터셋에서 FrozenSeg의 재현율(Recall)은 눈에 띄게 향상되었으며, PQ 점수가 44.3에서 45.8로 증가했습니다. 이는 더욱 어려운 PC-459 데이터셋에서도 mIoU가 17.3에서 19.7로 증가한 결과로 확인되었습니다.

### [Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries](https://arxiv.org/abs/2409.00844)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.00844.png)

Vote: 6

Authors: Pashootan Vaezipoor, Keiran Paster, Silviu Pitis, Blair Yang, Fuyang Cui, Michael R. Zhang, Jimmy Ba

- **What's New**: 이 논문에서는 대형 언어 모델(LLMs)의 성능을 보다 포괄적이고 해석 가능한 방식으로 평가하기 위해 Report Cards를 도입합니다. 이는 기존의 정량적 벤치마크가 포착하지 못하는 모델의 전체적인 능력과 한계를 이해하는 데 도움을 줍니다.
- **Technical Details**: LLM 평가 방법은 간결한 검증 집합 정확도 통계에서부터 매우 상세한 모델 출력 분석까지 다양합니다. 기존 방법과 달리, Report Cards는 LLM이 특정 기술이나 주제에 대해 어떻게 행동하는지를 요약합니다. Report Cards는 세 가지 기준으로 평가됩니다: 특이성, 충실성 및 해석 가능성. 여기서는 세 가지 LLM 역할을 사용합니다: 평가 대상 '학생' 모델, Report Cards 초안을 작성하는 평가자, Report Cards 품질을 평가하는 추정자입니다.
- **Performance Highlights**: 이 접근법은 모델 간의 차이를 구별할 수 있는 특이성 기준, 모델 성능을 정확하게 포착하는 충실성 기준, 그리고 인간이 이해하기 쉬운지 여부를 평가하는 해석 가능성 기준을 통해 검증되었습니다. 실험 결과는 다양한 LLM의 성능 평가에 있어 Report Cards의 보완적 가치를 보여줍니다.

### [Building Math Agents with Multi-Turn Iterative Preference Learning](https://arxiv.org/abs/2409.02392)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.02392.png)

Vote: 4

Authors: Bilal Piot, Chengshuai Shi, Wei Xiong, Zhen Qin, Mohammad Saleh, Chi Jin, Misha Khalman, Aviv Rosenberg, Rishabh Joshi, Tong Zhang, Tianqi Liu, Daniele Calandriello, Jiaming Shen

- **What's New**: 이번 연구에서는 기존에 제시된 강화학습(ML)의 인간 피드백 기반 강화 학습(Reinforcement Learning from Human Feedback, RLHF)을 활용해 LLM(대형 언어 모델)의 수학적 문제 해결 능력을 향상시키는 방법을 탐구합니다. 특히, 계산기, Python 라이브러리, 기호 솔버 등의 외부 도구를 통합하여 수학적 문제 해결을 개선합니다.
- **Technical Details**: 본 연구는 LLM 학습 과정을 마르코프 결정 과정(Markov Decision Process, MDP)으로 공식화하고 여러 번의 직접 정렬 알고리즘(M-DPO 및 M-KTO)을 개발했습니다. 이러한 알고리즘에서는 훈련 중 관련 없는 토큰을 마스킹 처리합니다. 또한, MATH와 GSM8K 벤치마크를 사용하여 다양한 기반 모델을 평가했습니다. 이 모델들은 최적화 문제에서 최적성을 도출한 후 반복적으로 훈련되었으며, 최종적으로 모델, 데이터셋 및 코드가 공개됩니다.
- **Performance Highlights**: Gemma-1.1-it-7B 모델의 경우 간단한 지도 학습 모델에서 77.5%에서 83.9%로, MATH 벤치마크에서는 46.1%에서 51.2%로 성능이 증가했습니다. 마찬가지로, Gemma-2-it-9B 모델은 84.1%에서 86.3%로, MATH 벤치마크에서는 51.0%에서 54.5%로 성능이 향상되었습니다. 이러한 실험 결과는 표준 지도 학습 모델에 비해 RLHF가 복잡한 추론 작업에서 성능을 크게 향상시킬 수 있음을 보여줍니다.

### [Statically Contextualizing Large Language Models with Typed Holes](https://arxiv.org/abs/2409.00921)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.00921.png)

Vote: 2

Authors: June Hyung Kim, Xiang Li, Cyrus Omar, Andrew Blinn

- **What's New**: 최근 생성 AI의 발전으로 인해 다양한 AI 코딩 보조 도구들이 등장하고 있습니다. 그 중 가장 유명한 것은 Copilot이며, 이 도구들은 대규모 언어 모델(LLM)을 활용하여 코드 완성을 제공하는데, 이러한 LLM은 다양한 자연 언어 문서와 여러 프로그래밍 언어로 작성된 코드 코퍼스를 기반으로 사전 학습되었습니다.
- **Technical Details**: LLM은 입력 토큰 시퀀스(프롬프트)를 다음 토큰 확률 분포로 변환하여 완료를 샘플링합니다. LLM은 훈련 데이터에서 통계적 규칙성을 학습하는 능력이 있으며, 대형 모델의 경우 제한된 추론 능력도 발전합니다. 그러나 현재 AI 보조 도구들은 커서 창(curosr window) 주변의 프로그램 텍스트를 중심으로 프롬프트를 구성하므로, 중요한 문맥 정보가 훈련 데이터나 커서 창에 존재하지 않으면 성능이 저하됩니다. 이를 해결하기 위해 Retrieval Augmented Generation (RAG) 기법이 사용됩니다. 이 기법은 코드 저장소의 다른 파일이나 외부 라이브러리로부터 추가 코드를 검색하여 프롬프트에 포함시킵니다.
- **Performance Highlights**: 이 논문에서는 언어의 타입과 바인딩 규율을 적극 활용하는 새로운 접근을 제시합니다. 현대 언어 서버를 통해 타입 보고, 타이핑 컨텍스트 검색, 오류 보고 등의 다양한 언어 서비스를 제공하여 코드 완성 성능을 향상시키는 지능형 AI 코딩 보조 도구를 Hazel을 통해 개발하고 평가합니다. Hazel은 완벽한 구문 오류 복구 및 타입 오류 복구 기능을 갖춘 타입된 함수형 프로그래밍 환경입니다.

