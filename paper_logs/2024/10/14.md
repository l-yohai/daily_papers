## Daily Papers (2024-10-14)

### [Baichuan-Omni Technical Report](https://arxiv.org/abs/2410.08565)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.08565.png)

Vote: 59

Authors: Shusen Zhang, Da Pan, Yaqi Zhao, Guosheng Dong, +, Jun Liu, Xin Wu, Fan Yang, Keer Lu, Yadong Li, Xu Li, Yuqi Huo, Tao Zhang, Yanjun Shen, Haoze Sun, Song Chen, Zhenglin Cheng, Mingan Lin, Bowen Ding, Zheng Liang, Tianpeng Li, Wei Song

- **What's New**: 새로운 연구인 Baichuan-Omni가 도입되었습니다. 이는 omni-modal 능력을 가진 대형 언어 모델(LLM)로, 텍스트, 이미지, 비디오, 오디오 입력을 동시에 처리할 수 있으며, 영어와 중국어를 포함한 다국어를 지원합니다. 이 모델은 여러 가지 모달리티 간의 상호작용을 강화하는 새로운 멀티모달(Multimodal) 훈련 방법론을 제안합니다.

### [Meissonic: Revitalizing Masked Generative Transformers for Efficient High-Resolution Text-to-Image Synthesis](https://arxiv.org/abs/2410.08261)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.08261.png)

Vote: 35

Authors: Xiangtai Li, Lei Zhu, Enxin Song, Tian Ye, Jinbin Bai, Shuicheng Yan, Wei Chow, Zhen Dong, Qing-Guo Chen

- **What's New**: 이 논문에서는 최신 인공지능 언어 모델(Large Language Models, LLM)을 활용한 새로운 텍스트 생성 기술을 소개합니다. 특히, GPT 계열의 모델을 기반으로 하는 수정된 아키텍처를 통해 생성된 텍스트의 품질을 크게 향상시켰습니다.
- **Technical Details**: 주요 기술적 요소로는 Transformer 기반의 아키텍처를 사용하여 대규모 데이터셋을 학습시켰으며, fine-tuning을 통해 특정 분야에 최적화된 언어 모델을 개발하였습니다. 또한, 새로운 attention mechanism을 도입하여 학습 효율성을 높였습니다.
- **Performance Highlights**: 실험 결과, 제안된 모델은 기존 모델 대비 텍스트 생성의 일관성과 다채로움에 있어 크게 향상된 성능을 보였습니다. 특히, BLEU와 ROUGE와 같은 평가 척도에서 5-10% 이상의 개선을 달성했습니다.

### [From Generalist to Specialist: Adapting Vision Language Models via Task-Specific Visual Instruction Tuning](https://arxiv.org/abs/2410.06456)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.06456.png)

Vote: 25

Authors: Yang Bai, Yong Liu, Yang Zhou, Daniel Shu Wei Ting, Rick Siow Mong Goh, Jun Zhou

- **What's New**: 이 연구에서는 대규모 비전 언어 모델(VLM)이 특정 작업에서 성능이 떨어지는 이유를 분석하고, 이를 개선할 새로운 프레임워크인 VITask를 제안합니다. VITask는 작업-특정 모델(TSM)과 VLM의 강점을 결합하여, VLM의 범용성과 지시-수행 능력을 유지하면서 작업-특정 성능을 향상시키는 것을 목표로 합니다.
- **Technical Details**: 이미지 분류를 사례 연구로 사용하여 VLM이 TSM보다 성능이 낮은 이유를 두 가지로 나눕니다: 1) 전처리에서 학습되는 이미지 표현이 작업-특정 분류에 효과적이지 않음. 2) 간접적인 조정 목표는 텍스트 생성 향상에 중점을 두며, 이미지 분류에 필요한 기능 학습을 방해할 수 있습니다. 이를 해결하기 위해 VITask는 소형 TSM과 작업-특정 조정 목표를 결합하고, 예시 프롬프트 및 응답 분포 정렬을 통한 비전-언어 정렬을 유지합니다.
- **Performance Highlights**: VITask는 12개의 의료 이미지 진단 데이터셋에서 TSM과 일반 지시-조정 VLM보다 일관되게 성능이 뛰어남을 보였습니다. 또한, 불완전한 지시에 대한 견고성을 보여, 실세계 응용 가능성을 높였습니다. 이러한 결과는 VITask가 의료 작업을 넘어 일반화할 수 있는 잠재력을 강조하며, 작업-특정 VLM 튜닝에 대한 다재다능한 프레임워크가 될 수 있음을 시사합니다.

### [EvolveDirector: Approaching Advanced Text-to-Image Generation with Large Vision-Language Models](https://arxiv.org/abs/2410.07133)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.07133.png)

Vote: 15

Authors: Junhao Zhang, Hangjie Yuan, Xiang Wang, Mike Zheng Shou, Yujie Wei, Lingmin Ran, Zhangjie Wu, Shiwei Zhang, Rui Zhao, Yingya Zhang, Yuchao Gu

- **What's New**: 이번 논문에서는 공개된 자원으로 고급 모델과 비슷한 성능을 구현할 수 있는 오픈소스 텍스트-이미지 모델 학습을 탐구합니다. 기존의 고급 모델들은 폐쇄된 파라미터와 내부 데이터로 인해 재현성과 민주화가 어려웠는데, EvolveDirector라는 새로운 프레임워크를 제안하여 이러한 과제를 해결하고자 합니다.
- **Technical Details**: EvolveDirector는 VLM(대형 비전-언어 모델)을 이용하여 학습 데이터를 지속적으로 평가하고 분류, 확장, 삭제 및 변형 과정을 통해 데이터를 동적으로 큐레이션함으로써 더 효율적인 학습을 가능하게 합니다. 이렇게 함으로써 원래 1,100만 샘플이 필요했던 학습을 10만 샘플로 줄여, 더 적은 데이터 양으로도 고급 모델의 성능을 모방할 수 있습니다.
- **Performance Highlights**: 제안된 프레임워크로 학습된 최종 모델, Edgen은 앞선 고급 모델들인 DeepFloyd IF, Playground 2.5, Stable Diffusion 3, Ideogram 등을 능가하는 성능을 보여줍니다. Edgen은 여러 고급 모델의 기능을 단일 프레임워크로 통합하여 접근하면서도 그들의 개별 성능을 초과하는 결과를 보여줍니다. 코드는 공개되어 후속 연구 및 개발에 기여할 것입니다.

### [StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization](https://arxiv.org/abs/2410.08815)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.08815.png)

Vote: 12

Authors: Haiyang Yu, Yaojie Lu, Qiaoyu Tang, Fei Huang, Hongyu Lin, Xianpei Han, Yongbin Li, Zhuoqun Li, Le Sun, Xuanang Chen

- **What's New**: StructRAG라는 새로운 프레임워크가 제안되었습니다. 이 프레임워크는 task 요구 사항에 따라 정보를 최적의 구조 형식으로 변환하고 활용하는 하이브리드 정보 구조화 메커니즘을 활용합니다. 이는 기존의 RAG(Retrieval-Augmented Generation) 방법이 지식 집약적 추론 작업에서 직면하는 한계를 극복하고자 합니다.
- **Technical Details**: StructRAG는 세 개의 모듈로 이루어져 있으며, 각각의 모듈은 연속적으로 적절한 구조 유형을 식별하고, 그 형식으로 구조화된 지식을 구축하며, 그 지식을 활용하여 최종 답변을 추론합니다. 특히 하이브리드 구조 라우터(hybrid structure router)를 사용하여 질문과 문서 정보를 기반으로 가장 적절한 구조 유형을 결정하며, 분산된 지식을 변환하는 LLM 기반 구조화 모듈과 질문 분해 및 정확한 지식 추출을 위한 구조적 지식 활용기를 사용합니다.
- **Performance Highlights**: 여러 지식 집약적 추론 작업에 대해 StructRAG가 평가되었으며, 여러 강력한 RAG 기반 라인과 비교하여 최첨단 성능을 달성하는 것으로 나타났습니다. 작업의 복잡성이 증가함에 따라 성능 향상이 더욱 뚜렷해졌습니다. 이는 StructRAG가 복합 지식 문제를 해결하는 데 있어 강력한 솔루션임을 확인시킵니다. 또한, 최근의 Graph RAG 방법과 비교했을 때 StructRAG는 광범위한 작업에서 우수한 성능을 나타내며, 평균적으로 더 빠르게 동작합니다.

### [PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness](https://arxiv.org/abs/2410.07035)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.07035.png)

Vote: 11

Authors: Zekun Wang, Wenhao Huang, Yibo Zhang, Feiyu Duan, Ke Xu, Wangchunshu Zhou, Jie Fu

- **What's New**: 이 연구에서는 모델의 위치 인식 능력을 향상시키기 위한 PositionID Prompting 및 PositionID Fine-Tuning을 제안합니다. 이를 통해 길이 제어 및 복사-붙여넣기 능력을 개선하고자 합니다.
- **Technical Details**: PositionID Prompting은 특별한 튜닝 없이도 LLM이 텍스트 생성 중에 단위 수를 지속적으로 세어볼 수 있도록 하는 기술입니다. 반면, PositionID Fine-Tuning은 모델을 PositionID Prompting 포맷의 데이터로 학습시켜 위치 인식을 강화합니다. 또한 위치 인식 능력을 활용한 복사 및 붙여넣기(CP) 기능을 검증하였습니다.
- **Performance Highlights**: LenCtrl-Bench와 CP-Bench 데이터셋에서 실험한 결과, PositionID Prompting과 PositionID Fine-Tuning을 통해 모델이 길이 제어된 텍스트 생성 지시사항을 더 정확하게 따를 수 있게 되었으며, 복사 및 붙여넣기 능력 역시 향상되었습니다.

### [SuperCorrect: Supervising and Correcting Language Models with Error-Driven Insights](https://arxiv.org/abs/2410.09008)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.09008.png)

Vote: 11

Authors: Zhaochen Yu, Tianjun Zhang, Ling Yang, Bin Cui, Shuicheng Yan, Joseph E. Gonzalez, Minkai Xu

- **What's New**: 이번 연구에서는 두 단계의 새로운 프레임워크인 SuperCorrect를 제안하여 대형 LLM(large language model)의 생각을 이용하여 작은 모델의 추론 및 반성 과정을 지도하고 수정합니다. 이 접근법은 두 단계로 구성되며, 첫 번째 단계에서는 교사 모델의 위계적 사고 템플릿을 추출하여 학생 모델이 더 미세한 추론을 생성하도록 안내합니다. 두 번째 단계에서는 Cross-Model Collaborative DPO를 통해 학생 모델의 자기 교정 능력을 향상시킵니다.
- **Technical Details**: SuperCorrect는 위계적 사고 템플릿을 사용하여 유사 문제에 대한 고수준 해결책과 비판적 추론 단계를 설명하는 자세한 솔루션을 제공합니다. 또한, 크로스 모델(DPO) 협력 방식을 통해 학생 모델의 오류 부분을 식별하고 수정하여 개선합니다. 이 접근법은 교사 모델이 오류 추적을 제공하여 학생 모델이 더 나은 자기 교정을 수행하도록 지도합니다. 고품질의 파인 튜닝 데이터셋과 사고 수준 교정 최적화를 위한 데이터셋도 구축되었습니다.
- **Performance Highlights**: 구축된 데이터셋과 SuperCorrect-Qwen, DeepSeek, Llama-7B의 세 가지 강력한 추론 LLM은 MATH 데이터셋에서 70.2% 정확도와 GSM8K 데이터셋에서 89.5% 정확도를 달성하여 모든 7B 모델 중 새로운 SOTA 성능을 설정했습니다.

### [Semantic Score Distillation Sampling for Compositional Text-to-3D Generation](https://arxiv.org/abs/2410.09009)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.09009.png)

Vote: 10

Authors: Ling Yang, Zixiang Zhang, Bohan Zeng, Runjia Li, Philip Torr, Wentao Zhang, Junlin Han

- **What's New**: Semantic Score Distillation Sampling (SemanticSDS)을 제안하여 기존의 텍스트 기반 3D 생성 과정에서의 비효율성을 극복하고자 합니다. 이는 더 정밀하고 표현력 있는 3D 생성에 초점을 맞추고 있으며, 3D Gaussian Splatting (3DGS)을 활용하여 명시적인 3D 표현을 강화합니다.
- **Technical Details**: 제안된 방법은 (1) 텍스트 지시문을 기반으로 LLM 기반 레이아웃 계획을 개선하는 프로그램 지원 접근법을 사용하고, (2) 다양한 렌더링 보기에서 일관성을 유지하고 객체 별로 명확하게 구분되는 새로운 시맨틱 임베딩을 도입하며, (3) 이러한 시맨틱 임베딩을 시맨틱 맵으로 렌더링하여 부분 단위 SDS 프로세스를 안내함으로써 세밀한 최적화와 조합적 생성을 촉진합니다.
- **Performance Highlights**: SemanticSDS는 기존의 레이아웃 안내 조합 방법들이 지닌 한계를 극복하고, SDS 과정에서 명시적 시맨틱 맵 지도를 활용하여 고품질의 3D 콘텐츠 생성에 성공적입니다. 이 방법은 다양한 객체와 특성을 가진 복잡한 3D 장면 생성에서 뛰어난 제어력을 제공합니다.

### [Mechanistic Permutability: Match Features Across Layers](https://arxiv.org/abs/2410.07656)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.07656.png)

Vote: 8

Authors: Ian Maksimov, Daniil Gavrilov, Nikita Balagansky

- **What's New**: 최근 자연어 처리 연구에서 기본 모델이 중요한 역할을 하고 있습니다. 이러한 모델의 예측을 인간이 이해 가능한 방식으로 해석하는 필요성이 증가하고 있으며, 이를 해결하기 위해 새롭게 제안된 방법이 SAE Match입니다. SAE Match는 신경망의 여러 레이어(layer)에서 Sparse Autoencoder (SAE) 특성을 정렬하여 모델의 깊이를 통해 특성의 진화를 분석하는 데이터 없이도 적용 가능한 방법입니다.
- **Technical Details**: SAE Match는 다층 신경망의 여러 레이어에 걸쳐 퍼뮤테이션(permutation) 없이 Sparse Autoencoder의 특성을 정렬하는 방법입니다. SAE Match는 활성화 임계값을 인코더 및 디코더 가중치에 통합하는 'parameter folding' 기술을 도입해 실질적인 특성 차이를 고려합니다. 이 기법을 활용하여 두 레이어 간의 MSE(Mean Squared Error)를 최소화하여 유사한 특성을 해석합니다.
- **Performance Highlights**: 제안된 SAE Match 방법은 Gemma 2 언어 모델에 대한 광범위한 실험을 통해 검증되었습니다. 실험 결과는 특성 매칭의 품질을 개선하고 레이어 간 특성의 지속성과 변환에 대한 통찰력을 제공하였습니다. 이를 통해, SAE Match는 신경망의 동작을 이해하고 더욱 투명하고 이해 가능한 모델 해석을 제공하는 데 기여합니다.

### [Multi-Agent Collaborative Data Selection for Efficient LLM Pretraining](https://arxiv.org/abs/2410.08102)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.08102.png)

Vote: 8

Authors: Jiahui Peng, Zhen Hao Wong, Xinlin Zhuang, Ling Yang, Qiu Jiantao, Lijun Wu, Chi Zhang, Binhang Yuan, Conghui He, Wentao Zhang, Tianyi Bai

- **What's New**: 이번 연구는 대규모 언어모델(LLM)의 사전 훈련을 위한 데이터 선택 기법을 개선하고자 합니다. 기존 데이터 선택 방법들은 독립적으로 작동하거나 통합에 도전 과제를 내포하고 있으며, 이 연구에서는 이러한 고급 데이터 선택 기법을 동적 사전 훈련 과정에서 효과적으로 통합할 수 있는 방법을 탐구합니다.
- **Technical Details**: 연구는 멀티 에이전트 협력 데이터 선택 프레임워크를 제안합니다. 이 프레임워크는 각 데이터 선택 방법이 에이전트로서 작동하며, 모든 에이전트의 점수를 통합하는 '에이전트 콘솔'을 설계하여 최적의 데이터 선택 결과를 산출합니다. 이와 함께 각 에이전트의 기여도를 동적으로 조정 가능한 메커니즘을 구현하여, LLM 훈련 과정에서 보다 유연하고 적응적인 데이터 선택을 가능케 합니다.
- **Performance Highlights**: 광범위한 실험을 통해 멀티 에이전트 협력 데이터 선택 방법이 데이터 효율성을 상당히 향상시키고, LLM 훈련의 수렴 속도를 가속화하며, 다양한 언어모델 벤치마크에서 기존 방법 대비 평균적으로 최대 10.5%의 개선을 이끌어냈습니다.

### [KV Prediction for Improved Time to First Token](https://arxiv.org/abs/2410.08391)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.08391.png)

Vote: 7

Authors: Chenfan Sun, Maxwell Horton, Sachin Mehta, Yanzi Jin, Qingqing Cao, Moin Nabi, Mohammad Rastegari

- **What's New**: 이 연구에서는 대형 언어 모델(LLM)의 Time to First Token(TTFT)을 개선하기 위한 새로운 방법을 제안합니다. 연구자들은 작은 보조(transformer) 모델을 사용하여 더 큰 모델의 키-값(KV) 캐시를 예측하고, 이를 통해 TTFT를 최적화하며 사용자 경험을 향상시킵니다.
- **Technical Details**: 제안된 방법은 보조 모델의 KV 캐시를 사용하여 기본 모델의 KV 캐시를 예측하는 선형 투영(learned linear projection)을 활용합니다. 이렇게 함으로써 생성 단계에서는 기본 모델로만 작동하여 실행 오버헤드를 제거합니다. 또한, 이 기술은 특정 효율성과 정확성의 trade-off를 비교하여 기존 방법보다 우수함을 입증합니다.
- **Performance Highlights**: 실험 결과에 따르면, TriviaQA 및 HumanEval 등의 데이터셋에서 이 방법은 기존 방법에 비해 최대 50%까지 정확성을 개선할 수 있었습니다. 또한, FLOP 수가 동일할 때, 더 나은 on-device 런타임 개선을 보여주었습니다.

### [ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion](https://arxiv.org/abs/2410.08168)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.08168.png)

Vote: 4

Authors: Anand Bhattad, Mathieu Garon, Zitian Zhang, Jean-François Lalonde, Frédéric Fortier-Chouinard

- **What's New**: ZeroComp은 사전 훈련된 Stable Diffusion (SD) 모델과 ControlNet을 결합한 새로운 접근법으로, 3D 객체를 사진에 자연스럽게 합성하는 원-프레임워크 솔루션을 제안합니다. 이 기법은 조명 추정이나 매칭 데이터셋 없이도 경쟁력 있는 결과를 제공합니다. Importantly, ZeroComp는 'Zero-shot compositing' 기능을 통해 사전 훈련 없이 다양한 장면에 객체 삽입을 가능하게 합니다.
- **Technical Details**: ZeroComp 모델은 심도, 표면 법선(normals), 반사율(albedo) 및 음영(shading)의 본질적인 지도(intrinsic maps)로부터 이미지를 렌더링하도록 학습되었습니다. 이 과정에서 주요한 요소는 자체 조명과 지오메트리 이해를 바탕으로 적절한 그림자와 음영 효과를 생성하는 것입니다. 학습은 OpenRooms와 InteriorVerse와 같은 합성 데이터셋을 기반으로 이루어지며, 평가에는 Amazon Berkeley Object 및 Laval HDR Indoor 데이터셋이 사용됩니다.
- **Performance Highlights**: 이 방법은 전통적인 라이팅 추정에 의존하는 기법들을 능가하며, 사용자 연구를 통해 다른 최첨단 방법들보다 더 매력적으로 보이는 결과를 생성하는 것으로 나타났습니다. ZeroComp은 본질적 지도를 활용하여, 초점이 된 객체와 배경 장면을 개별적으로 음영 조절하여 조화로운 합성을 가능하게 합니다.

### [DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models](https://arxiv.org/abs/2410.07331)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.07331.png)

Vote: 3

Authors: Shizhu He, Xiao Liu, Fangyu Lei, Yitong Zhang, Yiming Huang, Yifan Wei, Lifu Huang, Kang Liu, Jun Zhao, Jianwen Luo, Yan Yu

- **What's New**: 이 연구에서는 대형 언어 모델(Large Language Models, LLMs)이 자율 데이터 과학자가 될 수 있는 가능성을 탐구하고, 이를 평가하기 위한 새로운 벤치마크인 DA-Code를 소개합니다. DA-Code는 실제 데이터 분석 과제에서 추출한 500개의 복잡한 과제 예제를 포함하고 있으며, 데이터 웽글링, 머신러닝, 탐색적 데이터 분석(Exploratory Data Analysis, EDA)의 세 가지 주요 카테고리를 다룹니다.
- **Technical Details**: DA-Code는 다양한 환경과의 상호작용을 통해 코드를 생성하도록 하는 에이전트 데이터 과학 과제를 정의합니다. 이 과정은 상태 공간, 행동 공간, 관찰 공간, 코드 공간, 기록 공간으로 구성되며, 각 요소간의 상호작용을 통해 진행됩니다. 코드 에이전트는 Python, SQL, Bash와 같은 언어를 사용하여 데이터 분석 작업을 수행하며, 실험 환경에서 자율적 사고와 코드 완성을 가능하게 하는 상호작용형 샌드박스 환경이 마련되어 있습니다.
- **Performance Highlights**: 여러 최첨단 언어 모델들이 DA-Code에서 평가되었으며, 실험 결과는 이러한 과제를 자율적으로 완수하는 것이 여전히 도전 과제임을 나타냅니다. DA-Code는 현재의 LLM-에이전트들이 데이터 과학자로 성장하기 위한 유용한 데이터 자원을 제공하며, 실세계의 복잡한 설정에서 에이전트가 자율적으로 작업을 완료하도록 유도합니다.

### [Think While You Generate: Discrete Diffusion with Planned Denoising](https://arxiv.org/abs/2410.06264)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.06264.png)

Vote: 2

Authors: Sulin Liu, Tommi Jaakkola, Yilun Xu, Juno Nam, Andrew Campbell, Rafael Gómez-Bombarelli, Hannes Stärk

- **What's New**: 새로운 연구는 대규모 언어 모델(large language models)을 활용한 머신러닝 시스템의 성능 향상을 제안합니다. 이 연구는 더욱 효율적인 학습 기법과 모델 아키텍처를 통해 기존의 문제점들을 개선하고자 합니다.
- **Technical Details**: 이 연구에서는 Transformer 기반의 모델 아키텍처를 사용하며, 특히 attention 메커니즘(attention mechanism)의 효율성을 높이기 위해 여러 가지 최적화 기술을 도입하였습니다. 추가적으로, 모델의 학습을 가속화하기 위해 새로운 데이터 병렬화 기법을 도입하여 대량의 데이터를 보다 빠르게 처리할 수 있도록 하였습니다.
- **Performance Highlights**: 개발된 모델은 다양한 벤치마크 데이터셋에서 기존 최첨단 모델 대비 우수한 성능을 보여줍니다. 특히, 자연어 처리(natural language processing) 및 컴퓨터 비전(computer vision) 태스크에서 일관된 성능 향상을 기록하였습니다. 실험 결과, 모델의 정확도와 처리 속도가 모두 크게 향상되었음을 확인하였습니다.

### [MiRAGeNews: Multimodal Realistic AI-Generated News Detection](https://arxiv.org/abs/2410.09045)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.09045.png)

Vote: 2

Authors: Runsheng Huang, Liam Dugan, Chris Callison-Burch, Yue Yang

- **What's New**: 이 논문에서는 MiRAGeNews Dataset 및 MiRAGe 멀티모달 탐지기(Multimodal detector)라는 새로운 시스템을 소개합니다. 이 데이터셋과 탐지기는 최신 AI 생성 이미지와 캡션을 감지하기 위한 도구를 개발하고 테스트하는 데 필요한 기반을 제공합니다. 특히, 최신 (State-of-the-art) 확산 모델(SOTA diffusion-based models)이 생성한 현실적인 뉴스 이미지 및 캡션 쌍을 실험 데이터셋으로 활용하여 좀 더 효과적인 탐지 방법을 개발할 수 있도록 합니다.
- **Technical Details**: MiRAGeNews Dataset은 총 12,500개의 AI 생성 이미지와 캡션 쌍을 포함하고 있으며, 이는 훈련 및 검증 세트로 사용됩니다. 이 데이터셋은 다양한 미지의 이미지 생성기 및 뉴스 퍼블리셔로부터 수집한 2,500개의 이미지-캡션 쌍을 포함하여, 탐지기의 도메인 간 강건성(out-of-domain robustness)을 평가합니다. MiRAGe 탐지기는 두 가지 모델을 융합하여 이미지와 텍스트 모두를 감지하는 멀티모달 탐지기입니다. 이 모델은 블랙박스 리니어 모델과 해석 가능한 개념 병목 모델을 결합하여 생성된 뉴스 이미지를 탐지합니다.
- **Performance Highlights**: MiRAGe-Img는 이전의 최첨단 탐지기보다 더 우수한 도메인 내 (In-Domain) 및 도메인 간 (Out-of-Domain) 성능을 보여주었습니다. MiRAGe-Txt은 뉴욕 타임즈(New York Times) 뉴스에서 새롭게 작성된 캡션과 BBC 및 CNN의 미지의 뉴스 퍼블리셔로부터 나온 캡션 모두에서 우수한 성능을 기록했습니다. 멀티모달 설정에서는 MiRAGe 탐지기가 경쟁 벤치마킷보다 전반적인 OOD 강건성(out-of-domain robustness)에서 우수한 성능을 보여주었습니다.

### [Synth-SONAR: Sonar Image Synthesis with Enhanced Diversity and Realism via Dual Diffusion Models and GPT Prompting](https://arxiv.org/abs/2410.08612)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.08612.png)

Vote: 1

Authors: Purushothaman Natarajan, Kamal Basha, Athira Nambiar

- **What's New**: 이 논문에서는 새로운 소나 이미지 합성 프레임워크인 'Synth-SONAR'를 제안했습니다. 이 프레임워크는 텍스트 기반의 디퓨전 모델과 GPT 프롬팅을 통해 고품질의 현실적인 소나 이미지를 생성합니다. 이 방법은 기존의 제너레이티브 AI(GenAI) 기술을 활용하여 소나 데이터의 희소성과 정확성 문제를 해결하고자 합니다.
- **Technical Details**: Synth-SONAR는 3단계의 워크플로우를 가지며, 첫 번째 단계는 '데이터 수집 단계'입니다. 이 단계에서는 실제 이미지, CAD 시뮬레이션 이미지, GenAI 생성 이미지를 통합하여 대규모의 다양한 소나 데이터 코퍼스를 구성합니다. 두 번째 단계에서는 소나 이미지를 생성하기 위해 Denoising Diffusion Probabilistic Model(DDPM)을 GPT 기반의 프롬트와 통합해 '거친(coarse) 수준'의 이미지를 생성합니다. 마지막 단계에서는 생성된 거친 이미지를 Vision-Language Model(VLM)과 LoRA fine-tuning을 통해 '정교한(fine-grained)' 결과물로 정제합니다.
- **Performance Highlights**: Synth-SONAR는 다방면에서 높은 다각성과 사실성을 이루었으며, 프레셰 인셉션 거리(FID), 피크 신호 대 잡음비(PSNR), 구조적 유사성 지수(SSIM), 인셉션 점수(IS)와 같은 여러 메트릭에서 이를 입증했습니다. 논문의 주요 기여는 멀티 해상도 이미지 생성을 위한 이중 단계 텍스트 조건부 디퓨전 모델을 통합한 새로운 GenAI 프레임워크로, 고품질의 소나 이미지를 효과적으로 합성하는 데 있습니다.

### [SimpleStrat: Diversifying Language Model Generation with Stratification](https://arxiv.org/abs/2410.09038)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.09038.png)

Vote: 1

Authors: Sanjit A. Seshia, Michael Luo, Justin Wong, Joseph E. Gonzalez, Yury Orlovskiy

- **What's New**: 이번 연구는 Large Language Models(LLMs)의 리샘플링(resampling)을 개선하기 위한 새롭고 간편한 방법인 SimpleStrat를 제안합니다. SimpleStrat는 추가적인 학습 없이도 다양성을 높이며, LLM의 출력이 실제 정답 분포와 일치하도록 합니다. 이는 mode collapse 문제와 같은 심각한 상황에서도 수작업 개입 없이 가능하게 합니다.
- **Technical Details**: SimpleStrat는 세 단계로 구성된 방법으로, 1) 자동 계층화(auto-stratification), 2) 휴리스틱 추정(heuristic estimation), 3) 확률적 프롬프트(probalistic prompting)를 활용합니다. 자동 계층화 단계에서는 사용자 요청에 기반하여 솔루션 공간을 유용한 파티션으로 나눕니다. 그 다음 단계에서는 각 계층별로 결합 확률을 추정한 후, 최종적으로 선택된 계층을 사용하여 원래의 사용자 프롬프트를 보강합니다.
- **Performance Highlights**: CoverageQA 벤치마크를 사용한 평가에서 SimpleStrat는 Llama 3 모델에서 평균 0.36의 Kullback-Leibler (KL) Divergence 감소를 보였으며, GPT-4o를 포함한 모든 온도에서 일관된 0.05 회상의 증가를 달성했습니다. 이는 온도 증가와는 독립적으로 개선된 다양성을 보여줍니다.

### [I-Max: Maximize the Resolution Potential of Pre-trained Rectified Flow Transformers with Projected Flow](https://arxiv.org/abs/2410.07536)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.07536.png)

Vote: 1

Authors: Dongyang Liu, Ruoyi Du, Peng Gao, Le Zhuo, Qin Qi, Hongsheng Li, Zhanyu Ma

- **What's New**: 최근 몇 년간, 확산 모델(diffusion model)은 다양한 측면에서 혁신을 이루어왔으며, 이러한 경험을 바탕으로 정류 흐름 변환기(RFTs, Rectified Flow Transformers)가 미래의 확산 모델 확장이라는 잠재적 방향으로 주목받고 있습니다. 본 논문에서는 예측되지 않은 해상도로 생성할 수 있는 I-Max 프레임워크를 제안하였으며, 이는 튜닝이 필요 없는 해상도 추론의 실용적 가치를 높입니다.

### [Mentor-KD: Making Small Language Models Better Multi-step Reasoners](https://arxiv.org/abs/2410.09037)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.09037.png)

Vote: 1

Authors: Junho Kim, SangKeun Lee, Hojae Lee

- **What's New**: 이 논문에서는 대형 언어 모델(LLM)의 다중 단계 추론 능력을 LLM보다 작은 언어 모델(LM)로 전달하기 위한 멘토-지식 증류(Mentor-KD)라는 새로운 프레임워크를 제안합니다. 멘토라는 중간 크기의 작업 특화 모델을 도입하여, distillation set의 제한을 극복하고 보다 효과적으로 논리를 추출할 수 있도록 합니다.
- **Technical Details**: Mentor-KD의 핵심 아이디어는 특정 작업에 맞춘 중간 크기의 멘토 모델을 활용하여 증류 훈련 세트를 확대하는 것입니다. 먼저 LLM 교사 모델로부터 체인 오브 사고(CoT) 주석을 생성하고, 이를 바탕으로 멘토 모델을 미세 조정하여 추가적인 훈련 세트를 생성합니다. 최종적으로, 학생 모델은 멘토로부터 증류된 논리와 소프트 레이블링을 학습합니다.
- **Performance Highlights**: Mentor-KD는 다양한 추론 작업에서 고성능을 보였으며, 멘토 모델이 더 많은 올바른 논리 샘플을 생성할 수 있음을 실험으로 확인했습니다. 또한 Mentor-KD는 저자원이 시나리오에서도 데이터 증강 수단으로 효과적임을 보여주며, 비용 효율적입니다.

### [GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment](https://arxiv.org/abs/2410.08193)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.08193.png)

Vote: -

Authors: Yuancheng Xu, Sumitra Ganesh, Furong Huang, Udari Madhushani Sehwag, Alec Koppel, Sicheng Zhu, Bang An

- **What's New**: 이 연구에서는 N-D 차원의 공간에서의 다양한 샘플링 방법(sampling method)을 조사하고, 기존의 방법들에 비해 더욱 효율적인 것으로 제안된 메타-샘플링(meta-sampling) 기법을 소개합니다. 이 기법은 복잡한 함수들이 있는 고차원 공간에서의 샘플링을 최적화합니다.
- **Technical Details**: 제안된 메타-샘플링(meta-sampling)은 여러 기존 샘플링 기법들을 메타-학습(meta-learning) 관점으로 통합하여 각 샘플링 방법의 장점을 극대화하고자 합니다. 이를 위해 Monte Carlo 다차원적 접근법을 포함한 다양한 방법론들이 포함됩니다.
- **Performance Highlights**: 실험 결과, 메타-샘플링(meta-sampling) 기법은 기존의 단일 샘플링 방법과 비교했을 때 샘플링 효율성과 정확도가 크게 향상된 것으로 나타났습니다. 특히, 복잡한 다차원 문제들에서 그 성능 차이가 두드러졌습니다.

