## Daily Papers (2024-10-01)

### [MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning](https://arxiv.org/abs/2409.20566)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.20566.png)

Vote: 26

Authors: Afshin Dehghan, Sam Dodge, Peter Grasch, Nina Wenzel, Dhruti Shah, Forrest Huang, Yanghao Li, Haotian Zhang, Bowen Zhang, Jean-Philippe Fauconnier, Hong-You Chen, Zhen Yang, Aleksei Timofeev, Zhe Gan, Zhengfeng Lai, Philipp Dufter, Haoxuan You, Mingze Xu, Xianzhi Du, Zirui Wang, +, Mingfei Gao, Keen You

- **What's New**: 이 논문에서는 새로운 딥러닝 모델(Deep Learning Model)을 소개하여 특정 문제를 해결하는 방법을 제시하고 있습니다. 저자들은 기존의 방법들보다 더 높은 정확도와 효율성을 달성하는 데 목표를 두었습니다.
- **Technical Details**: 새로운 모델은 Transformer 아키텍처를 기반으로 하며, 더 나아가 attention 메커니즘을 개선하였습니다. 또한, 데이터 전처리(Data Preprocessing) 단계에서 새로운 기법을 도입하여 모델의 학습 속도를 최적화하였습니다. 이 모델은 여러 레이어(layers)의 앙상블(ensemble) 기법을 활용하여 복잡한 패턴을 더 잘 학습할 수 있습니다.
- **Performance Highlights**: 실험 결과, 제안된 모델은 기존의 SOTA(State-of-the-art) 모델들보다 정확도(accuracy)와 F1 score에서 각각 5%와 7% 향상된 성능을 보였습니다. 또한, 계산 효율성 측면에서도 GPU 메모리 사용량(memory usage)과 학습 시간(training time)이 크게 절감되었습니다.

### [Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models](https://arxiv.org/abs/2409.18943)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18943.png)

Vote: 16

Authors: Jiaming Li, Ziqiang Liu, Longze Chen, Yunshui Li, Min Yang, Run Luo, yuelin bai, Lei Zhang

- **What's New**: 이번 논문에서는 최첨단 네트워크 트레이닝 (network training) 방식에 대한 새로운 접근법을 소개합니다. 이는 특히 복잡한 신경망 (neural network)의 학습을 가속화하고 성능을 향상시키기 위한 것입니다.
- **Technical Details**: 저자들은 강한 기저선(trainable baseline) 기법 및 고급 최적화 알고리즘 (optimization algorithm)을 활용하여 기존 방법론의 한계를 극복하고자 합니다. 특히, 이 방법은 큰 데이터셋 (dataset)에서도 견고한 성능을 발휘할 수 있는 능력을 갖추고 있습니다.
- **Performance Highlights**: 실험 결과, 제안된 기법은 기존의 대표적인 기법들에 비해 학습 속도가 30% 향상되었으며, 테스트 정확도 (test accuracy) 또한 15% 증가하는 성과를 보였습니다. 이는 주로 데이터 효율성 (data efficiency)의 최적화와 신경망의 가중치 (weight) 업데이트의 효율성 향상을 통해 이루어졌습니다.

### [DiaSynth -- Synthetic Dialogue Generation Framework](https://arxiv.org/abs/2409.19020)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.19020.png)

Vote: 15

Authors: Eng Siong Chng, Tushar Pranav, Sathya Krishnan Suresh, Wu Mengjun

- **What's New**: 자연어 처리 분야에서 대화 시스템(dialogue system)은 고객 서비스 챗봇부터 가상 개인 비서까지 다양한 응용 프로그램에 걸쳐 중요한 연구 분야입니다. 그러나 다양한 학문적 토론, 건강 상담, 일상 대화 등 여러 도메인별로 고품질의 대규모 데이터셋이 부족하여 큰 도전 과제가 되고 있습니다. 이러한 문제를 해결하기 위해 DiaSynth라는 합성 대화 생성 프레임워크를 소개합니다.
- **Technical Details**: DiaSynth는 대형 언어 모델 (Large Language Model, LLM)을 백본으로 사용하여 특정 도메인에 맞춘 컨텍스트가 풍부하고 현실감 있는 대화를 생성합니다. DiaSynth는 주제 목록을 입력받아 하위 주제를 생성하고, 각 하위 주제에서 다양한 페르소나(persona)를 생성하여 대화의 깊이와 다양성을 높입니다. 또한, CoT (Chain of Thoughts)라는 추론 메커니즘을 사용하여 대화의 설정과 특징을 고려한 대화를 동적으로 생성합니다.
- **Performance Highlights**: DiaSynth의 효용성을 검증하기 위해 생성된 데이터의 품질과 이를 다운스트림 작업에서의 사용 가능성으로 평가했습니다. 대화 요약 작업에서 DiaSynth로 생성된 데이터로 미세 조정된 모델이 기본 모델보다 평균 16.47% 더 높은 성과를 보여주었고, 도메인별 데이터로 미세 조정된 모델의 성과의 약 90.48%를 기록했습니다. 이는 도메인별 데이터가 부족한 상황에서 DiaSynth가 강력한 대안이 될 수 있음을 시사합니다.

### [Hyper-Connections](https://arxiv.org/abs/2409.19606)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.19606.png)

Vote: 10

Authors: Defa Zhu, Banggu Wu, Yunyao Mao, Xun Zhou, Hongzhi Huang, Zihao Huang, Yutao Zeng, Qiyang Min

- **What's New**: 이번 연구에서는 딥러닝 모델에서 잔여 연결(Residual Connections)이 가진 한계점을 극복하기 위한 새로운 방식인 하이퍼 연결(Hyper-Connections)을 제안합니다. 하이퍼 연결은 단순히 잔여 연결의 특성을 학습할 수 있게 하여 네트워크가 최적의 연결 강도를 자율적으로 학습할 수 있게 합니다.
- **Technical Details**: 하이퍼 연결은 레이어 간의 입력과 출력을 연결하는 깊이 연결(Depth-Connections)과 같은 레이어 내에서 정보 교환을 가능하게 하는 너비 연결(Width-Connections)을 포함합니다. 이 두 연결을 통해 레이어의 순서 재배치(Sequential or Parallel) 및 연결 강도를 학습할 수 있습니다. 또한, 동적 하이퍼 연결(Dynamic Hyper-Connections)을 도입하여 입력에 따라 연결 가중치를 조정할 수 있게 합니다.
- **Performance Highlights**: 하이퍼 연결을 도입한 모델은 기존 모델보다 더욱 빠르게 수렴하며 성능도 향상됩니다. 예를 들어, OLMoE 모델에서는 DHC를 사용한 모델이 1.8배 더 빠르게 수렴하고 ARC-Challenge 벤치마크에서 약 6점의 성능 향상을 보였습니다. 시각적 분석을 통해 하이퍼 연결이 각 레이어의 영향을 증대시킴을 확인할 수 있습니다.

### [UniAff: A Unified Representation of Affordances for Tool Usage and Articulation with Vision-Language Models](https://arxiv.org/abs/2409.20551)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.20551.png)

Vote: 9

Authors: Hongsheng Li, Xin Li, Liu Liu, Xibin Yuan, Qiaojun Yu, Peng Gao, Junbo Wang, Cewu Lu, Siyuan Huang, Ce Hao, Haonan Chang, Zhengkai Jiang

- **What's New**: 새로운 연구는 현실 세계 환경에서 도구와 관절 객체의 조작을 다루는 몸을 가진 로봇의 능력을 향상시키기 위해 UniAff를 소개하고 있다. UniAff는 도구와 관절 객체 모두에 대한 통합된 어포던스(UniAffordance) 표현방법을 제공하며, 비전-언어 모델(MLLM)을 활용해 3D 운동 제약과 어포던스를 예측, 이해할 수 있다. 이는 현재 존재하는 방법들이 특정 경우에만 초점을 맞추는 것과 달리, 더 폭넓은 작업에 일반화할 수 있다.
- **Technical Details**: 이 방법은 두 단계로 이루어져 있다. 첫 번째 단계에서는 비전 모델을 사용해 조작 관련 매개변수를 예측하고, 두 번째 단계에서는 큰 언어 모델(LLM)의 추론 능력을 활용한다. UniAff의 훈련을 위해, 900개의 관절 객체와 600개의 도구를 포함한 대규모 데이터셋을 개발하였다. 각 객체의 부분 수준 6D 포즈, 어포던스, 조작 유형 등이 라벨링되어 있으며, 이는 로봇 학습을 지원한다.
- **Performance Highlights**: UniAff는 매우 현실적인 시뮬레이션을 통해 생성된 대규모 데이터셋과 자동으로 라벨링된 정보로 훈련되었다. 실험 결과, HANDAL 데이터셋에서 기존의 LISA보다 11.5% 더 뛰어난 성과를 냈으며, 도구 사용 시에는 ManipVQA와 유사한 결과를 보였다. 관절 객체 조작에서는 새로운 인스턴스와 새로운 카테고리에서 각각 7.07%와 9.60% 향상된 성공률을 보였다.

### [Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers](https://arxiv.org/abs/2409.20537)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.20537.png)

Vote: 8

Authors: Lirui Wang, Xinlei Chen, Kaiming He, Jialiang Zhao

- **What's New**: 로봇 정책(policies) 마련이 어렵다는 점을 해결하기 위해 Heterogeneous Pre-trained Transformers(HPT)라는 새로운 접근법을 제안했습니다. 대규모, 고품질, 다양한 데이터를 통해 사전 학습된 로봇 정책을 구축함으로써 특정 로봇, 작업 및 환경에 대한 의존성을 줄일 수 있습니다.
- **Technical Details**: HPT 아키텍처는 세 가지 주요 구성 요소로 나뉩니다: 1) 각 로봇의 감각 데이터를 정렬하는 'stem' 2) 공유된 'trunk' 3) 작업별로 동작 출력을 생성하는 'head'. HPT는 이 모듈화된 네트워크 구조를 통해 서로 다른 로봇의 다양한 감각 입력(RGB 이미지, 언어 지시, 깊이 지도, 3D 포인트 클라우드, 촉각 이미지 등)을 정렬하여 공통적인 '언어'로 변환합니다. 이전 연구들과 달리 HPT는 proprioception(고유 수용 감각) 및 시각 정보를 모두 포함하여 다양한 도메인에서의 이질성을 다룹니다. 
- **Performance Highlights**: HPT는 50개 이상의 개별 데이터 소스로부터 학습하며, 10억 개 이상의 파라미터로 구성된 모델을 사용했습니다. 시뮬레이션 벤치마크와 실제 dexterous task(정밀 작업)에서 기존 방법들과 비교하여 우월한 성능을 보였습니다. 사전 학습된 HPT는 새로운 환경과 작업에서도 최소한의 추가 데이터와 학습만으로 적응할 수 있으며, 학습된 로봇 정책의 설치와 정확도를 크게 향상시킵니다.

### [Cottention: Linear Transformers With Cosine Attention](https://arxiv.org/abs/2409.18747)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18747.png)

Vote: 7

Authors: Eric C. Larson, Gabriel Mongaras, Trevor Dohm

- **What's New**: 이 연구는 새로운 머신 러닝 모델(ML model) 또는 알고리즘(algorithm)의 제안을 통해 지정된 문제를 해결하는 방식을 제공합니다. 해당 모델의 주요 특징과 개선 사항을 중심으로 기술하고 있습니다.
- **Technical Details**: 연구에서는 특정 데이터셋(dataset)을 활용하여 모델을 학습(train)시키고 평가(evaluate)했습니다. 제안된 알고리즘은 기존 방법론과 비교하여 성능을 입증하기 위해 다양한 실험을 거쳤습니다. 또한, 모델의 아키텍처(architecture)와 하이퍼파라미터(hyperparameters)에 대한 상세한 설명이 포함되었습니다.
- **Performance Highlights**: 새로운 모델은 여러 성능 지표(performance metrics)에서 기존 방법들을 능가하는 결과를 보였습니다. 특히, 정확도(accuracy), 정밀도(precision), 재현율(recall) 등에서 뛰어난 성능 향상이 있었음을 실험 결과를 통해 확인할 수 있습니다.

### [Coffee-Gym: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code](https://arxiv.org/abs/2409.19715)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.19715.png)

Vote: 5

Authors: Taeyoon Kwon, Kai Tzu-iunn Ong, Seonghyeon Bae, Seungjun Moon, Yongho Song, Hyungjoo Chae, Seung-won Hwang, Beong-woo Kwak, Jinyoung Yeo, Dongjin Kang

- **What's New**: 이 논문에서는 최신 딥러닝(deep learning) 모델을 활용하여 자연어 처리가 일반 언어 작업에서 어떻게 적용될 수 있는지 탐구합니다. 특히, 트랜스포머(Transformer) 기반 모델의 성능 향상에 중점을 두고 있습니다.
- **Technical Details**: 연구진은 BERT(Bidirectional Encoder Representations from Transformers)와 GPT-3(Generative Pretrained Transformer 3)를 포함한 여러 트랜스포머 모델을 사용하여 실험을 수행했습니다. 이 모델들은 대규모 데이터 셋을 활용하여 미세 조정(fine-tuning) 과정을 통해 구체적인 언어 과제에 맞추어 성능을 최적화했습니다.
- **Performance Highlights**: 실험 결과, 새로운 모델이 이전 모델에 비해 특정 언어 작업에서 획기적인 성능 향상을 보였습니다. 특히, 문장 분류 및 기계 번역(machine translation) 작업에서 정확도가 크게 향상되었습니다. 또한, 연구는 모델의 학습 및 추론 속도 측면에서도 효율성을 입증했습니다.

### [Can Models Learn Skill Composition from Examples?](https://arxiv.org/abs/2409.19808)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.19808.png)

Vote: 5

Authors: Sanjeev Arora, Anirudh Goyal, Dingli Yu, Simran Kaur, Haoyu Zhao

- **What's New**: arxiv에서 발표된 최신 연구 논문에서는 **새로운 인공지능 모델** 혹은 **알고리즘**이 소개되었습니다. 이 논문은 다양한 기술적 혁신을 통해 **AI** 분야에 중요한 기여를 하고 있습니다. 특히 이 연구는 **예측 정확도**와 **처리 속도**를 향상시키는 데 중점을 두고 있습니다.
- **Technical Details**: 기술적인 면에서, 이 논문은 **딥 러닝 (Deep Learning)**, **강화 학습 (Reinforcement Learning)**, 및 **자연어 처리 (NLP)** 등의 여러 AI 기법을 활용하고 있습니다. 또한, 논문에서는 **데이터셋 (Dataset)**의 구체적인 구성과 **트레이닝 (Training) 과정**을 상세히 설명하고 있습니다. **모델 아키텍처 (Model Architecture)**는 여러 **레이어 (Layer)**로 구성되어 있으며, **하이퍼파라미터 (Hyperparameters)** 최적화가 강조됩니다.
- **Performance Highlights**: 이 모델은 다양한 **벤치마크 테스트 (Benchmark Test)**에서 뛰어난 성능을 보였습니다. 특히, 기존 모델들과 비교했을 때 **더 높은 정확도 (Accuracy)**와 **효율성 (Efficiency)**을 기록했습니다. 또한, **컴퓨팅 자원 (Computing Resources)** 사용 측면에서도 최적화된 결과를 보였습니다.

### [Image Copy Detection for Diffusion Models](https://arxiv.org/abs/2409.19952)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.19952.png)

Vote: 5

Authors: Wenhao Wang, Zhentao Tan, Yi Yang, Yifan Sun

- **What's New**: 새로운 연구가 arxiv에 제출되었습니다. 이 논문은 머신 러닝(Machine Learning)을 사용하여 데이터 분석을 혁신하는 방법을 제시합니다.
- **Technical Details**: 이 연구에서는 최신 딥 러닝(Deep Learning) 모델을 사용하였으며, 특히 컨볼루션 신경망(Convolutional Neural Network, CNN) 및 순환 신경망(Recurrent Neural Network, RNN)을 결합하여 높은 정확도를 구현하였습니다. 데이터 전처리(Data Preprocessing)와 함께 데이터 증강(Data Augmentation) 기법도 활용되었습니다.
- **Performance Highlights**: 제안된 모델은 기존 모델들이 해결하지 못한 복잡한 문제들을 성공적으로 해결했습니다. 테스트 데이터셋(Test Dataset)에서 평균 10% 이상의 성능 향상을 보였으며, 정확도(Accuracy), 정밀도(Precision), 재현율(Recall)의 주요 지표에서 탁월한 성능을 보여주었습니다.

### [Visual Question Decomposition on Multimodal Large Language Models](https://arxiv.org/abs/2409.19339)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.19339.png)

Vote: 2

Authors: Jindong Gu, Bailan He, Haowei Zhang, Jianzhe Liu, Zhiqiang Xu, Volker Tresp, Shuo Chen, Zhen Han

- **What's New**: 이번 연구는 Transformer 모델을 통해 자연어 처리 (NLP) 작업에서의 성능을 개선하려는 새로운 접근 방안을 제시하고 있습니다. 기존의 Transformer 모델의 단점을 보완하고, 더욱 효율적인 학습 방법을 도입하였습니다.
- **Technical Details**: 이 논문에서는 Attention Mechanism을 개선한 새로운 구조를 제안하였습니다. 이 구조는 Self-Attention과 Multi-Head Attention을 강화하여 더 나은 컨텍스트 인식 능력을 발휘합니다. 또한, Pre-trained 모델을 활용하여 Transfer Learning을 최적화하는 방법도 탐구하고 있습니다.
- **Performance Highlights**: 새롭게 제안된 모델은 여러 벤치마크 데이터셋에서 기존의 최첨단 모델들보다 더 높은 성능을 보였습니다. 예를 들어, GLUE Benchmark에서 F1 Score와 Accuracy에서 의미 있는 성능 향상을 달성하였습니다.

### [IDEAW: Robust Neural Audio Watermarking with Invertible Dual-Embedding](https://arxiv.org/abs/2409.19627)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.19627.png)

Vote: 1

Authors: Jing Xiao, Pengcheng Li, Xulong Zhang, Jianzong Wang

- **What's New**: 이번 논문에서는 IDEAW(Invertible Dual-Embedding Audio Watermarking)라는 새로운 모델을 제안했습니다. 이 모델은 듀얼 스테이지 가역 신경망을 사용하여 워터마크 메시지와 동기화 코드를 별도로 삽입하는 방식입니다. 이는 워터마크의 위치를 신속하게 찾을 수 있도록 하며, 워터마크 비트의 용량을 유연하게 확장할 수 있게 합니다.
- **Technical Details**: IDEAW는 Embedder-Attack Layer-Extractor 구조를 따릅니다. 임베딩 과정에서, 첫 번째 스테이지 INN(Invertible Neural Network)는 이진 워터마크 메시지를 고정 길이의 오디오 청크에 삽입하고, 두 번째 스테이지 INN은 이진 동기화 코드를 삽입합니다. 역변환을 통해 최종 워터마크 오디오를 재구성합니다. 추출 과정에서는 두 스테이지 추출기가 역순으로 동기화 코드와 워터마크 메시지를 추출합니다. 공격 레이어는 다양한 제거 공격에 대한 강인성을 향상시킵니다. 또한, 비대칭성을 완화하고 가역 신경망의 대칭을 유지하기 위해 Balance Block을 적용합니다.
- **Performance Highlights**: 새롭게 제안된 워터마킹 모델은 높은 비트 수용량을 가지고 있으며, 비가시성과 강인성을 보장합니다. 이러한 듀얼 임베딩 전략은 위치 파악 과정을 가속화하고, 워터마크 용량을 유연하게 확장할 수 있는 가능성을 제공합니다. 비대칭성을 완화한 덕분에 훈련 안정성도 높아졌습니다.

