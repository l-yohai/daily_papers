## Daily Papers (2024-10-24)

### [DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes](https://arxiv.org/abs/2410.18084)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.18084.png)

Vote: 9

Authors: ['Liang Pan', 'Lingdong Kong', 'Hengwei Bian', 'Yu Qiao', 'Haozhe Xie', 'Ziwei Liu']

- ***What's New***: DynamicCity는 새로운 4D LiDAR 생성 프레임워크로, 시간에 따라 변화하는 동적 환경을 대규모로, 고품질로 재현할 수 있는 모델을 제안합니다. 기존의 정적이며 단일 프레임에 초점을 맞췄던 방법들과 달리, DynamicCity는 동적 장면의 생성 및 시간을 반영한 진화까지 가능하게 합니다.
- ***Technical Details***: DynamicCity는 VAE 모델을 통해 HexPlane이라는 4D 표현을 학습하고, 이를 통해 동적 LiDAR 장면을 생성합니다. Novel Projection Module을 사용하여 4D LiDAR 특징을 2D 특징맵으로 압축, 향상된 HexPlane 적합성을 제공합니다. 또한, DiT 기반의 diffusion 모델을 통해 다양한 조건과 함께 4D 생성이 가능하며, Expansion & Squeeze Strategy를 도입해 재구성 효율과 정확성을 높입니다.
- ***Performance Highlights***: CarlaSC 및 Waymo 데이터셋에서 기존 최신 방법들을 능가하여, miOU 기준으로 각각 43.2%의 향상을 나타냈습니다. 학습 속도 및 메모리 효율 또한 상당히 개선되었으며, 다양한 생성 품질 지표에서 우월한 성능을 보입니다.

### [TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts](https://arxiv.org/abs/2410.18071)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.18071.png)

Vote: 3

Authors: ['Yuxuan Xie', 'Wenqi Shao', 'Tianhua Li', 'Kaipeng Zhang']

- ***What's New***: TP-Eval은 멀티모달 대형 언어 모델(Multimodal Large Language Models; MLLMs)의 평가에서 프롬프트(Prompt) 민감성 문제를 해결하기 위해 최적화된 프롬프트를 모델별로 맞춤화하여 모델의 잠재력을 최대한 평가할 수 있는 새로운 평가 프레임워크입니다.
- ***Technical Details***: TP-Eval은 자동 프롬프트 최적화 기술을 사용하여 MLLMs 평가에 맞춰 텍스트와 이미지를 함께 고려하는 프롬프트 최적화 방법을 적용하였습니다. 이 방법은 소수 샷(Few-Shot) 시나리오와 부족한 데이터 환경에서도 효과적으로 작동하도록 설계되었습니다. 정량적 피드백과 선택난이도를 줄이기 위한 프롬프트 변경 제한을 통해 overfitting을 방지합니다.
- ***Performance Highlights***: LLaVA, DeepSeek-VL, InternVL 모델들은 TP-Eval을 통해 각각 4%, 2.1%, 2.3%의 성능 향상을 보이며, 전체 개발 및 평가 비교에서 상당한 잠재능력 향상을 보여주었습니다. 이러한 성과는 원래의 단순화된 프롬프트가 모델의 실제 역량을 과소평가할 수 있음을 강조합니다.

### [MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models](https://arxiv.org/abs/2410.17637)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.17637.png)

Vote: 27

Authors: ['Conghui He', 'Haodong Duan', 'Dahua Lin', 'Yuanjun Xiong', 'Yuhang Cao', 'Jiaqi Wang', 'Pan Zhang', 'Yuhang Zang', 'Xiaoyi Dong', 'Ziyu Liu']

- ***What's New***: MIA-DPO는 대형 비전-언어 모델(Large Vision-Language Models; LVLMs)의 시각적 선호 정렬을 다중 이미지 입력으로 효과적으로 처리하는 방법을 제시합니다. 다양한 다중 이미지 데이터 부족과 높은 주석 비용 문제를 해결하기 위해 단일 이미지 데이터를 그리드 콜라주나 픽 인 픽 형태로 확장하여 annotation 비용을 크게 줄였습니다.
- ***Technical Details***: MIA-DPO는 LVLM의 다양한 구조에 호환되며 선택/거부 쌍을 구축하는 과정에서 주의(attention) 값을 사용하여 거부된 응답을 걸러냅니다. 사람의 주석, 추가 데이터, 외부 모델/API에 의존하지 않고 주의 기반 선택을 통해 DPO 데이터를 자동으로 구성합니다. 다양한 다중 이미지 벤치마크에 비해 기존 방법에 비해 더 나은 성능을 유지합니다.
- ***Performance Highlights***: MIA-DPO는 LLaVA-v1.5에서 평균 3.0% 성능 향상을, InternLM-XC2.5에서는 평균 4.3% 성능 향상을 기록하며 다중 이미지 벤치마크에서 우수한 성능을 보였습니다. 특히, 다중 시각적 맥락에서 어려움을 겪고 있는 오픈 소스 LVLM들을 위한 견고한 솔루션을 제시합니다.

### [LLM-based Optimization of Compound AI Systems: A Survey](https://arxiv.org/abs/2410.16392)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.16392.png)

Vote: 12

Authors: ['Yiran Wu', 'Gao Huang', 'Huan Liu', 'Andrew Zhao', 'Jun Liu', 'Yong-Jin Liu', 'Matthieu Lin', 'Yang Yue', 'Shenzhi Wang', 'Jenny Sheng']

- ***What's New***: 이 논문은 복합 AI 시스템(Compound AI Systems)의 최적화를 위해 대형 언어 모델(LLM) 기반 접근 방식을 조사했습니다. LLM을 옵티마이저로 사용하는 것이 최근 트렌드로, 그라디언트 기반 방식이나 강화 학습 방식이 필요하지 않아 효율성을 높입니다. 특히, 프로그램 분석의 개념을 사용하여 LLM 옵티마이저를 어떻게 프롬프트할 수 있는지 통합된 시각을 제공합니다.
- ***Technical Details***: 복합 AI 시스템은 LLM 호출, 검색기, 코드 인터프리터, 도구 등을 포함하는 시스템으로, 파라미터(예: 지침, 도구 정의)에 의해 주로 결정됩니다. LLM 기반 최적화는 다양한 파라미터를 단일 호출로 최적화하며, 폐쇄형 소스 LLM과도 작동합니다. 이 프레임워크는 훈련 데이터 셋에서 경험적 위험을 최소화하기 위해 파라미터의 최적화를 강조합니다. 최적화 과정은 프로그램 분석을 통해 정적 및 동적 방식으로 구분되며, 디버깅 대신 학습 시 최적화하는 비용 효율적인 방법을 제공합니다.
- ***Performance Highlights***: LLM 기반 최적화는 다양한 복합 AI 시스템에 대해 향상된 성능을 보여줍니다. 이 절차는 프로그램 분석에서 유래된 감독 신호를 통해 단일 혹은 다중 파라미터의 공동 최적화를 수행하며, 이는 훈련 데이터에 대한 시스템 실행 중 피드백을 활용하여 더 나은 파라미터를 생성하는 방식으로 진행됩니다. 특히, 이론적 분석뿐만 아니라 실험을 통해 그 효과가 검증되었습니다.

### [M-RewardBench: Evaluating Reward Models in Multilingual Settings](https://arxiv.org/abs/2410.15522)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.15522.png)

Vote: 3

Authors: ['Lester James V. Miranda', 'Rishabh Maheshwary', 'Sara Hooker', 'Sebastian Ruder', 'Drishti Sharma', 'Srishti Gureja', 'Shayekh Bin Islam', 'Gusti Winata', 'Nathan Lambert', 'Marzieh Fadaee']

- **What's New**: M-RewardBench는 다국어 환경에서 보상 모델(Reward Models; RM)의 성능을 평가하기 위한 최초의 멀티링구얼 벤치마크입니다. 이 벤치마크는 대화(chat), 안전성(safety), 추론(reasoning), 번역(translation) 능력을 평가하며, 23개 다양한 언어로 구성된 2.87k의 선호 인스턴스(preferece instances)를 포함하고 있습니다.
- **Technical Details**: M-REWARDBENCH는 다국어 보상 모델 평가를 위한 데이터셋으로, 23개 언어에 걸쳐 6가지 작업을 다룹니다. 데이터셋은 RewardBench와 MAPLE에서 번역된 인스턴스를 기반으로 하며, Google Translate API와 NLLB 3.3B를 사용해 번역되었습니다. 다양한 보상 모델 타입(Generative RMs, Classifier RMs, Implicit RMs)을 통해 성능을 평가하였고, 이 데이터셋을 공개하여 관련 연구에 기여하고자 합니다.
- **Performance Highlights**: 현재 보상 모델들은 영어와 비영어 환경 간에 큰 성능 차이를 보이며, 최대 13%의 성능 저하가 발견되었습니다. 번역 품질 개선은 보상 모델의 성능을 향상시키며, 데이터가 풍부한 언어에서는 더 나은 퍼포먼스를 보여주었습니다. Generative RM은 다국어 평가에서 가장 높은 성능을 기록하고, 고품질 번역을 제공할 때 이점이 더욱 두드러졌습니다.

### [LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding](https://arxiv.org/abs/2410.17434)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.17434.png)

Vote: 4

Authors: ['Zechun Liu', 'Hu Xu', 'Xiaoqian Shen', 'Vikas Chandra', 'Jun Chen', 'Mohamed Elhoseiny', 'Florian Bordes', 'Hyunwoo J. Kim', 'Chenchen Zhu', 'Fanyi Xiao', 'Zhuang Liu', 'Raghuraman Krishnamoorthi', 'Lemeng Wu', 'Balakrishnan Varadarajan', 'Yunyang Xiong', 'Bilge Soran', 'Changsheng Zhao']

- **What's New**: LongVU는 긴 비디오 이해를 위한 비디오-언어 모델(MLLMs)에 새로운 스페이셜-템포럴 적응형 압축 메커니즘을 도입하여 비디오 토큰을 줄이면서 시각적 세부 사항을 최대한 유지합니다. 이 방식은 크로스-모달 쿼리와 프레임 간 종속성을 활용하여 비디오의 시간적 및 공간적 중복을 적절히 감소시킵니다.
- **Technical Details**: LongVU는 DINOv2 기능을 활용하여 높은 유사성을 보이는 중복된 프레임을 제거하고, 텍스트 기반 크로스-모달 쿼리를 통해 선택적 프레임 기능을 줄여 비디오를 압축하는 전략을 제안합니다. 이 과정에서 정상적인 해상도 프레임 중 중요한 것들은 풀 토큰으로 유지하고, 다른 부분들은 저해상도 토큰 표현으로 축소합니다. 또한 공간 토큰의 축소 메커니즘은 시간적 종속성을 기반으로 수행됩니다.
- **Performance Highlights**: LongVU는 다양한 비디오 이해 벤치마크에서 기존의 비디오 LLM 모델을 크게 능가하며, 특히 VideoMME 및 MLVU와 같은 시간대가 긴 비디오 과제에서 우수한 성능을 보여줍니다. 또한 상업 모델인 GPT4-o와 비교하여 MVBench에서 더 나은 성능을 보이며, LLaVA-OneVision을 약 12.8% 초과하는 성능을 기록했습니다.

### [Scaling Diffusion Language Models via Adaptation from Autoregressive Models](https://arxiv.org/abs/2410.17891)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.17891.png)

Vote: 10

Authors: ['Wei Bi', 'Mukai Li', 'Hao Peng', 'Shansan Gong', 'Peilin Zhao', 'Lin Zheng', 'Jiacheng Ye', 'Lingpeng Kong', 'Shivam Agarwal', 'Chenxin An', 'Jiawei Han', 'Yizhe Zhang']

- ***What's New***: 본 논문에서는 대규모 자가회귀 모델(Autoregressive Models)을 활용하여 텍스트 확산 모델(Diffusion Language Models; DLMs)을 효율적으로 학습시키는 방법을 제안합니다. 이를 통해 127M부터 7B 파라미터 규모의 AR 모델(GPT-2 및 LLaMA)을 DiffuGPT 및 DiffuLLaMA로 변환시키며, 기존 확산 모델을 뛰어넘는 성능을 보여줍니다.
- ***Technical Details***: 자가회귀 모델과 확산 모델의 목표를 연결하여 두 모델 간의 차이를 극복하는 단순화된 계속 사전학습(Continual Pre-training) 접근을 소개합니다. 이 방법은 주의 마스크 소거(Attention Mask Annealing)와 쉬프트(Shift) 연산을 활용하여 양방향성을 엑세느하게 만듭니다. 최적화 과정에는 Full attention matrix와 causer attention masking을 점진적으로 전환하는 과정이 포함됩니다.
- ***Performance Highlights***: DiffuGPT는 대부분의 과제에서 GPT-2를 능가하며, DiffuLLaMA는 인-컨텍스트 학습과 코드 생성 및 강력한 텍스트 채우기 능력을 보여줍니다. 여기에 사용된 모델은 기존의 확산 모델보다 우수한 성능을 보이며, 7B 규모의 모델인 DiffuLLaMA는 코딩 및 수학 문제 해결에 뛰어난 성능을 보였습니다. 실험 결과는 AR 모델과의 비교 외에도 확산 모델의 새로운 활용 가능성을 강조합니다.

### [WorldSimBench: Towards Video Generation Models as World Simulators](https://arxiv.org/abs/2410.18072)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.18072.png)

Vote: 13

Authors: ['Yiran Qin', 'Jiwen Yu', 'Xijun Wang', 'Enshen Zhou', 'Lei Bai', 'Ruimao Zhang', 'Zhelun Shi', 'Lijun Li', 'Lu Sheng', 'Xihui Liu', 'Zhenfei Yin', 'Jing Shao', 'Wanli Ouyang']

- ***What's New***: WorldSimBench는 비디오 생성 모델(Video Generation Models)을 세계 시뮬레이터(World Simulators)로 평가하는 최초의 이중 평가 프레임워크입니다. 이는 인간의 선호도를 기반으로 한 시각적 평가와 행동 수준의 평가를 포함하여 예측 모델의 기능을 위계적으로 분류하여 평가합니다.
- ***Technical Details***: WorldSimBench는 세 가지 주요 시나리오, 즉 개방형 환경(Open-Ended Embodied Environment), 자율 주행(Autonomous Driving), 로봇 조작(Robot Manipulation)에서 World Simulators를 평가합니다. 명시적 지각 평가(Explicit Perceptual Evaluation)는 HF-Embodied 데이터셋을 활용하여 시각적 충실도를 평가하고, 암시적 조작 평가(Implicit Manipulative Evaluation)는 시뮬레이션 환경에서 생성된 비디오가 올바른 제어 신호로 변환될 수 있는지를 평가합니다.
- ***Performance Highlights***: WorldSimBench을 통해 자율 주행 시나리오에서 Video Generation Models는 아직 신뢰할 만한 물리적 일관성을 갖춘 콘텐츠를 생성하는 데 충분한 기술을 갖추지 못했음을 보여주었습니다. 오픈소스 비디오 생성 모델들은 생성 영상에서 발생하는 물리 법칙을 효과적으로 포착하는 데 한계가 있으며, 이는 World Simulators로서의 더 나은 성능 향상이 필요함을 시사합니다.

### [MedINST: Meta Dataset of Biomedical Instructions](https://arxiv.org/abs/2410.13458)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13458.png)

Vote: 3

Authors: ['Meng Fang', 'Qingyu Chen', 'Mykola Pechenizkiy', 'Ling Chen', 'Zihan Zhang', 'Wenhan Han', 'Zirui Song', 'Yu Yin']

- ***What's New***: MedINST는 133개의 생의학 NLP 태스크와 700만 개 이상의 학습 샘플로 구성된 복합 도메인의 학습 데이터세트로, 현재까지 가장 포괄적인 생의학 지침 데이터세트를 제공합니다. 이를 통해 대규모 언어 모델(LLM)의 일반화 능력을 평가하는 MEDINST32라는 챌린징 벤치마크를 마련하였습니다.
- ***Technical Details***: MedINST 데이터세트는 Named Entity Recognition(NER), Question Answering(QA) 등 12개 카테고리에 걸쳐 있는 133개의 생의학 관련 NLP 태스크로 구성되며, 각 태스크는 인스트럭션-팔로우 샘플 형태로 포맷되어 있습니다. 모델의 성능 향상을 위해 여러 규모의 LLM들이 MedINST로 파인튜닝되었으며, Cross-task Generalization을 평가하는 목적으로 설계되었습니다.
- ***Performance Highlights***: 우리 모델은 BIOINFER, BC5CDR와 같은 벤치마크에서 초월적인 성능을 보여주었으며, 특히 다양한 난이도의 태스크에서 뛰어난 일반화 성능을 입증했습니다. 일부 태스크에서는 GPT-4o를 능가하는데 성공하였으며, QA와 NER를 포함한 여러 핵심 태스크 카테고리에서 평균적으로 더 높은 Rouge-L 점수를 기록하였습니다.

### [Lightweight Neural App Control](https://arxiv.org/abs/2410.17883)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.17883.png)

Vote: 6

Authors: ['Filippos Christianos', 'Jun Wang', 'Kun Shao', 'Jianye Hao', 'Thomas Coste', 'Georgios Papoudakis']

- ***What's New***: 이 논문에서는 다양한 Android 앱에서 효율적인 상호작용과 제어를 위한 '앱 에이전트'라는 새로운 모바일 제어 아키텍처, 즉 LiMAC(Lightweight Multi-modal App Control)을 소개합니다. LiMAC은 과거의 모바일 관찰(스크린샷 및 UI 트리)과 텍스트 목표를 입력으로 받아 정확한 액션을 생성합니다.
- ***Technical Details***: LiMAC에서는 작은 Action Transformer (AcT)와 정밀하게 조정된 비전-언어 모델(VLM)을 사용하여 실시간 결정을 내리고 작업을 수행합니다. 이 시스템은 주어진 스마트폰 상태와 사용자 명령에 기초하여 클릭, 텍스트 입력, 스크롤 등의 다양한 액션 타입을 예측합니다. AcT는 UI 요소 사이의 대조 학습 목표를 사용하여 클릭 예측을 수행하며, 자연어 이해가 필요한 경우에는 VLM을 활용합니다.
- ***Performance Highlights***: LiMAC은 플로렌스2(Florence2) 및 Qwen2-VL과 같은 정밀 조정된 공개 소스 VLM보다 최대 19% 더 높은 액션 정확도를 제공하며, GPT-4o 기반의 프롬프트 엔지니어링 방식보다 42% 더 높은 성과를 보입니다. AcT와 결합한 LiMAC은 테스트 셋에서 타 모델 대비 최대 30배 더 빠른 실행 시간과 최대 40% 더 높은 정확도를 기록하였습니다.

### [ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding](https://arxiv.org/abs/2410.13924)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13924.png)

Vote: 5

Authors: ['Silvan Weder', 'Guangda Ji', 'Hermann Blum', 'Marc Pollefeys', 'Francis Engelmann']

- ***What's New***: ARKit LabelMaker는 실내 3D 장면 이해를 위한 첫 번째 대규모, 실제 데이터셋입니다. 이 논문에서는 ARKitScenes 데이터셋에 자동으로 생성된 밀도가 높은 의미 체계 주석을 추가하여 이를 중요한 학습 데이터로 사용합니다. LabelMaker를 개선한 LabelMakerV2 파이프라인을 소개하며, 다양한 기반 모델과 대규모 데이터 처리 강화를 통해 대규모 사전 훈련을 위한 데이터셋을 제공합니다.
- ***Technical Details***: LabelMakerV2는 최신 세그멘테이션 모델들을 통합하고 위성 뷰로부터 예측을 통합하여 RGB-D 데이터에서 의미 체계를 생성합니다. 이 파이프라인은 Nvidia 3090 GPU에서 48000 GPU 시간을 소요하며 ARKitScenes 전체 데이터셋을 처리합니다. 또한, 흔히 사용되는 스캐닝 소프트웨어를 통합하여 모바일 기기를 통해 취득한 모든 스캔에 대해 자동 라벨을 생성할 수 있도록 합니다.
- ***Performance Highlights***: 우리의 ALC 데이터셋으로 사전 훈련된 PTv3 모델은 ScanNet 벤치마크에서 최신 기술의 성능을 보여주며, ScanNet200 벤치마크에서도 하위 클래스 mIoU에서 상당한 개선을 보입니다. 이 데이터셋은 실제 데이터를 기반으로 하는 트레이닝에서 중요한 성능 향상을 이끌어낼 뿐만 아니라, 기존 합성 데이터에 비해 더 효과적인 것으로 나타납니다.

### [Scalable Ranked Preference Optimization for Text-to-Image Generation](https://arxiv.org/abs/2410.18013)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.18013.png)

Vote: 9

Authors: ['Zeynep Akata', 'Shyamgopal Karthik', 'Huseyin Coskun', 'Sergey Tulyakov', 'Jian Ren', 'Anil Kag']

- ***What's New***: 이 논문에서는 텍스트-이미지 생성(Text-to-Image Generation)의 선호(Preference) 데이터를 완전하게 합성하여 대규모로 수집하고, 순위 기반 최적화(Ranked Preference Optimization)를 통해 SDXL 모델과 SD3-Medium 모델의 성능을 개선하는 새로운 접근 방식을 제안합니다. 인간의 피드백 없이 미리 훈련된 보상 함수(Pre-trained Reward Function)를 사용하여 이미지를 레이블링함으로써 데이터 수집 비용을 크게 절감했습니다.
- ***Technical Details***: 이 연구에서는 다수의 텍스트-이미지 모델로부터 이미지를 생성하여 'Syn-Pic'라는 합성 데이터를 구축했습니다. 그런 다음, 다양하게 훈련된 보상 모델을 사용하여 각 이미지의 선호도를 평가하고 이를 사용하여 순위를 매겼습니다. 순위 기반 선호 최적화(RankDPO)를 통해, Direct Preference Optimization(DPO) 방법을 개선하여, 더 많은 예측과 평가를 가능하게 했습니다. 이는 생성된 이미지들 간의 순위를 조정함으로써 기존의 쌍 대 쌍 비교 방식보다 더 풍부한 신호를 제공했습니다.
- ***Performance Highlights***: RankDPO를 적용하여 SDXL 모델은 GenEval 및 T2I-Compbench와 같은 다양한 벤치마크에서 각각 10% 이상의 성능 향상을 보였습니다. SD3-Medium 모델 또한 기존의 인간 선호를 이용한 방식보다 3배 적은 데이터만으로 이와 유사한 성능 개선을 보였습니다. 또한, 사용자 연구를 통해 RankDPO가 기존 방법들보다 텍스트-이미지 일치와 시각적 품질의 측면에서 더 나은 결과를 가져오는 것으로 나타났습니다.

