## Daily Papers (2024-01-25)

### [Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild](https://arxiv.org/abs/2401.13627)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/msnFkMTpgMlWSxuqW5QCN.png)

Vote: 28

Authors: Zheyuan Li, Xiangtao Kong, Xintao Wang, Jingwen He, Yu Qiao, Jinjin Gu, Chao Dong, Fanghua Yu, Jinfan Hu

- 본 논문은 새로운 이미지 복원 방법인 SUPIR(Scaling-UP Image Restoration)을 소개하며, 생성적 사전 지식 활용과 모델 스케일링의 결합을 통해 혁신적인 이미지 복원을 가능하게 합니다.
- SUPIR은 멀티모달 기술과 발전된 생성적 사전 지식을 이용하여 지능적이고 실제적인 이미지 복원 분야에서 중대한 진전을 이룹니다.
- 모델 스케일링은 SUPIR의 핵심 촉매제 역할을 하여 이미지 복원 능력을 대폭 향상시키고 새로운 가능성을 보여줍니다.
- 논문에서는 2천만 개의 고해상도, 고품질 이미지로 구성되어 있고 설명적 텍스트 주석이 있는 데이터셋을 수집하여 모델 학습에 사용합니다.
- 텍스트 프롬프트에 의해 안내되는 이미지 복원 기능을 제공함으로써 SUPIR의 적용 범위와 잠재력을 넓힙니다.
- 더 나은 지각 품질을 개선하기 위해 부정적 품질 프롬프트를 도입합니다.
- 생성 기반 복원에서 발생하는 충실도 문제를 억제하기 위한 복원 가이드 샘플링 방법도 개발했습니다.
- 실험을 통해 SUPIR의 뛰어난 복원 효과와 텍스트 프롬프트를 통한 복원 조작의 새로운 능력을 입증합니다.

### [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://arxiv.org/abs/2401.13601)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Y0tfiCJCMsxDQHvzzvKU3.png)

Vote: 26

Authors: Dong Yu, Yahan Yu, Chenhui Chu, Duzhen Zhang, Jiahua Dong, Dan Su, Chenxing Li

- 지난 1년 간, 멀티모달 대형 언어 모델(MultiModal Large Language Models, MM-LLMs)이 상당한 발전을 이루며 기존 LLMs에 다양한 멀티모달 입력 및 출력을 지원하도록 확장되었습니다.
- 이러한 발전된 모델들은 LLMs의 기본적인 추리 및 의사 결정 능력을 유지하면서 다양한 멀티모달 작업을 수행할 수 있는 능력을 갖췄습니다.
- 본 논문은 MM-LLMs에 대한 포괄적인 연구를 촉진하기 위한 종합적인 조사를 제공합니다.
- 모델 아키텍처와 훈련 파이프라인을 위한 일반적인 설계 공식을 먼저 개요로 제시하고 있습니다.
- 본 조사는 각각의 특정 공식을 특징으로 하는 26개의 기존 MM-LLMs에 대한 간략한 소개를 포함하고 있습니다.
- 또한, 주류 벤치마크에서 MM-LLMs의 성능을 검토하고, MM-LLMs의 효능을 강화하기 위한 주요 훈련 레시피를 요약합니다.
- 마지막으로, MM-LLMs의 약속된 방향을 탐색하면서 동시에 이 분야의 최신 발전을 실시간으로 추적하는 웹사이트를 유지한다는 점을 소개합니다.
- 이 조사가 MM-LLMs 분야의 지속적인 진보에 기여하기를 바랍니다.

### [MambaByte: Token-free Selective State Space Model](https://arxiv.org/abs/2401.13660)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/B-gai_aNx76hER6seSPYz.png)

Vote: 25

Authors: Junxiong Wang, Jing Nathan Yan, Alexander M Rush, Tushaar Gangavarapu

- MambaByte는 서브워드 토큰화의 편향을 제거하고 원시 바이트에서 직접 학습하는 토큰-프리 언어 모델입니다.
- 바이트를 처리함으로써 길어진 시퀀스에 대해 표준 자동회귀 트랜스포머가 비효율적인 것에 대응하여, MambaByte는 바이트 시퀀스에 대해 자동회귀 훈련을 받은 Mamba 상태 공간 모델의 적응형 버전입니다.
- 실험을 통해 MambaByte가 다른 바이트 수준 모델에 비해 계산 효율성이 높은 것으로 나타났습니다.
- MambaByte는 최신 서브워드 트랜스포머와 비교해서 경쟁력이 있으며, 심지어 능가하는 성능을 보이기도 합니다.
- 길이에 대해 선형 스케일링을 하는 맘바바이트는 트랜스포머보다 빠른 추론을 가능하게 합니다.
- 이러한 연구 결과는 토큰-프리 언어 모델링을 가능하게 하는 MambaByte의 가능성을 입증합니다.

### [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://arxiv.org/abs/2401.13388)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/nmk4r-A2_nqlozVwQe3cD.png)

Vote: 8

Authors: Xinyan Xiao, Jiachen Liu, Xue Xu, Wei Li

- 기존의 텍스트-이미지 확산 모델들은 주로 텍스트 프롬프트로부터 이미지를 생성하지만, 텍스트의 간결성으로 인해 특정 개체나 장면과 같은 복잡한 세부 사항을 정확히 합성하는 데 어려움이 있습니다.
- 본 논문에서 제시하는 UNIMO-G는 텍스트와 시각 입력이 교차된 다중모달 프롬프트를 활용하여, 텍스트 기반 및 주제 기반 이미지 생성 모두에 통합된 능력을 보여주는 단순한 다중모달 조건부 확산 프레임워크입니다.
- UNIMO-G는 다중모달 프롬프트를 인코딩하는 Multimodal Large Language Model(MLLM)과 인코딩된 다중모달 입력에 기반하여 이미지를 생성하는 조건부 노이즈 감소 네트워크로 구성되어 있습니다.
- 이 프레임워크는 텍스트-이미지 쌍에 대한 대규모 사전 훈련을 거쳐 조건부 이미지 생성 능력을 발전시키고, 다중모달 프롬프트를 사용한 지시 튜닝을 통해 통합 이미지 생성 숙련도를 달성합니다.
- 언어 지상화(language grounding) 및 이미지 분할을 포함하는 잘 설계된 데이터 처리 파이프라인을 사용하여 다중모달 프롬프트를 구성합니다.
- UNIMO-G는 텍스트-이미지 생성 및 제로샷 주제 기반 합성에서 우수한 성능을 보이며, 복수 이미지 개체를 포함하는 복잡한 다중모달 프롬프트로부터 고해상도 이미지를 효과적으로 생성하는 데 특히 효과적입니다.

### [ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models](https://arxiv.org/abs/2401.13311)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/1QQmYe9JyOJgYxzagfR82.png)

Vote: 7

Authors: Nanyun Peng, Kai-Wei Chang, Rohan Wadhawan, Hritik Bansal

- 인공지능 최신 연구에 따라, 대규모 다중모달 모델(LMMs)은 사진 속의 텍스트와 시각적 내용에 대한 공동 추론을 처리하는 복잡한 작업(예: 공공장소의 지도 탐색)을 수행할 수 있게 되었습니다.
- 본 논문에서는 LMMs의 맥락에 민감한 텍스트-풍부한 시각적 추론 능력을 평가하기 위해 특별히 설계된 새로운 벤치마크인 ConTextual을 소개합니다.
- ConTextual은 시각적 및 텍스트 요소 간의 상호 작용에 대한 깊은 이해를 요구하는 시간 읽기, 탐색, 쇼핑 등 다양한 현실 세계 시나리오를 강조합니다.
- 연구 결과는 LMM 중에서 가장 높은 성능을 나타낸 GPT-4V(ision)과 인간의 평가를 사용한 인간 능력 사이에 30.8%의 상당한 성능 격차가 있음을 드러냈습니다.
- 특히 GPT-4V는 밈과 인용문 해석 같은 추상적인 범주에서 뛰어난 성능을 보였음에도 불구하고 전반적으로 인간의 성능에는 미치지 못했습니다.
- 저희는 또한 GPT-4를 사용한 자동 평가 지표를 통해 비슷한 성능 격차 추세를 발견했으며, 다양한 시각적 맥락에서 세부적인 평가를 수행하고 질적 분석을 제공하여 LMM 설계의 미래 발전을 위한 견고한 틀을 제공합니다.
- 더 자세한 정보 및 연구 결과에 대해서는 https://con-textual.github.io/ 웹사이트를 방문하시기 바랍니다.

### [SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection](https://arxiv.org/abs/2401.13160)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/pz2vcGnn2lS0P7DS9aYFE.png)

Vote: 6

Authors: Giulia DeSalvo, Ke Ye, Afshin Rostamizadeh, Lazaros Karydas, Jean-François Kagy, Sanjiv Kumar, Gui Citovsky, Ayan Chakrabarti, Heinrich Jiang

- 본 논문에서는 매우 리소스 집약적이며 종종 정보 이용을 최적화하지 못하는 대규모 언어 모델의 사전 학습 문제를 다룬다.
- 'SpacTor'라는 새로운 학습 절차를 제시하는데, 이는 스팬 오염(SC)과 토큰 교체 탐지(RTD)를 결합한 하이브리드 목적과 두 단계의 커리큘럼을 포함한다.
- 초기 타우 반복 후 표준 SC 손실로 전환되는 하이브리드 목적 최적화를 위한 이 커리큘럼은 하이브리드 목적 효과와 밀접한 관련이 있다는 것을 실증적으로 보여준다.
- 인코더-디코더 구조체(T5)를 사용한 다양한 자연어처리(NLP) 작업에 대한 실험에서, SpacTor-T5는 표준 SC 사전 학습과 동일한 다운스트림 성능을 달성하는 동시에 사전 학습 반복 횟수를 50% 줄이고 총 FLOPs를 40% 줄인다.
- 동일한 계산 예산을 가진 경우, SpacTor는 향상된 다운스트림 벤치마크 성능을 이끌어낼 수 있음을 발견한다.

### [MaLA-500: Massive Language Adaptation of Large Language Models](https://arxiv.org/abs/2401.13303)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/IU4V5Ei5MnxVNsNkOMvdg.png)

Vote: 4

Authors: Hinrich Schütze, André F. T. Martins, Peiqin Lin, Jörg Tiedemann, Shaoxiong Ji

- 대규모 언어 모델은 자연어 처리 최신 기술을 발전시켰지만 영어나 일부 한정된 언어들에 초점을 맞춘 설계로 인해 저자원 언어에 대한 효과에 큰 격차가 있습니다.
- 이러한 격차를 해소하기 위해, 저희는 534개 언어를 포괄하는 새로운 대규모 언어 모델인 MaLA-500을 소개합니다.
- MaLA-500의 훈련을 위해, 우리는 LLaMA 2에서 Glot500-c를 사용하여 어휘 확장과 지속적인 사전 훈련을 진행했습니다.
- SIB-200에서의 실험을 통해 MaLA-500이 최신 상태의 인-컨텍스트 학습 결과를 달성했다는 것을 입증했습니다.
- MaLA-500은 https://huggingface.co/MaLA-LM 에서 공개할 예정입니다.

