## Daily Papers (2024-01-31)

### [Weaver: Foundation Models for Creative Writing](https://arxiv.org/abs/2401.17268)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Ul91LlmQ42BPTn74Tcl8N.png)

Vote: 28

Authors: Xinle Deng, Long Li, Danjun Xiang, Shuai Wang, Zhaowei Gao, Qingrui Jia, Tiannan Wang, Zhiwei Huang, Zixin Chen, Chuou Xu, Han Xiao, Huilin Wang, +, Jihong Dai, Yibin Liu, Shengwei Ding, Jiamin Chen, Gangan Ma, Jialong Wu, Chunzhao Xie, Ruoyu Fang, Teng Yu, Yunxia Wang

- 이 논문은 창작 콘텐츠 제작에 특화된 큰 규모 언어 모델인 'Weaver'를 소개합니다.
- 'Weaver'는 창작 및 전문적 글쓰기 능력 향상에 초점을 맞춘 엄선된 말뭉치로 사전 훈련되었습니다.
- 전문 작가의 선호도에 맞추기 위해 새로운 방법들을 통한 지시 데이터 합성 및 언어 모델 정렬을 통해 세부적인 지침에 따른 다양한 콘텐츠 생성이 가능합니다.
- 'Weaver' 시리즈는 Weaver Mini(1.8B), Weaver Base(6B), Weaver Pro(14B), Weaver Ultra(34B) 등 다양한 크기의 모델로 구성되어 있으며, 응답 품질과 계산 비용의 균형을 위해 쿼리 복잡도에 따라 동적으로 배치됩니다.
- 언어 모델의 글쓰기 능력을 평가하기 위해 신중하게 만들어진 벤치마크에서 모든 크기의 'Weaver' 모델이 그들보다 훨씬 큰 범용 언어 모델들을 능가합니다.
- 특히 가장 능력이 뛰어난 Weaver Ultra 모델은 GPT-4와 같은 최신 범용 언어 모델들을 다양한 글쓰기 시나리오에서 능가하여 글쓰기 목적의 전문화된 언어 모델의 장점을 보여줍니다.
- 'Weaver'는 검색 강화 생성(Retrieval-Augmented Generation, RAG) 및 함수 호출(도구 사용)을 자연스럽게 지원합니다.
- 외부 지식 베이스, 도구 또는 API의 통합 및 개인화된 글쓰기 지원을 포함하여 이러한 기능을 활용한 다양한 사용 사례를 제시합니다.
- 또한, 특정 분야의 언어 모델을 사전 훈련 및 미세 조정하기 위한 가이드라인과 모범 사례를 논의하고 요약합니다.

### [BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation](https://arxiv.org/abs/2401.17053)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/CLwf9axTgbahkQa-4f7Gd.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/CLwf9axTgbahkQa-4f7Gd.mp4" muted="false"></video></div>

Vote: 17

Authors: Senbo Wang, Han Yan, Taizhang Shang, Zhennan Wu, Ruikai Cui, Weizhe Liu, Hongdong Li, Pan Ji, Yang Li, Weixuan Sun, Hiroyuki Sato

- BlockFusion은 확장 가능한 3D 장면을 생성하고 새로운 블록을 원활하게 추가하는 확산 기반 모델을 제시합니다.
- 이 모델은 전체 3D 장면 메시에서 무작위로 잘려진 3D 블록의 데이터셋을 사용하여 훈련됩니다.
- 훈련된 모든 블록은 기하학적 특징을 갖춘 삼중 평면을 포함한 혼합 신경 망상으로 변환되고, 다중 퍼셉트론(MLP)을 통해 서명된 거리 값들을 디코딩합니다.
- 삼중 평면을 잠재 삼중 평면 공간으로 압축하기 위해 변이 오토인코더가 사용됩니다.
- 잠재 표현에 적용된 확산 과정을 통해 고품질 및 다양한 3D 장면 생성이 가능합니다.
- 장면을 확장할 때는 기존 장면과 겹치는 빈 블록을 추가하기만 하고, 기존 잠재 삼중 평면을 확장하여 새로운 블록에 채웁니다.
- 확산 과정에서 교차하는 삼중 평면의 특성 샘플을 조건으로 하는 것은 시맨틱이고 기하학적 의미가 있는 일관된 전이를 생성합니다.
- 2D 레이아웃 조건 부여 메커니즘은 장면 요소의 배치와 정렬을 제어하는 데 사용됩니다.
- 실험 결과에 의하면, BlockFusion은 실내 및 실외 환경 모두에서 세부적이고 일관성 있는 무한한 크기의 3D 장면을 생성할 수 있음을 확인했습니다.

### [YOLO-World: Real-Time Open-Vocabulary Object Detection](https://arxiv.org/abs/2401.17270)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/xqQR8OqrNHD3a0F32v1pW.png)

Vote: 15

Authors: Wenyu Liu, Ying Shan, Lin Song, Xinggang Wang, Yixiao Ge, Tianheng Cheng

- YOLO(World) 시리즈의 탐지기가 효율적이고 실용적인 도구로 자리잡고 있지만, 사전에 정의되고 훈련된 객체 범주에 대한 의존성으로 인해 열린 시나리오에서의 적용성이 제한됩니다.
- 이러한 제한을 해결하기 위해, YOLO-World는 대규모 데이터셋에서의 비전-언어 모델링 및 사전 훈련을 통해 YOLO에 개방 어휘 탐지 기능을 개선하는 혁신적인 접근 방식을 제시합니다.
- 본 논문은 시각적 및 언어적 정보 간의 상호 작용을 용이하게 하는 새로운 재파라메터화 가능한 비전-언어 경로 집계 네트워크(RepVL-PAN)와 영역-텍스트 대조 손실을 제안합니다.
- 우리의 방법은 다양한 객체를 제로샷 방식으로 탐지하는 데 있어서 높은 효율성으로 뛰어난 성능을 보여줍니다.
- 도전적인 LVIS 데이터셋에서 YOLO-World는 V100에서 35.4 AP를 달성하며 52.0 FPS 속도로, 정확성과 속도 측면에서 많은 최신 방법들을 능가합니다.
- 미세 조정된 YOLO-World는 객체 탐지 및 개방 어휘 인스턴스 분할을 포함한 여러 다운스트림 작업에서 뛰어난 성능을 달성합니다.

### [Repositioning the Subject within Image](https://arxiv.org/abs/2401.16861)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Lgc5Q_GlMhBz-WLBUdXtz.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Lgc5Q_GlMhBz-WLBUdXtz.mp4" muted="false"></video></div>

Vote: 12

Authors: Chenjie Cao, Qiaole Dong, Yikai Wang, Yanwei Fu, Yifan Li

- 현재의 이미지 조작은 특정 영역 교체나 전체 스타일 변경과 같은 정적 조작에 주로 집중되어 있다.
- 본 논문에서는 새로운 동적 조작 과제인 주체 재배치(dynamic manipulation task, subject repositioning)를 소개한다. 이는 사용자가 지정한 주체를 원하는 위치로 이동시키면서 이미지의 신뢰도를 유지하는 과제이다.
- 우리의 연구는 주체 재배치의 기본 하위 과제들을 통합된, 프롬프트 안내 inpainting 과제로 효과적으로 재구성함을 밝힌다.
- 이러한 하위 과제들은 주체가 재배치되면서 생기는 빈 공간을 채우고, 가려진 주체 부분을 재구성하며, 주변 영역과 일관되게 주체를 혼합하는 것을 포함한다.
- 단일 확산 생성 모델(diffusion generative model)을 사용하여 우리가 제안한 과제 반전 기술을 통해 학습한 다양한 과제 프롬프트를 사용하여 이러한 하위 과제들을 해결할 수 있다.
- 또한, 우리는 주체 재배치의 품질을 더욱 향상시키기 위해 전처리 및 후처리 기술을 통합한다.
- 이러한 요소들을 함께 SEgment-gEnerate-and-bLEnd(SEELE) 프레임워크를 구성한다.
- SEELE의 주체 재배치에 대한 효과성을 평가하기 위하여, 우리는 'ReS'라는 실세계 주체 재배치 데이터셋을 구성한다.
- ReS에서의 결과는 재배치된 이미지 생성의 품질을 입증한다.

### [Transfer Learning for Text Diffusion Models](https://arxiv.org/abs/2401.17181)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/5qIudcXNRrZHgpKFK3RPx.png)

Vote: 12

Authors: Noah Constant, Noah Fiedel, Aditya Barua, Kehang Han, Kathleen Kenealy

- 이 보고서에서는 큰 언어 모델(LLMs)의 훈련과 배치 시 자동회귀(AR) 디코딩을 텍스트 확산으로 대체할 수 있는 가능성을 탐구합니다.
- 'AR2Diff'라고 부르는 가벼운 적응 절차를 통해 사전 훈련된 AR 모델을 텍스트 확산 모델로 변환할 수 있는지 특히 관심이 있습니다.
- 텍스트 확산 모델 훈련을 위한 강력한 베이스라인 환경을 설정한 후, 여러 아키텍처와 사전 훈련 목표를 비교합니다.
- 접두사 LM 목표를 가진 디코더-오직 모델을 훈련시키는 것이 여러 작업에서 최고 혹은 거의 최고의 성능을 보였다는 결론을 내립니다.
- 이러한 발견을 바탕으로, 텍스트 확산 모델을 위한 다양한 전이 학습 설정을 시험합니다.
- 기계 번역에서는 텍스트 확산이 표준 AR 접근법보다 성능이 낮았다는 것을 발견했습니다.
- 그러나 코드 합성과 추출적 QA에서, 처음부터 훈련된 확산 모델들이 많은 경우에서 AR 모델들을 초과하는 성능을 보였습니다.
- 또한, AR 모델을 확산 디코딩을 사용하도록 적응시키는 AR2Diff로부터 품질 향상을 관찰하였습니다.
- 텍스트 확산이 상대적으로 덜 탐구되었고 긴 텍스트 생성에 대해 AR 디코딩보다 상당히 빠를 수 있기 때문에 이러한 결과는 약속적입니다.

### [StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis](https://arxiv.org/abs/2401.17093)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/W-h6Xvj_WpR_OSSda21nz.png)

Vote: 11

Authors: Chenfei Wu, Yu Liu, Nan Duan, Shengming Yin, Lijuan Wang, Mingheng Ni, Juntao Li, Zekai Zhang, Zecheng Tang, Zicheng Liu, Zhengyuan Yang

- 기존 방식은 래스터 이미지 정보를 시각 모듈을 통해 이산 그리드 토큰으로 변환하여 시각 장면의 진정한 의미 표현을 포착하는 능력에 제한이 있었다.
- 이 연구는 이미지의 다른 표현 방식인 벡터 그래픽이 더 자연스럽고 의미론적으로 일관된 이미지 정보 분할을 가능하게 하여 이 제한을 극복할 수 있다고 제안한다.
- 벡터 그래픽에 대한 '스트로크 토큰'이라는 새로운 시각 표현 방식을 탐구하는 선도적인 작업인 StrokeNUWA를 소개하며, 이는 시각 의미론적으로 풍부하고, LLM(대규모 언어 모델)과 자연스럽게 호환되며, 높은 압축률을 가진다.
- StrokeNUWA는 벡터 그래픽 생성 작업에 있어서 전통적인 LLM 기반 및 최적화 기반 방법들을 다양한 척도에서 크게 능가한다.
- 또한, StrokeNUWA는 이전 방법들에 비해 추론 속도에서 최대 94배 빠른 성능을 달성하며, SVG 코드 압축률은 6.9%에 달한다.

### [Proactive Detection of Voice Cloning with Localized Watermarking](https://arxiv.org/abs/2401.17264)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/VUKYn20STNoo0V5amw1lR.png)

Vote: 11

Authors: Teddy Furon, Alexandre Défossez, Pierre Fernandez, Robin San Roman, Tuan Tran, Hady Elsahar

- 음성 생성 모델의 급속한 발전에 따라, 음성 복제의 위험에 대한 오디오 진위성을 확보할 필요성이 증가하고 있습니다.
- 'AudioSeal'은 AI 생성 음성을 국소적으로 탐지하기 위해 특별히 설계된 최초의 오디오 워터마킹 기술을 제시합니다.
- AudioSeal은 생성기/탐지기 아키텍처를 샘플 수준까지 국소적인 워터마크 탐지를 가능하게 하는 지역화 손실과 함께 훈련시킵니다.
- 새로운 지각적 손실은 청각 마스킹에 영감을 받아 AudioSeal이 더 나은 불가시성을 달성할 수 있도록 합니다.
- AudioSeal은 실제 오디오 조작에 대한 견고함과 자동 및 인간 평가 지표에 기반한 불가시성 면에서 최첨단 성능을 달성합니다.
- 또한, AudioSeal은 대규모 및 실시간 애플리케이션에 이상적인 속도로 탐지를 수행하는 빠른, 단일 통과 탐지기를 가지고 있으며, 기존 모델의 속도를 훨씬 뛰어넘습니다.

### [OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer](https://arxiv.org/abs/2401.16658)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/HIF5XPc8HvFUbMyIyvCX1.png)

Vote: 9

Authors: Yui Sudo, Jee-weon Jung, Yifan Peng, William Chen, Siddhant Arora, Kwanghee Choi, Brian Yan, Muhammad Shakeel, Jiatong Shi, Xuankai Chang, Shinji Watanabe, Jinchuan Tian

- 최근 연구들은 투명함과 개방된 과학을 촉진하기 위해 완전히 개방된 토대 모델을 옹호해 왔다.
- 초기 단계로서, Open Whisper-style Speech Model(OWSM)은 공개 데이터와 오픈소스 도구를 사용하여 OpenAI의 Whisper를 재현했다.
- 이전 OWSM v1에서 v3 모델들은 여전히 Transformer에 기반하고 있었지만, 이는 다른 최신 음성 인코더에 비해 성능이 낮을 수 있다.
- 본 연구에서는 추가적인 훈련 데이터 없이 OWSM의 성능과 효율성을 향상시키고자 한다.
- 본 논문은 100M 및 1B 두 가지 규모의 E-Branchformer 기반 OWSM v3.1 모델을 제시한다.
- 1B 모델은 공개된 가장 큰 E-Branchformer 기반의 음성 모델이며 이전 OWSM v3보다 더 좋은 성능을 다수의 평가 벤치마크에서 보여준다.
- 이 모델은 최대 25% 빠른 추론 속도를 달성하며 성능에서도 우수함을 입증한다.
- 데이터 준비 스크립트, 사전 훈련된 모델 및 훈련 로그들을 공개적으로 공유한다.

### [Weak-to-Strong Jailbreaking on Large Language Models](https://arxiv.org/abs/2401.17256)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/HGmvvHi9qDTpuE249bHYE.png)

Vote: 9

Authors: Lei Li, William Yang Wang, Tianyu Pang, Xianjun Yang, Chao Du, Xuandong Zhao, Yu-Xiang Wang

- 대규모 언어 모델(LLM)을 조정하는 데 상당한 노력이 기울여졌음에도 불구하고, 상대적인 적들이 악의적인 프롬프트, 조정 또는 디코딩을 통해 이런 모델들의 보안을 해제할 수 있다는 보고가 있다.
- 연구팀은 조정된 LLM들의 보안 해제 취약점을 조사한 결과, 해제된 모델과 조정된 모델 사이의 디코딩 분포는 초기 생성에서만 차이가 난다는 것을 발견했다.
- 이러한 관찰을 바탕으로 연구팀은, 공격자들이 더 작은 안전형/조정된 LLM(예: 7B)을 사용하여 훨씬 더 큰 조정된 LLM(예: 70B)에 대한 보안 해제를 유도할 수 있는 약-to-강 보안 해제 공격을 제안한다.
- 보안 해제를 위해 공격자는 큰 LLM을 디코딩하는 것에 비해 최소한의 연산과 지연만을 포함하여 두 개의 작은 LLM을 한 번만 추가로 디코딩하면 된다.
- 이 공격의 효과는 다른 세 기관의 다섯 가지 모델을 대상으로 한 실험을 통해 입증되었다.
- 해당 연구는 대규모 언어 모델을 조정할 때 고려해야 할 시급한 안전 문제를 드러내며, 아직은 도전적인 고급 방어 전략 수립을 위한 첫 시도로서 방어 전략을 제안한다.
- 이 방법을 복제하기 위한 코드는 https://github.com/XuandongZhao/weak-to-strong 에서 이용할 수 있다.

### [H2O-Danube-1.8B Technical Report](https://arxiv.org/abs/2401.16818)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/VpOXsuLx5gdgEaMrFsB2H.png)

Vote: 8

Authors: Philipp Singer, Sri Satish Ambati, Maximilian Jeblick, Yauhen Babakhin, Pascal Pfeiffer, Nischay Dhankhar, Gabor Fodor

- 본 논문에서는 LLama 2와 Mistral의 핵심 원칙을 따라 1조 토큰에 대해 훈련된 18억 언어 모델인 H2O-Danube-1.8B를 소개합니다.
- 동일한 크기의 참조 모델에 비해 상당히 적은 총 토큰으로 훈련되었음에도 불구하고, 다양한 벤치마크에서 경쟁력 있는 지표를 보여줍니다.
- 감독되는 미세조정에 이어 직접 선호 최적화 과정을 거친 챗봇 모델도 함께 발표합니다.
- H2O-Danube-1.8B는 Apache 2.0 라이선스하에 공개되어 경제적으로 더 넓은 대중에게 대규모 언어 모델을 민주화하는 데 기여합니다.

### [High-Quality Image Restoration Following Human Instructions](https://arxiv.org/abs/2401.16468)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/LcYTRUYm5nZgnoebUuAqA.png)

Vote: 7

Authors: Marcos V. Conde, Radu Timofte, Gregor Geigle

- 이미지 복원은 저하된 관찰로부터 고품질의 깨끗한 이미지를 복구하는 기본적인 문제입니다.
- 본 연구에서는 인간이 작성한 지시문을 사용하여 이미지 복원 모델을 안내하는 첫 번째 접근법을 제시합니다.
- 자연어 프롬프트를 주어, 우리의 모델은 다양한 유형의 저하를 고려하여 저하된 이미지로부터 고품질 이미지를 복구할 수 있습니다.
- 이 방법인 InstructIR은 이미지 노이즈 제거, 디레이닝, 디블러링, 디헤이징 및 (저조도) 이미지 향상을 포함한 여러 복원 작업에서 최신 기술의 성능을 달성합니다.
- InstructIR은 이전의 모든 기능을 갖춘 복원 방법들보다 +1dB의 향상을 이루었습니다.
- 우리의 데이터셋과 결과는 텍스트 기반 이미지 복원 및 향상에 대한 새로운 연구를 위한 새로운 벤치마크를 제시합니다.
- 우리의 코드, 데이터셋 및 모델은 https://github.com/mv-lab/InstructIR 에서 사용할 수 있습니다.

### [ReGAL: Refactoring Programs to Discover Generalizable Abstractions](https://arxiv.org/abs/2401.16467)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/IIt3ICqfv54muDzm3XcZ7.png)

Vote: 6

Authors: Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal

- 대규모 언어 모델은 프로그램 생성에 사용되고 있지만 유용한 추상화를 개발하는 데 필요한 전체적인 관점이 부족하여 중복된 기능을 여러 번 예측하곤 한다.
- 중복 코드 생성은 비효율적이며 오류가 발생하기 쉽다.
- 이 문제를 해결하기 위해 'ReGAL'이라는 기존 프로그램에서 재사용 가능한 함수 라이브러리를 학습하는 그래디언트-프리(refactorization) 방법을 제안한다.
- ReGAL은 실행 결과를 변경하지 않고 코드를 재구조화하는 방식을 통해 작은 프로그램 집합에서 학습하며, 실행을 통해 추상화를 점진적으로 검증하고 정제한다.
- ReGAL이 발견한 공유된 함수 라이브러리는 다양한 도메인에서 프로그램을 예측하기 쉽게 만든다.
- 세 데이터셋(LOGO 그래픽 생성, 날짜 추론, TextCraft라는 마인크래프트 기반 텍스트 게임)에서, 오픈 소스 및 상용 대규모 언어 모델의 정확도가 ReGAL 함수를 사용할 때 개선되었다.
- CodeLlama-13B의 경우, ReGAL은 그래픽에서 11.5%, 날짜 이해에서 26.1%, 그리고 TextCraft에서 8.1%의 절대 정확도 상승을 보여주었으며, 세 영역 중 두 곳에서 GPT-3.5를 능가했다.
- ReGAL의 추상화는 자주 사용되는 서브루틴과 환경 동작을 포괄하는 것으로 나타났다.

### [MouSi: Poly-Visual-Expert Vision-Language Models](https://arxiv.org/abs/2401.17221)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/8oknQWM-H8aEDdJO1V3Fe.png)

Vote: 4

Authors: Shuo Li, Shihan Dou, Junjie Ye, Tao Ji, Changhao Jiang, Xuanjing Huang, Rui Zheng, Sirui Song, Boyang Hong, Zhiheng Xi, Xipeng Qiu, Lu Chen, Caishuang Huang, Ming Zhang, Xiaoran Fan, +, Qi Zhang, Senjie Jin, Tao Gui, Hang Yan, Yuhao Zhou, Guodong Zheng, Junke Wang

- 현재 대규모 시각-언어 모델(VLMs)은 단일 시각 구성요소의 능력 부족과 너무 긴 시각 토큰으로 인해 정확한 복잡한 시각 정보 해석에 어려움을 겪고 있다.
- 이러한 문제를 해결하기 위해, 본 논문에서는 이미지-텍스트 매칭, OCR, 이미지 세분화 등에 능숙한 다양한 시각 인코더들의 능력을 결합하는 앙상블 전문가 기술을 제안한다.
- 이 기술은 다양한 시각 전문가들의 출력을 통합하고 이미지 인코더들과 미리 학습된 LLMs 사이의 연결을 강화하는 융합 네트워크를 도입한다.
- 또한, 긴 이미지 특성 시퀀스로 인한 위치 인코딩의 낭비를 줄이는 다양한 위치 인코딩 체계를 탐구함으로써, 위치 오버플로우와 길이 제한 문제를 효과적으로 해결한다.
- 예를 들어, 이 기술을 적용하여 SAM 모델의 위치 점유율을 4096에서 훨씬 더 효율적으로 관리 가능한 64 또는 1로 대폭 감소시켰다.
- 실험 결과는 다중 전문가를 갖춘 VLMs가 단독 시각 인코더보다 일관되게 우수한 성능을 보여주고, 더 많은 전문가가 통합될수록 성능이 크게 향상됨을 입증한다.
- 본 연구 보고서에서 사용된 훈련 코드는 오픈소스로 제공되며, 모든 자원은 프로젝트 웹사이트에서 찾아볼 수 있다.

### [T3: Transparent Tracking & Triggering for Fine-grained Overlap of Compute & Collectives](https://arxiv.org/abs/2401.16677)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/CFhzmbu9acItzdkH1M722.png)

Vote: 1

Authors: Shaizeen Aga, Nuwan Jayasena, Mahzabeen Islam, Matthew D. Sinclair, Suchita Pati

- 분산 기법은 대형 언어 모델의 학습 및 추론에 점점 더 의존하고 있으며, 이러한 기법은 장치 간 통신을 필요로 하여 장치의 수가 증가함에 따라 확장 효율성을 저하시킨다.
- 텐서 병렬성(Tensor Parallelism, TP)과 같은 일부 기술은 모델 실행과 통신을 직렬화 시켜서, 소프트웨어에서의 세밀한 통신과 계산의 중첩이 어려워진다.
- 이러한 문제를 극복하기 위해, T3는 하드웨어-소프트웨어 공동 설계를 활용하여 계산과 통신 간의 자원 공유로 인한 자원 경쟁을 최소화하면서 직렬화된 통신을 투명하게 중첩시킨다.
- T3는 생산자 연산을 후속 통신과 투명하게 퓨즈하며, 생산자의 출력 주소 공간을 간단히 구성함으로써 소프트웨어 변경을 최소화한다.
- 하드웨어 수준에서 T3는 가벼운 추적 및 트리거 메커니즘을 추가하여 생산자의 계산 및 통신을 조율하며, 통신을 위해 계산-향상된 메모리를 사용한다.
- 결과적으로 T3는 자원 경쟁을 줄이며, 계산과 직렬화된 통신을 효과적으로 중첩시켜 Transformer 모델에서 중요한 성과를 달성한다.
- T3는 T-NLG와 같은 트랜스포머 모델의 통신 집약적인 하위 레이어에서 평균 30% (최대 47%)의 속도 향상 및 데이터 이동을 평균 22% (최대 36%) 감소시켰다.
- 또한, T3는 모델이 확장됨에 따라 그 이점이 지속되며, 5000억 개의 파라미터 모델인 PALM과 MT-NLG의 하위 레이어에서 평균 29%의 개선을 보여준다.

