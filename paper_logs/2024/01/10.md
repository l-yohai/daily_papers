## Daily Papers (2024-01-10)

### [MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation](https://arxiv.org/abs/2401.04468)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/UTsPPOJFHtKOgZDLdcI-x.png)

Vote: 24

Authors: Weimin Wang, Jiawei Liu, Zhijie Lin, Zhijie Lin, Jiangqiao Yan, Jiangqiao Yan, Shuo Chen, Chetwin Low, Chetwin Low, Tuyen Hoang, Jie Wu, Jun Hao Liew, Jun Hao Liew, Hanshu Yan, Hanshu Yan, Daquan Zhou, Daquan Zhou, Jiashi Feng

- 본 논문에서는 텍스트 기반의 이미지 모델, 비디오 동작 생성기, 참조 이미지 임베딩 모듈 및 프레임 보간 모듈을 통합하여 종단간 비디오 생성 파이프라인인 MagicVideo-V2를 소개합니다.
- 이 아키텍처 설계 덕분에 MagicVideo-V2는 높은 해상도와 높은 심미성을 갖춘 매끄럽고 신뢰성 있는 비디오를 생성할 수 있습니다.
- 사용자 평가를 통해 MagicVideo-V2는 Runway, Pika 1.0, Morph, Moon Valley 및 Stable Video Diffusion 모델과 같은 선도하는 텍스트-비디오 시스템들을 뛰어넘는 성능을 보여줍니다.

### [Masked Audio Generation using a Single Non-Autoregressive Transformer](https://arxiv.org/abs/2401.04577)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DfwseQQErYPa8Ni225r52.png)

Vote: 16

Authors: Alon Ziv, Alon Ziv, Itai Gat, Itai Gat, Gael Le Lan, Tal Remez, Tal Remez, Felix Kreuk, Felix Kreuk, Alexandre Défossez, Alexandre Défossez, Jade Copet, Jade Copet, Gabriel Synnaeve, Gabriel Synnaeve, Yossi Adi, Yossi Adi

- 이 논문은 여러 오디오 토큰 스트림에 직접 작동하는 밀막 생성 시퀀스 모델링 방법인 MAGNeT를 소개합니다.
- MAGNeT는 단일 단계 비순차적(non-autoregressive) 트랜스포머로 구성되어 이전 작업들과 다릅니다.
- 훈련 중에는 마스킹 스케줄러에서 얻은 마스킹된 토큰의 스팬을 예측하며, 추론 시 여러 단계의 디코딩을 통해 점진적으로 출력 시퀀스를 구성합니다.
- 생성된 오디오의 품질을 향상시키기 위해, 외부 사전 훈련된 모델을 사용하여 MAGNeT의 예측값을 다시 점수를 매기고 순위를 매겨 후속 디코딩 단계에 사용하는 새로운 점수 재가산(rescoring) 방법을 도입합니다.
- 또한 MAGNeT의 하이브리드 버전이 탐색되어, 처음 몇 초를 순차적으로 생성하고 나머지 시퀀스는 병렬로 디코딩하는 자동 회귀 모델과 비자동 회귀 모델 간의 결합을 실험합니다.
- MAGNeT의 효율성은 텍스트-음악 및 텍스트-오디오 생성 과제에서 검증되며, 객관적인 지표와 인간 연구를 고려한 광범위한 실증 평가를 수행합니다.
- 제안된 접근 방식은 평가된 베이스라인과 경쟁력 있는 성능을 보이면서도 (자동 회귀 베이스라인보다 7배 빠른) 매우 빠른 속도를 자랑합니다.
- 추가적인 분석을 통해 MAGNeT을 구성하는 각 요소의 중요성과 자동 회귀 모델링 및 비자동 회귀 모델링 간의 트레이드오프(대기 시간, 처리량 및 생성 품질을 고려)를 밝힙니다.
- 데모 페이지(https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT)에서 생성된 오디오 샘플을 들을 수 있습니다.

### [Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models](https://arxiv.org/abs/2401.04658)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/za9K33hI3IwvcHme4EkIM.png)

Vote: 11

Authors: Zhen Qin, Zhen Qin, Weigao Sun, Weigao Sun, Dong Li, Dong Li, Xuyang Shen, Xuyang Shen, Weixuan Sun, Weixuan Sun, Yiran Zhong, Yiran Zhong

- 선형 주의(Linear attention)는 최근 전통적인 소프트맥스 주의(Softmax attention)에 대안으로 떠오르는 효율적인 주의 메커니즘으로, 이론적으로 선형의 연산 복잡성으로 토큰을 처리하는 능력을 가지고 있으며, 고정된 메모리 소비에 관계없이 다양한 시퀀스 길이에 대해 일정한 훈련 속도를 유지할 수 있습니다.
- 그러나 누적 합계(cumsum) 문제로 인해 현재의 선형 주의 알고리즘은 인과적 상황에서 이론적 우위를 발휘할 수 없습니다.
- 본 논문에서는 선형 주의가 이론적 연산 이점을 실현할 수 있도록 하는 첫 번째 선형 주의 구현인 Lightning Attention-2를 제시합니다.
- 이를 위해, 선형 주의 계산에서 블록 내부(intra-block)와 블록 간(inter-block) 구성 요소를 별도로 다루는 타일링 사고를 활용합니다.
- 블록 내부에서는 전통적인 주의 계산 메커니즘을 적용하고 블록 간에는 선형 주의 커널 트릭을 적용합니다.
- GPU 하드웨어를 최대한 활용하기 위해 전방향(forward) 및 역방향(backward) 절차에 걸쳐 타일링 기술을 채택합니다.
- 또한, 입출력(IO) 인식 및 하드웨어 친화적인 방식으로 Triton에서 우리의 알고리즘을 구현했습니다.
- 다양한 모델 크기 및 시퀀스 길이에 대한 실험을 진행한 결과, Lightning Attention-2는 입력 시퀀스 길이에 상관없이 일관된 훈련 및 추론 속도를 유지하며 기타 주의 메커니즘보다 훨씬 빠릅니다.
- 소스 코드는 https://github.com/OpenNLPLab/lightning-attention 에서 확인할 수 있습니다.

### [Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding](https://arxiv.org/abs/2401.04575)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/s7sLVear4Tp9gMaCiU6Cs.png)

Vote: 10

Authors: Yatong Bai, Yatong Bai, Utsav Garg, Utsav Garg, Apaar Shanker, Apaar Shanker, Haoming Zhang, Haoming Zhang, Samyak Parajuli, Samyak Parajuli, Erhan Bas, Erhan Bas, Isidora Filipovic, Amelia N. Chu, Amelia N. Chu, Eugenia D Fomitcheva, Elliot Branson, Elliot Branson, Aerin Kim, Aerin Kim, Somayeh Sojoudi, Kyunghyun Cho, Kyunghyun Cho

- 신경망의 시각 및 시각-언어 어플리케이션을 위해서는 대규모 주석이 달린 데이터셋이 필요하나, 이는 상당한 데이터 수집 과정을 요구하여 연구자와 실무자들이 몇 가지 선택지에 제한되는 문제가 있습니다.
- 이러한 문제를 해결하기 위해, 저희는 상업 쇼핑 웹사이트에서 깨끗하고, 정보가 풍부하며, 매끄러운 데이터를 수집하고 주석을 달아 'Let's Go Shopping (LGS)' 데이터셋을 소개합니다.
- 공개적으로 이용 가능한 전자상거래 웹사이트로부터 총 1500만 개의 이미지-캡션 쌍을 포함하는 이 대규모 공개 데이터셋은 배경이 덜 복잡하고 전경 객체에 초점을 맞춘 이미지를 제공합니다.
- LGS 데이터셋으로 실험한 결과, 기존 벤치마크 데이터셋에서 훈련된 분류기는 전자상거래 데이터에 즉시 일반화되지 않으나, 특정 자기지도 학습 방식의 시각 특징 추출기는 더 나은 일반화 능력을 보였습니다.
- 또한 LGS는 고품질의 전자상거래 중심 이미지들과 이모달(bimodal) 특성으로 인해, 시각-언어 양방향 작업에 유리하며 이를 통해 이미지-캡션 생성 모델이 더 풍부한 캡션을 생성할 수 있게 하고, 텍스트-이미지 생성 모델이 전자상거래 스타일 전환을 달성하는 데 도움을 줍니다.

### [Jump Cut Smoothing for Talking Heads](https://arxiv.org/abs/2401.04718)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/h9VVa3NBDUNq_kd9QhYsz.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/h9VVa3NBDUNq_kd9QhYsz.mp4" muted="false"></video></div>

Vote: 8

Authors: Xiaojuan Wang, Xiaojuan Wang, Taesung Park, Taesung Park, Yang Zhou, Eli Shechtman, Richard Zhang

- 돌발적이고 원하지 않는 변화를 제공하는 점프 컷을 완화하기 위한 새로운 프레임워크를 제시합니다.
- 토킹 헤드 비디오의 맥락에서 이를 다루며, 비디오 내 다른 소스 프레임의 대상 외형을 미드-레벨 표현인 DensePose 키포인트 및 얼굴 랜드마크에 의해 주도되면서 융합합니다.
- 점프 컷 주변의 마지막 프레임 사이에서 키포인트와 랜드마크를 보간함으로써 움직임을 달성합니다.
- 소스 프레임과 키포인트에서 이미지 변환 네트워크를 사용하여 픽셀을 합성합니다.
- 키포인트에 오류가 있을 수 있으므로, 각 키포인트에 대해 가장 적합한 소스를 선택하고 선택하는 교차 모달 어텐션 방식을 제안합니다.
- 우리의 방법은 강력한 비디오 보간 기준선보다 더 강력한 결과를 달성할 수 있습니다.
- 점프 컷에서 발생하는 충전 단어, 일시 정지, 심지어 무작위 절단과 같은 다양한 점프 컷에서 우리의 방법을 시연합니다.
- 우리의 실험은 토킹 헤드가 점프 컷에서 심하게 회전하거나 이동할 경우에도 매끄러운 전환을 달성할 수 있음을 보여줍니다.

### [Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding](https://arxiv.org/abs/2401.04398)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/t6k-byY94Hycy27sBuGLf.png)

Vote: 8

Authors: Zilong Wang, Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, Chen-Yu Lee, Tomas Pfister

- 대규모 언어 모델(Large Language Models, LLM)을 활용한 테이블 기반 추론이 테이블 이해 과제들을 해결하는 유망한 방향이다.
- 이와 같은 테이블 기반 추론은 자유형식의 질문과 반구조적 태블러 데이터 모두에서 기본 세멘틱스를 추출해야 한다는 요구가 있다.
- Chain-of-Thought 방식은 추론 체인을 텍스트 컨텍스트의 형태로 통합하지만, 이 추론 체인에서 태블러 데이터를 효과적으로 활용하는 방법은 여전히 미해결 문제이다.
- 저자들은 Chain-of-Table 프레임워크를 제안하여, 추론 체인에서 중간 생각을 대신할 수 있는 태블러 데이터를 명시적으로 사용한다.
- 특히, LLM을 이용하여 인-콘텍스트 학습을 통해 작업을 반복적으로 생성하고 테이블을 업데이트하여 테이블 추론 체인을 대표할 수 있도록 유도한다.
- 따라서 LLM은 이전 작업의 결과를 바탕으로 다음 작업을 동적으로 계획할 수 있다.
- 테이블의 지속적인 발전은 주어진 태블러 문제에 대한 추론 과정을 보여주는 체인을 형성한다.
- 이 체인은 중간 결과의 구조화된 정보를 담고 있어 더 정확하고 신뢰할 수 있는 예측을 가능하게 한다.
- Chain-of-Table은 WikiTQ, FeTaQA, 그리고 TabFact 벤치마크에서 다양한 LLM 선택에 걸쳐 새로운 최고 성능을 달성했다.

### [Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers](https://arxiv.org/abs/2401.04695)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/uEAx_Atd2-VvoKf-cbjk9.png)

Vote: 3

Authors: Gal Yona, Gal Yona, Roee Aharoni, Roee Aharoni, Mor Geva, Mor Geva

- 사실적 질문은 종종 서로 다른 수준의 세분성에서 정확하게 대답될 수 있으며, 예를 들어 "바락 오바마는 언제 태어났나요?"라는 질문에 대해 "1961년 8월 4일"뿐만 아니라 "1961년" 모두 올바른 답변이 될 수 있습니다.
- 그러나 기존 질문 응답(QA) 평가 프로토콜은 이러한 사실을 명시적으로 고려하지 않고 단일 세분성 수준의 답변과 예측된 답변을 비교합니다.
- 본 연구에서는 예측된 답변이 다중 세분성 답변 세트와 정확성 및 정보성의 측면에서 평가되는 새로운 평가 설정인 GRANOLA QA를 제안합니다.
- 기존 데이터셋을 다중 세분성 답변으로 풍부하게 하는 간단한 방법론을 제시하고, EntityQuestions 데이터셋의 다중 세분성 버전인 GRANOLA-EQ를 생성했습니다.
- GRANOLA-EQ에서는 모델의 불확실성과 응답 세분성을 일치시키는 새로운 알고리즘인 응답 집계 디코딩(Response Aggregation Decoding, DRAG)을 포함한 다양한 디코딩 방법론을 평가했습니다.
- 실험 결과, 표준 디코딩을 사용하는 대규모 언어 모델은 자주 틀리는 구체적인 답변을 생성하는 경향이 있습니다.
- 반면, 다중 세분성 답변에 대한 평가에서 DRAG은 평균적으로 거의 20포인트의 정확도 향상을 보였으며, 특히 드문 엔터티들에 대해 더욱 증가했습니다.
- 전반적으로, 이는 표준 평가 및 디코딩 방식이 언어 모델에 내재된 지식을 크게 과소평가할 수 있음을 드러냅니다.

### [FADI-AEC: Fast Score Based Diffusion Model Guided by Far-end Signal for Acoustic Echo Cancellation](https://arxiv.org/abs/2401.04283)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/-e0NpWsZ-BImClJDV1J5w.png)

Vote: 2

Authors: Yang Liu, Li Wan, Yun Li, Yiteng Huang, Ming Sun, James Luan, Yangyang Shi, Xin Lei

- 음성 향상에서 확산 모델의 잠재력에도 불구하고 음향 에코 취소(Acoustic Echo Cancellation, AEC)에는 그 활용이 제한되었습니다.
- 본 논문에서는 AEC에 특화된 확산 기반의 확률론적 재생성 접근 방식인 DI-AEC를 최초로 제안합니다.
- 또한, 엣지 디바이스에 적합하게 계산 요구를 절약하는 빠른 점수 기반 확산 AEC 프레임워크인 FADI-AEC를 제안합니다.
- FADI-AEC는 프레임 당 점수 모델을 한 번만 실행하여 처리 효율성을 크게 향상시킬 수 있습니다.
- 본 연구는 원거리 신호를 활용한 새로운 잡음 생성 기술을 도입하여, 원거리 및 근거리 신호 모두를 사용해 점수 모델의 정확도를 개선합니다.
- 제안한 방법은 ICASSP2023 마이크로소프트 딥 에코 취소 챌린지 평가 데이터셋에서 몇몇 엔드-투-엔드 방법들과 다른 확산 기반 에코 취소 방법들보다 우수한 성능을 보여주었습니다.

