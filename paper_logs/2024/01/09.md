## Daily Papers (2024-01-09)

### [Mixtral of Experts](https://arxiv.org/abs/2401.04088)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/j1Qd6ihPI9GXWlclLOVpO.png)

Vote: 86

Authors: Albert Q. Jiang, Albert Q. Jiang, Alexandre Sablayrolles, Alexandre Sablayrolles, Antoine Roux, Antoine Roux, Arthur Mensch, Arthur Mensch, Blanche Savary, Chris Bamford, Chris Bamford, Devendra Singh Chaplot, Devendra Singh Chaplot, Diego de las Casas, Diego de las Casas, Emma Bou Hanna, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, Lucile Saulnier, Marie-Anne Lachaux, Marie-Anne Lachaux, Pierre Stock, Pierre Stock, Sandeep Subramanian, Sandeep Subramanian, Sophia Yang, Sophia Yang, Szymon Antoniak, Szymon Antoniak, Teven Le Scao, Teven Le Scao, Théophile Gervet, +

- Mixtral 8x7B는 Sparse Mixture of Experts(SMoE) 언어 모델을 도입한 새로운 모델로, Mistral 7B의 아키텍처를 따르지만, 각 레이어가 8개의 피드포워드 블록(전문가)으로 구성되어 있습니다.
- 각 토큰에서 라우터 네트워크는 현재 상태를 처리하고 그 출력을 결합할 두 개의 전문가를 선택하며, 선택된 전문가는 각 타임스텝마다 다를 수 있습니다.
- 결과적으로 각 토큰은 47B 파라미터에 접근할 수 있지만, 추론 중에는 단 13B의 활성 파라미터만을 사용합니다.
- 32k 토큰의 문맥 크기로 훈련된 Mixtral은 수학, 코드 생성 및 다국어 벤치마크에서 Llama 2 70B와 GPT-3.5를 능가하거나 맞먹는 성능을 보여줍니다.
- 지시에 따르도록 미세 조정된 모델인 Mixtral 8x7B - Instruct는 인간 벤치마크에서 GPT-3.5 Turbo, Claude-2.1, Gemini Pro, 그리고 Llama 2 70B - 챗 모델을 뛰어넘는 성과를 보입니다.
- 기본 모델과 지시 모델 모두 Apache 2.0 라이선스 하에 공개됩니다.

### [MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://arxiv.org/abs/2401.04081)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/arhkhspbmHKeuYIc2mmKh.png)

Vote: 33

Authors: Maciej Pióro, Maciej Pióro, Kamil Ciebiera, Krystian Król, Jan Ludziejewski, Sebastian Jaszczur

- 순차적 모델링 분야에서 상태 공간 모델(SSM)이 트랜스포머의 지배적 위치에 도전하고 있습니다.
- 동시에 전문가 혼합(Mixture of Experts, MoE)은 최근의 최첨단 오픈 소스 모델을 포함하여 트랜스포머 기반 대규모 언어 모델(LLM) 성능을 획기적으로 개선했습니다.
- 저희는 SSM의 확장 가능성을 개방하기 위해 MoE를 결합할 것을 제안합니다.
- 이를 통해 트랜스포머와 유사한 성능을 달성하는 최신 SSM 기반 모델인 Mamba를 바탕으로 효율적인 적용 사례를 보여줍니다.
- 제안된 모델인 MoE-Mamba는 Mamba와 트랜스포머-MoE 모두를 성능 면에서 능가합니다.
- 특히, MoE-Mamba는 Mamba와 동일한 성능을 달성하면서도 훈련 단계를 2.2배 더 적게 소요하며, Mamba가 트랜스포머에 비해 가진 추론 성능 이점을 유지합니다.

### [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM](https://arxiv.org/abs/2401.02994)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/4PpM1Gxw0hKboNaIzrk5a.png)

Vote: 25

Authors: Xiaoding Lu, Xiaoding Lu, Adian Liusie, Adian Liusie, Vyas Raina, Vyas Raina, Yuwen Zhang, Yuwen Zhang, William Beauchamp, William Beauchamp

- 대화형 AI 연구에서는 ChatGPT와 같은 대규모 모델을 개발하는 경향이 있으나, 이는 상당한 계산 자원과 메모리를 요구합니다.
- 본 연구는 더 작은 모델들의 조합이 단일 대형 모델과 비등하거나 더 나은 성능을 달성할 수 있는지에 대한 중요한 질문을 탐구합니다.
- "블렌딩"이라고 하는 여러 대화형 AI 모델을 통합하는 간단하면서도 효과적인 접근 방식을 소개합니다.
- 특정 작은 모델들(6B/13B 매개변수)을 시너지적으로 혼합했을 때, ChatGPT(175B+ 매개변수)와 같은 훨씬 큰 모델의 성능 메트릭스를 능가하거나 맞출 수 있는 잠재력이 있음을 실증적 증거는 제안합니다.
- 이 가설은 Chai 연구 플랫폼에서 대규모 사용자 기반으로 30일 동안 실시한 A/B 테스트 방법론을 사용하여 엄격히 검토되었습니다.
- 연구 결과는 "블렌딩" 전략이 대화형AI의 효과를 향상시키는 동시에 계산 요구 사항을 증가시키지 않는 실현 가능한 접근법으로서의 잠재력을 강조합니다.

### [GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation](https://arxiv.org/abs/2401.04092)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ymmeVDhJSlBHBX0kBI58Z.png)

Vote: 10

Authors: Tong Wu, Guandao Yang, Guandao Yang, Zhibing Li, Zhibing Li, Kai Zhang, Kai Zhang, Ziwei Liu, Ziwei Liu, Leonidas Guibas, Dahua Lin, Dahua Lin, Gordon Wetzstein

- 텍스트로부터 3D를 생성하는 방법이 발전하고 있음에도 불구하고, 신뢰할 수 있는 평가 지표의 부재가 눈에 띈다.
- 기존의 평가 방식들은 텍스트와 자산의 일치성 같은 단일 기준에 집중하며 다른 평가 기준이나 인간의 선호도와 잘 맞지 않는 경우가 많다.
- 사용자 선호도 연구는 적응성과 인간 중심 결과를 제공하지만, 규모를 키울 경우 비용이 많이 든다.
- 본 논문에서는 텍스트로부터 3D 생성 모델을 위한 자동, 다재다능하며 인간 중심의 평가 지표를 소개한다.
- 이를 위해 GPT-4V를 사용하여 평가 촉진(prompts) 생성기를 개발하며 이는 3D 모델 비교에 사용되는 입력값으로 작용한다.
- 또한, 사용자 정의 기준에 따라 GPT-4V가 두 3D 자산을 비교하는 방법을 설계한다.
- 이러한 쌍대 비교 결과를 사용하여 모델들에게 엘로(Elo) 등급을 부여한다.
- 실험 결과는 우리의 평가 지표가 다양한 평가 기준에 걸쳐 인간의 선호도와 강하게 일치함을 제안한다.

### [DiarizationLM: Speaker Diarization Post-Processing with Large Language Models](https://arxiv.org/abs/2401.03506)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/LC5oryAGvz85jooNfQMGk.gif)

Vote: 9

Authors: Quan Wang, Quan Wang, Yiling Huang, Guanlong Zhao, Evan Clark, Wei Xia, Hank Liao, Hank Liao

- 본 논문에서는 DiarizationLM이라는 프레임워크를 소개하며 이를 통해 대규모 언어 모델(LLM)을 이용하여 화자 구분 시스템의 결과를 후처리하는 방법을 제안한다.
- 제안된 프레임워크는 대본의 가독성 향상 또는 단어 화자 구분 오류율(WDER) 감소와 같은 다양한 목표를 달성할 수 있다.
- 자동 음성 인식(ASR) 및 화자 구분 시스템의 출력물을 포함하는 간결한 텍스트 형식을 구성하여, 선택적으로 세부 튜닝된 LLM에 프롬프트로 제공한다.
- LLM의 출력물은 원하는 개선을 포함하는 정제된 화자 구분 결과로 사용될 수 있다.
- 이 프레임워크는 기존 구성 요소를 재훈련할 필요 없이 모든 상용 ASR 및 화자 구분 시스템에 쉽게 적용될 수 있는 후처리 단계이다.
- 실험 결과, 파인튜닝된 PaLM 2-S 모델은 Fisher 전화 통화 데이터셋에서 상대적으로 25.9%, Callhome 영어 데이터셋에서 상대적으로 31%의 WDER를 감소시켜 효과를 입증하였다.

### [Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon](https://arxiv.org/abs/2401.03462)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/oj1jmJ60kzxVSNSEaaGGK.png)

Vote: 9

Authors: Peitian Zhang, Peitian Zhang, Zheng Liu, Shitao Xiao, Shitao Xiao, Ninglu Shao, Ninglu Shao, Qiwei Ye, Qiwei Ye, Zhicheng Dou

- 대규모 언어 모델은 제한된 컨텍스트 윈도우 길이 때문에 긴 컨텍스트를 활용하는데 큰 도전을 직면하고 있습니다.
- 이 연구에서는 LLM의 원시 활성화를 더욱 간결한 형태로 압축하는 'Activation Beacon'을 제안하여 제한된 컨텍스트 윈도우를 가지고도 훨씬 긴 컨텍스트를 인식할 수 있도록 합니다.
- Activation Beacon은 LLM에 플러그 앤 플레이 모듈로 도입되어 짧은 컨텍스트에서의 LLM의 기존 능력을 완전히 보존하면서 긴 컨텍스트 처리 능력을 확장합니다.
- 또한, 긴 컨텍스트를 처리하기 위해 짧은 슬라이딩 윈도우를 사용하며 이는 훈련과 추론에서 경쟁력 있는 메모리 및 시간 효율성을 달성합니다.
- 다양한 압축 비율을 갖는 비컨의 혼합 조건에서 자기 회귀 작업을 통해 학습되는 Activation Beacon은 단기 시퀀스 데이터만으로 10K 스텝으로 9시간 미만 소요되며 단일 8xA800 GPU 머신에서 효율적으로 훈련됩니다.
- 실험적 연구에 의하면, Activation Beacon은 Llama-2-7B의 컨텍스트 길이를 100배 확장할 수 있으며(4K에서 400K로), 긴 컨텍스트 생성 및 이해 작업에서 뛰어난 결과를 달성합니다.
- 해당 모델과 코드는 BGE 저장소에서 제공될 예정입니다.

### [CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution](https://arxiv.org/abs/2401.03065)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/D_AyKIXDE2z1IWNeltG5-.png)

Vote: 8

Authors: Alex Gu, Alex Gu, Baptiste Rozière, Baptiste Rozière, Hugh Leather, Armando Solar-Lezama, Gabriel Synnaeve, Gabriel Synnaeve, Sida I. Wang, Sida I. Wang

- CRUXEval은 파이썬 함수 800개로 이루어진 벤치마크를 제시하며, 각 함수는 입력-출력 쌍을 포함하여 두 가지 자연스러운 작업인 입력 예측과 출력 예측을 수행할 수 있습니다.
- 이 연구는 미래의 벤치마크 변형 생성을 위한 실행 벤치마크를 생성하는 일반적인 방법을 제안합니다.
- 이 연구는 CRUXEval에서 스물 가지 코드 모델을 평가하고, HumanEval에서 높은 점수를 받은 많은 최신 모델들이 같은 개선을 보이지 않는다는 것을 발견합니다.
- 그들은 간단한 CoT(Chain of Thought)과 미세조정 방식이 벤치마크 성능을 향상시킬 수 있으나 아직 완전히 해결되지는 않았음을 보여줍니다.
- 최고의 설정인 GPT-4와 사고의 연쇄(CoT)는 입력 예측에서 75%, 출력 예측에서 81%의 pass@1을 달성하지만, Code Llama 34B는 각각 50%와 46%의 pass@1을 달성하여 개방형 및 폐쇄형 모델 간의 격차를 강조합니다.
- CRUXEval에서 완벽한 성과를 보이는 모델이 없기 때문에, 연구팀은 간단한 프로그램에서 일관성 있는 GPT-4의 실패 사례를 제공하여 코드 추론 능력과 개선해야 할 영역을 조명합니다.

### [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach](https://arxiv.org/abs/2401.02987)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/rgRKYm42JfVm3g01HKNVT.png)

Vote: 6

Authors: Prince Aboagye, Prince Aboagye, Yan Zheng, Junpeng Wang, Uday Singh Saini, Uday Singh Saini, Xin Dai, Michael Yeh, Michael Yeh, Yujie Fan, Yujie Fan, Zhongfang Zhuang, Shubham Jain, Liang Wang, Wei Zhang

- 이 연구에서는 사전 훈련된 모델들이 자연 언어 처리(NLP), 컴퓨터 비전, 관계형 데이터셋 등에 미친 중대한 영향에 대해 탐구합니다.
- 통상적으로, 이러한 모델들은 세부 조정된 다운스트림 태스크를 통해 평가되지만, 이 연구는 모델을 더 효율적이고 효과적으로 평가하는 방법에 질문을 던집니다.
- 연구는 각 개체와 연관된 메타 특징을 세계적 지식의 소스로 활용하고, 모델들로부터 나온 개체 표현을 사용하는 새로운 접근법을 탐색합니다.
- 연구자들은 이러한 표현과 메타 특징 사이의 일관성을 사전 훈련된 모델을 평가하는 척도로 제안합니다.
- 제안된 방법론의 효과는 관계형 데이터셋, 대규모 언어 모델, 이미지 모델을 포함한 다양한 도메인에서 입증되었습니다.

### [TeleChat Technical Report](https://arxiv.org/abs/2401.03804)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/WM4E6KEA8OYnGTFEJkSEj.png)

Vote: 5

Authors: Zihan Wang, Xinzhang Liu, Shixuan Liu, Yitong Yao, Yuyao Huang, Zhongjiang He, Xuelong Li, Yongxiang Li, Zhonghao Che, Zhaoxi Zhang, Yan Wang, Xin Wang, Luwen Pu, Huihan Xu, Ruiyu Fang, Yu Zhao, Jie Zhang, Xiaomeng Huang, Zhilong Lu, Jiaxin Peng, Wenjun Zheng, Shiquan Wang, +

- 이 기술 보고서에서 우리는 30억, 70억, 120억 매개변수를 가진 대규모 언어 모델인 TeleChat를 소개합니다.
- TeleChat는 영어와 중국어 텍스트가 포함된 다양한 텍스트 콜렉션을 포함한 광범위한 말뭉치에서 사전 훈련을 받았습니다.
- 모델은 인간의 선호도와 일치하도록 상세한 방법론을 따라 미세 조정을 거칩니다.
- 우리는 언어 이해, 수학, 추론, 코드 생성 및 지식 기반 질문 답변을 포함한 다양한 작업에서 TeleChat의 성능을 평가합니다.
- TeleChat은 유사한 크기의 다른 오픈 소스 모델들과 비교하여 공공 벤치마크에서 평등한 성능을 달성하는 것으로 나타났습니다.
- 우리는 대규모 언어 모델을 활용하는 미래 연구와 응용을 지원하기 위해 TeleChat의 70억 및 120억 변형 모델의 미세 조정된 체크포인트, 코드 및 사전 훈련 데이터의 일부를 공공 커뮤니티에 공개합니다.

### [AST-T5: Structure-Aware Pretraining for Code Generation and Understanding](https://arxiv.org/abs/2401.03003)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/6s_wYAiSQa5MHBPEoffXb.png)

Vote: 4

Authors: Linyuan Gong, Linyuan Gong, Mostafa Elhoushi, Mostafa Elhoushi, Alvin Cheung

- 대규모 언어 모델들(Large language models, LLMs)이 코드 관련 작업에서 중요한 발전을 이루었음에도 불구하고 많은 모델들이 코드를 단순한 연속적인 시퀀스로만 취급하여 코드의 구조적 성격을 간과했습니다.
- 본 논문에서는 추상 구문 트리(Abstract Syntax Tree, AST)를 활용하여 코드 생성, 변환(transpilation), 및 이해를 향상시키는 새로운 사전 훈련 패러다임인 AST-T5를 소개합니다.
- 동적 프로그래밍을 통해 'AST-Aware Segmentation’은 코드 구조를 유지하는 반면, ‘AST-Aware Span Corruption’ 목적은 모델이 다양한 코드 구조를 재구성할 수 있도록 준비시킵니다.
- AST-T5는 다른 모델과 달리 복잡한 프로그램 분석이나 구조 변경이 필요 없으므로, 어떤 인코더-디코더 트랜스포머와도 이음매 없이 통합됩니다.
- 평가 결과, AST-T5는 다양한 코드 관련 작업에서 유사한 크기의 언어 모델들을 일관되게 능가했으며, 특히 코드 대 코드 작업에서 매우 강력하다는 것을 입증했습니다.
- AST-T5는 CodeXGLUE의 자바-C# 변환 작업에서 CodeT5를 3점 차이, Bugs2Fix 작업에서 2점 차이로 정확도 점수에서 앞질렀습니다.
- 본 논문의 코드 및 모델은 https://github.com/gonglinyuan/ast_t5에서 공개적으로 이용 가능합니다.

### [AGG: Amortized Generative 3D Gaussians for Single Image to 3D](https://arxiv.org/abs/2401.04099)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/fLZHvWHG-syKOGXJxkOxT.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/fLZHvWHG-syKOGXJxkOxT.mp4" muted="false"></video></div>

Vote: 3

Authors: Dejia Xu, Dejia Xu, Ye Yuan, Morteza Mardani, Morteza Mardani, Sifei Liu, Sifei Liu, Jiaming Song, Jiaming Song, Zhangyang Wang, Arash Vahdat, Arash Vahdat

- 단일 이미지로부터 3D 객체를 생성하기 위해 다양한 3D 표현법이 연구되었으며, 렌더링 효율성이 높은 3D 가우시안 스플래팅 기반 모델이 3D 재구성 및 생성에서 우수성을 보여왔습니다.
- 기존의 3D 가우시안 스플래팅 접근법은 최적화 기반으로, 계산 비용이 많이 드는 여러 점수 정제 단계가 필요했습니다.
- 이러한 도전을 극복하기 위해, AGG(Amortized Generative 3D Gaussian framework)는 개별 최적화 과정 없이 단일 이미지에서 즉시 3D 가우시안을 생성하는 프레임워크를 도입했습니다.
- AGG는 중간 하이브리드 표현을 이용하여 3D 가우시안 위치 및 기타 외관 속성을 분해하여 조인트 최적화를 실시합니다.
- 또한, 우리는 3D 데이터의 대략적인 표현을 먼저 생성한 후 3D 가우시안 초해상도 모듈로 업샘플링하는 단계적 파이프라인을 제안합니다.
- AGG는 기존의 최적화 기반 3D 가우시안 프레임워크 및 기타 3D 표현을 활용하는 샘플링 기반 파이프라인과 비교하여 질적 및 양적으로 경쟁력 있는 생성 능력을 보여주며, 여러 차수 더 빠른 속도의 이점이 있습니다.
- 프로젝트 페이지: https://ir1d.github.io/AGG/

