## Daily Papers (2024-01-24)

### [Lumiere: A Space-Time Diffusion Model for Video Generation](https://arxiv.org/abs/2401.12945)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/dhPQGlz-vGOESoWSlOobW.png)

Vote: 38

Authors: Hila Chefer, Tali Dekel, Tomer Michaeli, Deqing Sun, Oliver Wang, Roni Paiss, Yuanzhen Li, Ariel Ephrat, Junhwa Hur, Inbar Mosseri, Omer Tov, Charles Herrmann, Shiran Zada, Omer Bar-Tal

- 본 논문에서는 현실적이고 다양하며 일관된 움직임을 표현하는 동영상을 합성하는데 설계된 텍스트-투-비디오 확산 모델인 Lumiere를 소개합니다.
- 글로벌한 시간적 일관성을 달성하기 어려운 기존 동영상 모델과 달리, Lumiere는 Space-Time U-Net 아키텍처를 도입하여 단일 모델 패스를 통해 동영상의 전체 시간적 길이를 한 번에 생성합니다.
- 공간적 및 시간적 다운샘플링과 업샘플링을 활용하고 사전 훈련된 텍스트-투-이미지 확산 모델을 레버리지하여, 모델은 다중 공간-시간 척도에서 처리함으로써 전체 프레임 속도의 저해상도 비디오를 직접 생성합니다.
- 우리는 텍스트-투-비디오 생성에서 최첨단 결과를 보여주고, 이미지-투-비디오, 비디오 인페인팅, 스타일화 생성 등 다양한 콘텐츠 생성 작업과 비디오 편집 응용 프로그램을 용이하게 처리할 수 있는 우리의 디자인을 보여줍니다.

### [Small Language Model Meets with Reinforced Vision Vocabulary](https://arxiv.org/abs/2401.12503)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/7uakxR2KcG2IizSJZLfwr.png)

Vote: 24

Authors: Chunrui Han, Xiangyu Zhang, Jinyue Chen, Lingyu Kong, Liang Zhao, Haoran Wei, Zheng Ge, Jianjian Sun, En Yu

- 2023년 시점에서 인공지능 커뮤니티 내에서 대규모 시각 언어 모델(LVLMs)을 활용하는 것이 유행이나, 이러한 모델들은 대체로 매개변수 수가 70억이 넘어 일반 GPU에서의 훈련 및 배치가 어려움.
- 자원이 제한된 연구자들도 현재 LVLMs의 모든 기능을 체험할 수 있도록 소형 사이즈의 Vary-toy와 기본 "대형" 언어 모델인 Qwen-1.8B를 소개함.
- Vary-toy에서는 시각 어휘를 개선하여 Vary의 모든 기능을 유지하면서도 더 넓은 범용성을 갖추게 함.
- 구체적으로, 시각 어휘를 생성하는 과정에서 자연 이미지의 부정적 샘플을 객체 감지에 의해 주도되는 긍정적 샘플 데이터로 대체하여 어휘망의 능력을 보다 충분히 활용하고 자연 객체에 해당하는 시각 정보를 효율적으로 인코딩할 수 있도록 함.
- 실험 결과 Vary-toy는 DocVQA에서 65.6% ANLS, ChartQA에서 59.1% 정확도, RefCOCO에서 88.1% 정확도, MMVet에서 29%를 달성함.
- 코드는 홈페이지에 공개될 예정임.

### [Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment](https://arxiv.org/abs/2401.12474)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/fjabQbavpKD1qiqhSFADJ.png)

Vote: 19

Authors: Jingren Zhou, Keming Lu, Chang Zhou, Bowen Yu

- 대규모 언어 모델은 방대한 학습 데이터에 내재된 다양한 캐릭터와 잠재적 대화를 통해 본질적으로 역할 놀이(role-play) 능력을 가지고 있다는 가설을 세웠다.
- 연구팀은 역할 놀이를 위한 '자기 조정(self-alignment)' 방법인 'Ditto'를 소개했고, 이는 캐릭터 지식에 중점을 두고 지시를 따르는 언어 모델이 역할 놀이 대화를 모사하게 한다.
- Ditto는 4,000개의 캐릭터를 포함한 역할 놀이 훈련 세트를 생성하여, 현재 사용 가능한 데이터셋 보다 역할의 수에서 열 배 큰 규모를 달성했다.
- 이 자체 생성된 데이터셋을 사용하여 언어 모델을 미세 조정함으로써, 그것의 역할 놀이 기능을 향상시켰다.
- 다수의 역할 놀이 벤치마크와 MT-Bench의 역할 놀이 하위 집합을 평가한 결과, 다양한 매개변수 크기를 가진 Ditto는 일관된 역할 인식과 특정 역할에 맞는 정확한 지식을 다단계 역할 놀이 대화에서 유지하는 것으로 나타났다.
- Ditto는 모든 오픈소스 역할 놀이 기준을 뛰어 넘는 성능을 보여주었고, 고급 사유 챗봇과 비교할 수 있는 성능 수준을 보여주었다.
- 연구팀은 역할 놀이 분야에서의 첫 번째 포괄적 교차 감독(cross-supervision) 정렬 실험을 제시했는데, 이는 작은 모델의 지도하에 언어 모델의 본질적 능력이 역할 놀이 내의 지식을 한정시키며, 역할 놀이 스타일은 쉽게 습득할 수 있음을 밝혀냈다.
- 관련 자원은 https://github.com/OFA-Sys/Ditto에서 오픈소스로 제공한다.

### [Large-scale Reinforcement Learning for Diffusion Models](https://arxiv.org/abs/2401.12244)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/gi8z5i6oJ7XQDiUOYF5UP.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/gi8z5i6oJ7XQDiUOYF5UP.mp4" muted="false"></video></div>

Vote: 18

Authors: Dmitry Kislyuk, Yinan Zhang, Yilun Du, Eric Tzeng

- 텍스트-이미지 확산 모델은 고품질 이미지 생성에 있어 인상적인 능력을 보여준 깊은 생성 모델의 한 유형이다.
- 그러나, 이러한 모델은 웹 규모의 텍스트-이미지 훈련 쌍으로부터 비롯되는 내재된 편향에 취약하며, 우리가 중요하게 생각하는 이미지의 측면을 부정확하게 모델링할 수 있다.
- 이는 최적이 아닌 샘플, 모델 편향, 그리고 인간의 윤리와 선호도와 일치하지 않는 이미지들을 초래할 수 있다.
- 본 논문에서는 인간의 선호도, 구성성(compositionality), 공정성에 관한 다양한 보상 함수를 통해 수백만 개의 이미지에 걸쳐 확산 모델을 개선하기 위한 효과적이고 확장 가능한 강화 학습(RL) 알고리즘을 제시한다.
- 저자들은 이 접근 방식이 인간의 선호도와 일치하는 확산 모델을 조정하기 위해 기존 방법들을 크게 능가함을 보여준다.
- 최근 선호된 Stable Diffusion (SD) 모델을 개선하여 생성된 샘플들에 대해, 기존 SD 모델보다 인간이 80.3% 더 선호하는 샘플을 생성하는 동시에 생성 샘플의 구성과 다양성을 향상시킴을 추가로 설명한다.

### [Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding](https://arxiv.org/abs/2401.12954)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/lf_yRJf-jTWaFayUk2xny.png)

Vote: 15

Authors: Adam Tauman Kalai, Mirac Suzgun

- 메타-프롬프팅(Meta-Prompting)은 단일 언어 모델(LM)을 여러 독립적인 LM 쿼리를 관리하고 통합하는 다면적인 조율자로 변환하는 효과적인 스캐폴딩 기술을 소개합니다.
- 고수준의 지시를 활용하여 메타-프롬프팅은 복잡한 과제를 더 작고 관리하기 쉬운 부분 과제로 나눕니다.
- 이러한 부분 과제들은 동일 LM의 "전문가" 인스턴스들에 의해, 맞춤형 지시하에 처리됩니다.
- LM은 조율자로서의 역할을 하며, 이 전문가 모델들로부터의 결과물을 원활하게 통합하고 효과적으로 커뮤니케이션합니다.
- 또한, LM은 내재된 비판적 사고와 강력한 검증 과정을 사용하여 최종 결과를 정제하고 인증합니다.
- 이 협업 프롬프팅 방법은 단일 LM이 종합적인 조정자와 다양한 전문가 패널로 동시에 활동하게 하여 다양한 과제에서 성능을 크게 향상시킵니다.
- 메타-프롬프팅은 과제 별 상세한 지시가 필요없는 제로-샷, 과제 불가지론적 특성으로 사용자 상호작용을 크게 단순화합니다.
- 연구는 Python 인터프리터와 같은 외부 도구를 메타-프롬프팅 프레임워크에 원활하게 통합하는 것을 보여주며 그 적용성과 유용성을 넓힙니다.
- GPT-4를 사용한 철저한 실험을 통해, 메타-프롬프팅은 24게임, 체크메이트-인-원, 그리고 Python 프로그래밍 퍼즐을 포함한 모든 과제에서 이전의 스캐폴딩 방법들을: 표준 프롬프팅보다 17.1%, 전문가(동적) 프롬프팅 보다 17.3%, 멀티페르소나 프롬프팅 보다 15.2% 뛰어난 결과를 나타낸다는 것을 입증합니다.

### [Orion-14B: Open-source Multilingual Large Language Models](https://arxiv.org/abs/2401.12246)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/JPPFh1WRf9mo2KrKvjmP7.png)

Vote: 7

Authors: Zhipeng Zhang, Yongqiang Liu, Xiaopu Li, Yongqiang Li, Dacheng Zhang, Du Chen, Kun Han, Leichao Xu, Yi Huang, Haihui Pan

- 이 연구에서는 14억 개의 파라미터를 가진 다국어 대형 언어 모델 모음인 Orion-14B를 소개합니다.
- Orion-14B는 영어, 중국어, 일본어, 한국어 등 여러 언어로 된 텍스트에서 추출한 2.5조 개의 토큰을 다양한 데이터를 스케줄링하여 교육한 기초 모델을 이용합니다.
- 대화형 애플리케이션과 다른 특정 사용 사례를 위한 일련의 모델을 세밀하게 튜닝했습니다.
- 평가 결과 Orion-14B는 다양한 작업에서 최신 성능을 달성하는 것으로 나타났습니다.
- Orion-14B 모델 패밀리와 그와 관련된 코드를 https://github.com/OrionStarAI/Orion 에서 공개하여, 분야의 미래 연구와 실용적인 응용을 촉진하기를 희망합니다.

### [AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents](https://arxiv.org/abs/2401.12963)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/z1u5HcBr9b2neYGO7b7W7.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/z1u5HcBr9b2neYGO7b7W7.mp4" muted="false"></video></div>

Vote: 6

Authors: Yao Lu, Pierre Sermanet, Isabel Leal, Brian Ichter, Alex Irpan, Kanishka Rao, Montse Gonzalez Arenas, Dorsa Sadigh, Quan Vuong, Keerthana Gopalakrishnan, Debidatta Dwibedi, Pannag Sanketi, +, Sean Kirmani, Chelsea Finn, Sharath Maddineni, Edward Lee, Karol Hausman, Ryan Julian, Sergey Levine, Michael Ahn, Nikhil Joshi

- 본 논문은 언어, 시각, 그리고 최근에는 행동을 포함하는 기초 모델들이 유용한 작업에 대해 인터넷 데이터를 활용하는 능력을 혁신적으로 발전시켰음을 지적한다.
- 물리적 세계에 기반한 데이터 부족은 실체화된 기초 모델을 훈련시키는 주요 도전 과제 중 하나이다.
- 연구팀은 최소한의 인간 감독으로 완전히 새로운 시나리오에서 로봇의 운영을 확장하는 데 기존의 기초 모델을 활용하는 AutoRT 시스템을 제안한다.
- AutoRT는 장면 이해와 지상 명령을 위해 시각-언어 모델(VLM)을 사용하고, 로봇 군단이 수행할 다양하고 새로운 지시 사항을 제안하기 위해 대규모 언어 모델(LLM)을 활용한다.
- 기초 모델의 지식을 활용하여 데이터 수집을 안내하는 AutoRT는 자율성의 교환점과 안전성에 대해 효과적으로 판단하며 로봇 학습을 위한 데이터 수집을 대폭 확장할 수 있다.
- AutoRT가 여러 건물에 걸쳐 20대 이상의 로봇에게 지시 사항을 제안하고 원격조작과 자율 로봇 정책을 통해 77,000개의 실제 로봇 에피소드를 수집함으로써 그 효율성을 입증한다.
- 그리고 AutoRT가 수집하는 "실세계" 데이터는 이전보다 훨씬 다양하며, LLM을 사용함으로써 인간의 선호도에 맞춰지는 지시 따르기 데이터 수집 로봇들을 가능하게 한다는 것을 실험적으로 보여준다.

### [BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models](https://arxiv.org/abs/2401.12522)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Ps8q1L7lusxyD7_QwIOb6.png)

Vote: 6

Authors: Hanling Yi, Guangming Lu, Yifan Yang, Feng Lin, Hongbin Li, Rong Xiao, Xiaotian Yu

- 대규모 언어 모델(Large language models, LLMs)들은 추론 중에 자동회귀 생성(auto-regressive generation)을 사용하여 높은 메모리 대역폭 수요와 확장된 지연 시간을 야기한다.
- 이러한 비효율성을 완화하기 위해, 우리는 스트림라인된 반자동회귀 생성(semi-autoregressive generation)과 초안 검증(draft verification)을 통해 LLM을 가속화하는 혁신적인 방법인 양방향 튜닝을 위한 손실 없는 가속(Bi-directional Tuning for lossless Acceleration, BiTA)을 제안한다.
- 프롬프트 튜닝의 개념에서 영감을 받아, 반자동회귀 생성에 있어서 효율적인 가속을 가능케 하는 양방향 튜닝이라는 새로운 매개변수 효율적 설계를 LLM에 적용했다.
- 효율적인 트리 기반 디코딩(tree-based decoding)을 사용하여, 모델들은 초안 후보 생성과 검증을 병렬로 수행하여, 탐욕적 샘플링 하에서 자동회귀 대응본과 동일한 출력을 보장한다.
- BiTA는 추가적인 보조 모델이나 상당한 추가 메모리 비용 없이 기존 LLM의 추론 효율성을 높이는 경량 플러그인 모듈로 작동한다.
- 제안된 BiTA를 적용하여 LLaMA-2-70B-Chat은 MT-Bench 벤치마크에서 2.7배의 속도 향상을 달성했다.
- 광범위한 실험을 통해, 우리의 방법이 최신의 가속 기술들을 뛰어넘음을 확인하였다.

### [GALA: Generating Animatable Layered Assets from a Single Scan](https://arxiv.org/abs/2401.12979)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/2g0hPK7dYkqTD52QfhiNV.qt)

Vote: 4

Authors: Taeksoo Kim, Hanbyul Joo, Byungjun Kim, Shunsuke Saito

- GALA는 하나의 단일 레이어 옷을 입은 3D 인간 메쉬를 입력으로 받아 완전한 다층 3D 자산으로 분해하는 프레임워크를 제공합니다.
- 이 프레임워크로 생성된 출력물은 다른 자산과 결합되어 새로운 자세의 다양한 옷을 입은 인간 아바타를 만들 수 있습니다.
- 기존의 3D 복원 접근법들이 인간을 단일 기하학적 레이어로만 취급하며, 헤어스타일, 의류, 액세서리의 복합성을 간과하여 응용 프로그램에 제한을 준다는 점을 개선하였습니다.
- 단일 레이어 메쉬를 각각의 레이어로 분해하는 것이 어려운 작업이며, 강하게 가려진 영역에 대해 가능한 기하학과 질감을 합성해야 합니다.
- 성공적인 분해에도 불구하고 메쉬가 자세와 몸매 측면에서 표준화되지 않아 새로운 정체성 및 자세와 혼합하는 데 실패합니다.
- 이러한 문제들에 대처하기 위해, 사람들과 다른 자산들을 위한 기하학 및 외모의 선행 지식으로 선행 학습된 2D 확산 모델을 활용하는 것을 제안합니다.
- 우선 다시점 2D 분할로부터 추출된 3D 표면 분할을 사용하여 입력 메쉬를 분리합니다.
- 그런 다음, 새로운 포즈 가이드 스코어 증류 샘플링(SDS) 손실을 이용하여 포즈 및 기본 공간에서 다른 레이어의 누락된 기하학을 합성합니다.
- 고품질의 3D 기하학 내부채움을 완료하면, 처음에 가려진 영역까지 포함한 완전한 외모를 얻기 위해 동일한 SDS 손실을 질감에 적용합니다.
- 이러한 일련의 분해 단계를 거쳐 자세와 인간 모양 측면에서 표준화된 공용 기본 공간에서 다중 레이어의 3D 자산을 얻습니다, 따라서 신규 정체성으로의 무리 없는 구성과 새로운 자세로의 재애니메이션을 지원합니다.
- 저희의 실험은 분해, 표준화, 그리고 구성 과제와 관련하여 기존 솔루션과 비교해 저희 접근법의 효과성을 입증합니다.

### [Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study](https://arxiv.org/abs/2401.12789)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/U--QsL0sBcKSZ9Vj0Zb6r.png)

Vote: 4

Authors: Yu Zhang, Tongzhou Chen, Cyril Allauzen, Yongqiang Wang, James Qin, Tara N. Sainath, Shuo-Yiin Chang, Ke Hu, W. Ronny Huang, Kilol Gupta

- 대규모 모델의 시대에서 디코딩의 자동회귀적 특성으로 인한 지연 시간이 상당한 병목 현상으로 작용한다는 문제를 인식하고, 가속기 하드웨어의 병렬 처리 능력을 효과적으로 활용하는 비자동회귀적(LM-fused) ASR 시스템을 제안합니다.
- 이 연구에서는 범용 음성 모델(USM)과 PaLM 2 언어 모델을 결합하여 세그먼트별 스코어링 모드에서 FLEURS에서 평균 10.8%, YouTube 캡셔닝에서 평균 3.6%의 상대적인 WER (Word Error Rate, 단어 오류율) 개선을 달성했습니다.
- 종합적인 분석 연구를 통해 언어 모델 크기(128M에서 340B 매개변수까지), 컨텍스트 길이, 단어집 크기, 융합 방법론 등 주요 파라미터들이 ASR 성능에 미치는 영향에 대해 분석했습니다.
- 연구 결과는 대규모 언어 모델을 융합한 실용적인 규모의 음성 인식 시스템의 효과성에 영향을 미치는 요소들에 대한 중요한 통찰력을 제공합니다.

