## Daily Papers (2024-05-27)

### [ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models](https://arxiv.org/abs/2405.15738)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15738.png)

Vote: 34

Authors: Chunjiang Ge, Sijie Cheng, Shiji Song, Ziming Wang, Jun Song, Bo Zheng, Yuan Gao, Gao Huang, Jiale Yuan

- 이 논문에서는 고해상도 대규모 멀티모달 모델(LMM)이 직면하는 과도한 시각적 토큰과 시각적 복잡성 문제를 해결하기 위해 ConvNeXt 계층적 백본을 사용하는 새로운 방법인 ConvLLaVA를 제안합니다.
- ConvLLaVA는 고해상도 이미지를 정보가 풍부한 시각적 특징으로 압축하여 시각적 토큰의 과도한 생성을 효과적으로 방지합니다.
- 또한, 저해상도로 사전 훈련된 ConvNeXt가 고해상도에서 성능 저하를 보이는 문제를 해결하고, 원본 ConvNeXt의 압축 비율이 높은 해상도 입력에 부족한 문제를 개선하기 위해 두 가지 중요한 최적화를 제안합니다.
- 이러한 최적화를 통해 ConvLLaVA는 1536x1536 해상도 입력을 처리하면서도 단 576개의 시각적 토큰만을 생성할 수 있으멍, 다양한 종횡비의 이미지를 처리할 수 있습니다.
- 실험 결과, ConvLLaVA는 주요 벤치마크에서 최신 모델과 경쟁력 있는 성능을 달성함을 보여주멀면, 모델 시리즈는 https://github.com/alibaba/conv-llava 에서 공개적으로 제공됩니다.

### [Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models](https://arxiv.org/abs/2405.15574)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15574.png)

Vote: 31

Authors: Yong Man Ro, Byung-Kwan Lee, Beomchan Park, Chae Won Kim

- 최근 대규모 언어 및 비전 모델(LLVM)의 발전은 고품질 비주얼 인스트럭션 튜닝 데이터셋과 추가 비전 인코더 또는 다중 컴퓨터 비전 모델을 활용하여 강력한 비공개 소스 LLVM과의 성능 격차를 줄이는 데 도움을 주었습니다.
- 이러한 발전은 기본 이미지 이해, 상식과 비물체 개념에 대한 실제 지식(e.g., 차트, 다이어그램, 상징, 표지판, 수학 문제), 복잡한 질문을 해결하기 위한 단계별 절차 등 다양한 요구에 필요한 다면적 정보에서 기인합니다.
- 우리는 다면적 근거를 활용하여 이해와 답변 능력을 향상시키는 새로운 효율적인 LLVM, Mamba 기반 근거 추론(Meteor)을 제시합니다.
- 정보가 풍부한 긴 근거를 포함하기 위해 순차 데이터를 선형 시간 복잡도로 처리할 수 있는 Mamba 아키텍처를 사용합니다.
- 근거의 효율적인 임베딩을 촉진하는 근거 추론의 새로운 개념을 도입합니다.
- 그 후, 근거를 도움으로 삼아 답변을 생성하는 다기능 언어 모델(MLM)의 학습이 이루어집니다.
- 이러한 단계를 통해 Meteor는 모델 크기를 확대하거나 추가 비전 인코더 및 컴퓨터 비전 모델을 사용하지 않고도 다양한 능력을 요구하는 여러 평가 벤치마크에서 시각 언어 성능을 크게 향상시키는 성과를 달성했습니다.

### [Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization](https://arxiv.org/abs/2405.15071)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15071.png)

Vote: 20

Authors: Boshi Wang, Xiang Yue, Huan Sun, Yu Su

- 이 논문은 트랜스포머가 매개변수 지식을 암시적으로 추론할 수 있는지를 연구하였으며, 이러한 기술은 언어 모델이 어려워하는 부분이다.
- 구성(composition)과 비교(comparison) 두 가지 대표적인 추론 유형에 집중하여, 트랜스포머는 암시적 추론을 학습할 수 있지만, 이는 오버피팅을 훨씬 넘어선 확장된 훈련, 즉 'grokking'을 통해서만 가능하다는 것을 발견했다.
- 트랜스포머는 비교 유형에서는 일반화하나, 구성 유형에서는 분포 외 예제에 대해 체계적으로 일반화하는 데 실패한다는 차이점이 있다.
- 학습 과정에서 모델 내부를 조사하고 분석적 실험을 통해 일반화 회로의 형성 및 일반화와 기억 회로의 상대적 효율성과의 관계를 포함한 grokking의 메커니즘을 밝혀냈다.
- 시스템성과 일반화 회로의 구성 간의 연결을 탐구하였으며, 데이터와 훈련 설정을 개선하여 암시적 추론을 더 잘 유도할 수 있는 방향으로 지도한다.
- 복잡한 추론 작업에 대해 트랜스포머 아키텍처 개선을 제안하며, 대규모 검색 공간이 있는 도전적인 추론 작업에서, 비매개변수 메모리를 사용한 GPT-4-Turbo와 Gemini-1.5-Pro는 다양한 프롬프팅 스타일이나 검색 보강에도 불구하고 좋지 않은 성능을 보여 주었지만, 완전히 Grokked된 트랜스포머는 거의 완벽한 정확도를 달성함으로써 매개변수 메모리의 강력함을 보여주었다.

### [Aya 23: Open Weight Releases to Further Multilingual Progress](https://arxiv.org/abs/2405.15032)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15032.png)

Vote: 15

Authors: Marzieh Fadaee, Ahmet Üstün, Hangyu Lin, Sebastian Ruder, Julia Kreutzer, Bharat Venkitesh, Nick Frosst, Viraat Aryabumi, Madeline Smith, Dwarak Talupuru, David Cairuz, Kelly Marchisio, Sara Hooker, Acyr Locatelli, Phil Blunsom, Saurabh Dash, John Dang

- 이 기술 보고서에서는 새로운 다국어 언어 모델인 Aya 23을 소개하며, 이는 최근 발표된 Aya 모델을 기반으로 하여, 더 좋은 성능을 가진 사전 훈련 모델과 최근 출시된 Aya 컬렉션을 결합합니다.
- Aya 23은 23개 언어를 지원하는 다국어 대형 언어 모델로, 세계 인구의 약 절반에 달하는 지역에 최첨단 언어 모델링 기능을 제공합니다.
- 이전 Aya 모델은 101개 언어를 지원했지만, Aya 23은 포함된 언어에 더 많은 용량을 할당하는 것이 더 깊이 있는 효과를 조사하는 실험입니다.
- Aya 23은 자체 제공 언어들에 대해 이전의 대규몬 다국어 모델인 Aya 101은 물론 Gemma, Mistral, Mixtral과 같은 널리 사용되는 모델들을 능가하며 다양한 판별 및 생성 작업에서 뛰어난 성능을 보입니다.
- 8B 및 35B 모델의 개방형 가중치를 공개함으로써, 다국어 진보에 대한 접근 확대를 위한 지속적인 노력의 일환으로 발표합니다.

### [The Road Less Scheduled](https://arxiv.org/abs/2405.15682)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15682.png)

Vote: 13

Authors: Aaron Defazio, Ashok Cutkosky, Ahmed Khaled, Xingyu, Yang, Harsh Mehta, Konstantin Mishchenko

- 이 연구에서는 최적화 중단 시점 T를 명시할 필요가 없는 학습률 일정에 초점을 맞추어, T에 의존하는 학습률 일정보다 월등한 성능을 보여주는 새로운 접근 방식을 제안합니다.
- 제안된 '스케줄-프리' 방식은 기존의 모멘텀을 사용하는 표준 최적화 알고리즘에 비해 추가적인 하이퍼파라미터가 필요 없으멈서, 볼록 문제부터 대규모 딥 러닝 문제에 이르기까지 다양한 문제군에서 최고의 성능을 보입니다.
- 이 방법은 스케줄링과 반복 평균화를 통합하는 새로운 이론을 개발함으로써 직접적으로 도출되었습니다.
- 관련 소스 코드는 오픈 소스로 제공되며, GitHub에서 접근할 수 있습니다. (https://github.com/facebookresearch/schedule_free)

### [AutoCoder: Enhancing Code Large Language Model with \textsc{AIEV-Instruct}](https://arxiv.org/abs/2405.14906)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14906.png)

Vote: 13

Authors: Qiuwu Chen, Yuchen Li, Bin Lei

- AutoCoder는 GPT-4 Turbo(Apr 2024)와 GPT-4o를 넘어서 Human Eval 벤치마크 테스트에서 pass@1 성능이 90.9%로 90.2%인 이전 모델들을 능가하는 최초의 대규모 언어 모델입니다.
- 이 모델은 GPT-4 터보 및 GPT-4o와 비교하여 더 다양한 코드 인터프리터를 제공하며, 내장 패키지에 제한되지 않고 외부 패키지를 설치할 수 있습니다.
- AutoCoder의 훈련 데이터는 에이전트 상호작용과 외부 코드 실행 검증을 결합한 시스템으로 생성된 다중 턴 대화 데이터셋이며, 이 방법을 \textsc{AIEV-Instruct} (Instruction Tuning with Agent-Interaction and Execution-Verified)라고 합니다.
- \textsc{AIEV-Instruct}를 사용함으로써 독점적인 대규모 모델에 대한 의존도를 줄이고 실행 검증된 코드 데이터셋을 제공합니다.
- 모델의 코드와 데모 비디오는 https://github.com/bin123apple/AutoCoder에서 확인할 수 있습니다.

### [Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training](https://arxiv.org/abs/2405.15319)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15319.png)

Vote: 11

Authors: Reynold Cheng, Yike Guo, Yikang Shen, Wenyu Du, Zeyu Huang, Zihan Qiu, Tongxu Luo, Jie Fu

- 대규모 언어 모델(LLM)의 효율적인 사전 학습을 위해 작은 모델을 이용하여 큰 모델의 학습을 가속화하는 모델 성장 방식이 유망하게 떠오르고 있으나, 이 방법의 실제적 효용성은 아집도 확인되지 않았다.
- 이 연구에서는 효율적인 LLM 사전 학습을 위한 모델 성장 방법의 세 가지 주요 장애물을 식별하고, 이를 해결하기 위해 기존 접근 방식을 네 가지 핵심 성장 연산자로 요약하여 체계적으로 평가하였다.
- 특히 깊이 쌓기(depthwise stacking) 연산자인 G_{stack}가 학습 속도를 눈에 띄게 향상시키고, 여덟 가지 표준 NLP 벤치마크에서 전반적인 성능을 개선하였다는 점을 발견했다.
- G_{stack}의 확장성과 실용성을 평가하기 위해, 최대 7B 크기의 LLM을 대상으로 한 실험을 수행하고, 이를 통해 일반적인 LLM 사전 학습에 적용할 수 있는 성장 타이밍 및 성장 요인을 결정하기 위한 경험적 지침을 정립하였다.
- 연구 결과, G_{stack}는 기존의 7B 모델이 300B 토큰을 사용하는 대신 194B 토큰을 사용하여 같은 손실에 도달할 수 있어, 54.6%의 학습 속도 향상을 보여주었다.
- 이 연구의 코드와 사전 훈련된 모델은 온라인에서 접근 가능하며, G_{stack}에 대한 심층 토론과 포괄적인 소거 연구도 제공된다.

### [iVideoGPT: Interactive VideoGPTs are Scalable World Models](https://arxiv.org/abs/2405.15223)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15223.png)

Vote: 9

Authors: Xu He, Mingsheng Long, Shaofeng Yin, Dong Li, Jialong Wu, Jianye Hao, Ningya Feng

- 이 연구는 상호작용적인 환경에서 실시간 의사 결정을 위해 사고하고 계획할 수 있도록 돕는 분야에서, 비디오 생성 모델의 최근 진전을 활용하는 데 있어서의 도전을 다룬다.
-  연구진은 비디오GPT의 상호작용 가능한 버전인 Interactive VideoGPT(iVideoGPT)을 소개하며, 이는 시각적 관찰, 행동, 보상 등의 다중 신호를 토크너의 연속으로 통합하여 에이전트의 상호작용 경험을 가능하게 한다.
- iVideoGPT는 고차원의 시각적 관찰을 효율적으로 이산화하는 새로운 압축 토크나이제이션 기술을 특징으로 한다.
- 확장 가능한 구조를 활용하여 수백만 개의 인간 및 로봇 조작 궤적에 대해 사전 학습을 수행함으로써, 다양한 하류 작업에 적용 가능한 다목적 기반을 마련한다.
- iVideoGPT는 행동 조건부 비디오 예측, 시각적 계획, 모델 기반 강화 학습 등에서 경쟁력 있는 성능을 달성하며, 이는 생성적 비디오 모델과 실용적인 모델 기반 강화 학습 응용 사이의 격차를 메우는 데 기여한다.

### [CraftsMan: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner](https://arxiv.org/abs/2405.14979)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14979.png)

Vote: 9

Authors: Ping Tan, Jiarui Liu, Yixun Liang, Weiyu Li, Xuelin Chen, Xiaoxiao Long, Rui Chen

- CraftsMan은 고해상도 3D 기하학을 다양한 형태로 생성할 수 있는 새로운 생성적 3D 모델링 시스템입니다.
- 이 시스템은 정규 메쉬 토폴로지와 상세한 표면을 가지며, 사용자가 상호 작용적으로 기하학을 세밀하게 조정할 수 있습니다.
- 기존의 3D 생성 방법은 최적화 과정이 길고, 메쉬 토폴로지가 불규칙하며, 표면에 잡음이 많고 사용자 수정을 수용하기 어려운 문제가 있었습니다.
- CraftsMan은 대략적인 형태를 먼저 만들고 후에 표면 상세를 다듬는 장인의 작업 방식에서 영감을 받았습니다.
- 특히, 이 시스템은 텍스트 프롬프트나 참조 이미지를 입력으로 사용하여 몇 초 안에 정규 메쉬 토폴로지를 가진 조악한 기하학을 생성하는 3D 네이티브 확산 모델을 사용합니다.
- 이후, 다중 시점(MV) 확산 모델을 통해 생성된 다중 시점의 조악한 기하학을 이용하여 3D 기하학을 생성하는 MV-조건부 3D 확산 모델을 활용하여 강인성과 일반화 능력을 크게 향상시킵니다.
- 마지막으로, 정상 기반 기하학 정제기를 사용하여 표면 세부사항을 크게 향상시킬 수 있으며, 이 과정은 자동 또는 사용자가 제공한 수정을 통해 상호 작용적으로 수행됩니다.
- 광범위한 실험을 통해, CraftsMan은 기존의 방법들보다 우수한 품질의 3D 자산을 생성하는데 있어 높은 효율성을 달성함을 보여줍니다.
- 제공된 홈페이지와 코드를 통해 자세한 정보와 사용법을 제공합니다: [홈페이지](https://craftsman3d.github.io/), [코드](https://github.com/wyysf-98/CraftsMan).

### [Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition](https://arxiv.org/abs/2405.15216)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15216.png)

Vote: 8

Authors: Erik McDermott, Navdeep Jaitly, Tatiana Likhomanenko, Ronan Collobert, He Bai, Zijin Gu

- 자동음성인식(ASR) 시스템의 결과를 개선하기 위해 오랫동안 사용된 언어 모델(LM)은 ASR 시스템이 만들어내는 오류를 인지하지 못했습니다.
- 본 논문에서는 방대한 양의 합성 데이터로 훈련된 새로운 스케일의 오류 수정 모델인 Denoising LM(DLM)을 제시하며, 이는 기존 시도를 크게 뛰어넘으면서 최신 ASR 성능을 달성합니다.
- DLM은 텍스트-음성(TTS) 시스템을 사용하여 오디오를 합성하고, 이를 ASR 시스템에 제공하여 소음이 섞인 가설을 생성한 후 원본 텍스트와 짝지어 훈련합니다.
- DLM은 확장된 모델 및 데이터, 다중 화자 TTS 시스템 사용, 여러 소음 증대 전략의 결합, 새로운 디코딩 기술과 같은 여러 주요 요소를 포함합니다.
- 결과적으로, DLM은 외부 오디오 데이터를 사용하지 않는 설정에서 Librispeech의 test-clean에서 1.5%의 단어 오류율(WER)을, test-other에서는 3.3%의 WER을 달성했으며, 이는 자체 자가 감독 학습 방식이 사용하는 외부 오디오 데이터와 일치합니다.
- 또한, 단일 DLM은 다양한 ASR에 적용 가능하며, 전통적 LM 기반 빔 탐색 재점수 기법의 성능을 크게 뛰어넘습니다.
- 이러한 결과는 오류 수정 모델에 대한 적절한 연구가 전통적 LM을 대체할 가능성을 가지며, ASR 시스템의 새로운 정확도 수준을 열쇠를 쥐고 있음을 시사합니다.

### [Data Mixing Made Efficient: A Bivariate Scaling Law for Language Model Pretraining](https://arxiv.org/abs/2405.14908)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14908.png)

Vote: 8

Authors: Bolin Ding, Yaliang Li, Ce Ge, Zhijian Ma, Daoyuan Chen

- 이 연구는 기존의 다양한 데이터 사용법이 이론적 지침 없이 휴리스틱 방식에 의존하는 한계를 개선하기 위하여 저비용 프록시를 기반으로 한 데이터 혼합 전략을 조사합니다.
- 연구진은 데이터 양과 혼합 비율의 양자 변동을 정확하게 모델링하는 BiMix라는 통합된 스케일링 법칙을 제안합니다.
- 시스템적인 실험을 통해 BiMix의 예측력과 기본 원리에 대한 실증적 증거를 제공하며, 트레이닝이 필요 없는 엔트로피 기반 데이터 혼합이 자원 집약적 방법보다 비슷하거나 더 나은 성능을 달성할 수 있음을 밝힙니다.
- 이 연구는 비용 효율적인 언어 모델링을 위한 심도 있는 연구와 개발에 대한 통찰력을 제공할 것으로 기대됩니다.

### [Automatic Data Curation for Self-Supervised Learning: A Clustering-Based Approach](https://arxiv.org/abs/2405.15613)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15613.png)

Vote: 6

Authors: Marc Szafraniec, Hugo Touvron, Timothée Darcet, Théo Moutakanni, Vasil Khalidov, Maxime Oquab, Piotr Bojanowski, Hervé Jégou, Camille Couprie, Armand Joulin, Nikita Smetanin, Patrick Labatut, Huy V. Vo

- 이 연구는 자기 지도 학습을 위해 고품질 데이터셋의 자동 큐레이션 문제를 다룬다.
- 데이터셋은 크고, 다양하며, 균형 잡힌 특성을 가져야 한다는 가정 하에, 클러스터링 기반 접근 방식을 제안한다.
- 큰 규모의 다양한 데이터 저장소에 k-평균 알고리즘을 연속적이고 계층적으로 적용하여, 데이터 개념 분포가 균일한 클러스터를 생성한다.
- 생성된 클러스터에서 계층적이고 균형 잡힌 샘플링을 통해 데이터셋을 구축한다.
- 웹 이미지, 위성 이미지, 텍스트 등 세 가지 다른 데이터 도메인에서의 광범위한 실험을 통해, 자동 큐레이션 데이터셋에서 학습된 특징들이 비큐레이션 데이터 대비 성능이 우수하며 수동 큐레이션 데이터와 비교해도 우수하거나 동등한 결과를 보여준다는 것을 확인했다.

### [HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting](https://arxiv.org/abs/2405.15125)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.15125.png)

Vote: 3

Authors: Zihao Xiao, Yaoyao Liu, Alan Yuille, Yulun Zhang, Yixun Liang, Xiaokang Yang, Yuanhao Cai

- 고동적 범위(HDR) 새로운 시점 합성(NVS)은 HDR 이미징 기술을 사용하여 새로운 시점에서 사진처럼 사실적인 이미지를 생성하는 것을 목표로 합니다.
- 기존의 HDR NVS 방법들은 주로 NeRF 기반으로 되어 있으며, 이는 긴 학습 시간과 느린 추론 속도의 문제를 가지고 있습니다.
- 본 논문에서는, 사용자 입력 노출 시간에 따른 LDR 이미지와 새로운 HDR 시점을 효율적으로 렌더링할 수 있는 새로운 프레임워크인 HDR-GS(High Dynamic Range Gaussian Splatting)를 제안합니다.
- HDR 색상을 맞추기 위해 구형 조화 함수를 사용하고, MLP 기반 톤 매퍼로 LDR 색상을 렌더링하는 이중 동적 범위(DDR) 가우시안 점 구름 모델을 설계하였습니다.
- HDR 및 LDR 색상은 두 개의 병렬 차별화 가능한 래스터화(PDR) 과정에 입력되어 HDR 및 LDR 뷰를 재구성합니다.
- HDR NVS에서 3D 가우시안 스플래팅 기반 방법에 대한 연구 데이터 기반을 마련하기 위해 카메라 매개변수를 재보정하고 가우시안 점 구름의 초기 위치를 계산합니다.
- 실험 결과, HDR-GS는 상태별 최신 NeRF 기반 방법보다 LDR 및 HDR NVS에서 각각 3.84 및 1.91 dB 높은 성능을 보이며, 추론 속도는 1000배 빠르고 학습 시간은 6.3%만 요구합니다.

