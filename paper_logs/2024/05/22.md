## Daily Papers (2024-05-22)

### [Your Transformer is Secretly Linear](https://arxiv.org/abs/2405.12250)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.12250.png)

Vote: 55

Authors: Matvey Mikhalchuk, Nikolai Gerasimenko, Andrey Kuznetsov, Anton Razzhigaev, Elizaveta Goncharova, Denis Dimitrov, Ivan Oseledets

- 이 논문은 트랜스포머 디코더, 예를 들어 GPT, LLaMA, OPT, BLOOM 등의 모델이 지닌 새로운 선형 특성을 밝힙니다.
- 순차적인 계층 간의 임베딩 변환을 분석하여 거의 완벽한 선형 관계(Procrustes 유사성 점수 0.99)를 발견했습니다.
- 그러나 잔여 구성요소를 제거하면 트랜스포머 계층의 출력 노름이 일관되게 낮아져 선형성이 감소합니다.
- 일부 가장 선형적인 블록을 제거하거나 선형으로 근사화해도 손실이나 모델 성능에 큰 영향을 미치지 않는 것으로 나타났습니다.
- 또한, 작은 모델에 대한 사전 훈련 실험에서 층의 선형성을 감소시키는 것을 목표로 한 코사인 유사성 기반 정규화를 도입했으며, 이는 Tiny Stories와 SuperGLUE 벤치마크에서 성능 지표를 개선시키는 데 성공했습니다.
- 이 연구는 트랜스포머 구조에 대한 기존의 이해를 도전하며, 이들의 작동이 이전에 가정되었던 것보다 더 선형적일 수 있다는 것을 제안합니다.

### [Diffusion for World Modeling: Visual Details Matter in Atari](https://arxiv.org/abs/2405.12399)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.12399.png)

Vote: 13

Authors: Adam Jelley, François Fleuret, Tim Pearce, Amos Storkey, Eloi Alonso, Vincent Micheli, Anssi Kanervisto

- 'Diffusion for World Modeling: Visual Details Matter in Atari' 논문에서는 강화 학습 에이전트를 안전하고 효율적으로 훈련하기 위한 promising한 접근 방식으로서 월드 모델을 제시합니다.
- 최근 월드 모델은 환경 동역학을 모델링하기 위해 이산 잠재 변수의 순서에서 작동하지만, 이러한 압축은 강화 학습에서 중요한 시각적 세부사항을 무시할 수 있습니다.
- 한편, 이미지 생성에서 주류가 된 확산 모델은 이산 잠재 모델을 모델링하는 고정 관념적 방법에 도전하고 있습니다.
- 이러한 패러다임 변화에 동기를 얻어, DIAMOND (DIffusion As a Model Of eNvironment Dreams)라는 확산 월드 모델에서 훈련된 강화 학습 에이전트를 소개합니다.
- 논문은 확산을 월드 모델링에 적합하게 만드는 필수 설계 선택을 분석하고, 개선된 시각적 세부 사항이 에이전트 성능 향상으로 이어질 수 있음을 보여줍니다.
- DIAMOND는 경쟁적인 Atari 100k 벤치마크에서 사람 평균 정규화 점수 1.46을 달성하여, 완전히 월드 모델 내에서 훈련된 에이전트로는 새로운 최고 기록을 세웠습니다.
- 확산을 이용한 월드 모델링에 대한 미래 연구를 촉진하기 위해, 저자들은 코드, 에이전트 및 플레이 가능한 월드 모델을 https://github.com/eloialonso/diamond에서 공개했습니다.

### [Face Adapter for Pre-Trained Diffusion Models with Fine-Grained ID and Attribute Control](https://arxiv.org/abs/2405.12970)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.12970.png)

Vote: 9

Authors: Jiangning Zhang, Yong Liu, Yue Han, Chengjie Wang, Wei Li, Yanhao Ge, Junwei Zhu, Keke He, Xu Chen, Xiangtai Li

- 최근 얼굴 재연과 얼굴 교환 방법은 GAN 프레임워크에 주로 의존했지만, 우수한 생성 능력으로 인해 사전 훈련된 확산 모델에 초점이 맞춰지고 있습니다.
- 이러한 확산 모델을 훈련하는 것은 자원 집약적이며, 결과물은 아직 만족스러운 수준에 도달하지 못했습니다.
- 이 문제를 해결하기 위해, 우리는 사전 훈련된 확산 모델을 위한 고정밀 및 고화질 얼굴 편집을 위해 설계된 효율적이고 효과적인 어댑터인 Face-Adapter를 소개합니다.
- Face-Adapter는 얼굴 재연 및 교환 작업을 위해 목표 구조, ID 및 속성의 조합이 필수적임을 확인하고, 이러한 요소들의 제어를 충분히 분리하여 한 모델에서 두 작업을 수행할 수 있도록 하였습니다.
- 구체적으로, 우리의 방법은 정밀한 랜드마크와 배경을 제공하는 공간 조건 생성기, 페이스 임베딩을 텍스트 공간으로 전송하는 플러그 앤 플레이 아이덴티티 인코더, 공간 조건 및 상세 속성을 통합하는 속성 제어기를 포함합니다.
- Face-Adapter는 동작 제어 정밀도, ID 유지 능력 및 생성 품질 면에서 완전히 미세 조정된 얼굴 재연/교환 모델과 비교하여 비슷하거나 더 우수한 성능을 달성합니다.
- 또한, Face-Adapter는 다양한 StableDiffusion 모델과 원활하게 통합됩니다.

### [Reducing Transformer Key-Value Cache Size with Cross-Layer Attention](https://arxiv.org/abs/2405.12981)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.12981.png)

Vote: 9

Authors: Mayank Mishra, Aniruddha Nrusimha, Rameswar Panda, William Brandon, Jonathan Ragan Kelly

- 트랜스포머 기반의 자동 회귀형 대규모 언어 모델의 디코딩 가속화에 핵심적인 역할을 하는 키-값(KV) 캐싱은 긴 시퀀스 길이와 큰 배치 크기에서 저장해야 할 메모리 양이 지나치게 많아질 수 있다.
- 트랜스포머 발명 이래로 KV 캐시 크기를 줄이는 데 가장 효과적인 방법 중 두 가지는 다중 질의 주의(Multi-Query Attention, MQA)와 이의 일반화인 그룹화된 질의 주의(Grouped-Query Attention, GQA)로, 여러 질의 헤드가 단일 키/값 헤드를 공유하도록 주의 블록의 설계를 수정함으로써 키/값 헤드의 수를 크게 줄일 수 있었다.
- 본 논문에서는 MQA를 더 발전시켜 인접한 계층 간에도 키와 값 헤드를 공유함으로써 새로운 주의 구조인 교차 계층 주의(Cross-Layer Attention, CLA)를 제안하며, CLA를 통해 거의 동일한 정확도를 유지하면서 KV 캐시 크기를 추가로 2배 줄일 수 있음을 보여준다.
- 10억 및 30억 매개변수 모델을 처음부터 훈련하는 실험에서 CLA는 기존 MQA와 비교하여 메모리/정확도 트레이드오프에서 파레토 개선을 제공하며, 그렇지 않으면 불가능할 더 긴 시퀀스 길이와 더 큰 배치 크기에서 추론을 가능하게 한다.

### [OmniGlue: Generalizable Feature Matching with Foundation Model Guidance](https://arxiv.org/abs/2405.12979)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.12979.png)

Vote: 5

Authors: Qixing Huang, Arjun Karpur, Hanwen Jiang, Bingyi Cao, Andre Araujo

- 이 논문은 새로운 도메인에서의 일반화 능력을 핵심 원칙으로 설계된 최초의 학습 가능한 이미지 매칭 기술인 OmniGlue를 소개합니다.
- OmniGlue는 기존에 학습하지 않았던 분야로의 일반화를 증진시키기 위해 비전 파운데이션 모델에서 폭넓은 지식을 활용하여 특징 매칭 과정을 안내합니다.
- 또한, 공간적 정보와 외형 정보를 분리해 주는 새로운 키포인트 위치 가이드 어텐션 메커니즘을 제안하여 매칭 설명자를 강화하였습니다.
- 다양한 이미지 도메인을 포함하는 7개의 데이터셋에 대한 광범위한 실험을 수행하여, 학습하지 않은 도메인에서 직접 비교 가능한 참조 모델 대비 20.9%의 상대적 성능 향상을 달성했습니다.
- OmniGlue는 최근의 LightGlue 방법보다도 9.5% 상대적으로 우수한 성능을 보여주었습니다.

### [Personalized Residuals for Concept-Driven Text-to-Image Generation](https://arxiv.org/abs/2405.12978)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.12978.png)

Vote: 4

Authors: Matthew Fisher, Richard Zhang, Nicholas Kolkin, Tobias Hinz, Yuchen Liu, James Hays, Cusuh Ham

- 본 논문에서는 사전 훈련된 텍스트 조건의 확산 모델을 고정하고 소규모의 레이어에 대해 저랭크 잔여를 학습함으로써 개념을 표현하는 효율적인 개념 기반 생성을 위한 맞춤형 잔차와 지역화된 주의 유도 샘플링을 제시한다.
- 제안된 샘플링 기법은 학습된 잔차를 개념이 지역화된 곳에만 적용하고 다른 영역에서는 원래의 확산 가중치를 사용한다.
- 지역화된 샘플링은 개념의 학습된 정체성과 기존 확산 모델의 생성 선행을 결합한다.
- 개인화된 잔차는 단일 GPU에서 약 3분 만에 정규화 이미지 사용 없이 개념의 정체성을 효과적으로 포착하며, 이전 모델보다 적은 파라미터를 사용한다.
- 이를 통해 지역화된 샘플링은 이미지의 대부분의 부분에 대해 원래 모델을 강력한 선행으로 사용할 수 있게 한다.

