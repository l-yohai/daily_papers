## Daily Papers (2024-05-30)

### [MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series](https://arxiv.org/abs/2405.19327)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.19327.png)

Vote: 19

Authors: Bill Lin, Yiming Liang, Esther Cheng, Ziyang Ma, +, Jie Liu, Ge Zhang, Qunshu Lin, Scott Qu, Chenchen Zhang, Yizhi Li, Raven Yuan, Xinrun Du, Wei Pang, Danny Pan, Tuney Zheng, Huan Yang, Chenghua Lin, Emmanouil Benetos, Jiaheng Liu, Junting Zhou, Yinghao Ma, Chou Leuang Yu

- 대규모 언어 모델은 다양한 작업에서 전례 없는 성능을 달성하기 위해 최근 몇 년 간 큰 발전을 이루었으나, 상업적인 이유로 GPT, Gemini, Claude와 같은 경쟁력 있는 모델들은 세부적인 훈련 과정이 공개되지 않은 채 소유권이 있는 인터페이스로 제한되었습니다.
- 최근 많은 기관들이 LLaMA-3과 같은 강력한 대규모 언어 모델을 오픈소스화 했지만, 대부분의 세부사항(예: 중간 체크포인트, 사전 훈련 코퍼스, 훈련 코드 등)은 공개되지 않았습니다.
- 이에 따라, 연구 커뮤니티는 훈련 세부 사항이 더 많이 제공되는 진정한 오픈 소스 대규모 언어 모델(Pythia, Amber, OLMo 등)을 개발하는 데 힘써왔으멎, 이러한 모델들은 이러한 대규모 모델의 장단점, 편향, 위험을 과학적으로 연구하는 데 크게 기여하였습니다.
- 그러나, 기존과 유사한 크기의 최신 상태의 대규모 언어 모델에 비해 여전히 논리, 지식, 코딩 작업에서 성능이 떨어지는 문제가 관찰되었습니다.
- 이에 대응해, 저희는 MAP-Neo라는 7B 매개변수를 가진 높은 성능의 이중 언어 모델을 처음부터 4.5T 고품질 토큰으로 훈련시켜 오픈소스화 하였습니다.
- MAP-Neo는 기존 최신 상태의 대규모 언어 모델과 비교할 수 있는 성능을 가진 최초의 완전 오픈소스 이중 언어대규모 언어 모델입니다.
- 또한, MAP-Neo의 재현을 위한 모든 세부 정보(정제된 사전 훈련 코퍼스, 데이터 정제 파이프라인, 체크포인트, 최적화된 훈련/평가 프레임워크)를 공개합니다.
- 최종적으로, 저희의 MAP-Neo가 오픈 연구 커뮤니티를 강화하고, 대규모 언어 모델의 추가적인 개선을 촉진할 수 있는 더 많은 혁신과 창의성을 불러일으킬 것을 기대합니다.

### [T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback](https://arxiv.org/abs/2405.18750)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.18750.png)

Vote: 8

Authors: Sugato Basu, Xinyi Wang, Weixi Feng, Jiachen Li, Wenhu Chen, Tsu-Jui Fu, William Yang Wang

- 이 연구에서는 반복적 샘플링 프로세스의 느린 샘플링 속도로 인해 어려움을 겪고 있는 텍스트 대비디오(T2V) 모델의 품질 병목 문제를 해결하고자 합니다.
- T2V-Turbo는 사전 훈련된 T2V 모델의 일관성 증류(CD) 과정에 다양한 차별화된 보상 모델의 피드백을 통합한 새로운 모델입니다.
- 이 모델은 CD 손실을 계산하면서 자연스럽게 발생하는 단일 단계 생성에 대한 보상을 직접 최적화함으로써 반복적 샘플링 과정을 통한 그래디언트 역전파로 인한 메모리 제약을 효과적으로 우회합니다.
- T2V-Turbo는 4단계 생성을 통해 VBench에서 가장 높은 전체 점수를 달성했으며, Gen-2 및 Pika를 능가하였습니다.
- 추가적으로 실시한 인간 평가를 통해 T2V-Turbo의 4단계 생성이 10배 이상의 가속화와 함께 비디오 생성 품질을 향상시킨 것으로 확인되었습니다.

### [LLMs achieve adult human performance on higher-order theory of mind tasks](https://arxiv.org/abs/2405.18870)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.18870.png)

Vote: 4

Authors: Alison Lentz, Robin I. M. Dunbar, Tatenda Kanyere, Michael McKibben, Blaise Aguera y Arcas, Benjamin Barnett, Adrien Baranes, Geoff Keeling, Winnie Street, John Oliver Siy

- 이 논문은 대규모 언어 모델이 고차 이론 마인드(ToM)를 얼마나 개발했는지를 조사합니다.
- 고차 이론 마인드는 인간이 여러 정신적, 감정적 상태를 재귀적 방식으로 추론했다는 능력을 의미합니다(예: 나는 네가 그녀가 안다고 믿는다고 생각한다).
- 새로운 수기 테스트 스위트, 멀티-오더 이론 마인드 Q&A를 도입하여 기존 연구를 확장하고, 이를 통해 다섯 가지 LLM의 성능을 성인 인간 벤치마크와 비교합니다.
- GPT-4와 Flan-PaLM은 성인 수준 및 그에 근접한 성능을 보이며, GPT-4는 6차 추론에서 성인 성능을 뛰어넘습니다.
- 모델 크기와 미세 조정 사이의 상호 작용이 ToM 능력 실현에 있어 중요함을 나타내멎 이 성능이 우수한 LLM은 일반화된 ToM 능력을 개발했다고 제안합니다.
- 고차 이론 마인드는 다양한 협력적 및 경쟁적 인간 행동에서 중요한 역할을 하므로, 이러한 결과는 사용자와의 상호작용에서 LLM 애플리케이션에 중대한 영향을 미칠 수 있습니다.

### [NPGA: Neural Parametric Gaussian Avatars](https://arxiv.org/abs/2405.19331)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.19331.png)

Vote: 3

Authors: Tobias Kirschstein, Martin Rünz, Lourdes Agapito, Simon Giebenhain, Matthias Nießner

- 고해상도 디지털 인간 얼굴 아바타의 생성은 가상 요소를 일상 생활에 통합하는 중요한 단계입니다.
- 본 연구에서는 다시점 비디오 녹화를 통해 사실적인 제어 가능한 아바타를 생성하기 위해 데이터 기반 접근 방식인 Neural Parametric Gaussian Avatars(NPGA)를 제안합니다.
- 3D Gaussian Splatting을 기반으로 하여 효율적인 렌더링과 포인트 클라우드의 위상적 유연성을 활용합니다.
- 기존 연구와 달리, 메쉬 기반 3DMM 대신 신경망 파라메트릭 본 모델(NPHM)의 풍부한 표현 공간에 아바타의 동작을 조건화합니다.
- 다시점 비디오로부터 미세한 표정 관련 디테일을 학습하고, 아바타의 대표력을 높이기 위해 동적 행동을 지배하는 개별 요소의 잠재적 특성을 확장합니다.
- 이 증대된 동적 표현력을 정규화하기 위해 잠재적 특성과 예측된 동적 변화에 대한 라플라시안 요소를 제안합니다.
- 공개된 NeRSemble 데이터셋에서 평가를 수행해, 자체 재연 작업에서 기존 최고의 아바타보다 2.6 PSNR 만큼 성능이 향상되었다는 것을 입증하였습니다.
- 또한 실제 단일 카메라 비디오에서 정확한 애니메이션 기능을 보여줍니다.

### [Self-Exploring Language Models: Active Preference Elicitation for Online Alignment](https://arxiv.org/abs/2405.19332)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.19332.png)

Vote: 3

Authors: Zhaoran Wang, Ziyi Yang, Hany Hassan, Donghan Yu, Shuohang Wang, Shenao Zhang, Hiteshi Sharma

- 인간의 피드백으로부터 강화 학습(RLHF)을 통한 선호도 최적화가 큰 언어 모델(LLMs)의 인간 의도에 부합하는 조정에 중요한 성공을 거두었습니다.
- 오프라인 조정과 달리, 온라인 피드백 수집은 반복적인 과정을 통해 더 정교한 보상 모델과 더 잘 조정된 LLMs를 만들어냅니다.
- 글로벌하게 정확한 보상 모델을 달성하기 위해서는 자연어의 광범위한 영역을 아우르는 다양한 응답을 생성하는 체계적인 탐색이 요구됩니다.
- 표준 보상 최대화 LLMs만의 무작위 샘플링은 이러한 요구를 충족시키기에 부족합니다.
- 이 문제를 해결하기 위해, 우리는 높은 보상에 대한 잠재력이 있는 응답들을 적극적으로 탐색하도록 편향된 이중목표를 제안합니다.
- 재매개변수화된 보상 함수를 사용하여 내부 문제를 해결함으로써, 새로운 알고리즘인 자기 탐색 언어 모델(SELM)은 별도의 보상 모델(RM) 없이 LLM을 직관적인 목표로 반복적으로 업데이트합니다.
- SELM 목표는 바람직하지 않은 추정을 무분별하게 선호하는 것을 감소시키며 탐색 효율성을 향상시킵니다.
- 실험 결과에 따르면, SELM은 Zephyr-7B-SFT 및 Llama-3-8B-Instruct 모델에 미세 조정될 때, MT-Bench 및 AlpacaEval 2.0과 같은 지시에 따른 벤치마크와 다양한 표준 학술 벤치마크에서 성능을 크게 향상시킵니다.
- 우리의 코드와 모델은 https://github.com/shenao-zhang/SELM 에서 확인 가능합니다.

### [Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities](https://arxiv.org/abs/2405.18669)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.18669.png)

Vote: 2

Authors: Melissa Merrari, Dirk Padfield, Peter Chen, Vicky Zayats

- 다양한 생성 기반 모델을 효과적으로 통합하는 것에는 정렬된 데이터의 부족과 도메인 간 생성 작업에서 단일 모드 표현을 효율적으로 활용하는 것이 주요 장애물이다.
- 'Zipper'는 독립적으로 사전 훈련된 단일 모드 디코더들로부터 다모달 생성 모델을 유연하게 구성하기 위해 교차 주의(cross-attention)를 사용하는 다중 탑 디코더 구조를 제안한다.
- 텍스트와 음성 모다리티를 융합하는 실험에서, 제안된 구조는 정렬된 텍스트-음성 데이터가 제한적인 상황에서 매우 경쟁력 있는 성능을 보여준다.
- 모델은 특정 모달 타워(예: 텍스트)를 고정시켜 단일 모드(예: 텍스트 대 텍스트 생성) 성능을 선택적으로 유지할 수 있는 유연성을 보여준다.
- 자동 음성 인식(ASR)과 같은 교차 모달 작업에서는 텍스트 백본을 고정시키면 성능 저하가 거의 발생하지 않는다.
- 텍스트에서 음성으로 생성하는 작업(TTS)에서는 사전 훈련된 음성 백본을 사용함으로써 기준 모델 대비 우수한 성능을 달성한다.

### [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](https://arxiv.org/abs/2405.19325)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.19325.png)

Vote: 2

Authors: Ari Holtzman, Wen-tau Yih, Jimmy Lin, Minghan Li, Xilun Chen, Xi Victoria Lin, Beidi Chen

- 이 논문에서는 ‘Nearest Neighbor Speculative Decoding (NEST)’라는 새로운 반모수 언어 모델링 방법을 소개하는데, 이는 실제 세계의 텍스트 범위를 고려해 언어 모델 생성물에 추가하고 그 출처를 속성화할 수 있습니다.
- NEST는 추론 과정의 각 단계에서 토큰 수준 검색을 수행하여 반모수 혼합 분포를 계산하고 코퍼스에서 유망한 범위 연속성을 식별합니다.
- 이 방법은 검색된 범위의 접두사를 수용하거나 새 토큰을 생성하는 근사적인 추론 절차를 사용합니다.
- NEST는 기본 언어 모델의 생성 품질과 귀속 비율을 크게 향상시키고, 기존의 kNN-LM 방법을 넘어서며, 문맥 검색 강화와 경쟁적으로 수행됩니다.
- 추가적으로, NEST는 추론 시간에서 1.8배의 속도 향상을 달성하여, Llama-2-Chat 70B에 적용 시 처리 속도가 크게 개선됩니다.

### [Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF](https://arxiv.org/abs/2405.19320)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.19320.png)

Vote: 2

Authors: Katayoon Goshvadi, Dale Schuurmans, Yuejie Chi, Shicong Cen, Sherry Yang, Bo Dai, Hanjun Dai, Jincheng Mei, Tong Yang

- 인간 선호도에 기반한 강화학습(RLHF)은 큰 언어 모델을 인간의 선호에 맞추는 데 큰 가능성을 보여주고 있습니다.
- 온라인 및 오프라인 RLHF 모두에서 선호도 데이터의 사용 가능성에 따라 활발히 연구되고 있으며, 선호 데이터로부터 배운 보상 함수에 불확실성 추정을 통합하는 방법이 주요 과제입니다.
- 본 논문에서는 최대 우도 추정치를 해당 가치 함수로 정규화하고 낙관적 또는 비관적 태도를 선택하는 신호로 조절하는 방식인 '값-인센티브 선호 최적화(VPO)'라는 통합 접근 방식을 소개합니다.
- VPO는 보상 모델링을 암시적으로 최적화하며, 이는 직접적인 선호 최적화와 유사한 간소화된 RLHF 프로세스를 공유합니다.
- 이론적 보장은 온라인 및 오프라인 설정 모두에 대해 제공되며, 표준 RL과 동일한 비율을 맞춥니다.
- 텍스트 요약 및 대화 실험을 통해 VPO의 실용성과 효과성이 입증되었습니다.

### [Atlas3D: Physically Constrained Self-Supporting Text-to-3D for Simulation and Fabrication](https://arxiv.org/abs/2405.18515)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.18515.png)

Vote: 1

Authors: Xuan Li, Zeshun Zong, Chenfanfu Jiang, Yin Yang, Tianyi Xie, Ying Nian Wu, Yunuo Chen, Feng Gao

- 기존의 확산 기반 텍스트-투-3D 생성 방법은 주로 시각적으로 현실적인 형태와 외관을 생산하는 데 중점을 두고 있으나, 이러한 생성 모델들은 물리 기반 시뮬레이션 또는 3D 프린팅에서 배치될 때 종종 균형을 유지하지 못합니다.
- 이러한 균형은 인터랙티브 게임, 실체화된 AI, 로보틱스와 같은 분야에서 사용자의 디자인 의도를 충족시키기 위해 필수적이며, 신뢰할 수 있는 상호 작용을 위해 안정적인 모델이 필요합니다.
- 또한, 안정적인 모델은 가정 장식용 피규어와 같은 3D 프린트 객체가 추가 지지대 없이 스스로 서 있을 수 있도록 보장합니다.
- 이러한 요구를 충족시키기 위해 우리는 기존의 점수 증류 샘플링(SDS) 기반 텍스트-투-3D 도구를 향상시키는 자동이고 쉽게 구현할 수 있는 방법인 Atlas3D를 소개합니다.
- Atlas3D는 중력, 접촉 및 마찰의 물리 법칙을 준수하는 자체 지지 3D 모델의 생성을 보장하며, 새로운 차별화 가능한 시뮬레이션 기반 손실 함수와 물리적으로 영감을 받은 정규화를 결합합니다.
- 이 접근 방식은 기존 프레임워크를 위한 개선이나 후처리 모듈로서 사용될 수 있으며, 광범위한 생성 작업을 통해 Atlas3D의 효과를 검증하고 시뮬레이션 및 실제 환경에서 결과 3D 모델을 검증합니다.

### [Offline Regularised Reinforcement Learning for Large Language Models Alignment](https://arxiv.org/abs/2405.19107)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.19107.png)

Vote: 1

Authors: Bilal Piot, Remi Munos, Yunhao Tang, Lior Shani, Mohammad Gheshlaghi Azar, Daniele Calandriello, Tianqi Liu, Daniel Guo, Rafael Rafailov, Bernardo Avila Pires, Eugene Tarassov, Gil Shamir, Lucas Spangher, Rishabh Joshi, Will Ellsworth, Pierre Harvey Richemond, Jonathan Mallinson, Aliaksei Severyn

- 대규모 언어 모델(LLM)의 정렬을 위한 주요 프레임워크는 인간의 피드백으로부터의 강화 학습이나 직접적인 선호 최적화를 통해 선호도 데이터로부터 학습하는 것이다.
- 선호도 데이터는 보통 프롬프트, 독립적인 두 응답, 그리고 두 응답 사이의 인간의 선호도로 구성된 네 개의 요소를 포함한다.
- 그러나 이러한 데이터는 일반적으로 희귀하고 수집이 비싸다. 반면에, 프롬프트, 응답, 인간의 피드백으로 구성된 단일 경로 데이터셋이 더 풍부하다.
- 본 논문에서는 페어링된 선호도가 필요 없는 DRO(Direct Reward Optimisation) 프레임워크와 관련 알고리즘을 제안한다.
- DRO는 다양한 방식으로 구현 가능한 간단한 평균 제곱 목표를 사용한다.
- T5 인코더-디코더 언어 모델을 사용한 경험적 검증을 통해 DRO가 Kahneman-Tversky 최적화(KTO) 같은 선택된 기준들에 대해 우수한 성능을 보임을 확인하였다.
- 이를 통해 DRO는 단일 경로 정책 최적화를 위한 단순하면서 경험적으로 유력한 방법임을 입증한다.

### [SoundCTM: Uniting Score-based and Consistency Models for Text-to-Sound Generation](https://arxiv.org/abs/2405.18503)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.18503.png)

Vote: -

Authors: Koichi Saito, Yuki Mitsufuji, Yuhta Takida, Dongjun Kim, Chieh-Hsin Lai, Zhi Zhong, Takashi Shibuya

- 비디오 게임, 음악, 영화 등의 멀티미디어 작품에 필수적인 사운드 콘텐츠 생성을 위해, 고품질 확산 기반 사운드 생성 모델이 제작자에게 유용한 도구로 사용되고 있습니다.
- 기존 모델들이 고품질 사운드를 생성하지만 느린 추론 속도로 인해 제작자들이 시행착오를 겪으며 사운드를 다듬어야 하는 부담이 있습니다.
- 이러한 문제를 해결하기 위해, 우리는 Sound Consistency Trajectory Models (SoundCTM)을 도입하여 고품질의 1단계 사운드 생성과 다단계 생성을 유연하게 전환할 수 있게 합니다.
- SoundCTM은 1단계 샘플로 초기에 사운드를 조절한 후 다단계 생성을 통해 세밀하게 다듬을 수 있게 함으로써, 초기 단계의 제어 및 세밀한 조정을 가능하게 합니다.
- 추가적으로 훈련된 특징 추출기와 적대적 손실에 의존하는 기존 CTM의 성능을 개선하기 위해, 교사 네트워크를 활용한 새로운 특징 거리를 도입하고 이를 이용한 distillation 손실로 CTM의 훈련 프레임워크를 재구성했습니다.
- 우리는 조건부 및 비조건부 학생 모델을 동시에 훈련시키고 추론 중에 이 모델들 사이를 보간함으로써, 별도의 네트워크 없이도 1단계 및 다단계 실시간 사운드 생성을 가능하게 합니다.
- 또한, SoundCTM의 유연한 샘플링 능력을 활용하여 훈련 없는 제어 가능한 프레임워크를 제안하여, 훈련 없이도 제어 가능한 사운드 생성을 실현시킵니다.

### [EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture](https://arxiv.org/abs/2405.18991)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.18991.png)

Vote: -

Authors: Bo Liu, Jun Huang, Xing Shi, MengLi Cheng, Kunzhe Huang, Xinyi Zou, Jiaqi Xu, Yunkuo Chen

- 이 논문은 변환 아키텍처의 능력을 활용하여 고성능 비디오 생성을 위한 EasyAnimate라는 고급 방법을 제시합니다.
- EasyAnimate는 2D 이미지 합성을 위해 설계된 DiT 프레임워크를 확장하여 3D 비디오 생성의 복잡성을 수용하고, 동적 움직임을 캡처하기 위해 모션 모듈 블록을 포함합니다.
- 이 모션 모듈은 다양한 스타일의 비디오를 생성하기 위해 다양한 DiT 기본 방법에 적용할 수 있으며, 훈련 및 추론 단계에서 다양한 프레임 속도와 해상도로 비디오를 생성할 수 있습니다.
- 또한, 긴 시간의 비디오 생성을 용이하게 하기 위해 시간 축을 요약하는 새로운 접근 방식인 slice VAE를 도입했습니다.
- 현재 EasyAnimate는 144 프레임의 비디오를 생성할 수 있는 능력을 보여줍니다.
- 이 방법론은 데이터 전처리, VAE 훈련, DiT 모델 훈련 (기본 모델 및 LoRA 모델 포함), 그리고 종단 간 비디오 추론을 포괄하는 비디오 제작을 위한 생태계를 제공합니다.
- 관련 코드는 https://github.com/aigc-apps/EasyAnimate에서 확인할 수 있으며, 지속적으로 성능을 향상시키기 위해 노력하고 있습니다.

