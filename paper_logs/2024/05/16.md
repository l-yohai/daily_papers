## Daily Papers (2024-05-16)

### [ALPINE: Unveiling the Planning Capability of Autoregressive Learning in Language Models](https://arxiv.org/abs/2405.09220)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.09220.png)

Vote: 14

Authors: Shi Feng, Wei Chen, Yifei Shen, Siwei Wang, Shang-Hua Teng, Haoran Sun

- 이 논문에서는 'Autoregressive Learning for Planning In NEtworks'를 의미하는 ALPINE 프로젝트를 통해 트랜스포머 기반 언어 모델에서의 계획 기능 개발에 대한 이론적 연구를 시작하고, 해당 학습 메커니즘이 계획 능력에 제한을 가지고 있는지를 확인한다.
- 계획을 네트워크에서 유효한 경로를 생성하는 탐색 작업으로 추상화하고, 트랜스포머가 인접 행렬과 범위 행렬을 자체 가중치 내에 구현함으로써 경로 찾기를 수행할 수 있음을 보여준다.
- 이론적 분석을 통해 트랜스포머가 인접 행렬과 제한된 형태의 범위 행렬을 학습할 수 있음이 드러나며, 실험을 통해 이러한 이론적 예측이 실제로 확인된다.
- 또한, 실제 계획 벤치마크인 Blocksworld를 적용할 때에도 관찰 결과는 일관된 양상을 보인다.
- 트랜스포머는 전달성을 통한 도달가능성 관계를 식별하지 못하여 경로 연결이 필요한 경우에는 실패할 수 있는 가능성을 보여준다.
- 본 연구는 자기회귀 학습의 내부 메커니즘이 네트워크에서 어떻게 계획을 가능하게 하는지에 대한 새로운 시각을 제공하며, 다른 관련 도메인에서의 일반적인 계획 능력에 대한 이해에 기여할 수 있다.

### [Xmodel-VLM: A Simple Baseline for Multimodal Vision Language Model](https://arxiv.org/abs/2405.09215)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.09215.png)

Vote: 8

Authors: Wanting Xu, Yang Liu, Langping He, Xucheng Huang, Ling Jiang

- Xmodel-VLM은 소비자 GPU 서버에서 효율적으로 배치될 수 있는 첨단 다중 모드 비전 언어 모델을 소개합니다.
- 이 모델은 대규모 다중 모달 시스템의 널리 활용을 방해하는 높은 서비스 비용 문제에 직면합니다.
- 우리는 LLaVA 패러다임을 사용하여 처음부터 10억 규모의 언어 모델을 개발했습니다.
- Xmodel-VLM은 크기가 작고 실행 속도가 빠르면서도 다른 큰 모델들과 비교할 때 비슷한 성능을 제공합니다.
- 다양한 클래식 다중 모달 벤치마크를 통한 광범위한 테스트 결과가 이를 증명합니다.
- 모델 체크포인트와 코드는 GitHub에서 공개적으로 제공됩니다.

### [BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation](https://arxiv.org/abs/2405.09546)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.09546.png)

Vote: 5

Authors: Yunzhu Li, Cem Gokmen, Jiashu Xu, Benjamin Jose Martinez, Ruohan Zhang, Chengshu Li, Pengchuan Zhang, +, Shengxin Zha, Roberto Martín-Martín, Miao Liu, Ayush K Chakravarthy, Sanjana Srivastava, Yihe Tang, Li Fei-Fei, Mona Anvari, Wensi Ai, Sharon Lee, Arman Aydin, Laurent Itti, Hong-Xing Yu, Yunhao Ge, Josiah Wong

- 컴퓨터 비전 모델의 체계적인 평가 및 분석을 위해 BEHAVIOR Vision Suite(BVS)라는 도구 및 자산 집합을 개발하여, 사용자 맞춤형 합성 데이터 생성을 지원합니다.
- 실제 선례의 부족과 현존하는 합성 데이터 생성기의 한계를 보완하기 위해, BVS는 고화질 자산과 렌더링, 다양한 다양성, 현실적 물리 속성을 갖춘 데이터를 생성합니다.
- BVS는 장면 수준(예: 조명, 객체 배치), 객체 수준(예: 조인트 구성, "채워진", "접힌" 등의 속성), 카메라 수준(예: 시야 각, 초점 거리)에서 조정 가능한 많은 매개변수를 제공합니다.
- 연구자들은 이러한 매개변수들을 자유롭게 변화시켜 제어된 실험을 수행할 수 있으며, 데이터 생성 과정을 통해 모델의 강인성 평가, 장면 이해 모델 평가, 시뮬레이션-실제 전환 학습 및 평가 등 다양한 응용 시나리오를 시연합니다.
- 프로젝트 웹사이트는 다음과 같습니다: https://behavior-vision-suite.github.io/

### [Naturalistic Music Decoding from EEG Data via Latent Diffusion Models](https://arxiv.org/abs/2405.09062)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.09062.png)

Vote: 1

Authors: Hiroaki Kitano, Natalia Polouliakh, Taketo Akama, Emanuele Rodolà, Akima Connelly, Emilian Postolache

- 이 논문은 뇌파(EEG) 데이터를 사용하여 다양한 악기, 목소리 및 효과가 풍부한 복잡한 음악을 복원하는 잠재 확산 모델의 가능성을 탐구합니다.
- 잠재 확산 모델은 강력한 생성 모델로, 이 연구는 고질적인 음악 재구성을 비침습적 EEG 데이터를 사용하여 달성하는 초기 시도를 나타냅니다.
- 연구자들은 공개 NMED-T 데이터 세트에서 모델을 훈련하고, 신경 임베딩 기반 메트릭을 제안하여 정량적 평가를 수행합니다.
- 또한 생성된 트랙을 기반으로 노래 분류 작업을 수행합니다.
- 이 연구는 뇌-컴퓨터 인터페이스와 신경 디코딩 연구에 기여하며, 복잡한 청각 정보를 재구성하기 위해 EEG 데이터 사용의 실현 가능성에 대한 통찰을 제공합니다.

