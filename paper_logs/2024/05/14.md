## Daily Papers (2024-05-14)

### [What matters when building vision-language models?](https://arxiv.org/abs/2405.02246)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.02246.png)

Vote: 42

Authors: Léo Tronchon, Hugo Laurençon, Matthieu Cord, Victor Sanh

- 시각-언어 모델(VLMs)에 대한 관심이 증가하고 있으며, 이는 대규모 언어 모델과 비전 변환기의 발전에 의해 주도되고 있습니다.
- 많은 연구에도 불구하고 VLM의 설계와 관련한 중요한 결정들이 종종 정당화되지 않아, 어떤 선택이 모델 성능을 향상시키는지 식별하기 어렵게 만듭니다.
- 이러한 문제를 해결하기 위해 우리는 사전 훈련된 모델, 아키텍처 선택, 데이터 및 훈련 방법에 대한 광범위한 실험을 수행했습니다.
- 연구 결과로, 80억 개의 파라미터를 가진 효율적인 기초 시각-언어 모델인 Idefics2를 개발했으며, 이 모델은 다양한 멀티모달 벤치마크에서 그 크기 범주 내 최고의 성능을 달성했습니다.
- Idefics2는 자체 크기의 네 배인 모델과 비교할 때 종종 동등한 성능을 보여줍니다.
- 모델(기본형, 지시형, 대화형)과 그 훈련에 사용된 데이터셋을 공개합니다.

### [RLHF Workflow: From Reward Modeling to Online RLHF](https://arxiv.org/abs/2405.07863)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.07863.png)

Vote: 32

Authors: Wei Xiong, Bo Pang, Haoxiang Wang, Han Zhao, Caiming Xiong, Hanze Dong, Doyen Sahoo, Yingbo Zhou, Nan Jiang, Tong Zhang

- 본 기술 보고서에서는 최근 대규모 언어 모델(Large Language Model, LLM) 문헌에서 그 성능이 오프라인 대응보다 월등히 뛰어나다고 보고된 온라인 반복 강화 학습(RLHF) 워크플로우를 소개합니다.
- 기존의 오픈소스 RLHF 프로젝트들은 대부분 오프라인 학습 환경에 국한되어 있으나, 본 보고서에서는 온라인 반복 RLHF의 상세한 재현 가능한 레시피를 제공하여 이러한 격차를 해소하고자 합니다.
- 온라인 인간 피드백이 일반적으로 불가능한 오픈소스 커뮤니티의 제한된 자원을 고려하여, 다양한 오픈소스 데이터셋을 활용해 선호 모델을 구축하고, 이를 통해 인간 피드백을 대략적으로 모방합니다.
- 이후 온라인 반복 RLHF의 이론적 통찰과 알고리즘 원리에 대해 논의하고, 실제적인 구현을 자세히 설명합니다.
- 우리가 훈련한 LLM, SFR-Iterative-DPO-LLaMA-3-8B-R은 AlpacaEval-2, Arena-Hard, MT-Bench 뿐만 아니라 HumanEval, TruthfulQA와 같은 학술 벤치마크에서도 인상적인 성과를 달성했습니다.
- 감독된 미세조정(SFT)과 반복 RLHF는 전적으로 오픈소스 데이터셋을 사용하여 최첨단 성능을 달성할 수 있음을 증명합니다.
- 우리는 모델, 큐레이트된 데이터셋, 그리고 단계별 코드 가이드북을 공개적으로 제공하고 있으며, 자세한 정보는 https://github.com/RLHFlow/RLHF-Reward-Modeling 과 https://github.com/RLHFlow/Online-RLHF 에서 확인할 수 있습니다.

### [SUTRA: Scalable Multilingual Language Model Architecture](https://arxiv.org/abs/2405.06694)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.06694.png)

Vote: 20

Authors: Jaewon Lee, Simon Gibbs, Steven Ripplinger, Abhijit Bendale, Pranav Mistry, Michael Sapienza

- 본 논문에서는 50개 이상의 언어를 이해, 추론 및 생성할 수 있는 다국어 대형 언어 모델 아키텍처인 SUTRA를 소개합니다.
- SUTRA는 핵심 개념 이해와 언어 특화 처리를 분리하여 다양한 언어에 효율적으로 적용할 수 있는 구조를 갖추고 있습니다.
- 언어 및 개념 처리에 전문가 혼합(Mixture of Experts) 프레임워크를 사용하여 계산 효율성과 반응성을 높였습니다.
- SUTRA는 다국어 작업을 위한 Massive Multitask Language Understanding (MMLU) 벤치마크에서 기존 모델들(GPT-3.5, Llama2)을 20-30% 상회하는 성과를 보였습니다.
- 또한, SUTRA는 인터넷의 지식을 활용하여 정확하고 최신의 사실을 반영하는 반응을 제공하면서도 다국어능력을 유지하는 온라인 LLM으로 작동합니다.
- 이 아키텍처는 AI 기술의 글로벌 접근성을 높이고, 주로 비영어권 지역에서의 AI의 공정성과 유용성을 개선할 수 있는 잠재력을 가지고 있음을 탐구합니다.
- SUTRA는 다국어 모델의 중요한 갭을 메우며, AI 애플리케이션의 운영 효율성과 확장성에 있어 새로운 벤치마크를 설정합니다.

### [SambaNova SN40L: Scaling the AI Memory Wall with Dataflow and Composition of Experts](https://arxiv.org/abs/2405.07518)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.07518.png)

Vote: 16

Authors: Xiangyu Song, Karen Li, Kejie Zhang, Tuowen Zhao, +, Yun Du, Apurv Vivek, Darshan Gandhi, Calvin Leung, Mingran Wang, Arjun Sabnis, Manish K. Shah, Tianren Gao, Jiayu Bai, Raghu Prabhakar, Joshua Brot, Mark Luttrell, Yongning Sheng, Mark Gottscho, Angela Wang, Ram Sivaramakrishnan, David Jackson, Denis Sokolov

- GPT-4와 같은 대형 언어 모델이 현대 생성 AI 응용 프로그램의 발전을 이끌었지만, 이러한 모델을 규모에 맞춰 훈련하고 유지하는 것은 비용이 많이 들고 도전적입니다.
- 최신 AI 가속기의 컴퓨팅 대 메모리 비율 증가로 인해 메모리 벽이 생성되었고, 이를 극복하기 위한 새로운 방법이 필요합니다.
- 전문가의 구성(CoE)은 훈련 및 서빙의 비용과 복잡성을 낮추는 모듈식 접근 방식을 제공하지만, 기존 하드웨어에서는 두 가지 주요 도전 과제가 있습니다: 작은 모델의 작업 강도가 낮고, 많은 수의 모델을 호스팅하는 것이 비용이 많이 들거나 느립니다.
- 이 논문에서는 CoE, 스트리밍 데이터 흐름 및 삼단계 메모리 시스템을 결합하여 AI 메모리 벽을 확장하는 방법을 설명합니다.
- Samba-CoE 시스템은 150명의 전문가와 1조 개의 총 파라미터를 갖추고 있으며, SambaNova SN40L 가변 데이터 흐름 유닛(RDU)에서 배포됩니다.
- 이 칩은 칩 내 분산 SRAM, 패키지 내 HBM, 패키지 외 DDR DRAM을 포함한 새로운 삼단계 메모리 시스템을 도입합니다.
- RDU 간 전용 네트워크를 통해 여러 소켓에서 확장성을 높일 수 있습니다.
- 노노어서는 8개의 RDU 소켓이 운영되는 다양한 벤치마크에서 최대 13배의 속도 향상을 보여줍니다.
- CoE 추론 배포의 경우, 8소켓 RDU 노드는 기계 발자국을 최대 19배 줄이고, 모델 전환 시간을 최대 31배 빠르게 하며, DGX H100 및 DGX A100 대비 각각 3.7배 및 6.6배의 전체 속도 향상을 달성합니다.

### [Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots](https://arxiv.org/abs/2405.07990)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.07990.png)

Vote: 12

Authors: Qiushan Guo, Jiahao Wang, Zeyu Lu, Chengyue Wu, Yixiao Ge, Ying Shan, Zhixuan Liang, Ping Luo

- 다중 모드 대형 언어 모델(MLLMs)의 뛰어난 성능이 시각적 맥락에서 주목을 받고 있지만, 시각적 자료를 실행 가능한 코드로 변환하는 능력은 충분히 평가되지 않았습니다.
- 이를 해결하기 위해, 저희는 공정하고 심층적인 평가를 위해 설계된 종합적인 시각 코딩 벤치마크인 Plot2Code를 소개합니다.
- Plot2Code는 공개적으로 이용 가능한 matplotlib 갤러리에서 선별된 132개의 고품질 matplotlib 그래프 이미지와 이에 대한 원본 코드, GPT-4로 요약된 설명적 지시를 제공합니다.
- 저희는 코드 통과율, 텍스트 일치 비율, GPT-4V 전체 평가 등 세 가지 자동 평가 메트릭을 제안하여 코드 및 생성된 이미지의 세밀한 평가를 수행합니다.
- GPT-4V를 사용하여 단순히 합격 여부를 판단하는 대신, 생성된 이미지와 참조 이미지 사이의 종합적인 판단을 내리며, 이는 인간 평가와 일관성이 있음을 보여줍니다.
- 평가 결과는 GPT-4V, Gemini-Pro 및 오픈 소스 Mini-Gemini 등 14개 MLLMs의 분석을 포함하고 있으며, Plot2Code가 제시하는 주요 도전 과제를 강조합니다.
- Plot2Code를 통해 대부분의 현존하는 MLLMs가 텍스트가 많은 플롯의 시각 코딩에 어려움을 겪고 있으며, 텍스트 지시에 크게 의존함을 밝혀냈습니다.
- Plot2Code에 관련된 모든 데이터는 https://huggingface.co/datasets/TencentARC/Plot2Code에서 이용 가능합니다.

### [LogoMotion: Visually Grounded Code Generation for Content-Aware Animation](https://arxiv.org/abs/2405.07065)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.07065.png)

Vote: 8

Authors: Matthew Fisher, Timothy Langlois, Seth Walker, Vivian Liu, Lydia Chilton, Rubaiat Habib Kazi, Li-Yi Wei

- 애니메이션 로고는 개인과 브랜드가 온라인에서 자신들을 표현하는 매력적이고 널리 사용되는 방법입니다.
- 수작업으로 이러한 로고를 제작하는 데는 상당한 예술적 기술과 노력이 필요합니다.
- 로고모션(LogoMotion)은 초보 디자이너가 콘텐츠에 맞춤화된 애니메이션 코드를 생성하여 애니메이션 로고를 만들 수 있도록 지원하는 LLM 기반 시스템입니다.
- 이 시스템은 계층화된 문서를 입력받아 시각적으로 연계된 프로그램 합성을 통해 애니메이션 로고를 생성합니다.
- HTML 캔버스 표현 생성, 주요 및 보조 요소 식별, 애니메이션 코드 합성 및 애니메이션 오류 시각적 디버깅 기술을 소개합니다.
- 업계 표준 도구와 비교했을 때, 로고모션은 콘텐츠 인식이 더 강하고 품질 면에서 동등한 애니메이션을 생산하는 것으로 나타났습니다.
- LLM 생성 애니메이션의 모션 디자인에 대한 함의를 논의하여 논문을 마무리합니다.

### [Piccolo2: General Text Embedding with Multi-task Hybrid Loss Training](https://arxiv.org/abs/2405.06932)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.06932.png)

Vote: 7

Authors: Zihao Jing, Yichao Wu, Zhongjie Hu, Mengya Gao, Junqin Huang

- 본 보고서에서는 CMTEB 벤치마크의 6가지 작업에 대한 종합적 평가에서 다른 모델들을 능가하는 임베딩 모델인 Piccolo2를 소개합니다.
- Piccolo2는 효율적인 다중 작업 하이브리드 손실 훈련 방식을 주로 사용하여 다양한 하위 작업의 텍스트 데이터와 레이블을 효과적으로 활용합니다.
- 또한, Piccolo2는 임베딩 차원을 확장하고 MRL 훈련을 사용하여 더 유연한 벡터 차원을 지원합니다.
- Piccolo2 모델에 대한 최신 정보는 https://huggingface.co/sensenova 웹사이트에서 확인할 수 있습니다.

### [Large Language Models as Planning Domain Generators](https://arxiv.org/abs/2405.06650)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.06650.png)

Vote: 6

Authors: James Oswald, Michael Katz, Junkyu Lee, Kavitha Srinivas, Harsha Kokel, Shirin Sohrabi

- 인공지능 계획에서 도메인 모델을 개발하는 것은 여전히 수동적인 인간 노동을 요구하는 몇 안 되는 분야 중 하나입니다.
- 이 연구에서는 간단한 텍스트 설명에서 계획 도메인 모델을 생성할 수 있는지 여부를 조사하고자 대규모 언어 모델(Large Language Models, LLM)의 사용 가능성을 탐구했습니다.
- 특히, LLM으로 생성된 도메인을 자동으로 평가하는 프레임워크를 도입하고 도메인 인스턴스에 대한 계획 세트를 비교함으로써 평가합니다.
- 연구는 자연어 도메인 설명의 세 가지 클래스에서 9개의 다양한 계획 도메인에 걸쳐 코딩 및 대화 모델을 포함한 7가지 대규모 언어 모델을 경험적으로 분석했습니다.
- 결과적으로, 특히 매개변수 수가 많은 LLM은 자연어 설명에서 정확한 계획 도메인을 생성하는 데 있어 중등도의 숙련도를 보여줬습니다.
- 연구에 사용된 코드는 https://github.com/IBM/NL2PDDL에서 확인할 수 있습니다.

### [MS MARCO Web Search: a Large-scale Information-rich Web Dataset with Millions of Real Click Labels](https://arxiv.org/abs/2405.07526)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.07526.png)

Vote: 4

Authors: Paul Bennett, Corby Rosset, Nikhil Rao, Jingwen Lu, +, Qi Chen, Zheng Liu, Kun Zhou, Anlei Dong, Tao Shen, Nick Craswell, Chenyan Xiong, Bryan Tower, Wenqi Jiang, Zengzhong Li, Chuanjie Liu, Fan Yang, Xing Xie, Rangan Majumder, Mingqin Li, Carolyn Buractaon, Xiubo Geng, Yeyun Gong

- MS MARCO Web Search는 수백만 건의 실제 클릭 쿼리-문서 레이블을 특징으로 하는 최초의 대규모 정보 풍부한 웹 데이터 세트를 소개합니다.
- 이 데이터 세트는 실제 웹 문서와 쿼리 분포를 밀접하게 모방하고, 다양한 종류의 하류 작업을 위한 풍부한 정보를 제공하며, 일반 엔드-투-엔드 신경 인덱서 모델, 일반 임베딩 모델 및 대규모 언어 모델을 사용한 차세대 정보 접근 시스템 연구를 촉진합니다.
- MS MARCO Web Search는 기계 학습 및 정보 검색 시스템 연구 분야에서 혁신을 요구하는 세 가지 웹 검색 도전 과제를 제공하는 검색 벤치마크를 제공합니다.
- 대규모, 실제 및 풍부한 데이터 요구 사항을 충족하는 최초의 데이터 세트로서 MS MARCO Web Search는 AI 및 시스템 연구에서의 미래 발전을 위한 길을 열어줍니다.
- MS MARCO Web Search 데이터 세트는 다음 위치에서 사용할 수 있습니다: https://github.com/microsoft/MS-MARCO-Web-Search.

