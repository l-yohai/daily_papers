## Daily Papers (2024-05-15)

### [Coin3D: Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning](https://arxiv.org/abs/2405.08054)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.08054.png)

Vote: 6

Authors: Xiao Liu, Yuewen Ma, Liyuan Cui, Hujun Bao, Lin Ma, Zhaopeng Cui, Bangbang Yang, Wenqi Dong

- Coin3D는 기본 형태로 조립된 거친 기하학적 프록시를 사용하여 3D 생성을 제어할 수 있는 새로운 3D 자산 모델링 프레임워크입니다.
- 이 프레임워크는 사용자가 지역 부분을 원활하게 편집할 수 있도록 지원하며, 몇 초 내에 반응하는 3D 객체 미리보기를 제공합니다.
- 기술적인 측면에서, 3D 어댑터는 확산 모델에 볼륨적인 거친 형태 제어를 적용하고, 프록시 제한 편집 전략은 정밀한 부분 편집을 위해 사용됩니다.
- 또한, 반응형 미리보기를 지원하기 위한 점진적 볼륨 캐시 및 일관된 메쉬 재구성을 보장하는 볼륨-SDS가 개발되었습니다.
- 다양한 형태의 프록시에 대한 상호 작용 생성 및 편집 실험을 통해, Coin3D는 3D 자산 생성 작업에서 뛰어난 제어 가능성과 유연성을 달성함을 입증했습니다.

### [Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding](https://arxiv.org/abs/2405.08748)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.08748.png)

Vote: 6

Authors: Chen Zhang, Rongwei Quan, Jihong Zhang, Jianwei Zhang, Jianxiang Lu, Qin Lin, Dayou Chen, Yixuan Li, Jiajun He, Zedong Xiao, Xiaoyan Yuan, Yingfang Zhang, Minbin Huang, +, Xinchi Deng, Yanxin Long, Jiahao Li, Jiabin Huang, Xiaoxiao Zheng, Wenyue Li, Zhimin Li, Jiangfeng Xiong, Xingchao Liu

- Hunyuan-DiT는 영어와 중국어 모두의 세부적인 이해력을 갖춘 텍스트-이미지 변환 트랜스포머 모델입니다.
- 이 모델은 트랜스포머 구조, 텍스트 인코더 및 위치 인코딩을 신중하게 설계하여 구축하였습니다.
- 새로운 데이터 파이프라인을 개발하여 반복적 모델 최적화를 위한 데이터 업데이트 및 평가를 수행합니다.
- 세밀한 언어 이해를 위해, 다모달 대형 언어 모델을 학습시켜 이미지의 캡션을 세밀하게 다듬습니다.
- Hunyuan-DiT는 사용자와의 다차례 다모달 대화를 수행하며, 맥락에 따라 이미지를 생성하고 수정할 수 있습니다.
- 50명 이상의 전문 평가자와 함께한 종합적인 인간 평가 프로토콜을 통해, Hunyuan-DiT는 다른 오픈 소스 모델들과 비교하여 중국어 이미지 생성에서 새로운 최고 기준을 설정하였습니다.
- 코드와 사전 훈련된 모델은 github.com/Tencent/HunyuanDiT에서 공개적으로 제공됩니다.

### [Compositional Text-to-Image Generation with Dense Blob Representations](https://arxiv.org/abs/2405.08246)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.08246.png)

Vote: 6

Authors: Weili Nie, Arash Vahdat, Chao Liu, Sifei Liu, Benjamin Eckart, Morteza Mardani

- 현재의 텍스트-이미지 모델들은 복잡한 텍스트 프롬프트를 따르는 데 어려움을 겪어, 보다 나은 제어성을 위해 추가적인 그라운딩 입력이 필요합니다.
- 이 연구에서는 세밀한 장면의 세부 사항을 포함하면서도 모듈식으로, 인간이 이해할 수 있고, 쉽게 구성할 수 있는 시각적 기본 요소인 '밀집 블롭 표현'으로 장면을 분해할 것을 제안합니다.
- 블롭 표현을 기반으로, 복합적인 생성을 위한 블롭-구동 텍스트-이미지 확산 모델인 BlobGEN을 개발했습니다.
- 특히, 블롭 표현과 시각적 특징 사이의 융합을 분리할 새로운 마스크된 크로스-어텐션 모듈을 도입했습니다.
- 대규모 언어 모델의 복합성을 활용하기 위해, 텍스트 프롬프트에서 블롭 표현을 생성하기 위한 새로운 인-컨텍스트 학습 접근법을 소개합니다.
- 연구 결과로 BlobGEN은 MS-COCO에서 뛰어난 제로샷 생성 품질과 더 나은 레이아웃-유도 제어성을 달성했습니다.
- 대규모 언어 모델을 활용할 때, 우리의 방법은 복합 이미지 생성 벤치마크에서 상위 수치적 정확성과 공간적 정확성을 보여줍니다.
- 프로젝트 페이지: https://blobgen-2d.github.io

### [Beyond Scaling Laws: Understanding Transformer Performance with Associative Memory](https://arxiv.org/abs/2405.08707)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.08707.png)

Vote: 3

Authors: Lei Deng, Xueyan Niu, Bo Bai, Wei Han

- 트랜스포머 모델의 크기를 늘리는 것이 항상 성능 향상으로 이어지지는 않으며, 이 현상은 경험적 스케일링 법칙으로 설명될 수 없습니다.
- 이 논문은 트랜스포머 기반 언어 모델의 기억 과정과 성능 동태를 밝히는 이론적 틀을 제시합니다.
- 트랜스포머의 동작을 호프필드 네트워크를 사용하는 연관 메모리로 모델링하여 각 트랜스포머 블록이 근사 최근접 이웃 탐색을 수행하게 합니다.
- 현대 연속 호프필드 네트워크에서 사용되는 에너지 함수에 비견될 수 있는 함수를 설계하여 어텐션 메커니즘에 대한 통찰력 있는 설명을 제공합니다.
- 주요화-최소화 기법을 사용하여 트랜스포머의 계층적 구조를 포착하는 전역 에너지 함수를 구성합니다.
- 특정 조건 하에서, 최소 달성 가능한 교차 엔트로피 손실이 대략 1의 상수로 아래로 제한됨을 보입니다.
- GPT-2를 사용한 다양한 데이터 크기에 대한 실험과 200만 토큰 데이터셋으로 베닐라 트랜스포머를 훈련시키는 실험을 통해 이론적 결과를 입증합니다.

### [SpeechVerse: A Large-scale Generalizable Audio Language Model](https://arxiv.org/abs/2405.08295)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.08295.png)

Vote: 3

Authors: Jie Yuan, Xing Niu, Nilaksh Das, Xilai Li, Kyu J Han, David Huang, Prashant Mathur, Monica Sunkara, Rohit Paturi, Sundararajan Srinivasan, Srikanth Ronanki, Katrin Kirchhoff, Sai Muralidhar Jayanthi, Saket Dingliwal, Karel Mundnich, Dhanush Bekal

- 대규모 언어 모델(Large language models, LLMs)은 자연 언어 지시사항을 이해하는 데 필요한 작업 수행에서 높은 능력을 보여왔습니다.
- 최근 연구들은 이러한 능력을 텍스트와 오디오의 다중 모달 입력을 인식하는 데로 확장하고 있지만, 그 능력은 자동 음성 인식과 번역과 같은 특정 작업에 국한되어 있습니다.
- 이에, 우리는 사전 훈련된 음성 및 텍스트 기반 모델을 소수의 학습 가능한 매개변수를 통해 결합하고 훈련 동안 사전 훈련된 모델을 고정시키는 강건한 다중 작업 훈련 및 커리큘럼 학습 프레임워크인 SpeechVerse를 개발하였습니다.
- 이 모델은 자연 언어 지시사항을 사용하여 다양한 음성 처리 작업에서 최적의 제로샷 성능을 달성하기 위해 음성 기반 모델에서 추출된 지속적인 잠재 표현을 사용하여 지시사항 기반으로 미세 조정됩니다.
- 우리는 다양한 데이터셋과 작업에서 전통적인 기준선과 비교하여 모델 성능을 폭넓게 벤치마킹하였습니다.
- 또한 영역 외 데이터셋, 새로운 프롬프트, 그리고 보지 못한 작업에 대한 테스트를 통해 일반화된 지시사항을 따르는 모델의 능력을 평가했습니다.
- 실험 결과, 다중 작업 SpeechVerse 모델은 11가지 작업 중 9가지에서 전통적인 작업 특정 기준선보다 우수한 성능을 보여주었습니다.

### [SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models](https://arxiv.org/abs/2405.08317)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.08317.png)

Vote: 2

Authors: Nilaksh Das, Daniel Garcia-Romero, Kyu J Han, Zejiang Hou, Goeric Huybrechts, Anshu Bhatia, Sundararajan Srinivasan, Srikanth Ronanki, Katrin Kirchhoff, Sai Muralidhar Jayanthi, Srikanth Vishnubhotla, Raghuveer Peri, Saket Dingliwal, Karel Mundnich

- 최근 대화형 명령을 이해하고 관련 텍스트 응답을 생성할 수 있는 통합 음성 및 대규모 언어 모델(SLM)의 인기가 높아지고 있으나, 이러한 모델의 안전성과 견고성은 여전히 불분명합니다.
- 본 연구에서는 이러한 명령 수행 음성-언어 모델이 적대적 공격과 탈옥(jailbreaking)에 어떻게 취약할 수 있는지를 조사하였습니다.
- 이를 위해 우리는 인간의 개입 없이 SLM을 탈옥할 수 있는 적대적 예제를 생성할 수 있는 알고리즘을 화이트 박스 및 블랙 박스 공격 환경에서 설계하였습니다.
- 추가적으로, 이러한 탈옥 공격을 방지하기 위한 대책을 제안하였습니다.
- 음성 명령이 포함된 대화 데이터에서 훈련된 우리의 모델은 말로 하는 질문-응답 작업에서 상태 기록 성능을 달성하여 안전성 및 유용성 메트릭 모두에서 80% 이상의 점수를 받았습니다.
- 안전 조치에도 불구하고, 탈옥 실험은 SLM이 적대적 변형과 전송 공격에 취약함을 보여주며, 12가지 다양한 독성 범주를 포함한 신중하게 설계된 해로운 질문의 데이터셋에서 평균 공격 성공률이 각각 90% 및 10%입니다.
- 그러나, 우리가 제안한 대책은 공격 성공률을 현저하게 감소시키는 것으로 나타났습니다.

### [No Time to Waste: Squeeze Time into Channel for Mobile Video Understanding](https://arxiv.org/abs/2405.08344)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.08344.png)

Vote: 1

Authors: Xinghao Chen, Wenshuo Li, Yunhe Wang, Yingjie Zhai, Yehui Tang

- 현재 비디오 이해를 위한 아키텍처는 주로 3D 컨볼루션 블록 또는 추가적인 시간적 모델링을 위한 연산을 포함한 2D 컨볼루션을 기반으로 하고 있지만, 이러한 방법들은 비디오 시퀀스의 시간 축을 별도의 차원으로 간주하여 대량의 계산 및 메모리 예산이 요구되며, 이는 모바일 기기에서의 사용을 제한합니다.
- 이 논문에서는 비디오 시퀀스의 시간 축을 채널 차원으로 압축하고, 모바일 비디오 이해를 위한 경량화된 비디오 인식 네트워크인 SqueezeTime을 제시합니다.
- 시간적 모델링 능력을 강화하기 위해, 시간 동적을 포착하는 Channel-Time Learning (CTL) 블록을 설계하였고, 이 모듈은 시간적 중요성 학습을 위한 한 분기와 시간적 위치 복원 능력을 강화하는 다른 분기로 구성되어 있습니다.
- 제안된 SqueezeTime은 모바일 비디오 이해를 위해 가벼우면서 빠르고 높은 정확도를 제공합니다.
- Kinetics400, Kinetics600, HMDB51, AVA2.1 및 THUMOS14 등 다양한 비디오 인식 및 행동 감지 벤치마크에서의 광범위한 실험을 통해 우리 모델의 우수성을 입증하였습니다. 예를 들어, SqueezeTime은 기존 방법들에 비해 Kinetics400에서 +1.2%의 정확도와 +80%의 GPU 처리량 향상을 달성했습니다.
- 코드는 https://github.com/xinghaochen/SqueezeTime 및 https://github.com/mindspore-lab/models/tree/master/research/huawei-noah/SqueezeTime에서 공개적으로 이용 가능합니다.

### [Understanding the performance gap between online and offline alignment algorithms](https://arxiv.org/abs/2405.08448)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.08448.png)

Vote: 1

Authors: Zeyu Zheng, Michal Valko, Yunhao Tang, Bernardo Ávila Pires, Eugene Tarassov, Yong Cheng, Will Dabney, Rémi Munos, Daniele Calandriello, Yuan Cao, Daniel Zhaohan Guo

- 인간 피드백에서의 강화 학습(RLHF)은 큰 언어 모델 정렬의 기본 프레임워크로 확립되어 왔으나, 최근 오프라인 정렬 알고리즘의 인기가 높아짐에 따라 RLHF 내의 정책 샘플링의 필요성에 대한 의문이 제기되고 있다.
- 온라인 방법이 오프라인 방법보다 성능 우위를 보임을 실험을 통해 보여주며, 성능 차이의 원인을 조사하기 위해 세밀하게 설계된 실험적 어블레이션을 수행하였다.
- 오프라인 데이터의 범위나 데이터의 질만으로는 성능 차이를 설득력 있게 설명할 수 없음이 입증되었다.
- 오프라인 알고리즘으로 훈련된 정책은 쌍을 비교하는 능력에서는 우수하나 생성 작업에서는 떨어지는 반면, 온라인 알고리즘으로 훈련된 정책은 생성 작업에서는 뛰어나면서 쌍을 비교하는 작업에서는 떨어졌다.
- 이는 차별화와 생성 능력 간의 독특한 상호 작용을 시사하며, 샘플링 과정에 의해 크게 영향을 받는다.
- 성능 차이는 대조적 및 비대조적 손실 함수 모두에서 지속되며 정책 네트워크를 확장하는 것만으로는 해결되지 않는다.
- 이 연구는 AI 정렬에서 정책 샘플링의 중요한 역할을 강조하며, 오프라인 정렬 알고리즘의 근본적인 도전과제에 대한 통찰을 제공한다.

