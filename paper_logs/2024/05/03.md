## Daily Papers (2024-05-03)

### [Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models](https://arxiv.org/abs/2405.01535)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.01535.png)

Vote: 30

Authors: Juyoung Suk, Seungone Kim, Moontae Lee, Jamin Shin, Graham Neubig, Sean Welleck, Bill Yuchen Lin, Minjoon Seo, Shayne Longpre, Kyungjae Lee

- GPT-4와 같은 독점적 언어 모델들은 다양한 언어 모델의 응답 품질을 평가하는 데 자주 사용되지만, 투명성, 제어 가능성, 비용 문제 등으로 인해 평가 전문의 오픈 소스 언어 모델 개발의 필요성이 대두되었습니다.
- 기존의 오픈 소스 평가 모델은 인간의 평가와 크게 다른 점수를 부여하고, 직접 평가와 쌍방향 순위 매기기의 두 가지 주요 평가 형식을 수행하는 데 필요한 유연성이 부족하며, 일반적인 속성(도움이 되는 성질, 해롭지 않은 성질 등)에만 초점을 맞추어 맞춤형 평가 기준을 바탕으로 평가하는 능력이 없습니다.
- 이러한 문제들을 해결하기 위해, 우리는 인간과 GPT-4의 판단을 더욱 잘 반영하면서도 이전 모델보다 강력한 평가자 언어 모델인 Prometheus 2를 소개합니다.
- Prometheus 2는 직접 평가 및 쌍방향 순위 매기기 형식 모두 처리할 수 있으며 사용자 정의 평가 기준과 함께 처리할 수 있습니다.
- Prometheus 2는 직접 평가 벤치마크 네 개와 쌍방향 순위 매기기 벤치마크 네 개에서 테스트된 모든 오픈 소스 평가자 언어 모델들 중 인간 및 독점적 언어 모델 판단과 가장 높은 상관성과 일치도를 기록했습니다.
- 우리의 모델, 코드, 데이터는 모두 https://github.com/prometheus-eval/prometheus-eval에서 공개적으로 이용 가능합니다.

### [LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report](https://arxiv.org/abs/2405.00732)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.00732.png)

Vote: 24

Authors: Wael Abid, Travis Addair, Timothy Wang, Piero Molino, Devvret Rishi, Justin Zhao, Alex Sherstinsky, Geoffrey Angus, Jeffery Kinnison, Arnav Garg

- 낮은 랭크 적응(Low Rank Adaptation, LoRA)은 대규모 언어 모델(LLM)의 파라미터 효율적인 미세조정(PEFT)을 위한 가장 널리 채택된 방법 중 하나로 부상하였다.
- LoRA는 미세조정 시 훈련 가능한 파라미터 수와 메모리 사용을 줄이면서도 전체 미세조정과 비교 가능한 성능을 달성한다.
- 연구자들은 LoRA로 미세 조정된 LLM의 품질을 10개의 기본 모델과 31개의 작업에 걸쳐 총 310개의 모델에서 평가하였으며, 4비트 LoRA 미세 조정 모델이 기본 모델들을 평균 34점, GPT-4를 10점 앞서는 성능을 보였다.
- 또한, 가장 효과적인 기본 모델을 찾고 작업 복잡성 휴리스틱의 상관 관계 및 예측 능력을 평가하여 미세 조정 결과를 예측하였다.
- LoRAX, 다중 LoRA 미세 조정 모델을 단일 GPU에서 공유된 기본 모델 가중치와 동적 어댑터 로딩을 사용하여 배포할 수 있는 오픈 소스 멀티-LoRA 추론 서버의 지연 시간 및 동시성 기능을 평가하였다.
- LoRA Land 웹 애플리케이션은 하나의 NVIDIA A100 GPU에서 25개의 LoRA로 미세 조정된 Mistral-7B LLM을 호스팅하여 단일 범용 LLM보다 여러 전문화된 LLM을 사용하는 것의 품질과 비용 효율성을 강조한다.

### [StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation](https://arxiv.org/abs/2405.01434)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.01434.png)

Vote: 18

Authors: Yupeng Zhou, Jiashi Feng, Qibin Hou, Daquan Zhou, Ming-Ming Cheng

- 이 논문에서는 연속적인 이미지 생성에서 일관된 내용을 유지하는 것이 중요한 도전 과제로 제시되며, 이를 해결하기 위해 'Consistent Self-Attention' 이라는 새로운 자기 주의 계산 방법을 제안합니다.
- 제안된 방법은 기존의 사전 훈련된 확산 기반 텍스트-이미지 모델을 개선하여 Zero-shot 방식으로 이미지 간의 일관성을 크게 향상시킵니다.
- 또한, 장기 비디오 생성을 위해 'Semantic Motion Predictor'라는 새로운 의미 공간 시간 모션 예측 모듈을 도입하여 두 이미지 간의 움직임 조건을 의미 공간에서 추정하게 합니다.
- 이 모듈 덕분에 생성된 이미지 시퀀스를 부드러운 전환과 일관된 주제를 가진 비디오로 변환할 수 있으며, 특히 긴 비디오 생성 컨텍스트에서 기존 잠재 공간 기반 모듈보다 훨씬 안정적인 결과를 제공합니다.
- StoryDiffusion 프레임워크는 텍스트 기반 스토리를 다양한 내용을 포함하는 일관된 이미지나 비디오로 묘사할 수 있으며, 시각적 스토리 생성 분야에서 새로운 탐색을 제시합니다.
- 이 연구의 코드는 공개적으로 제공되며, 아키텍처 변경 측면에서 더 많은 연구를 촉진하기를 기대합니다.

### [WildChat: 1M ChatGPT Interaction Logs in the Wild](https://arxiv.org/abs/2405.01470)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.01470.png)

Vote: 16

Authors: Wenting Zhao, Claire Cardie, Xiang Ren, Yuntian Deng, Yejin Choi, Jack Hessel

- GPT-4 및 ChatGPT와 같은 챗봇이 수백만 명의 사용자에게 서비스를 제공하고 있음에도 불구하고, 실제 사용자들이 이러한 도구를 어떻게 사용하는지 보여주는 공개 데이터셋의 부족이 존재합니다.
- 이 격차를 메우기 위해, 연구자들은 온라인 사용자들에게 ChatGPT 접근을 무료로 제공하고, 그 대가로 사용자들의 동의를 받아 채팅 내역과 요청 헤더를 익명으로 수집하였습니다.
- 이로부터 1백만 개의 사용자-ChatGPT 대화로 구성된 WildChat 데이터셋을 만들었으며, 이 데이터셋은 250만 개 이상의 상호작용 턴을 포함합니다.
- WildChat 데이터셋을 다른 인기 있는 사용자-챗봇 상호작용 데이터셋과 비교했을 때, 가장 다양한 사용자 프롬프트, 가장 많은 언어 수, 가장 풍부한 잠재적으로 유해한 사용 사례들을 포함하고 있는 것으로 나타났습니다.
- 연구자들은 시간대별 채팅 기록, 주, 국가, 해시된 IP 주소, 요청 헤더 등 인구 통계 데이터로 데이터셋을 풍부하게 하여, 다양한 지리적 지역 및 시간적 차원에서의 사용자 행동을 더 자세히 분석할 수 있도록 하였습니다.
- 이 데이터셋은 넓은 범위의 사용 사례를 캡처함으로써, 지시를 따르는 모델을 미세 조정하는 데 있어서의 잠재적 유용성을 시연합니다.
- WildChat은 AI2 ImpACT 라이센스하에 https://wildchat.allen.ai 에서 공개되었습니다.

### [NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment](https://arxiv.org/abs/2405.01481)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.01481.png)

Vote: 11

Authors: Markel Sanz Ausin, Shengyang Sun, Ashwath Aithal, Yi Dong, Olivier Delalleau, Gerald Shen, Jimmy Zhang, Sahil Jain, Ali Taghibakhshi, Oleksii Kuchaiev, Zhilin Wang, Jiaqi Zeng, Daniel Egert

- 인간의 가치와 선호도에 맞는 대규모 언어 모델(Large Language Models, LLMs) 정렬은 이들을 유용하고 안전하게 만드는 데 필수적입니다.
- NeMo-Aligner은 수백 대의 GPU에서 효과적으로 확장되는 모델 정렬을 위한 툴킷으로, 사람의 피드백에 따른 강화 학습(RLHF), 직접 선호 최적화(DPO), SteerLM, 자체 플레이 정밀 조정(SPIN)과 같은 주요 모델 정렬 방식을 매우 최적화되고 확장 가능한 구현으로 제공합니다.
- 이 툴킷은 대부분의 정렬 기술을 매개 변수 효율적인 미세 조정(Parameter Efficient Fine-Tuning, PEFT) 환경에서 실행할 수 있도록 지원합니다.
- NeMo-Aligner는 확장성을 고려하여 설계되었으며, 최소한의 노력으로 다른 정렬 기술을 지원하도록 재구성할 수 있습니다.
- Apache 2.0 라이선스로 오픈 소스화되어 있으며, https://github.com/NVIDIA/NeMo-Aligner에서 커뮤니티의 공헌을 초대합니다.

### [Customizing Text-to-Image Models with a Single Image Pair](https://arxiv.org/abs/2405.01536)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.01536.png)

Vote: 7

Authors: Maxwell Jones, Nupur Kumari, Sheng-Yu Wang, Jun-Yan Zhu, David Bau

- 이 논문은 참조 작업의 변형을 만드는 예술 재해석의 관행에 대해 다룹니다.
- 연구팀은 단일 이미지 쌍을 사용하여 생성 모델을 사용자 정의하도록 스타일 차이를 학습할 수 있는지를 탐구합니다.
- 제안된 'Pair Customization' 방법은 단일 이미지 쌍에서 스타일 차이를 학습하여 생성 과정에 적용합니다.
- 이 방법은 쌍을 이루는 이미지 간의 스타일 차이를 포착하여 특정 이미지 내용에 과적합하는 것을 방지합니다.
- 스타일과 내용을 분리하는 LoRA 가중치 공간을 사용하는 공동 최적화 방법을 사용하여 이 새로운 작업에 접근합니다.
- 스타일 가이던스를 기반으로 수정된 확산 과정을 통해 추론 중에 스타일 변경을 적용합니다.
- 질적 및 양적 실험을 통해 이 방법이 스타일을 효과적으로 학습하면서 이미지 내용에 과적합하지 않음을 보여줍니다.

### [FLAME: Factuality-Aware Alignment for Large Language Models](https://arxiv.org/abs/2405.01525)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.01525.png)

Vote: 7

Authors: Jimmy Lin, Luyu Gao, Xilun Chen, Sheng-Chieh Lin, Wen-tau Yih, Wenhan Xiong, Barlas Oguz

- 대규모 언어 모델(LLM)의 기존 조정 과정은 팩트의 정확성을 향상시키지 못하고 오히려 거짓 사실을 더 많이 생성하는 문제가 있습니다.
- 이 연구는 감독 학습(SFT) 및 강화 학습(RL) 단계에서 환각을 유발하는 요인을 파악하여 조정 과정을 보다 팩트 중심으로 만드는 방법을 모색합니다.
- 특히, LLM이 낯선 지식이나 텍스트에 대해 학습할 때 환각이 촉진될 수 있으며, 이는 SFT가 새롭고 인간이 레이블링한 데이터를 기반으로 수행될 때 덜 사실적인 결과를 초래할 수 있습니다.
- 또한, 표준 RL에서 사용되는 보상 함수는 종종 더 긴 및 상세한 응답을 선호함으로써 환각을 장려하는 경향이 있습니다.
- 이러한 관찰을 바탕으로, 본 논문은 팩트 중심 감독 학습 및 팩트 중심의 강화 학습을 통한 직접 선호 최적화를 포함하는 팩트 중심 조정을 제안합니다.
- 실험 결과, 제안된 팩트 중심 조정 방법은 LLM이 지시사항을 따르면서 보다 사실적인 반응을 제공하도록 유도함을 보여줍니다.

### [LLM-AD: Large Language Model based Audio Description System](https://arxiv.org/abs/2405.00983)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.00983.png)

Vote: 7

Authors: Andre Abrantes, Jiang Wang, Peng Chu

- 오디오 설명(AD)은 비디오 콘텐츠를 더욱 접근 가능하고 포괄적으로 만드는 중요한 발전 단계입니다.
- 이 논문에서는 GPT-4V(ision)의 강력한 멀티모달 및 지시에 따른 수행 능력을 활용하는 자동화된 AD 생성 파이프라인을 소개합니다.
- 사용된 방법론은 추가적인 훈련 없이 사용할 수 있는 기존 컴포넌트들을 활용하며, 설명적 스타일의 캡션에서 AD 스타일로의 맞춤화가 필요하지 않습니다.
- 시스템은 자연스러운 언어 AD 생산 기준을 준수할 뿐만 아니라, 추적 기반의 캐릭터 인식 모듈을 통해 프레임 간 일관된 캐릭터 정보를 유지합니다.
- MAD 데이터셋에서의 철저한 분석을 통해, 본 접근법은 자동화된 AD 생산에서 학습 기반 방법들과 동등한 수준의 성능을 달성하였으며, 이는 CIDEr 점수 20.5로 입증되었습니다.

