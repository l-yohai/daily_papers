## Daily Papers (2024-05-24)

### [Not All Language Model Features Are Linear](https://arxiv.org/abs/2405.14860)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14860.png)

Vote: 17

Authors: Max Tegmark, Wes Gurnee, Joshua Engels, Eric J. Michaud, Isaac Liao

- 최근 연구에서는 언어 모델이 개념의 일차원적 표현("특징")을 활성화 공간에서 조작함으로써 계산을 수행한다는 선형 표현 가설을 제안하였습니다.
- 이에 반해, 일부 언어 모델 표현이 본질적으로 다차원일 수 있음을 탐구합니다.
- 우리는 독립적이거나 동시에 발생하지 않는 저차원 특징으로 분해할 수 있는지 여부에 따라 축소 불가능한 다차원 특징의 엄격한 정의를 개발합니다.
- 이러한 정의에 동기를 얻어, GPT-2와 Mistral 7B에서 다차원 특징을 자동으로 찾기 위한 확장 가능한 방법을 디자인하였고, 이 방법은 희소 오토인코더를 사용합니다.
- 자동으로 발견된 특징들 중에는 주목할 만한 해석 가능한 예가 포함되어 있으며, 예를 들어 주의 날짜와 연도의 달을 나타내는 원형 특징들이 있습니다.
- 이러한 정확한 원형들이 주의 날짜와 연도의 달에 관련된 모듈러 산술 문제를 해결하는 데 사용됨을 확인합니다.
- 마지막으로, Mistral 7B와 Llama 3 8B에 대한 개입 실험을 통해 이러한 원형 특징이 이러한 작업에서 계산의 근본적인 단위임을 입증하는 증거를 제공합니다.
- 추가로, 이러한 작업에 대한 숨겨진 상태를 해석 가능한 구성 요소로 분해함으로써 더 많은 원형 표현을 찾습니다.

### [DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data](https://arxiv.org/abs/2405.14333)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14333.png)

Vote: 11

Authors: Chong Ruan, Wenda Li, Daya Guo, Huajian Xin, Zhihong Shao, Bo Liu, Xiaodan Liang, Qihao Zhu, Zhizhou Ren

- Lean에 의해 수학적 증명 검증의 정확성과 신뢰성이 향상되었으나, LLM의 정형 정리 증명 발전은 훈련 데이터 부족으로 제한되었습니다.
- 이를 해결하기 위해 고등학교 및 대학 수준의 수학 경시 문제에서 파생된 방대한 Lean 4 증명 데이터를 생성하는 접근법을 도입하였습니다.
- 자연어 문제를 공식 문장으로 번역하고, 저품질 문장을 필터링하며, 증명을 생성하여 합성 데이터를 만드는 과정을 포함합니다.
- 합성 데이터셋(800만 개의 공식 문장과 증명 포함)으로 DeepSeekMath 7B 모델을 미세 조정한 결과, Lean 4 miniF2F 테스트에서 64개 샘플에 대해 46.3%, 누적 52%의 전체 증명 생성 정확도를 달성하였습니다.
- 이는 기준 모델인 GPT-4와 트리 검색 강화 학습 방법을 크게 뛰어넘는 성과입니다.
- 또한, 모델은 Lean 4 Formalized International Mathematical Olympiad (FIMO) 벤치마크에서 148개 문제 중 5개를 성공적으로 증명하였으며, GPT-4는 하나도 증명하지 못했습니다.
- 이러한 결과는 대규모 합성 데이터를 활용하여 LLM에서의 정리 증명 능력을 향상시킬 수 있는 가능성을 보여줍니다.
- 연구 지원을 위해 합성 데이터셋과 모델은 공개될 예정입니다.

### [ReVideo: Remake a Video with Motion and Content Control](https://arxiv.org/abs/2405.13865)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.13865.png)

Vote: 11

Authors: Chong Mou, Zhaoyang Zhang, Mingdeng Cao, Ying Shan, Xintao Wang, Jian Zhang

- 이 논문은 ReVideo를 통해 동영상의 특정 부분에 대한 정밀 편집을 구현하고, 내용과 동작을 동시에 제어할 수 있는 새로운 동영상 편집 방법을 제시합니다.
- 첫번째 프레임을 수정하여 내용을 편집하고, 궤적 기반의 동작 제어를 통해 직관적인 사용자 상호 작용을 제공합니다.
- 내용과 동작 제어 사이의 결합과 훈련 불균형을 해결하기 위해, 세 단계의 훈련 전략을 개발하여 이 두 측면을 점차 분리시킵니다.
- 공간적 위치와 샘플링 단계에 걸쳐 내용과 동작 제어를 통합하는 시공간 적응 융합 모듈을 제안합니다.
- ReVideo는 동영상의 내용을 지역적으로 변경하면서 동작을 유지하거나 내용은 그대로 두고 새로운 동작 궤적을 사용자 지정하거나 두 가지 모두를 수정하는 등의 다양한 정밀 비디오 편집 애플리케이션에서 유망한 성능을 보입니다.
- ReVideo는 특정 훈련 없이도 다지역 편집을 원활하게 확장할 수 있어 유연성과 강인성을 입증합니다.

### [LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models](https://arxiv.org/abs/2405.14477)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14477.png)

Vote: 10

Authors: Otmar Hilliges, Seyedmorteza Sadat, Romann M. Weber, Jakob Buhmann, Derek Bradley

- LiteVAE는 고해상도 이미지 생성을 혁신한 잠재 확산 모델(LDMs)을 위한 새로운 가족의 오토인코더로, 표준 변이형 오토인코더(VAEs)보다 확장성과 계산 효율성을 개선하기 위해 2D 이산 웨이블릿 변환을 활용합니다.
- 이 논문에서는 LiteVAE의 훈련 방법론과 디코더 구조를 조사하고, 훈련 동역학과 재구성 품질을 개선하는 여러 가지 향상을 제안합니다.
- 기초 LiteVAE 모델은 기존 LDM 내의 VAE와 동일한 품질을 유지하면서 인코더 파라미터를 6배 줄여, 더 빠른 훈련과 낮은 GPU 메모리 요구사항을 가능하게 합니다.
- 더 큰 모델은 비교 가능한 복잡성을 가진 다른 VAE보다 모든 평가 척도(rFID, LPIPS, PSNR, SSIM)에서 우수한 성능을 보입니다.

### [Dense Connector for MLLMs](https://arxiv.org/abs/2405.13800)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.13800.png)

Vote: 9

Authors: YuXin Song, Huanjin Yao, Jingdong Wang, Wenhao Wu, Zhiheng Li, Yifan Sun, Haocheng Feng, Wanli Ouyang, Mengxi Zhang, Taojiannan Yang

- 다양한 매체에 대한 이해력을 향상시키기 위해 다양한 MLLM들이 큰 주목을 받아왔지만, 현재의 MLLM 개발 경쟁에서는 주로 언어적 측면에 중접되어 있다.
- 이 논문에서는, 기존의 MLLM에 사용되는 고정된 시각적 인코더에서 추출된 최고 수준의 기능에만 의존하는 현 상황에 주목하고, 시각적 신호를 모든 층에서 활용하는 Dense Connector를 소개한다.
- Dense Connector는 간단하고 효과적이며, 추가적인 계산 부하를 최소화하면서 MLLMs에 적용 가능한 플러그 앤 플레이 비전-언어 연결기로서 기능한다.
- 단일 이미지 학습을 통한 모델은 영상 이해에서도 뛰어난 제로샷 능력을 선보이며, 다양한 비전 인코더, 이미지 해상도, 교육 데이터셋의 크기, LLM의 크기(2.7B에서 70B), MLLM의 다양한 구조(예: LLaVA 및 Mini-Gemini)에서의 실험 결과가 이 접근법의 다양성과 확장성을 입증한다.
- 논문은 19개의 이미지 및 비디오 벤치마크에서 최고의 성능을 달성함으로써 MLLM 개발을 위한 중요한 경험과 기본 모듈을 제공하길 기대한다.

### [Thermodynamic Natural Gradient Descent](https://arxiv.org/abs/2405.13817)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.13817.png)

Vote: 8

Authors: Denis Melanson, Maxwell Aifer, Patrick J. Coles, Samuel Duffield, Gavin Crooks, Kaelan Donatella

- 이 논문은 자연 경사 하강법(Natural Gradient Descent, NGD)이 적절한 하드웨어를 채택함으로써 1차 방법과 비슷한 계산 복잡성을 가질 수 있음을 보여줍니다.
- 디지털-아날로그 하이브리드 알고리즘을 제시하여, 부담스러운 선형 시스템 해를 피하면서 NGD에 해당하는 신경망 훈련을 가능하게 합니다.
- 이 알고리즘은 아날로그 시스템의 열역학적 속성을 활용하여, 아날로그 열역학 컴퓨터가 필요합니다.
- 훈련은 디지털-아날로그 루프에서 이루어지며, 경사와 피셔 정보 행렬 또는 다른 양의 준정부호 곡률 행렬이 정해진 시간 간격으로 계산됩니다.
- 분류 작업 및 언어 모델 미세조정 작업에서 이 접근 방법이 최신 디지털 1차 및 2차 훈련 방법보다 우수함을 수치적으로 입증합니다.

### [Improved Distribution Matching Distillation for Fast Image Synthesis](https://arxiv.org/abs/2405.14867)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14867.png)

Vote: 8

Authors: Eli Shechtman, Michaël Gharbi, Taesung Park, William T. Freeman, Richard Zhang, Tianwei Yin, Fredo Durand

- 최근 연구에서는 확산 모델을 효율적인 원스텝 생성기로 정제하는 방법을 탐구했습니다.
- 기존의 배포 일치 정제(DMD) 방식은 추가적인 회귀 손실을 필요로 하여 대규모 텍스트-이미지 합성에서 비용이 많이 들고, 학생 모델의 질이 교사 모델의 샘플링 경로에 지나치게 의존하게 합니다.
- 새롭게 소개된 DMD2는 이러한 한계를 극복하고 DMD 훈련을 개선하는 기술들을 제안합니다.
- DMD2는 비용이 많이 드는 데이터셋 구축의 필요성 없이 회귀 손실을 제거하고, 가짜 비평가가 생성된 샘플의 분포를 정확히 추정하지 못하는 불안정성을 두 시간 규모 업데이트 규칙으로 해결합니다.
- 또한, 생성된 샘플과 실제 이미지를 구분하는 GAN 손실을 증류 절차에 통합하여, 교사 모델의 불완전한 실제 점수 추정을 완화하고 품질을 향상시킵니다.
- 마지막으로, 멀티스텝 샘플링을 가능하게 하는 훈련 절차를 수정하고, 훈련 시 시뮬레이션으로 추론 시 생성기 샘플을 구현하여 훈련-추론 입력 불일치 문제를 해결합니다.
- 이러한 개선을 통해, DMD2는 ImageNet-64x64에서 FID 점수 1.28, COCO 2014 제로샷에서 8.35로 원래의 교사 모델을 뛰어넘는 새로운 벤치마크를 설정하며, 추론 비용을 500배 줄였습니다.
- 또한, SDXL를 정제하여 메가픽셀 이미지를 생성할 수 있으며, 몇 단계의 방법 중에서 뛰어난 시각적 품질을 보여줍니다.

### [Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation](https://arxiv.org/abs/2405.14598)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14598.png)

Vote: 8

Authors: Shiqi Yang, Masato Ishii, Zhi Zhong, Mengjie Zhao, Shusuke Takahashi, Takashi Shibuya, Yuki Mitsufuji

- 최근 몇 년 동안, 현실적인 생성 결과 및 맞춤형 응용 프로그램의 다양성으로 인해 확산 기반 생성 모델이 시각 및 음향 생성 분야에서 큰 주목을 받고 있다.
- Text2image 혹은 Text2audio 생성에 비해 Audio2visual 및 Visual2audio 생성 연구는 상대적으로 느리게 진행되고 있으며, 최근의 오디오-비주얼 생성 방법들은 대형 언어 모델이나 조합 가능한 확산 모델을 주로 사용하고 있다.
- 본 논문에서는 거대한 모델을 설계하는 대신, 간단하고 가벼운 생성 트랜스포머가 다중 모달 생성에서 뛰어난 결과를 달성할 수 있음을 보여준다.
- 이 트랜스포머는 이산 오디오 및 비주얼 Vector-Quantized GAN 공간에서 작동하며 마스크 잡음 제거 방식으로 훈련된다.
- 훈련 후, 분류자 없는 지도를 즉시 사용할 수 있으며 추가 훈련이나 수정 없이 성능이 향상된다.
- 모달리티 적대성을 가진 이 트랜스포머 모델은 오디오2이미지 생성 및 공동 생성에도 직접 배치할 수 있다.
- 실험을 통해 이 간단한 방법이 최근의 이미지2오디오 생성 방법들을 능가하는 것을 보여준다.
- 생성된 오디오 샘플은 온라인에서 확인할 수 있다.

### [AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability](https://arxiv.org/abs/2405.14129)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14129.png)

Vote: 7

Authors: Junjie Guo, Shangyu Xing, Xinyu Dai, Chunhui Li, Fei Zhao, Taotian Pang, Zhen Wu

- 멀티모달 대형 언어 모델(MLLM)은 인공 일반 지능(AGI) 탐구에 있어 핵심적인 요소로 여겨지며, 이들의 중심은 다양한 모달 간의 정렬 능력 달성에 있습니다.
- 기존의 MLLM은 모든 이미지-텍스트 쌍이 동일하게 정렬되어 있다고 가정하며, 이는 실제와 다를 수 있는데, 정렬 정도가 다양한 이미지-텍스트 쌍을 고려하지 못하는 단점이 있습니다.
- 또한, 튜닝 단계에서 사용되는 지침이 다양한 작업을 포함하고 있어, 다양한 수준의 정렬 능력을 요구하지만, 이전 모델들은 이러한 차별화된 정렬 요구 사항을 간과했습니다.
- 이러한 문제들을 해결하기 위해 우리는 새로운 멀티모달 대형 언어 모델인 AlignGPT를 제안합니다. 이 모델은 이미지-텍스트 쌍마다 다른 수준의 정려 능력을 할당하고, 지시-튜닝 단계에서 이 다른 수준의 정렬 능력을 동적으로 조합하여 다양한 지시의 정렬 요구를 충족시킵니다.
- AlignGPT는 12개의 벤치마크에서 경쟁력 있는 성능을 보였습니다, 이를 통해 제안 모델의 유효성이 입증되었습니다.

### [RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance](https://arxiv.org/abs/2405.14677)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14677.png)

Vote: 7

Authors: Di Zhang, Yadong Mu, Zhicheng Sun, Liwei Chen, Yang Jin, Haozhe Chi, Kun Xu, Kun Gai, Zhenhao Yang, Yang Song, Hao Jiang

- 사용자 제공 참조 이미지에서 신원 보존 이미지를 생성하는 맞춤형 확산 모델을 다루는 새로운 문제가 제시되었습니다.
- 기존의 대부분의 접근 방식은 특정 도메인의 대량 이미지 학습을 필요로 하여 다양한 사용 사례에서의 유연성이 부족합니다.
- 이 문제를 해결하기 위해 기존 분류기를 사용하는 확산 모델을 조정하는 교육이 필요 없는 분류기 안내 기술을 활용합니다.
- 최근 정류된 흐름 프레임워크를 기반으로, 바닐라 분류기 안내의 주요 제한을 간단한 고정점 솔루션으로 해결하여 개인 맞춤화를 위한 유연성을 제공합니다.
- 이 방법은 참조 흐름 궤적에 고정되어 있을 때 안정적으로 해결책을 찾는 데 성공했으며, 수렴을 보장합니다.
- 인간 얼굴, 실제 주제, 특정 객체에 대한 유리한 개인화 결과를 생성하는 데 다른 기성 이미지 판별기와 함께 정류된 흐름에서 구현되었습니다.
- 관련 코드는 https://github.com/feifeiobama/RectifID에서 제공됩니다.

### [Distributed Speculative Inference of Large Language Models](https://arxiv.org/abs/2405.14105)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14105.png)

Vote: 6

Authors: Moshe Wasserblat, Moshe Berchansky, Tomer Galanti, David Harel, Daniel Korat, Nadav Timor, Oren Pereg, Michal Gordon, Jonathan Mamou

- 본 논문은 대형 언어 모델(LLMs)의 추론 속도를 높이는 분산 추론 알고리즘, 분산 추측적 추론(Distributed Speculative Inference, DSI)을 소개하며, 이는 기존의 추측적 추론(Speculative Inference, SI) 및 전통적인 자기회귀 추론(non-SI)보다 빠르다고 증명된다.
- DSI는 훈련이나 구조적 변경 없이 고정된 LLM에서 작동하며, 타깃 분포를 유지한다는 점에서 다른 SI 알고리즘들과 유사하다.
- 기존의 연구에서 SI가 비-SI 대비 눈에 띄는 속도 향상을 보였으나, 충분히 빠르고 정확한 기초 모델(Drafter LLM)을 활용하기 어려운 실제 상황에서는 SI의 효율이 저하될 수 있음이 드러났다.
- DSI는 타깃 모델과 다수의 기초 모델을 조율함으로써, 기존 SI 및 non-SI보다 모든 기초 모델에서 빠르게 작동함을 증명, SI만으로는 가속화할 수 없는 LLM을 지원한다.
- 실제 설정에서 벗어나지 않은 LLM에 대한 시뮬레이션 결과, DSI는 SI보다 1.29-1.92배 빠른 속도 향상을 보였다.

### [DiM: Diffusion Mamba for Efficient High-Resolution Image Synthesis](https://arxiv.org/abs/2405.14224)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14224.png)

Vote: 6

Authors: Yue Wu, Yu Wang, Guohao Dai, Han Shi, Zhenguo Li, Yao Teng, Xuefei Ning, Xihui Liu

- 이미지 생성에서 큰 성공을 거둔 확산 모델은 U-Net에서 비전 트랜스포머로 진화하였으나, 고해상도 이미지를 처리할 때 트랜스포머의 계산 비용은 토큰 수에 비례하여 제곱으로 증가하는 문제가 있습니다.
- 이 연구에서는 상태 공간 모델(SSM)을 기반으로 하는 효율적인 시퀀스 모델인 'Mamba'의 효율성과 확산 모델의 표현력을 결합하여 고해상도 이미지 합성을 위한 'Diffusion Mamba (DiM)'를 제안합니다.
- 2D 신호에 일반화가 어려운 Mamba의 한계를 극복하기 위해 다방향 스캔, 각 행과 열의 끝에 배치되는 학습 가능한 패딩 토큰, 경량의 지역 특성 강화 설계를 포함한 여러 아키텍처 설계를 수행하였습니다.
- DiM 아키텍처는 고해상도 이미지에 대한 추론 시간 효율성을 달성합니다.
- 또한, 고해상도 이미지 생성의 학습 효율을 더욱 향상시키기 위해, 저해상도 이미지(256x256)에서 DiM을 사전 훈련시킨 후 고해상도 이미지(512x512)로 미세조정하는 '약간-강함' 훈련 전략을 탐구합니다.
- 훈련 없는 업샘플링 전략을 추가로 탐색하여, 모델이 더 높은 해상도 이미지(예: 1024x1024, 1536x1536)를 미세 조정 없이 생성할 수 있게 합니다.
- 실험을 통해 DiM의 효과성과 효율성이 입증되었습니다.

### [CamViG: Camera Aware Image-to-Video Generation with Multimodal Transformers](https://arxiv.org/abs/2405.13195)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.13195.png)

Vote: 5

Authors: Dan Kondratyuk, Andrew Marmon, José Lezama, Irfan Essa, Grant Schindler, Bryan Seybold

- 이 연구에서는 비디오 생성 작업을 위해 3D 카메라 모션을 조건 신호로 포함하는 멀티모달 트랜스포머의 확장을 제안합니다.
- 제너레이티브 비디오 모델이 강력해지면서 모델의 출력을 제어하는 방법에 대한 연구가 집중되고 있습니다.
- 연구팀은 생성된 비디오에 3차원 카메라 움직임의 인코딩을 조건으로 하여 가상의 3D 카메라 제어를 추가하였습니다.
- 결과는 단일 프레임과 카메라 신호에서 시작하여 비디오 생성 중 카메라를 성공적으로 제어할 수 있음을 보여주며,
- 생성된 3D 카메라 경로의 정확성을 전통적인 컴퓨터 비전 방법을 사용하여 입증합니다.

### [Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling](https://arxiv.org/abs/2405.14847)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14847.png)

Vote: 4

Authors: Kalyan Sunkavalli, Iliyan Georgiev, Liwen Wu, Ravi Ramamoorthi, Fujun Luan, Kai Zhang, Sai Bi, Zexiang Xu

- 이 논문은 반사성 물체의 새로운 시점 합성을 위해 NeRF(Neural Radiance Fields)의 시점 의존적 외관 인코딩인 Neural Directional Encoding(NDE)을 제시합니다.
- NDE는 기능-격자 기반 공간 인코딩 개념을 각도 영역으로 전달하여 고주파수 각도 신호를 모델말 수 있도록 크게 향상시킵니다.
- 이 방법은 단지 각도 입력만 사용하는 기존 방법들과 달리, 공간적으로 변화하는 방향적 인코딩을 얻기 위해 공간 특징을 콘-트레이싱하여 어려운 내부 반사 효과를 해결합니다.
- 실제 데이터셋과 합성 데이터셋에서의 광범위한 실험을 통해, NDE를 적용한 NeRF 모델은 반사성 물체의 시점 합성에서 최신 기술을 뛰어넘는 성능을 보이며, 작은 네트워크로도 실시간 추론이 가능함을 보여줍니다.
- 프로젝트 웹페이지와 소스 코드는 https://lwwu2.github.io/nde/에서 확인할 수 있습니다.

### [Semantica: An Adaptable Image-Conditioned Diffusion Model](https://arxiv.org/abs/2405.14857)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14857.png)

Vote: 4

Authors: Manoj Kumar, Emiel Hoogeboom, Neil Houlsby

- 이미지 생성 모델을 다양한 데이터셋에 맞게 적응시키는 과제를 조사하고, 이를 위해 Semantica라는 이미지 조건부 확산 모델을 소개합니다.
- Semantica는 조건부 이미지의 의미론적 요소에 기반하여 이미지를 생성할 수 있도록 훈련되며, 웹 페이지의 무작위 이미지 쌍을 사용합니다.
- 연구에서는 사전 훈련된 이미지 인코더의 표현력과 고품질 이미지 생성을 위한 의미 기반 데이터 필터링의 필요성을 강조합니다.
- 한 번 훈련되면, 특정 데이터셋으로부터 입력 이미지를 사용하여 새로운 이미지를 적응적으로 생성할 수 있습니다.
- Semantica의 전이 특성은 ImageNet, LSUD 교회, LSUN 침실 및 SUN397에서 연구되었습니다.

### [Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using Sparse RGB Cameras](https://arxiv.org/abs/2405.14866)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14866.png)

Vote: 3

Authors: Hao Zhang, Shunyuan Zheng, Wenyu Li, Hanzhang Tu, Shengping Zhang, Xue Dong, Ruizhi Shao, Siyan Ma, Boyao Zhou, Yebin Liu, Meili Wang, Lili Chen

- 본 논문에서는 동료 간 통신 시나리오를 대상으로 저비용이면서도 높은 진위성을 갖춘 양방향 원격재현 시스템인 'Tele-Aloha'를 제시합니다.
- 이 시스템은 네 대의 희소 RGB 카메라, 소비자용 GPU 하나, 그리고 입체감 있는 영상을 생성할 수 있는 자동 스테레오스코픽 화면 하나만을 사용하여 구현됩니다.
- Tele-Aloha는 고해상도(2048x2048), 실시간 처리(30fps), 낮은 지연 시간(150ms 미만) 및 견고한 원거리 통신을 달성합니다.
- 시스템의 핵심으로, 상반신을 위한 효율적인 새로운 시점 합성 알고리즘이 제안되며, 이는 견고한 기하학적 단서를 얻기 위해 연속적인 불일치 추정기를 설계합니다.
- 추가로, 타겟 뷰로의 잠재 기능을 투영하고 이를 저해상도로 디코딩하기 위해 가우시안 스플래팅을 이용한 신경 래스터라이저가 도입됩니다.
- 고품질의 데이터를 활용하여 가중치 혼합 메커니즘을 통해 최종 해상도인 2K 이미지로 디코딩된 이미지를 정제합니다.
- 세계 선도적인 자동 스테레오스코픽 디스플레이와 저지연 아이리스 추적을 활용함으로써 사용자는 별도의 착용형 디스플레이 장치 없이도 강렬한 3차원 감각을 경험할 수 있습니다.
- 전체적으로, Tele-Aloha 원격재현 시스템은 실제 실험에서 현존감을 입증하며, 차세대 통신 기술에 영감을 제공합니다.

### [NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections](https://arxiv.org/abs/2405.14871)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2405.14871.png)

Vote: 3

Authors: Ben Mildenhall, Dor Verbin, Jonathan T. Barron, Peter Hedman, Benjamin Attal, Pratul P. Srinivasan, Richard Szeliski

- 기존의 신경 복사 필드(NeRF)는 시점이 변할 때 급격히 변하는 높은 광택을 가진 객체의 재구성과 렌더링에서 어려움을 겪습니다.
- 최근 연구들은 멀리 있는 환경 조명의 세밀한 광택 표현력을 향상시켰지만, 가까운 콘텐츠의 일관된 반사를 만들어내지 못합니다.
- 이러한 기술들은 방출되는 시점 의존성 광선을 모델링하기 위해 크고 계산 비용이 많이 드는 신경망에 의존하며, 이는 최적화와 렌더링 속도를 크게 제한합니다.
- 우리는 비싼 신경망을 조회하는 대신, 카메라 레이를 따라 각 지점에서 반사 레이를 캐스팅하여 NeRF 표현을 통해 추적하고 이를 통해 렌더링된 특징 벡터를 작고 저렴한 네트워크를 사용해 색상으로 디코딩하는 레이 트레이싱 기반 접근 방식을 제안합니다.
- 우리 모델은 반짝이는 객체가 포함된 장면의 시점 합성에서 이전 방법들을 능가하는 성능을 보여주며, 실제 세계 장면에서 사실적인 광택과 반사를 합성할 수 있는 유일한 기존 NeRF 방법입니다.
- 또한, 현재 최첨단 시점 합성 모델과 비교해도 비슷한 최적화 시간이 요구됩니다.

