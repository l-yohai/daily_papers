## Daily Papers (2024-05-01)

### [Octopus v4: Graph of language models](https://arxiv.org/abs/2404.19296)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19296.png)

Vote: 44

Authors: Wei Chen, Zhiyuan Li

- 언어 모델은 다양한 응용 분야에서 효과적이지만, 가장 고급 모델들은 종종 독점적입니다. 예를 들어, OpenAI의 GPT-4와 Anthropic의 여러 모델은 비용이 많이 들고 많은 에너지를 소모합니다.
- 반면에 오픈 소스 커뮤니티는 Llama3처럼 경쟁력 있는 모델을 생산했으며, 법률, 의료 또는 금융 작업에 특화된 소규모 언어 모델은 독점 모델을 능가하는 성능을 보였습니다.
- 이 논문은 다양한 오픈 소스 모델을 통합하기 위해 기능 토큰을 사용하는 새로운 접근 방식을 소개합니다. 우리가 개발한 새로운 Octopus v4 모델은 기능 토큰을 사용하여 사용자 쿼리를 가장 적합한 수직 모델로 지능적으로 연결하고 쿼리를 재포맷하여 최상의 성능을 달성합니다.
- Octopus v4는 선택, 매개변수 이해 및 재포맷에 있어 탁월한 성능을 보여주며, Octopus v1, v2, v3 모델의 진화된 버전입니다.
- 그래프라는 다용도 자료 구조를 사용하여 여러 오픈 소스 모델을 효과적으로 조정함으로써 Octopus 모델과 기능 토큰의 능력을 활용합니다.
- 10B 미만의 매개변수를 활성화한 모델로, 동일 수준 모델 중 SOTA MMLU 점수 74.8을 달성했습니다.
- Octopus v4 모델을 시도하고 더 큰 언어 모델 그래프에 기여하려면 우리의 오픈 소스 GitHub(https://www.nexa4ai.com/)을 사용하고 (https://huggingface.co/NexaAIDev/Octopus-v4)을 방문하십시오.

### [InstantFamily: Masked Attention for Zero-shot Multi-ID Image Generation](https://arxiv.org/abs/2404.19427)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19427.png)

Vote: 34

Authors: Shichang Joung, Chanran Kim, Jeongin Lee, Bongmo Kim, Yeul-Min Baek

- 본 논문에서는 개인화된 이미지 생성 분야에서 'InstantFamily'라는 새로운 접근 방식을 소개하였으며, 이는 새로운 마스크된 교차 주의 메커니즘과 다중 모드 임베딩 스택을 사용하여 제로샷 다중 ID 이미지 생성을 달성하는 데 중점을 둡니다.
- InstantFamily 방법은 전처리된 얼굴 인식 모델의 글로벌 및 로컬 특징을 텍스트 조건과 결합하여 ID를 효과적으로 보존하면서 사용합니다.
- 마스크된 교차 주의 메커니즘은 생성된 이미지에서 다중 ID와 구성의 정밀한 제어를 가능하게 합니다.
- 실험을 통해 InstantFamily가 다중 ID 이미지를 생성하는 데 우세함을 보여주며, 알려진 다중 ID 생성 문제를 해결함을 시연했습니다.
- 또한, 이 모델은 단일 ID 및 다중 ID 보존에서 최신 성능을 달성하였고, 원래 훈련된 것보다 더 많은 ID 보존에 대한 놀라운 확장성을 보여줍니다.

### [Better & Faster Large Language Models via Multi-token Prediction](https://arxiv.org/abs/2404.19737)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19737.png)

Vote: 29

Authors: Fabian Gloeckle, Baptiste Rozière, Gabriel Synnaeve, David Lopez-Paz, Badr Youbi Idrissi

- GPT와 Llama와 같은 대형 언어 모델들은 다음 토큰 예측 손실로 훈련되었으나, 본 연구에서는 언어 모델이 한 번에 여러 미래 토큰을 예측하도록 훈련함으로써 샘플 효율성이 향상됨을 제안합니다.
- 훈련 코퍼스의 각 위치에서, 모델은 공유된 모델 본체의 상단에서 독립적으로 작동하는 n개의 출력 헤드를 사용하여 다음 n개의 토큰을 예측하도록 요청받습니다.
- 다중 토큰 예측을 보조 훈련 과제로 고려할 때, 코드 및 자연어 모델 모두에 대해 훈련 시간의 추가 부담 없이 하류 능력이 향상되었습니다.
- 이 방법은 모델 크기가 클수록, 그리고 여러 에포크 동안 훈련할 때 특히 유용하며, 생성 벤치마크에서 높은 성능 향상을 보여줍니다.
- 특히 코딩과 같은 생성 벤치마크에서, 우리의 모델은 강력한 베이스라인을 수 퍼센트 포인트 차이로 일관되게 능가했습니다.
- 13B 매개변수 모델은 HumanEval에서 12% 더 많은 문제를 해결하고, MBPP에서는 17% 더 많은 문제를 해결했습니다.
- 다중 토큰 예측은 유도 헤드 및 알고리즘 리즈닝 능력의 개발에 유리하다는 것이 소규모 알고리즘 작업에서의 실험을 통해 입증되었습니다.
- 추가적인 혜택으로, 4-토큰 예측으로 훈련된 모델은 큰 배치 크기에서도 추론 시 최대 3배 빠르게 작동할 수 있습니다.

### [Iterative Reasoning Preference Optimization](https://arxiv.org/abs/2404.19733)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19733.png)

Vote: 25

Authors: Richard Yuanzhe Pang, Weizhe Yuan, Kyunghyun Cho, Sainbayar Sukhbaatar, He He, Jason Weston

- 여러 최근 연구에서 일반적인 지시사항 조정 과제에서 선호도 최적화 방법이 잘 수행되었지만, 추론 과제에서는 개선이 거의 없었다는 점을 발견하였습니다.
- 이 연구는 경쟁하는 생성된 사고의 연쇄(CoT) 후보들 간의 선호도를 최적화하는 반복적 접근법을 개발하여, 올바른 답으로 이어지는 추리 단계에서 승리와 패배를 최적화합니다.
- 수정된 DPO 손실과 추가적인 음의 로그 가능도 용어를 사용하여 훈련하는 것이 중요하다고 밝혔습니다.
- 이 방식을 반복적으로 적용함으로써 추론 능력이 개선되었다는 결과를 보여줍니다. 
- 훈련 세트의 예제만을 사용하여, GSM8K에서 Llama-2-70B-Chat의 정확도가 55.6%에서 81.6%로, MATH에서는 12.5%에서 20.8%로, ARC-Challenge에서는 77.8%에서 86.7%로 증가하였습니다.
- 추가 데이터셋에 의존하지 않고 Llama-2-기반 모델과 비교하여 뛰어난 성능을 보여줍니다.

### [KAN: Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19756.png)

Vote: 23

Authors: Thomas Y. Hou, James Halverson, Fabian Ruehle, Marin Soljačić, Sachin Vaidya, Max Tegmark, Yixuan Wang, Ziming Liu

- 콜모고로프-아르놀드 표현 정리에 영감을 받아, 다층 퍼셉트론(MLP)에 대한 유망한 대안으로 콜모고로프-아르놀드 네트워크(KAN)를 제안합니다.
- KAN은 노드의 활성화 함수가 고정된 MLP와는 다르게, 엣지에 학습 가능한 활성화 함수를 사용합니다.
- KAN은 모든 선형 가중치를 단변량 함수로 대체하며, 이 함수들은 스플라인으로 파라미터화됩니다.
- 이러한 변화는 KAN이 데이터 적합 및 PDE 해결에서 크기가 훨씬 작음에도 불구하고 MLP보다 더 높거나 비슷한 정확도를 달성할 수 있게 합니다.
- 이론적 및 경험적으로, KAN은 MLP보다 빠른 신경 스케일링 법칙을 가집니다.
- KAN은 직관적으로 시각화되며 사용자와 쉽게 상호 작용할 수 있어 해석 가능성 측면에서도 우수합니다.
- 수학과 물리학의 두 가지 예를 통해 KAN이 과학자들이 수학적 및 물리적 법칙을 (재)발견하는 데 유용한 협력자가 될 수 있음을 보여줍니다.
- 결론적으로, KAN은 MLP에 대한 유망한 대안으로, MLP에 크게 의존하는 현재의 딥러닝 모델들을 더욱 개선할 기회를 제공합니다.

### [Extending Llama-3's Context Ten-Fold Overnight](https://arxiv.org/abs/2404.19553)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19553.png)

Vote: 16

Authors: Peitian Zhang, Zheng Liu, Ninglu Shao, Shitao Xiao, Qiwei Ye, Hongjin Qian, Zhicheng Dou

- Llama-3-8B-Instruct 모델의 컨텍스트 길이를 8K에서 80K까지 QLoRA 미세 조정을 통해 확장하였습니다.
- 전체 훈련 과정은 단 8시간 만에 8xA800(80G) GPU 기계에서 완료되어 매우 효율적입니다.
- 수정된 모델은 NIHS, 주제 검색, 장문의 언어 이해와 같은 다양한 평가 작업에서 우수한 성능을 보이며, 짧은 맥락에서의 기존 능력도 잘 유지하고 있습니다.
- 이러한 극적인 컨텍스트 확장은 GPT-4에 의해 생성된 3,500개의 합성 훈련 샘플에 주로 기인하며, 이는 기존의 컨텍스트 길이를 확장할 수 있는 LLMs의 잠재력을 시사합니다.
- 컨텍스트 길이는 더 많은 계산 자원을 통해 80K를 훨씬 초과할 수 있으며, 팀은 연구를 촉진하기 위해 데이터, 모델, 데이터 생성 파이프라인, 훈련 코드를 포함한 모든 자원을 공개할 예정입니다.

### [MotionLCM: Real-time Controllable Motion Generation via Latent Consistency Model](https://arxiv.org/abs/2404.19759)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19759.png)

Vote: 13

Authors: Yansong Tang, Wenxun Dai, Jingbo Wang, Ling-Hao Chen, Jinpeng Liu, Bo Dai

- 이 연구는 제어 가능한 모션 생성을 실시간 수준까지 확장하는 MotionLCM을 소개합니다.
- 기존의 공간 제어 방법은 실행 시간 비효율성의 문제를 겪고 있는데, 이를 해결하기 위해 잠재 확산 모델(MLD)을 기반으로 하는 모션 잠재 일관성 모델(MotionLCM)을 제안합니다.
- 단일 단계 또는 소수 단계 추론을 활용함으로써 모션 생성을 위한 모션 잠재 확산 모델의 실행 시간 효율성을 개선합니다.
- MotionLCM의 잠재 공간 내에 모션 ControlNet을 통합하고 기존의 잠재 공간이 없는 확산 모델처럼 직접 통제 신호(예: 골반 궤적)를 활용하여 생성 과정을 직접 제어할 수 있습니다.
- 이러한 기술을 사용함으로써 우리의 접근 방식은 텍스트와 제어 신호를 사용하여 실시간으로 인간의 움직임을 생성할 수 있습니다.
- 실험 결과는 MotionLCM의 뛰어난 생성 및 제어 능력을 보여줄 뿐만 아니라 실시간 실행 효율성을 유지함을 입증합니다.

### [Visual Fact Checker: Enabling High-Fidelity Detailed Caption Generation](https://arxiv.org/abs/2404.19752)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19752.png)

Vote: 11

Authors: Ming-Yu Liu, Jacob Samuel Huffman, Xiaohui Zeng, Yunhao Ge, Yin Cui, Tsung-Yi Lin

- 기존의 시각 콘텐츠 자동 캡션 생성 방법은 세부정보 부족, 내용 환영, 명령 따르기 등의 문제에 직면해 있습니다.
- 이 연구에서는 2D 이미지 및 3D 객체에 대해 고정밀도 및 상세한 캡션을 생성하는 유연하고 훈련이 필요 없는 파이프라인인 VisualFactChecker(VFC)를 제안합니다.
- VFC는 캡션 제안, 사실 확인, 최종 캡션 생성의 세 단계로 구성됩니다; 여기서 대규모 언어 모델(LLM)이 객체 감지 및 VQA 모델을 활용해 제안된 캡션을 사실 확인합니다.
- VFC는 복잡한 지시사항을 따르는 다양한 스타일의 캡션을 유연하게 생성할 수 있습니다.
- 이미지-텍스트 유사성, 이미지-이미지 유사성, 아마존 기계적 트루크를 통한 인간 연구, GPT-4V를 이용한 세밀한 평가와 같은 네 가지 평가 방법을 사용하여 평가를 수행했습니다.
- 평가 결과, VFC는 COCO 데이터셋의 2D 이미지 및 Objaverse 데이터셋의 3D 자산에서 오픈 소스 캡션 생성 방법을 능가하는 성능을 보였습니다.
- 이 연구는 오픈소스 모델을 파이프라인으로 결합함으로써 GPT-4V와 같은 독점 모델에 비해 훨씬 작은 모델 크기에도 불구하고 비슷한 캡션 생성 능력을 얻을 수 있음을 보여줍니다.

### [GS-LRM: Large Reconstruction Model for 3D Gaussian Splatting](https://arxiv.org/abs/2404.19702)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19702.png)

Vote: 8

Authors: Kai Zhang, Sai Bi, Zexiang Xu, Nanxuan Zhao, Hao Tan, Yuanbo Xiangli, Kalyan Sunkavalli

- GS-LRM은 단일 A100 GPU에서 0.23초 안에 2-4개의 포즈가 있는 희박한 이미지로부터 고품질의 3D 가우시안 원시 데이터를 예측할 수 있는 확장 가능한 대규모 재구성 모델을 제안합니다.
- 이 모델은 매우 간단한 트랜스포머 기반 아키텍처를 특징으로 하며, 입력된 포즈 이미지를 패치화하여 연결된 멀티뷰 이미지 토큰을 트랜스포머 블록 시퀀스를 통과시킨 후, 이 토큰으로부터 차별화 가능한 렌더링을 위해 픽셀별 가우시안 매개변수를 직접 디코딩합니다.
- GS-LRM은 개별 객체만 재구성이 가능한 이전의 LRM과 달리, 픽셀별 가우시안을 예측함으로써 크기와 복잡성이 크게 다른 장면들을 자연스럽게 처리합니다.
- 이 모델은 Objaverse와 RealEstate10K에서 각각 훈련하여 객체 및 장면 캡처 모두에서 작동함을 보여주며, 두 시나리오 모두에서 기존의 최신 기술보다 훨씬 뛰어난 성능을 보입니다.
- 또한, 이 모델을 사용한 하류 3D 생성 작업의 응용 사례를 시연합니다.
- 프로젝트 웹페이지는 https://sai-bi.github.io/project/gs-lrm/ 에서 확인할 수 있습니다.

### [SAGS: Structure-Aware 3D Gaussian Splatting](https://arxiv.org/abs/2404.19149)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19149.png)

Vote: 6

Authors: Evangelos Ververas, Stefanos Zafeiriou, Rolandos Alexandros Potamias, Jiankang Deng, Jifei Song

- NeRFs의 등장과 함께, 3D 가우스 스플래팅(3D-GS)이 복잡한 볼륨 계산의 문제를 극복하며 실시간 뉴럴 렌더링을 가능하게 했으나, 기존 방법들은 장면의 본연의 3D 구조를 무시하는 최적화 방식을 채택함으로써 표현력과 품질이 제한되어 여러 결함을 생성했습니다.
- 본 연구에서는 장면의 지오메트리를 내재적으로 인코딩하는 구조 인식 가우스 스플래팅 방법(SAGS)을 제안하여 기존보다 우수한 렌더링 성능을 보이고, 저장 공간도 줄일 수 있는 방법을 개발했습니다.
- SAGS는 복잡한 장면 학습을 용이하게 하고 장면의 지오메트리를 보존하는 의미있는 점 이동을 촉진하는 지역-전역 그래프 표현에 기초를 두고 있으며, 간단하지만 효과적인 중간점 보간 체계를 사용하는 경량 버전도 소개하였습니다.
- 다양한 벤치마크 데이터셋에서의 광범위한 실험을 통해 SAGS가 기존 3D-GS 방법들을 렌더링 품질과 모델 크기 모두에서 우월함을 입증하며, 이전 방법들의 부유물과 불규칙한 왜곡을 효과적으로 완화시키면서 정확한 깊이 맵을 제공함을 보여줍니다.
- 자세한 정보와 더 많은 내용은 프로젝트 페이지에서 확인할 수 있습니다: https://eververas.github.io/SAGS/.

### [Invisible Stitch: Generating Smooth 3D Scenes with Depth Inpainting](https://arxiv.org/abs/2404.19758)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19758.png)

Vote: 5

Authors: Paul Engstler, Iro Laina, Andrea Vedaldi, Christian Rupprecht

- 3D 장면 생성은 2D 생성적 확산 모델의 일관된 개선에 힘입어 새로운 연구 분야로 빠르게 부상하고 있다.
- 이전 연구들은 대부분 생성된 이미지를 기존 지오메트리와 반복적으로 결합하여 장면을 생성하는 방식에 의존하였다.
- 기존 방법들은 특히 단안 깊이 예측기를 사용하여 생성된 이미지를 3D로 변환하고 기존 장면 표현과 융합하는데, 이는 기존 장면의 기하학을 무시하는 문제가 있다.
- 본 연구에서는 기존 장면의 기하학을 고려하여 3D 융합 과정을 학습하도록 설계된 새로운 깊이 완성 모델을 도입하며, 이는 장면의 기하학적 일관성을 향상시킨다.
- 또한, 장면 생성 방법의 품질을 평가하는 새로운 벤치마킹 체계를 도입하였으며, 이는 실제 기하학을 기반으로 하여 장면의 구조 품질을 측정한다.

### [MicroDreamer: Zero-shot 3D Generation in $\sim$20 Seconds by Score-based Iterative Reconstruction](https://arxiv.org/abs/2404.19525)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19525.png)

Vote: 4

Authors: Jun Zhu, Tingting Gao, Hang Su, Zhengyi Wang, Chongxuan Li, Luxi Chen

- 본 논문에서는 다중 시점 기반 확산 모델을 사용하여 3D 생성을 위한 효율적이고 일반화된 알고리즘인 점수 기반 반복 재구성(Score-based Iterative Reconstruction, SIR)을 소개합니다.
- SIR은 확산 모델에 의해 생성된 이미지를 기반으로 3D 매개변수를 반복적으로 최적화함으로써, 기존의 점수 완화 샘플링(Score Distillation Sampling, SDS) 방식에서 요구되는 기능 평가 횟수(NFEs)를 감소시킵니다.
- 픽셀 공간에서의 최적화를 포함한 여러 개선을 통해, MicroDreamer는 다양한 3D 표현과 3D 생성 작업에 일반적으로 적용되며 효율적인 접근 방식을 제시합니다.
- MicroDreamer는 3D 가우시안 분할에서 메쉬를 생성할 때 단일 A100 GPU를 사용하여 약 20초가 소요되며, 이는 가장 빠른 제로샷 베이스라인인 DreamGaussian의 시간을 절반으로 줄입니다.
- 특히, 비교 가능한 성능을 유지하면서 SDS보다 5-20배 빠른 속도로 신경 복사장 네트워크를 생성합니다.
- 관련 코드는 https://github.com/ML-GSAI/MicroDreamer에서 확인할 수 있습니다.

### [DOCCI: Descriptions of Connected and Contrasting Images](https://arxiv.org/abs/2404.19753)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19753.png)

Vote: 4

Authors: Alexander Ku, Garrett Tanzer, Sunayana Rane, Jordi Pont-Tuset, Roopal Garg, Zarana Parekh, Su Wang, Jason Baldridge, Zachary Berger, Yonatan Bitton, Yasumasa Onoe, Jaemin Cho

- 기존 데이터세트가 가지고 있는 세밀한 상세 설명의 부족함을 해결하기 위해, DOCCI(Descriptions of Connected and Contrasting Images)라는 새로운 비전-언어 데이터세트를 소개합니다.
- 이 데이터세트는 단일 연구자가 촬영, 선별, 기증한 15,000개의 이미지에 대해 긴, 인간이 주석을 단 영어 설명을 포함하고 있습니다.
- 이 설명들은 평균적으로 136단어 길이이며, 공간 관계, 계수, 텍스트 렌더링, 세계 지식 등의 주요 도전 과제를 포착하기 위해 구성되었습니다.
- DOCCI는 이미지 대 텍스트 생성을 위한 효과적인 훈련 자원으로 활용됨을 양적 및 질적 분석을 통해 입증하였고, PaLI 5B 모델이 DOCCI에서 파인튜닝을 거친 결과, LLaVA-1.5 7B 및 InstructBLIP 7B와 같은 더 크고 고성능인 모델들과 동등하거나 우수한 성능을 보였습니다.
- 또한, 텍스트 대 이미지 생성을 위한 유용한 실험 경기장으로서, 현재의 텍스트 대 이미지 모델들이 긴 설명과 세밀한 세부 사항을 포착하는 데 있어 제한점을 강조하고 있습니다.

### [Lightplane: Highly-Scalable Components for Neural 3D Fields](https://arxiv.org/abs/2404.19760)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.19760.png)

Vote: 3

Authors: Ang Cao, Justin Johnson, David Novotny, Andrea Vedaldi

- 최근 3D 연구는 주로 2D 이미지를 입력 또는 감독으로 활용하고 있으나, 현재의 2D-3D 매핑 설계는 많은 메모리를 필요로 해서 기존 방법들의 한계점이 되고 있습니다.
- 이에 대응하여, 보다 적은 메모리와 계산 비용으로 훨씬 더 많고 고해상도의 이미지 처리를 가능하게 하는 Lightplane Render와 Splatter라는 두 가지 확장 가능한 3D 뉴럴 필드 컴포넌트를 제안합니다.
- 이러한 혁신은 이미지 레벨 손실을 이용한 단일 장면 최적화부터 3D 재구성 및 생성의 극적인 확대를 위한 다재다능한 파이프라인 구현에 이르기까지 다양한 어플리케이션에서 그 유효성을 입증합니다.
- 관련 코드는 https://github.com/facebookresearch/lightplane 에서 확인할 수 있습니다.

