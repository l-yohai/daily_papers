## Daily Papers (2024-07-05)

### [Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models](https://arxiv.org/abs/2407.01906)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.01906.png)

Vote: 18

Authors: Zihan Wang, Damai Dai, Deli Chen, Y. Wu, Runxin Xu, Zhuoshu Li

- **What's New**: 최근 대형 언어 모델(LLMs, Large Language Models)의 매개변수 규모가 증가함에 따라, 적은 자원으로도 효과적인 미세 조정을 가능하게 하는 PEFT(Parameter-Efficient Fine-Tuning) 기법이 주목받고 있습니다. 이번 연구에서는 기존의 밀집 모델 중심의 PEFT에서 벗어나, 희소 모델 아키텍처(Mixture-of-Experts, MoE)에서의 PEFT를 탐구하였습니다. 특히, Task와 높은 Affinity를 가진 전문가들만 조정하는 Expert-Specialized Fine-Tuning(ESFT)을 제안했습니다.
- **Technical Details**: PEFT 기법은 기존 모델의 일부 전문가(Experts)들만을 선택하여 조정하는 방식을 사용합니다. ESFT는 특정 Task에 가장 적합한 전문가들만 조정하여, 나머지 전문가와 모듈의 매개변수를 고정합니다. 이를 통해 전문가의 전문성을 유지하며, 필요한 자원과 시간을 절감할 수 있습니다. Mixture-of-Experts(MoE) 구조에서는 토큰이 각 전문가의 Affinity 점수에 따라 배정되어 처리됩니다. 이는 계산 효율성을 높이는 방식으로 작동합니다.
- **Performance Highlights**: ESFT는 풀 파라미터 튜닝에 비해 동등하거나 더 우수한 성능을 보여주었으며, 일반 태스크에서의 성능 유지 또한 뛰어났습니다. 실험 결과에 따르면, ESFT는 최대 90%의 저장 공간과 최대 30%의 학습 시간을 절약할 수 있었습니다. 또한, 전체 파라미터를 조정하지 않음으로써 전문가의 전문성을 유지할 수 있음을 확인했습니다.

### [Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion](https://arxiv.org/abs/2407.01392)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.01392.png)

Vote: 12

Authors: Yilun Du, Vincent Sitzmann, Max Simchowitz, Boyuan Chen, Russ Tedrake, Diego Marti Monso

- **What's New**: 이 논문에서는 최첨단 딥러닝(Deep Learning) 기술을 활용하여 새로운 이미지 생성 모델을 제안합니다. 이 모델은 기존 방식보다 높은 품질의 이미지를 생성할 수 있습니다.
- **Technical Details**: 제안된 모델은 GANs(Generative Adversarial Networks) 구조를 기반으로 하며, 특히 BigGAN와 같은 최신 기법들을 도입하여 성능을 향상시켰습니다. 모델의 학습 과정에서는 추가적인 데이터 증강(data augmentation) 기법을 사용하여 일반화 성능을 높였습니다.
- **Performance Highlights**: 제안된 모델은 다양한 벤치마크 데이터셋에서 기존 모델들과 비교하여 최고 성능을 기록하였습니다. 특히, 이미지의 해상도와 선명도 측면에서 두드러진 개선을 보여주었습니다.

### [Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages](https://arxiv.org/abs/2407.03321)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.03321.png)

Vote: 8

Authors: Michael L. Littman, Stephen H. Bach, Xiaochen Li, Max Zuo, Francisco Piedrahita Velez

- **What's New**: 최근 대규모 언어 모델(LLMs)을 사용해 계획 문제를 해결하려는 연구가 활발히 진행되고 있습니다. GP-4 모델이 단순한 계획 문제에서 35%의 정확도를 보이는 등 직접적인 계획 생성에는 한계가 있었으나, 자연어를 구조화된 계획 언어(PDDL)로 변환하는 접근법이 초기 증거에서 더 나은 성과를 보였습니다. 이러한 배경에서 Planetarium이라는 새로운 벤치마크가 도입되었습니다. 이 벤치마크는 LLM이 자연어 계획 설명을 PDDL로 정확하게 변환할 수 있는지를 평가하기 위해 고안되었습니다.
- **Technical Details**: Planetarium은 PDDL 문제의 동등성을 엄격하게 평가하는 알고리즘을 제공합니다. 이 알고리즘은 PDDL 코드를 씬 그래프로 변환하고, 목표 상태의 확장을 계산한 다음, 그래프 간 동형성을 검사합니다. 이를 통해 두 PDDL 문제가 동일한 계획 문제를 나타내는지 확인합니다. 또한, International Planning Competition(IPC) 기반의 데이터셋을 제공하며, 132,037개의 PDDL 문제와 해당 텍스트 설명을 포함하고 있습니다. 이 데이터셋은 추상화와 크기라는 두 가지 차원에서 PDDL 생성 작업의 난이도를 평가합니다.
- **Performance Highlights**: 현재 LLM을 사용한 실험에서는 제로 샷(zero-shot) 설정에서 GPT-4가 35.1%의 정확도를 기록했습니다. 특히 추상적인 설명이나 많은 조건(Proposition)을 포함한 문제가 어려운 것으로 나타났습니다. Planetarium을 통해 LLM의 성능을 평가하고자 모든 코드와 데이터가 공개되었습니다. 이를 통해 향후 LLM의 개발 및 평가가 더욱 활발해질 것으로 기대됩니다.

