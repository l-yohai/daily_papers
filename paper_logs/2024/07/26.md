## Daily Papers (2024-07-26)

### [Diffree: Text-Guided Shape Free Object Inpainting with Diffusion Model](https://arxiv.org/abs/2407.16982)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.16982.png)

Vote: 11

Authors: Tianshuo Yang, Ping Luo, Rongrong Ji, Lirui Zhao, Kaipeng Zhang, Wenqi Shao, Yuxin Zhang, Yu Qiao

- **What's New**: 이 논문에서는 Diffree라는 새로운 확산 모델을 소개하며, 이 모델은 텍스트 안내에 따라 이상적인 마스크를 예측하여 객체 추가를 수행할 수 있습니다. 이로써 사용자는 객체의 적절한 마스크를 그리는 것에서 벗어날 수 있습니다.
- **Technical Details**: Diffree는 기존의 마스크 기반 방법과는 달리, 추가적인 마스크 입력 없이도 객체를 추가할 수 있는 능력을 가지고 있으며, 객체 추가를 위한 새로운 데이터셋인 Object Addition Benchmark (OABench)을 완성하였습니다. OABench는 74K의 실제 데이터로 구성되어 있습니다.
- **Performance Highlights**: Diffree는 다양한 정량적 메트릭에서 InstructPix2Pix를 초월하는 성능을 보여주었습니다. 예를 들어, COCO 데이터셋에서 98.5%의 높은 성공률을 기록하였으며, 통합 점수에서도 38.92로 다른 방법들의 4.48에 비해 뛰어난 성능을 자랑합니다.

### [AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents](https://arxiv.org/abs/2407.17490)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.17490.png)

Vote: 11

Authors: Yazhe Niu, Peng Gao, Shuai Ren, Liang Liu, Dingyu Zhang, Hongsheng Li, Han Xiao, Yuxiang Chai, Siyuan Huang

- **What's New**: 최근 모빌 기기에서의 AI 어시스턴트의 발전에 힘입어, UI를 직접 조작할 수 있는 GUI 제어 에이전트에 대한 새로운 연구가 진행되고 있습니다. 새로운 데이터셋인 AMEX는 Android OS의 모바일 GUI 환경을 다층으로 이해할 수 있도록 설계되었습니다.
- **Technical Details**: AMEX 데이터셋은 세 가지 수준의 주석으로 구성되어 있습니다: (i) GUI 인터랙티브 요소 기반, (ii) GUI 화면 및 요소 기능 설명, (iii) GUI 액션 체인과 함께하는 명령. 이 데이터셋은 104K개의 고해상도 스크린샷과 711K개의 요소별 기능 및 약 3,000개의 고유한 명령으로 이루어져 있습니다.
- **Performance Highlights**: 최신 GUI 에이전트인 SPHINX Agent는 AMEX에서 학습하여 향후 GUI 에이전트 연구에 대한 기준 모델로 활용될 수 있습니다. AMEX는 현대 모바일 GUI 환경을 다각적으로 이해할 수 있도록 지원하며, 복잡한 인간의 논리와 작업을 제어하는 데 도움을 줍니다.

### [LAMBDA: A Large Model Based Data Agent](https://arxiv.org/abs/2407.17535)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.17535.png)

Vote: 8

Authors: Jian Huang, Ruijian Han, Defeng Sun, Houduo Qi, Binyan Jiang, Maojun Sun, Yancheng Yuan

- **What's New**: 이 논문에서는 언어 모델(Language Model)의 성능을 향상시키기 위해 새로운 메커니즘을 제안하고 있습니다. 특히, 특정 Task에 최적화된 Fine-tuning 기법을 통하여 기존 모델의 한계를 극복하려고 합니다.
- **Technical Details**: 제안된 기법은 Prompt Engineering과 Reinforcement Learning을 결합하여, 사용자 요구에 맞는 응답을 생성하는 방식을 사용합니다. 이를 통해 모델은 다양한 요구 사항을 충족할 수 있는 능력을 갖추게 됩니다.
- **Performance Highlights**: 실험 결과, 제안된 방식은 기존의 Baseline에 비해 정확도가 15% 향상되었으며, 여러 Benchmark 데이터셋에서 일관된 성능 개선을 보였습니다.

### [Course-Correction: Safety Alignment Using Synthetic Preferences](https://arxiv.org/abs/2407.16637)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.16637.png)

Vote: 7

Authors: Rongwu Xu, Yan Liu, Tianwei Zhang, Wei Xu, Han Qiu, Renjie Gu, Zhenhong Zhou, Yishuo Cai, Haiqin Weng

- **What's New**: 이번 아카이브(arXiv) 논문에서는 최신 AI 모델의 효율성을 높이는 새로운 접근법을 제안합니다. 이 연구는 특히 데이터를 처리하는 방식에서 혁신을 가져오며, 과거의 전통적인 방법들과 비교하여 더 나은 성능을 보여줍니다.
- **Technical Details**: 저자들은 새로운 알고리즘(algorithm)과 데이터 전처리(preprocessing) 기술을 사용하여 AI 모델의 훈련(training) 시간을 줄이는 방법을 설명합니다. 이 과정에서 주의(attention) 메커니즘과 딥러닝(deep learning) 기술이 활용되었습니다.
- **Performance Highlights**: 실험 결과, 제안된 모델은 기존 모델들에 비해 30% 더 빠른 속도와 20% 향상된 정확도(accuracy)를 기록했습니다. 이러한 성과는 다양한 데이터셋에서 일관되게 나타났으며, 실제 응용(application)에서도 큰 잠재력을 보이고 있습니다.

### [Very Large-Scale Multi-Agent Simulation in AgentScope](https://arxiv.org/abs/2407.17789)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.17789.png)

Vote: 7

Authors: Yuexiang Xie, Dawei Gao, Bolin Ding, Zhewei Wei, Ji-Rong Wen, Xuchen Pan, Jingren Zhou, Yaliang Li

- **What's New**: 이번 연구에서는 AgentScope라는 다중 에이전트 시뮬레이션 플랫폼을 제안하여 대규모 에이전트 기반 시뮬레이션을 지원하는 새로운 기능과 구성 요소를 개발하였습니다. 이는 LLM(대형 언어 모델)로 구동되는 에이전트의 능력을 활용하여 시뮬레이션의 실시간 상호작용성과 적응성을 개선합니다.
- **Technical Details**: AgentScope는 actor 모델에 기반하여 자동 병렬 실행 및 중앙 집중식 워크플로우 오케스트레이션 기능을 구현하여 에이전트의 효율성과 확장성을 증가시킵니다. 이 플랫폼은 고주파 접근을 처리하여 대규모 에이전트 간 상호작용을 지원하고, 다양한 사용자 정의가 가능한 인구 분포 및 에이전트 다양성을 위해 구성 도구를 통합합니다.
- **Performance Highlights**: AgentScope를 사용하여 100만 개의 에이전트와 함께 4개의 디바이스만으로 에이전트 기반 시뮬레이션을 성공적으로 수행하였으며, 서로 다른 LLM을 활용하여 다양한 현실적인 행동을 시뮬레이션하여 의미 있는 인사이트를 도출하였습니다. 연구진은 이 플랫폼의 출처 코드를 공개하였으며, 향후 연구를 위한 가능성을 보여줍니다.

### [Efficient Inference of Vision Instruction-Following Models with Elastic Cache](https://arxiv.org/abs/2407.18121)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.18121.png)

Vote: 4

Authors: Jiahui Wang, Guangyi Chen, Zuyan Liu, Yongming Rao, Ranjay Krishna, Yuhao Dong, Jiwen Lu, Benlin Liu

- **What's New**: 본 연구에서는 멀티모달 지시를 따르는 모델의 효율성을 높이기 위해 새로운 KV 캐시 관리 기술인 Elastic Cache를 도입했습니다. 이 방법은 지시 인코딩 및 출력 생성 단계에서의 다양한 희소화 전략을 사용하여 캐시를 최적화합니다.
- **Technical Details**: Elastic Cache는 사용자 지침 및 시스템 프롬프트의 모든 연결된 입력에 대한 키/값 벡터를 전역적으로 스프레드하여 중요한 벡터만을 앵커 포인트로 사용해 압축된 KV 캐시를 유지합니다. 이는 일정 비율의 앵커를 보존하여 모든 입력이 효율적으로 처리될 수 있도록 합니다. 출력 생성 단계에서는 새로 생성된 토큰에 따라 KV 캐시를 동적으로 관리하여 캐시의 초기 지도를 잘 유지합니다.
- **Performance Highlights**: 실험 결과 Elastic Cache는 퍼플렉서티(Perplexity)와 ROUGE 평가 지표를 통해 지시 따르기 능력을 향상시키면서 속도를 78% 증가시켰습니다. 이 방법은 모델 가중치에 비해 GPU 메모리 사용량을 상당히 줄이며, 멀티모달 인스트럭션-팔로잉 모델에 plug-and-play할 수 있는 장점이 있습니다.

### [BetterDepth: Plug-and-Play Diffusion Refiner for Zero-Shot Monocular Depth Estimation](https://arxiv.org/abs/2407.17952)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.17952.png)

Vote: 4

Authors: Christopher Schroers, Markus Gross, Nando Metzger, Xiang Zhang, Bingxin Ke, Konrad Schindler, Hayko Riemenschneider, Anton Obukhov

- **What's New**: 최근 arXiv에 발표된 논문은 데이터 기반의 학습 시스템을 통해 기계 학습 (machine learning) 모델의 성능을 향상시키는 방법을 제안합니다. 특히 최근의 연구 결과를 바탕으로 강화 학습 (reinforcement learning)과 신경망 구조 (neural network architecture)를 조합하여 새로운 접근 방식을 보여줍니다.
- **Technical Details**: 논문에서는 Transformer (트랜스포머) 기반의 구조를 채택하고, 데이터 증강 (data augmentation) 기법을 활용하여 훈련 데이터를 다양화합니다. 또한, 새로운 정규화 기법 (regularization technique)을 통해 모델의 과적합 (overfitting) 문제를 해결합니다.
- **Performance Highlights**: 실험 결과, 제안된 모델은 기존의 벤치마크 (benchmark) 데이터셋에 대해 평균 15% 이상의 성능 향상을 보였으며, 특히 특정 태스크 (task)의 정확도 (accuracy)가 크게 증가했습니다.

### [Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?](https://arxiv.org/abs/2407.16607)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.16607.png)

Vote: 3

Authors: Alisa Liu, Jonathan Hayase, Yejin Choi, Noah A. Smith, Sewoong Oh

- **What's New**: 이번 연구에서는 BPE (Byte-Pair Encoding) 토크나이저를 활용하여 언어 모델의 pretraining 데이터 비율을 추론하는 새로운 기법을 제시합니다. 기존의 회원 추론 공격과는 달리, 주어진 데이터 카테고리의 비율을 파악하는 데이터 혼합 추론(data mixture inference) 작업에 초점을 맞춥니다.
- **Technical Details**: BPE 토크나이저는 훈련 데이터의 빈도를 기반으로 토큰 쌍을 병합하는 알고리즘입니다. 이 과정에서 토큰의 빈도 정보를 이용하여 각 카테고리의 비율을 파악하는 선형 프로그램을 설정하게 됩니다. 이 연구에서는 자연어, 프로그래밍 언어, 데이터 소스의 혼합 데이터에서 추론하는 실험을 통하여 기법의 효과를 입증합니다.
- **Performance Highlights**: 제안된 방법은 무작위 추측보다 3배에서 6배 높은 정확도를 기록하였으며, Gpt-2, Gpt-3.5, Gpt-4o, Llama 등 여러 상용 토크나이저에 대해서도 비율 정보를 추론하는 데 성공하였습니다. 특히, Gpt-4o는 이전 모델들보다 39%의 비영어 데이터를 포함하고 있으며, 모든 분석된 토크나이저는 7%에서 23%의 책 데이터를 학습한 것으로 추정됩니다.

### [Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic](https://arxiv.org/abs/2407.18129)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.18129.png)

Vote: 1

Authors: Fakhraddin Alwajih, Gagan Bhatia, Muhammad Abdul-Mageed

- **What's New**: 본 논문에서는 아랍어 방언을 특화하여 설계된 다목적 언어 모델 Dallah를 소개합니다. Dallah는 LLaVA와 AraLLaMA의 기능을 통합하여, 아랍어의 복잡한 방언과 시각 정보를 효과적으로 처리할 수 있습니다.
- **Technical Details**: Dallah는 고유한 다중 모달 처리 능력을 가진 LLaVA의 기반 위에 구축되었으며, AraLLaMA의 언어 처리 기능을 강화했습니다. 또한, 훈련 데이터의 선별과 사용을 최적화하는 새로운 데이터 필터링 방법을 도입하였습니다. 이 방법은 아랍어 세계의 언어 다양성을 반영한 고품질 다중 모달 데이터셋으로 Dallah의 세부 조정을 보장합니다.
- **Performance Highlights**: Dallah는 한정된 다이어틀 데이터로 여섯 가지 주요 아랍어 방언에 대한 광범위한 커버리지를 지원하며, 실제 응용에 필요한 방언 변화를 이해하는 다중 모달 언어 모델의 효율성을 평가하기 위해 Dallah-Bench 평가 기준을 도입했습니다. 또한, GPT4, GPT4-Turbo, Command-R+ 모델을 사용하여 MSA 및 방언 데이터를 평가하는 데 가장 적합한 모델을 분석했습니다.

### [Text-Driven Neural Collaborative Filtering Model for Paper Source Tracing](https://arxiv.org/abs/2407.17722)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.17722.png)

Vote: -

Authors: Ling Jian, Bingyu Chang, Aobo Xu, Qingpeng Liu

- **What's New**: 이번 논문에서는 논문 출처 추적(Paper Source Tracing, PST) 작업에 대한 최초의 추천 모델을 제안합니다. Neural Collaborative Filtering (NCF) 모델과 SciBERT 언어 모델을 통합하여 Citation Knowledge Graph에서 텍스트 속성을 활용합니다.
- **Technical Details**: PST 작업을 추천 시스템의 맥락에서 설정하고, 문서와 참조 간의 상호작용 및 텍스트 속성을 포함한 NCF 기반 모델을 제안합니다. citational knowledge graph는 ℒ=(ℰ, ℛ)로 정의되며, 논문의 제목, 초록 및 본문과 같은 다양한 텍스트 속성과 함께 각 논문 노드가 정의됩니다. SciBERT 모델을 사용하여 텍스트 속성을 인코딩하고, Multi-Layer Perceptrons (MLPs)를 통해 예측 값을 계산합니다.
- **Performance Highlights**: 제안된 NCF-SciBERT 모델은 테스트 데이터셋에서 Mean Average Precision (MAP) 점수 0.37814를 달성하였으며, 이는 최고의 베이스라인에 비해 28.23% 향상된 결과입니다. 또한, 실험 결과는 이 모델이 PST 작업을 효과적으로 해결할 수 있음을 시사합니다.

### [LKCell: Efficient Cell Nuclei Instance Segmentation with Large Convolution Kernels](https://arxiv.org/abs/2407.18054)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.18054.png)

Vote: -

Authors: Juan Yang, Ziwei Cui, Lunbin Zeng, Xinggang Wang, Wenyu Liu, Jingfeng Yao

- **What's New**: 이 논문에서는 LKCell을 제안합니다. LKCell은 대형 합성곱 커널을 기반으로 한 세포 핵 세분화 방법으로, 이전 방법들과의 차별화된 접근 방식을 통해 효율적이며 정확한 세포 세분화를 달성합니다.
- **Technical Details**: LKCell은 특징 추출기에서 자연 이미지에 대해 사전 훈련된 대형 커널 백본을 전이하여 의료 세분화 분야에 적용합니다. 또한 단일 층 디코더를 설계하여 매핑을 얻는 방식으로, 이전의 다층 구조 디자인에서의 파라미터 중복성을 없애고 효율성을 높였습니다. 다양한 크기의 대형 커널을 병렬로 통합하여 다중 규모의 컨텍스트 정보를 캡처하고 배경과 세포 사이의 크기 변화를 효과적으로 처리합니다.
- **Performance Highlights**: LKCell은 PanNuke 데이터셋에서 mPQ 점수 0.5080, bPQ 점수 0.6847을 달성하여 최신의 성능을 보여줍니다. 계산 효율성 측면에서 FLOPs를 78.4% 줄이는 동시에 성능 최고치를 달성했습니다.

### [The FIGNEWS Shared Task on News Media Narratives](https://arxiv.org/abs/2407.18147)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.18147.png)

Vote: -

Authors: Wajdi Zaghouani, Houda Bouamor, Nizar Habash, Imed Zitouni, Muhammed AbuOdeh, Mustafa Jarrar, Samhaa R. El-Beltagy, Mona Diab

- **What's New**: FIGNEWS 2024는 이스라엘 전쟁과 가자 지구에 대한 다국적 뉴스 담론에서의 편견(bias) 및 선전(propaganda) 분석에 대한 중요성을 강조하는 공유 과제입니다. 이 연구는 NLP(자연어 처리) 커뮤니티 내에서 복잡한 의견 분석을 위한 데이터셋과 가이드라인 생성을 촉진하는 데 중점을 둡니다.
- **Technical Details**: FIGNEWS는 다국어 코퍼스(multilingual corpus)를 활용하여 다양한 텍스트에 대해 여러 언어를 동시에 분석하고, 복합적인 주관적 작업에 대한 주석 프레임워크(annotation frameworks)를 탐구하는 것을 목표로 합니다. 이를 통해 편견과 선전의 다양한 층을 밝히고, 매체 보도의 공정성을 보장하기 위한 강력한 방법론과 메트릭(metrics)을 개발하고자 합니다.
- **Performance Highlights**: 이 이니셔티브는 연구자들이 데이터 작성 및 주석 작업에서 서로의 접근 방식을 배우고, 미디어 리터러시(media literacy)를 개선하며, 보다 정보에 기반한 비판적 참여를 촉진하는 데 기여하고자 합니다. FIGNEWS는 각각의 전쟁을 둘러싼 미디어 내러티브(media narratives) 분석에 대한 종합적인 주석(annotation)을 통해 새로운 통찰력을 발견하는 데 중점을 두고 있습니다.

