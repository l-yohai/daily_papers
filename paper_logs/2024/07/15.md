## Daily Papers (2024-07-15)

### [SpreadsheetLLM: Encoding Spreadsheets for Large Language Models](https://arxiv.org/abs/2407.09025)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09025.png)

Vote: 60

Authors: Haoyu Dong, José Cambronero, Mengyu Zhou, Jianbo Zhao, Junyu Xiong, Dongmei Zhang, Shi Han, Shiyu Xia, Yeye He, Yuzhang Tian, Yun Lin

- **What's New**: 새로운 프레임워크 SpreadsheetLLM을 소개합니다. 이 프레임워크는 LLMs의 능력을 최대한 활용하여 스프레드시트를 이해하고 추론하는 데 초점을 맞추고 있습니다. 특히, 스프레드시트의 구조를 효과적으로 인코딩할 수 있도록 SheetCompressor라는 혁신적인 인코딩 프레임워크를 제안합니다.
- **Technical Details**: SpreadsheetLLM은 처음에 스프레드시트를 시퀀스로 직렬화하는 기본 인코딩 방법을 제안하며, Markdown 인코딩 방법을 보강하여 필수적인 셀 주소와 포맷을 포함시킵니다. SheetCompressor는 세 가지 모듈로 구성됩니다: 1) 효율적인 레이아웃 이해를 위한 구조적 앵커(Structural Anchors), 2) 토큰 효율성을 위한 역 인덱스 변환(Inverted-Index Translation), 3) 숫자 셀의 데이터 포맷 집계(Data Format Aggregation).
- **Performance Highlights**: SheetCompressor는 스프레드시트 인코딩의 토큰 사용량을 96% 감소시키는 데 성공했습니다. 또한, SpreadsheetLLM은 스프레드시트 테이블 감지에서 이전 SOTA 방법을 12.3%로 초과하는 뛰어난 성능을 보여주었습니다. 스프레드시트 QA 작업에서도 CoT(Chain of Thought) 방법론을 기반으로 한 CoS(Chain of Spreadsheet)를 제안하여 기존 방법들을 능가하는 성과를 보였습니다.

### [Human-like Episodic Memory for Infinite Context LLMs](https://arxiv.org/abs/2407.09450)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09450.png)

Vote: 34

Authors: Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Haitham Bou-Ammar, Jun Wang, Gerasimos Lampouras, Zafeirios Fountas

- **What's New**: 본 논문에서는 기존의 Transformer 기반의 대규모 언어 모델(LLM)이 긴 문맥을 처리하는 데 있어 겪는 한계점들을 극복하기 위해 새로운 아키텍처 EM-LLM을 제안했습니다. 이 모델은 인간의 에피소드 기억 시스템에서 영감을 받아, LLM의 문맥 창을 확장하고, 이벤트 인식과 에피소드 기억을 통합하여 긴 문맥 처리 성능을 향상시킵니다.
- **Technical Details**: EM-LLM은 서프라이즈(예측 오류)를 기반으로 한 기억 형성 프로세스를 사용하여 토큰 시퀀스를 개별적인 메모리 유닛으로 분할합니다. 이 메모리 유닛들은 그래프 이론적 메트릭을 활용해 유사성을 기준으로 세분화됩니다. 메모리 리콜 과정에서는 유사성 기반의 검색과 시간적 연속성 및 비대칭 효과를 통합하여 효과적인 정보 접근을 가능하게 합니다. 이 과정은 minimal한 추가 연산 비용을 가지며, 특히 서프라이즈 기반의 분할은 추가 연산이 필요하지 않습니다.
- **Performance Highlights**: 제안된 EM-LLM은 인간 주석된 팟캐스트 스크립트와 긴 문맥을 포함한 PG-19 데이터셋을 통해 검증되었습니다. 특히 LongBench 벤치마크에서 4.3%의 전체적인 성능 향상과 PassageRetrieval 태스크에서 33%의 성능 향상을 보였습니다. 이는 기존의 최첨단 모델인 InfLLM을 능가하는 성과입니다.

### [Toto: Time Series Optimized Transformer for Observability](https://arxiv.org/abs/2407.07874)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07874.png)

Vote: 21

Authors: Ben Cohen, Emaad Khwaja, Youssef Doubli, Othmane Abou-Amal, Elise Ramé, Kan Wang, Charles Masson

- **What's New**: Datadog에서 개발한 최신 시계열 예측 모델 Toto를 소개합니다. 이 모델은 observability 데이터를 다루기 위해 설계되었으며, 최신 transformer 아키텍처를 활용하여 획기적인 정확도와 성능을 제공합니다. 다양한 시계열 데이터셋을 학습하여 zero-shot 예측 능력을 갖추고 있습니다.
- **Technical Details**: Toto는 디코더 전용(Decoder-only) 아키텍처를 채택했으며, 이는 확장성이 뛰어나고 임의의 예측 범위를 가능하게 합니다. 이 모델은 pre-normalization, RMSNorm, SwiGLU 등의 최신 기술을 사용합니다. 입력 임베딩을 위해 비중첩 패치 투영(non-overlapping patch projections)을 사용하며, 시간 차원(time-wise) 및 공간 차원(space-wise) 상호작용을 모델링하기 위해 다중 헤드 주의(multi-head attention) 아키텍처를 2차원으로 확장했습니다.
- **Performance Highlights**: Toto는 높은 정확도와 강인함을 자랑하며, 기존의 클래식 모델을 능가하는 성능을 보여줍니다. 이러한 발전은 새로운 데이터를 훈련하지 않고도 정확한 예측을 제공하는 zero-shot 예측 능력 덕분입니다. 이것은 특히 관찰 가능한 도메인에서 큰 매력이 있으며, 다양하고 빈번한 시계열 데이터를 다루는데 최적화되어 있습니다.

### [H2O-Danube3 Technical Report](https://arxiv.org/abs/2407.09276)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09276.png)

Vote: 14

Authors: Yauhen Babakhin, Pascal Pfeiffer, Gabor Fodor, Nischay Dhankhar, Philipp Singer, Sri Satish Ambati

- **What's New**: H2O-Danube3 모델 시리즈 발표: H2O-Danube3-4B와 H2O-Danube3-500M. 이 모델들은 주로 영어 웹 데이터로 사전 훈련되었으며, 다양한 학문, 채팅, 파인-튜닝 벤치마크에서 경쟁력 있는 성능을 보입니다. 모델들은 Apache 2.0 라이선스 하에 공개되어 누구나 사용할 수 있도록 합니다.
- **Technical Details**: H2O-Danube3 모델은 디코더 전용 LLM 구조로, Llama와 Mistral의 핵심 원칙들을 채택했습니다. Mistral tokenizer를 사용하며, 최대 컨텍스트 길이는 8,192입니다. Grouped Query Attention을 통해 뛰어난 파라미터 효율성과 연산 효율성을 달성했습니다. H2O-Danube3-4B 모델은 약 3.96억 매개변수를 포함하며, H2O-Danube3-500M은 500만 매개변수를 포함해 경량 장치에서도 효율적으로 작동할 수 있습니다.
- **Performance Highlights**: H2O-Danube3-4B는 다양한 벤치마크에서 최고의 성능을 보이며, 특히 CommonsenseQA와 PhysicsQA에서 두각을 나타냅니다. GSM8K 수학 중심 벤치마크에서는 50.14%의 강력한 정확도를 기록했습니다. 또한, H2O-Danube3-500M도 유사한 크기의 다른 모델들과 비교해 12개 벤치마크 중 8개에서 최고 점수를 기록했습니다.

### [MUSCLE: A Model Update Strategy for Compatible LLM Evolution](https://arxiv.org/abs/2407.09435)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09435.png)

Vote: 8

Authors: Ting-Yao Hu, Fartash Faghri, Chun-Liang Li, Raviteja Vemulapalli, Oncel Tuzel, Hadi Pouransari, Jessica Echterhoff

- **What's New**: 최근 논문에서는 대형 언어 모델(LLMs)의 업데이트 시 발생하는 성능 퇴보 문제를 해결하기 위한 접근법을 제안했습니다. 특히 다운스트림 작업에서 모델 호환성을 유지하면서 성능을 향상시키는 방법에 초점을 맞췄습니다.
- **Technical Details**: 기존의 대형 언어 모델(LLMs)은 주로 제로/피우샷 성능과 컨텍스트 학습 능력을 평가하는 벤치마크를 사용하여 평가됩니다. 대규모 모델 업데이트가 발생하면 관련된 작업 어댑터도 재훈련해야 합니다. 이 논문에서는 모델 업데이트 시 네 가지 다양한 데이터 샘플 유형을 고려하며, 새로운 모델이 전체 성능에서는 우수하지만 일부 샘플에서는 부정적인 영향을 줄 수 있다는 점에 주목했습니다. 이러한 'Negative flip' 문제를 해결하고 사용자의 혼란을 줄이기 위해 '호환성 어댑터(compatibility adapter)'를 학습시키는 방법을 제안했습니다.
- **Performance Highlights**: 제안된 방법은 언어 이해 (예: Llama 1에서 Llama 2로의 업데이트) 작업에서 Negative flip 비율을 최대 40%까지 줄였으며, 요약, 수학적 추론, 상식 질문 응답과 같은 다른 다운스트림 작업에서도 모델 불일치를 감소시켰습니다.
- **Related Work**: 이전 연구들은 분류 작업의 모델 호환성을 평가하기 위해 Negative flip rate (NFR), 뒤로 신뢰 호환성(BTC) 등의 지표를 사용할 것을 제안했으며, 이는 주로 분류 작업에서 사용되었습니다. 최근 연구는 앙상블 모델, 게이팅 메커니즘, 모델 부분 재사용, 지식 증류 등 다양한 접근을 통해 모델 업데이트 시 발생하는 회귀 문제를 줄이는 방법을 탐구했습니다. 그러나 대부분의 접근법이 생성 작업에 대한 평가를 포함하지 않았으며, 구모델과 신모델의 동시 메모리 요구 사항을 수반하였습니다.

### [SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers](https://arxiv.org/abs/2407.09413)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09413.png)

Vote: 6

Authors: Subhashini Venugopalan, Rama Chellappa, Shraman Pramanick

- **What's New**: 이번 연구는 과학 연구 논문의 복잡한 그림과 표를 해석하기 위하여, 사용자가 과학 논문 내에서 질의응답(Question Answering, QA)을 수행할 수 있도록 하는 최초의 대규모 데이터셋 SPIQA(Scientific Paper Image Question Answering)를 소개합니다. 이 데이터셋은 컴퓨터 과학 분야의 다양한 영역에 걸쳐 도출되었으며, 총 26,000개의 논문에서 270,000개의 질문-답변-이유(triplets)를 생성하였습니다.
- **Technical Details**: SPIQA는 다음과 같은 세 가지 주요 작업(Task)을 평가합니다: (1) 논문의 그림과 표를 바탕으로 한 직접적인 질의응답, (2) 논문의 전체 텍스트 및 그림과 표를 바탕으로 한 직접적인 질의응답, (3) Chain of Thought (CoT) 기반 질의응답으로, 시스템이 먼저 유용한 그림을 식별한 후 이에 따라 질문에 답변합니다. 이를 통해 모델의 정밀한 추론 및 근거 능력을 평가합니다.
- **Performance Highlights**: 우리는 여러 최신의 닫힌(multimodal) 모델과 공개된 모델을 SPIQA 데이터셋을 통해 평가하고, InstructBLIP 및 LLaVA 1.5 모델을 SPIQA 훈련 세트로 미세 조정한 결과, zero-shot 평가에 비해 성능이 크게 개선됨을 확인했습니다. 또한, QA 평가를 위해 새로운 LLM 기반 평가 메트릭인 LLMLogScore (L3Score)를 도입하였으며, 이는 기존 LLM 기반 평가보다 더 효과적인 것으로 나타났습니다.

### [Transformer Layers as Painters](https://arxiv.org/abs/2407.09298)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09298.png)

Vote: 6

Authors: Aakash Kumar Nain, Qi Sun, Marc Pickett, Llion Jones

- **What's New**: 이 연구는 트랜스포머 기반 대형 언어 모델(LLMs)의 중간 레이어가 공통 표현 공간(shared representation space)을 사용하는지 여부를 실험을 통해 조사했습니다. 트랜스포머의 각 레이어가 역할을 변경하거나 스킵해도 안정적인 성능을 보이는지를 다양한 벤치마크에서 검증했습니다.
- **Technical Details**: 모델로는 Llama2와 BERT-Large를 사용했으며 두 모델 모두 사전 훈련(pretrained)된 상태에서 파라미터를 수정하지 않고 실험을 진행했습니다. Llama2는 32에서 80 레이어까지 다양한 버전을 사용했으며, BERT-Large는 24 레이어를 가집니다. 벤치마크로는 ARC, HellaSwag, GSM8K, WinoGrande, LAMBADA 등이 사용되었습니다.
- **Performance Highlights**: Llama2-7B 및 Llama2-13B 모델의 실험 결과, 중간 레이어들은 서로 표현 공간을 공유하고 있음을 발견했으며, 레이어 순서 변경이나 스킵에서도 성능 저하 없이 안정적인 동작을 보였습니다. 이는 모델의 중간 레이어들이 공통된 의미적 표현 공간을 사용하고 있음을 시사합니다.

### [New Desiderata for Direct Preference Optimization](https://arxiv.org/abs/2407.09072)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09072.png)

Vote: 4

Authors: Xiangkun Hu, David Wipf, Tong He

- **What's New**: 새로운 연구는 대형 언어 모델(LLMs)이 인간의 선호와 충돌할 수 있는 응답을 생성할 수 있다는 기존의 문제점을 해결하기 위해, RLHF(RL with human feedback) 방식 외에 직접 선호 최적화(DPO: Direct Preference Optimization) 접근법을 제안합니다. 이번 논문에서는 DPO 모델이 직면한 몇 가지 제약 사항과 이를 극복하기 위한 새로운 손실 함수인 ℓTYPO를 소개합니다.
- **Technical Details**: 논문은 레퍼런스 모델과의 성능 보존 문제를 해결하기 위해 새로운 평가 기준을 개발하고, 기존 DPO 기반 접근법이 만족하지 못하는 부분을 지적합니다. 특히, DPO 목적 함수가 초래할 수 있는 고른 규제 효과로 인해 레퍼런스 모델이 강한 영역에서는 성능을 유지하지 못할 수 있다는 점을 증명했습니다. 또 이 논문은 학습 제약 조건이 도입되면 코어 재매개변수가 엄격하게 유지되지 않는다는 것을 증명했습니다. 이에 따라 새로운 선호 최적화 손실 ℓTYPO를 제안하며, 이는 재매개변수화에 의존하지 않고도 평가 기준을 만족합니다.
- **Performance Highlights**: 제안된 새로운 손실 함수 ℓTYPO는 여러 염려를 덜어주며, 기존 선호 최적화 모델과 비교했을 때 더 나은 특성을 보입니다. 몬테카를로 시뮬레이션을 통해 ℓTYPO가 DPO 모델의 한계를 극복하며, 인간 선호와 더 잘 일치하는 결과를 도출함을 확인했습니다.

### [GAVEL: Generating Games Via Evolution and Language Models](https://arxiv.org/abs/2407.09388)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09388.png)

Vote: 4

Authors: Matthew Stephenson, Dennis J. N. J. Soemers, Alexander Padula, Éric Piette, Graham Todd, Julian Togelius

- **What's New**: 이번 연구에서는 게임 규칙 표현과 코드 생성의 최근 발전을 활용하여 자동 게임 디자인의 핵심 과제를 해결하는 GAVEL(Games via Evolution and Language Models)을 소개합니다. GAVEL은 Ludii 게임 설명 언어(Ludii game description language)와 대규모 코드 언어 모델을 사용하며, 품질-다양성 최적화를 통해 다양한 보드 게임을 생성합니다.
- **Technical Details**: GAVEL은 세 가지 주요 구성 요소를 기반으로 합니다: (1) Ludii 게임 설명 언어를 통해 다양한 보드 게임 규칙 집합을 효율적으로 인코딩, (2) 대규모 코드 언어 모델을 통해 기존 게임을 변형하고 새롭게 구성, (3) 품질-다양성 최적화(Quality-Diversity Optimization)를 통해 플레이 가능한 게임을 생성합니다. 이러한 구성요소들은 서로를 보완하며 협력적으로 작동합니다.
- **Performance Highlights**: GAVEL은 훈련 중 접했던 게임들과 상당히 다른 새로운 보드 게임을 생성할 수 있습니다. 자동화된 평가 메트릭을 통해 성능을 평가한 결과, GAVEL이 생성한 게임은 인간이 제작한 게임과 유사한 성능을 보였습니다. 또한, 초기의 질적 분석에서도 GAVEL이 생성한 게임이 매력적이고 흥미롭다는 결과가 나타났습니다.

### [StyleSplat: 3D Object Style Transfer with Gaussian Splatting](https://arxiv.org/abs/2407.09473)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09473.png)

Vote: 4

Authors: Prabhdeep Singh Sethi, Sahil Jain, Avik Kuthiala, Prakanshul Saxena

- **What's New**: 3D 장면을 포착하고 표현하는 데 있어 방사장(radiance field) 생성의 혁신으로 인해 세밀함과 현실감에서 전례 없는 수준을 달성하게 되었습니다. 이 기술은 게임, 가상 현실, 디지털 아트와 같은 산업에서 예술적 스타일을 3D 개체에 전달하는 새로운 방식으로 혁신적인 접근을 제공합니다.
- **Technical Details**: 이 연구는 3D Gaussian splatting(3DGS)을 사용하여 3D 장면을 표현하는 새로운 방법인 StyleSplat을 소개합니다. StyleSplat은 세 가지 주요 단계로 구성됩니다: 2D 마스크 생성 및 추적, 3D Gaussian 훈련 및 분할, 마지막으로 3D 스타일 전이(transfer) 단계입니다. 먼저, 일관된 2D 마스크를 생성하여 장면 전체에서 시간적으로 일관된 마스크 식별자를 생성합니다. 그런 다음, 이러한 마스크를 사용하여 3D Gaussian을 분할하고 기하학 및 색상을 최적화합니다. 마지막으로, 스타일 이미지를 기반으로 선택한 Gaussian의 구면 고조파 계수를 정렬하여 스타일 일관성과 시각적 매력을 확보합니다.
- **Performance Highlights**: StyleSplat은 다양한 장면과 데이터 셋에서 뛰어난 결과를 보여주며, 서로 다른 예술적 스타일을 적용하는 데 유연성을 입증합니다. 이 방법은 매우 맞춤화된 고품질 스타일 전이를 가능하게 하며 기존의 NeRF(신경 방사장) 방법과 비교하여 훨씬 빠른 훈련 및 렌더링 속도를 자랑합니다.

### [TCAN: Animating Human Images with Temporally Consistent Pose Guidance using Diffusion Models](https://arxiv.org/abs/2407.09012)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09012.png)

Vote: 4

Authors: Jeongho Kim, Junsoo Lee, Min-Jung Kim, Jaegul Choo

- **What's New**: 포즈 기반 인간 이미지 애니메이션은 정적인 이미지를 생동감 있게 만드는 작업입니다. 본 논문에서는 이를 위한 새로운 프레임워크인 TCAN을 제안합니다. TCAN은 시간적 일관성을 유지하면서도 보지 못한 도메인에서도 잘 일반화될 수 있는 혁신적인 모델입니다.
- **Technical Details**: TCAN은 두 단계 훈련 프레임워크를 따릅니다. 첫 번째 단계에서는 주어진 소스 이미지를 드라이빙 비디오의 각 프레임의 포즈에 맞게 변환합니다. 이를 위해 ControlNet을 사용하여 각 프레임의 포즈 정보를 생성된 이미지의 디노이징(Unet) 네트워크에 삽입합니다. 두 번째 단계에서는 이미지 생성 모델을 비디오 생성 모델로 확장하며, 시간층(temporal layers)을 추가해 포즈 시퀀스의 시간적 정보를 캡처합니다.
- **Performance Highlights**: TCAN은 FID-VID와 FVD 같은 비디오 품질 지표에서 높은 성능 개선을 보여줍니다. 이 모델은 특히 특정 도메인에 과적합(overfitting)되는 문제를 방지하고, 미세한 디테일을 유지하며 포즈와 외형 정보를 효과적으로 분리합니다.

### [Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training](https://arxiv.org/abs/2407.09121)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.09121.png)

Vote: 3

Authors: Youliang Yuan, Jiahao Xu, Pinjia He, Wenxuan Wang, Wenxiang Jiao, Jen-tse Huang, Tian Liang, Zhaopeng Tu

- **What's New**: 이번 연구에서는 LLMs (Large Language Models)의 새로운 안전 조율 방법인 'Decoupled Refusal Training (DeRTa)'을 제안합니다. 이는 모델이 어떤 응답 위치에서도 순응을 거부할 수 있도록 명시적으로 훈련하는 방법입니다.
- **Technical Details**: 기존 안전 조율 데이터에서 거부 위치 편향(refusal position bias)이 있는 문제를 발견하였으며, 이를 해결하기 위해 DeRTa 방법을 도입했습니다. 이 방법은 두 가지 주요 구성 요소를 포함합니다: 1) 해로운 응답 접두사를 포함한 최대 가능도 추정(MLE with Harmful Response Prefix) 전략과 2) 강화된 전이 최적화(Reinforced Transition Optimization, RTO) 전략을 통한 안전 전환 강화를 목표로 합니다.
- **Performance Highlights**: LLaMA3와 Mistral 모델(8B 및 70B)에 대해 제안한 방법을 평가한 결과, 안전성을 향상시키면서도 성능 저하가 없음을 확인했습니다. 또한, GPT-4와 LLaMA3-70B의 지시 변형보다도 공격 방어 성능이 뛰어났습니다. 정량적 및 정성적 평가 모두 본 전략이 잠재적인 위험을 감지하고 안전하지 않은 콘텐츠 생성을 중단할 수 있는 LLMs를 효과적으로 무장시킨다는 것을 지지합니다.

### [Model Surgery: Modulating LLM's Behavior Via Simple Parameter Editing](https://arxiv.org/abs/2407.08770)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.08770.png)

Vote: 3

Authors: Rui Lu, Shenzhi Wang, Huanqian Wang, Shiji Song, Gao Huang, Andrew Zhao, Yang Yue, Jingxin Shi

- **What's New**: 최근 연구는 LLMs (Large Language Models)이 자연어 이해, 텍스트 생성 및 문제 해결과 같은 뛰어난 능력을 보이고 있다는 것을 강조합니다. 이러한 발전은 LLMs가 인간과 유사한 어시스턴트 역할을 할 잠재력을 촉발했습니다. 그러나 유해하거나 편향된 콘텐츠 생성을 방지하는 비독성 및 안전성이 주요 관심사로 떠오르고 있습니다. 이 논문에서는 LLMs의 비독성 및 안전성을 개선하기 위해 직접 매개변수를 편집하는 새로운 접근 방식인 '모델 수술'을 제안합니다.
- **Technical Details**: 이 연구에서는 LLMs의 숨겨진 레이어 공간에서 독성 대 비독성, 탈옥 대 비탈옥과 같은 대립 속성이 선형 구분 가능성(linear separability)을 통해 명확하게 구별될 수 있다는 관찰에서 착안하여 작업이 진행되었습니다. 주요 기법으로는 행동 프로브(behavior probe)를 통한 특정 행동의 방향성을 잡아내는 것입니다. 그 후, 이 프로브의 방향성과 반대되는 효과를 낼 수 있도록 LLM의 일부 매개변수를 직접 수정하는 방식을 채택했습니다.
- **Performance Highlights**: 모델 수술 기술은 다양한 시나리오에서 그 효율성을 입증했습니다. 예를 들어, 독성 콘텐츠 생성을 51.4%에서 5.17%로 줄였고, 탈옥 프롬프트 저항 성공률을 64.6%에서 77.4%로 증가시키는 등 뛰어난 성능을 보였습니다. 기본적인 이해, 추론 및 생성 능력을 유지하면서도 긍정적인 응답 비율을 36.4%에서 54.8%로 높이는 결과를 보였습니다.

### [Characterizing Prompt Compression Methods for Long Context Inference](https://arxiv.org/abs/2407.08892)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.08892.png)

Vote: 3

Authors: Sehoon Kim, Kurt Keutzer, Amir Gholami, Lutfi Eren Erdogan, Siddharth Jha

- **What's New**: 최근 몇 년 동안 거대 언어 모델 (LLM)의 사용이 기하급수적으로 증가하면서 광범위한 텍스트 컨텍스트를 관리하는 애플리케이션이 급증하고 있습니다. 예를 들어, OpenAI의 GPT-3/3.5-Turbo/4-Turbo 모델은 컨텍스트 윈도우 크기가 수천 토큰에서 128K 토큰까지 기하급수적으로 증가했으며, Google의 Gemini 모델은 최대 1M 컨텍스트 길이를 지원하는 모델을 공개했습니다. 이와 함께 긴 컨텍스트 추론 능력은 법률 및 금융 문서 분석, 대규모 코드베이스의 코파일럿, 요약, 대화형 시스템에서 필수적입니다.
- **Technical Details**: 긴 프롬프트를 지원하는 애플리케이션을 구축하는 데 있어 시스템 차원의 도전 과제는 계산 요구 사항, 메모리 요구 사항, 비용 증가 등 다양한 문제가 있습니다. 이러한 긴 프롬프트는 모델의 추론 능력이 저하될 가능성도 있습니다. 이를 해결하기 위해 긴 프롬프트 길이를 압축하면서 필수 정보를 유지하려는 다양한 프롬프트 압축 방법이 제안되었습니다. 본 연구에서는 추출 압축, 요약 압축, 또는 토큰 제거로 방법을 분류하고, 쿼리 무관 또는 쿼리 인식 방식으로 구분하여 종합적인 평가를 수행했습니다.
- **Performance Highlights**: 놀랍게도, 추출 압축 방식은 다른 접근 방식을 모두 능가하며, 최소한의 정확도 저하로 최대 10배의 압축을 가능하게 합니다. 최근 여러 주장에도 불구하고, 토큰 제거 방법은 종종 추출 압축 방식에 뒤처지는 것으로 나타났습니다. 요약 작업에서는 약간의 개선만을 보였습니다.

### [Understanding Retrieval Robustness for Retrieval-Augmented Image Captioning](https://arxiv.org/abs/2406.02265)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.02265.png)

Vote: 3

Authors: Wenyan Li, Jiaang Li, Raphael Tang, Desmond Elliott, Rita Ramos

- **What's New**: 최근 이미지 캡션 생성 모델 분야에서, 관련 캡션을 검색하여 활용하는 모델들이 성공적으로 이미지 캡션 성능을 향상시키면서도 모델 파라미터 수를 줄이는 데 성공했습니다(관련 연구: Ramos et al., 2023b; Sarto et al., 2022; Yang et al., 2023). 이러한 모델들은 입력 이미지 외에도 검색된 정보를 추가 컨텍스트로 사용합니다.
- **Technical Details**: SmallCap 모델의 견고성을 평가하기 위해 검색된 캡션의 순서 및 내용 관련성을 고려한 통제 실험을 수행하였습니다. 모델은 k개의 검색된 캡션을 통해 입력을 구성하고, 언어 모델 디코더에 제공합니다. 검색된 캡션은 이미지-텍스트 검색 시스템 (CLIP embeddings) 을 통해 얻어지며, 코사인 유사도를 기준으로 정렬됩니다. 검색된 캡션의 순서를 뒤섞거나 반대로 정렬함으로써 모델의 캡션 생성에 미치는 영향을 평가했습니다.
- **Performance Highlights**: 우리의 평가 결과, SmallCap 모델은 무작위로 검색된 콘텐츠를 처리할 때 견고하지 않다는 것을 발견했습니다. 또한, 검색된 캡션에서 자주 등장하는 토큰이 모델이 생성한 토큰에 높은 귀속 점수를 갖는 현상을 발견했습니다. 마지막으로, 더 큰 목록에서 랜덤하게 샘플링된 검색된 캡션을 사용하여 훈련할 때, 고정된 상위 k개의 관련 캡션을 사용할 때보다 모델의 견고성 및 도메인 외 성능이 향상되었습니다.

### [RRM: Relightable assets using Radiance guided Material extraction](https://arxiv.org/abs/2407.06397)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.06397.png)

Vote: 2

Authors: Diego Gomez, Élie Michel, Adrien Kaiser, Julien Philip

- **What's New**: 최근 몇 년 동안 3D 씬 표현을 위한 완전 최적화 모델의 사용과 새로운 시점 합성 문제 해결에 인상적인 결과를 가져왔습니다. 이러한 모델들은 장면의 다수의 사진을 훈련 데이터로 사용하여 보이지 않는 시점에서도 3차원성을 유일한 앞선 정보(prior)로써 추론할 수 있습니다. NeRF(Neural Radiance Fields)에서 시작하여, Fourier features, hash-grids of InstantNGP, TensoRF와 같은 뉴런 없는 표현(Neuron-free representations)까지 발전해왔습니다. 특히 이번 연구는 물리적 기반의 3D 랜더링 파이프라인에 호환되는 매개 변수를 추출하여 성능을 향상시키는 것에 중점을 둡니다.
- **Technical Details**: 이번 연구에서는 물리적 인식 라디언스 모듈을 도입하여 거친 표면 법선(normals)과 표면의 거칠기(roughness)를 추출하고, 예측 라디언스 신호를 시점 의존성 및 비의존성 요소로 분리합니다. 또한 Laplacian Pyramid와 다중 중요 샘플링(Multiple Importance Sampling, MIS) 알고리즘을 기반으로 환경 맵을 새로운 방법으로 표현하여 복잡한 기하학에서 고도로 반사되는 효과를 회복할 수 있습니다. 이 과정에서 라디언스 필드를 가이드로 사용하여 물리적 기반 매개 변수를 학습합니다.
- **Performance Highlights**: 기술적 기여를 통해 얻은 이점들은 고품질 매개 변수 추출을 가능하게 하여 glossy 장면에서의 조명 재현 및 법선 수치 결과의 비교에서 높은 성능을 입증했습니다. 특히, 복잡한 물체인 빵 굽는 토스터와 같은 오브젝트를 효과적으로 재현하였으며, 기존의 NeRFactor와 NeRV를 능가하는 성능을 보였습니다.

