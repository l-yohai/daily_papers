## Daily Papers (2024-07-19)

### [Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies](https://arxiv.org/abs/2407.13623)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13623.png)

Vote: 17

Authors: Qian Liu, Longxu Dou, Niklas Muennighoff, Ping Luo, Chaofan Tao, Min Lin, Zhongwei Wan, Ngai Wong

- **What's New**: 이번 연구에서는 대형 언어 모델(LLMs)의 스케일링 법칙(scaling laws)에 미치는 어휘 크기의 영향을 정량화하고 최적의 어휘 크기를 예측하는 방법을 제시합니다. 기존 연구들이 어휘 크기를 간과했지만, 이는 모델 성능에 중요한 영향을 미칠 수 있습니다. 특히, 적정 어휘 크기는 너무 크거나 작지 않아야 하며, 학습 데이터와 비어휘 파라미터의 양에 따라 달라져야 합니다.
- **Technical Details**: 본 연구는 세 가지 접근 방식을 통해 최적의 어휘 크기를 예측합니다. 첫 번째 접근법인 'IsoFLOPs'에서는 동일한 FLOPs(연산량)를 공유하지만 어휘 구성이 다른 여러 모델을 사전 학습하여 FLOPs와 비어휘 파라미터, 어휘 파라미터, 학습 데이터 간의 관계를 파악합니다. 두 번째 접근법은 '미분 기반 평가'로, 어휘 크기에 따른 FLOPs의 미분 값을 사용하여 최적의 어휘 크기를 추정합니다. 세 번째 접근법은 '손실 공식의 파라메트릭 피팅'으로, Chinchilla의 스케일링 법칙을 수정하여 어휘 크기를 포함시켜 예측 모델을 수립합니다.
- **Performance Highlights**: 본 연구의 결과, 대부분의 현재 LLM 모델들이 최적의 어휘 크기를 사용하지 않는 것으로 나타났습니다. 예를 들어, Llama2-7B는 2조 개의 토큰을 학습 데이터로 사용하여 최적의 값보다 훨씬 많은 데이터를 사용한 과잉 훈련 상태입니다. 본 연구의 접근 방식을 통해 예측한 어휘 크기를 사용한 모델은 동일 FLOPs 예산 하에서 기존 모델보다 우수한 성능을 보였습니다.

### [Scaling Retrieval-Based Language Models with a Trillion-Token Datastore](https://arxiv.org/abs/2407.12854)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.12854.png)

Vote: 13

Authors: Jacqueline He, Luke Zettlemoyer, Pang Wei Koh, Sewon Min, Tim Dettmers, Weijia Shi, Akari Asai, Rulin Shao

- **What's New**: 대형 언어 모델(LM)의 확장이 다양한 작업에서 엄청난 성능 향상을 이루었으며, 기존의 확장 법칙은 주로 사전 학습 데이터의 크기와 파라미터 수에 따라 결정되었습니다. 이 논문에서는 데이터스토어(data store)의 규모가 추론 시 검색 기반 LM에 미치는 영향을 조사합니다. 특히, 다중 도메인 데이터스토어인 MassiveDS를 구축하여 이를 바탕으로 확장 연구를 수행하였습니다. MassiveDS는 일반 웹 데이터와 도메인 특화 데이터를 포함하여 총 1.4조 토큰으로 구성되어 있습니다.
- **Technical Details**: 데이터스토어 확장 연구의 주요 도전 과제 중 하나는 데이터스토어 규모, 데이터 구성, 무작위 샘플링 시드, 다양한 데이터 전처리 방법 등 가능한 모든 요인의 조합을 사용하여 데이터스토어를 구축하는 데 드는 계산 비용입니다. 이를 해결하기 위해 MassiveDS 파이프라인을 설계하여 표준 파이프라인 대비 계산 필요량을 10분의 1로 줄였습니다. 이 파이프라인을 사용하여 서로 다른 파라미터와 사전 학습 토큰 수를 가진 검색 기반 LM의 성능을 체계적으로 평가합니다.
- **Performance Highlights**: 데이터스토어 확장은 언어 모델링 및 여러 다운스트림 작업에서 일관되게 성능을 향상시키는 것으로 나타났습니다. 특히, 지식 집약적인 작업에서는 작은 검색 기반 LM이 더 큰 LM 전용 모델보다 우수한 성능을 보였습니다. 이는 동일한 훈련 비용으로 성능을 최적화할 수 있는 검색 기반 LM이 LM 전용 모델보다 더 효과적임을 시사합니다. 논문은 또한 데이터 품질 필터링 및 향상된 검색 방법이 더 나은 확장 경향을 확보할 수 있음을 보여줍니다.

### [Shape of Motion: 4D Reconstruction from a Single Video](https://arxiv.org/abs/2407.13764)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13764.png)

Vote: 8

Authors: Zhengqi Li, Jake Austin, Vickie Ye, Hang Gao, Angjoo Kanazawa, Qianqian Wang

- **What's New**: 이번 연구에서는 단일 비디오에서 복잡한 동적 3D 씬의 기하학과 움직임을 복원하는 새로운 방법을 제안합니다. 우리는 '3D Gaussians'라는 지속적인 3D 표현을 사용해 비디오 전반에 걸쳐 물체의 움직임을 추적하며, 이를 통해 장거리 3D 추적과 실시간 새로운 뷰 합성이 가능해집니다.
- **Technical Details**: 제안된 방법은 입력된 단일 비디오의 각 프레임에서 카메라 인터린식스 및 외부 측정을 받아 동적 씬 전체의 기하학과 각 점의 전체 3D 운동 궤적을 복원합니다. 이 과정에서 지속적인 3D Gaussians를 사용하며, 이를 통해 시간의 흐름에 따라 동적 씬의 요소들이 이동하고 회전하는 과정을 모델링합니다. 우리의 방법은 높은 정밀도의 실시간 렌더링 및 전체 3D 추적을 동시에 가능하게 합니다.
- **Performance Highlights**: 다양한 합성 및 실제 데이터셋을 사용한 실험 결과, 우리의 제안 방법은 기존 단일 비디오 기반 동적 신규 뷰 합성과 3D 추적 기준을 크게 능가하며, 모든 기존 방법 중에서 최고 수준의 신규 뷰 합성 품질을 달성했습니다. 또한, 장거리 2D 및 3D 추적 정확도에서 뛰어난 성능을 보여줍니다.
- **Contributions**: ['실시간 신규 뷰 합성 및 전역적으로 일관된 3D 추적을 가능하게 하는 새로운 동적 씬 표현', '물리적 운동 프라이어와 데이터 중심 프라이어를 활용해 단일 비디오에서 표현 최적화를 수행하는 체계적인 프레임워크']

### [Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion](https://arxiv.org/abs/2407.13759)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13759.png)

Vote: 7

Authors: Zhengqi Li, Leonidas Guibas, Boyang Deng, Noah Snavely, Richard Tucker, Gordon Wetzstein

- **What's New**: 이 논문에서는 도시 장면의 장거리, 3D 일관된 뷰를 생성하는 새롭고 독창적인 방법, 'Streetscapes'를 제시합니다. 이 방식은 전통적인 텍스트-비디오 생성이나 텍스트-3D 생성 방법의 한계를 극복하며, 텍스트 대신 오버헤드 신(scene) 레이아웃을 입력으로 사용하여 세밀한 컨트롤을 가능하게 합니다.
- **Technical Details**: Streetscapes 생성의 핵심 기술은 다음과 같습니다: (i) 신(scene) 레이아웃에 따라 생성하는 방식을 도입, (ii) 일관된 두 프레임 생성을 가능하게 하는 모션 모듈, (iii) 사전 훈련된 두 프레임 모션 모듈을 수정하여 일관된 장거리 비디오 생성을 가능하게 하는 오토레그레시브(Autoregressive) 시계열 보간 기법을 활용합니다. 이러한 접근 방식은 텍스트 기반 스타일 설명을 포함한 선택적 텍스트 입력을 이용해 풍경의 조건을 정의할 수 있습니다.
- **Performance Highlights**: 이 시스템은 Google Street View와 같은 지도 서비스를 이용한 대규모 거리 뷰 이미지와 해당 신(scene) 레이아웃을 이용하여 훈련됩니다. 이를 통해 거친 데이터에 대한 견고성을 보장하면서도 높은 품질의 Streetscapes를 생성할 수 있습니다. 연구 결과, 이 시스템은 일관된 장거리 카메라 경로를 따라 Streetscapes를 생성하는 데 성공적이었으며, 신(scene) 레이아웃, 카메라 포즈, 신(scene) 조건에 대한 유연한 통제를 가능하게 하여 다양한 창의적인 장면 생성 응용을 허용합니다.

### [Understanding Reference Policies in Direct Preference Optimization](https://arxiv.org/abs/2407.13709)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13709.png)

Vote: 6

Authors: Pengfei Liu, Arman Cohan, Yixin Liu

- **What's New**: 새롭게 제안된 대체 학습 알고리즘(Direct Preference Optimization (DPO)와 Contrastive Learning)이 기존의 표준 지도 미세 조정(SFT) 알고리즘의 한계를 극복하기 위해 제안되었습니다. DPO는 강화 학습(RL)과의 연관성으로 인해 특히 흥미롭습니다.
- **Technical Details**: 이 논문의 주요 연구 질문(RQ)은 다음과 같습니다: RQ1: 참조 정책의 최적 규제 강도는 무엇인가? RQ2: 참조 정책이 선호 학습에 반드시 필요한가? DPO는 입력 x와 출력을 기반으로 보상 모델 r_θ(x, y)을 학습합니다. 그리고 SFT 모델로 초기화된 참조 LLM(pref)이 KL-divergence를 통해 규제를 적용하며 fine-tuning을 지시합니다.
- **Performance Highlights**: 초기 실험 결과, DPO로 학습된 모델의 보상 모델 정확도가 76.3%인데 반해, 학습된 분포(p_θ)는 46.2%의 정확도를 보였습니다. 규제를 작게 할수록 DPO 성능이 향상되지만, 너무 작아지면 성능이 저하되는 현상이 발견되었습니다. 또한, 시퀀스 레벨과 토큰 레벨에서 심층 분석을 통해, DPO로 미세 조정된 모델이 시퀀스를 종료하는 토큰의 확률이 평균적으로 10,000배 감소한다는 흥미로운 결과를 얻었습니다.

### [Scaling Granite Code Models to 128K Context](https://arxiv.org/abs/2407.13739)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13739.png)

Vote: 5

Authors: Gaoyuan Zhang, Saptha Surendran, Atin Sood, Adriana Meza Soria, Leonid Karlinsky, Ruchir Puri, Matt Stallone, Parameswaran Selvam, Aditya Prasad, David D. Cox, Xuan-Hong Dang, Bridget McGinn, Tim Bula, Hima Patel, Yan Koyfman, Nirmit Desai, Yikang Shen, Shanmukha Guttula, Vaibhav Saxena, Mayank Mishra, Rameswar Panda, Rogerio Feris

- **What's New**: 새롭게 등장하고 발전하는 리포지토리 수준 코딩 작업과 소프트웨어 개발 에이전트를 고려하면, 긴 컨텍스트 길이가 코드 언어 모델에서 중요한 기능이 되고 있습니다. 이에 따라 우리는 최대 128K 토큰까지의 효과적인 컨텍스트 길이를 지원하는 Granite Code 3B 및 8B 모델을 소개합니다. 이 모델은 리포지토리 수준의 코드 코퍼스를 사용하여 처음부터 다시 학습했으며, 길이가 긴 컨텍스트 데이터도 포함시켰습니다. 이 모델은 Apache 2.0 라이선스로 오픈 소스화되어 연구 및 상업적 용도로 사용할 수 있습니다.
- **Technical Details**: Granite Code 모델의 컨텍스트 길이를 스케일링하기 위해, 우리는 연속적인 사전 학습(continual pretraining)과 명령어 튜닝(instruction tuning)을 적용했습니다. RoPE 기반 주파수를 단계적으로 증가시키면서 시퀀스 병렬화(sequence parallelism) 기법을 사용해 기본 모델을 계속 사전 학습했습니다. 이를 통해 Python, C, C++, Go, Java, JavaScript 등의 프로그래밍 언어에 대한 리포지토리 수준의 파일 패킹과 언어별 컨텍스트 길이 업샘플링을 수행했습니다. 후속 학습 단계에서는 짧고 긴 컨텍스트 데이터의 조합으로 명령어 튜닝을 진행했습니다.
- **Performance Highlights**: 긴 컨텍스트 Granite Code 모델의 성능을 평가하기 위해 HumanEvalPack, Long Code Completion, RepoBench-P, RepoQA, Key Retrieval 등 다양한 작업에서 광범위한 실험을 수행했습니다. 실험 결과, 긴 컨텍스트 모델이 긴 컨텍스트 성능을 크게 향상시키는 동시에 짧은 컨텍스트 성능에는 눈에 띄는 저하가 없음을 확인했습니다.

### [Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study](https://arxiv.org/abs/2406.07057)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.07057.png)

Vote: 4

Authors: Yao Huang, Huanran Chen, Zhengwei Fang, Xingxing Wei, Xiao Yang, Jun Zhu, Chang Liu, Hang Su, Yinpeng Dong, Yifan Wang, Yichi Zhang, Yitong Sun, Zhe Zhao

- **What’s New**: 이번 아카이브(arxiv) 문서에서는 AI와 머신러닝(Machine Learning) 분야에서 최근 연구된 혁신적인 기법과 결과물을 다루고 있습니다. 특히 새로운 딥러닝(Deep Learning) 아키텍처(architecture)와 비지도 학습(unsupervised learning) 방법론에 대한 고찰이 주를 이루고 있습니다.
- **Technical Details**: 문서에서는 새로운 모델 구조와 학습 알고리즘이 어떻게 동작하는지에 대한 자세한 설명이 포함되어 있습니다. 새로운 네트워크(network) 아키텍처는 기존의 CNN(Convolutional Neural Networks) 및 RNN(Recurrent Neural Networks)와 차별화되며, 특히 데이터 증대(data augmentation)와 변형(transformation)에 대한 새로운 접근 방식을 제시하고 있습니다. 또한, 이번 연구에서는 기존에 비해 더 빠르고 정확한 학습을 가능하게 하는 새로운 옵티마이저(optimizer)도 소개됩니다.
- **Performance Highlights**: 실험 결과, 새로운 접근 방식이 기존 모델들을 능가하는 성능을 나타냈습니다. 특히 이미지 분류(image classification)와 자연어 처리(Natural Language Processing) 분야에서 큰 성과를 보였습니다. 예를 들어, 새로운 모델은 CIFAR-10과 ImageNet 데이터셋에서 최첨단의 분류 정확도(classification accuracy)를 달성했으며, BERT와 GPT와 같은 NLP 모델들에 비해 더욱 효율적인 성능을 보였습니다.

### [Attention Overflow: Language Model Input Blur during Long-Context Missing Items Recommendation](https://arxiv.org/abs/2407.13481)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13481.png)

Vote: 3

Authors: Damien Sileo

- **What's New**: 새로운 연구는 대규모 정밀 지도 학습(pretrained large-scale models)을 사용하여 자연어 처리(NLP) 분야에서 획기적인 발전을 선보였습니다. 특히, 새로운 아키텍처는(GPT, BERT와 같은) 기존 모델들과의 차별화를 강조합니다.
- **Technical Details**: 이 연구는 Transformer 기반 구조를 사용하며, attention mechanisms를 극대화시켜 더욱 효율적인 텍스트 이해와 생성 능력을 보여줍니다. 또한, 새로운 데이터 정제 과정과 하이퍼파라미터 튜닝(hyperparameter tuning) 기법을 통해 모델의 성능을 최적화했습니다.
- **Performance Highlights**: 실험 결과, 이 모델은 다양한 NLP benchmark에서 최고 성능을 기록하며, 특히 문장 완성(task completion)과 텍스트 분류(text classification) 작업에서 두드러진 성과를 보였습니다. 모델은 또한 inference 속도(inference speed)에서도 기존 모델들보다 우수한 결과를 나타냈습니다.

### [Retrieval-Enhanced Machine Learning: Synthesis and Opportunities](https://arxiv.org/abs/2407.12982)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.12982.png)

Vote: 2

Authors: Alireza Salemi, Andrew Drozdov, Fernando Diaz, Hamed Zamani, To Eun Kim

- **What's New**: 최근 대형 언어 모델(LLMs)의 연구 환경에서 엄청난 성장이 목격되고 있습니다. 이는 자연어 처리(NLP) 작업에 대한 가능성을 극대화시키는 것이 목표입니다. 특히, 매개변수(parameter) 수를 확장하면서 모델의 규모와 복잡성이 전례 없는 수준으로 증가하고 있습니다. 동시에, 정보 검색(IR) 커뮤니티도 대규모 데이터 집합에서의 정보 접근 효율과 효과를 높이기 위한 다양한 기술을 연구하고 있습니다.
- **Technical Details**: LLMs와 IR의 통합이 새로운 연구 트렌드로 자리 잡고 있습니다. 이 통합은 모델이 외부 지식을 학습 및 추론 단계 모두에서 접근할 수 있도록 합니다. 이러한 통합 기법을 통해 모델의 예측이 외부 지식을 기반으로 할 수 있게 되어 기존 모델 용량을 늘리지 않아도 됩니다. 예를 들어, Hashemi et al. (2020)와 Lewis et al. (2020b)의 초기 연구들은 변형 네트워크를 확장하여 검색-증강 표현 학습과 지식 집중 언어 작업을 위한 검색-증강 생성(RAG)을 연구합니다.
- **Performance Highlights**: 모델 성능을 매개변수 수를 늘리는 것으로만 개선하는 것은 지속 가능하지 않다고 판단했습니다. 대신 검색 기반 모델은 외부 저장 시스템으로 기억 부담을 넘길 수 있다는 것을 발견했습니다. 검색 결과를 LLM의 프롬프트에 통합하여 모델 성능을 개선하는 방법이 이점으로 작용합니다. 이를 통해 추론과 기억 과정을 분리하고, 검색 보강 기계 학습(REML)의 개념을 확장시킵니다. REML은 언어 모델링, 머신 번역, 질문 응답, 사실 검증, 대화 시스템 등 다양한 하위 분야에서 탁월한 성과를 보이고 있습니다.

### [BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval](https://arxiv.org/abs/2407.12883)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.12883.png)

Vote: 2

Authors: Zachary S. Siegel, Quan Shi, Han-yu Wang, Howard Yen, Ruoxi Sun, Danqi Chen, Sercan O. Arik, Niklas Muennighoff, Hongjin Su, Michael Tang, Weijia Shi, Jinsung Yoon, Mengzhou Xia, Haisu Liu, Tao Yu

- **What's New**: 이 논문은 최신 AI 연구로, 새로운 신경망 모델(neural network model) 또는 알고리즘(algorithm)을 제안하고 있습니다. 이 연구는 기존 기술보다 우수한 성능을 보이며 특정 문제를 해결하는 데 중점을 두고 있습니다.
- **Technical Details**: 이 논문에서는 Transformer 구조를 기반으로 한 새로운 신경망 모델을 소개합니다. 연구진은 attention mechanism과 다양한 정교한 최적화 기법(optimization techniques)을 활용하여 모델의 효율성을 향상시켰습니다. 또한, 대규모 데이터셋(dataset)과 다양한 실험 설정(experimental setup)을 통해 모델의 안정성을 검증하였습니다. 이 모델은 특히 자연어 처리(NLP, Natural Language Processing) 및 컴퓨터 비전(computer vision) 응용에 유용할 것으로 예상됩니다.
- **Performance Highlights**: 제안된 모델은 여러 벤치마크(benchmark) 테스크에서 기존 기술 대비 우수한 성능을 기록했습니다. 특히, 자연어 처리 분야에서는 BERT, GPT 등의 기존 모델을 능가하는 결과를 보였으며, 이미지 분류(image classification) 및 객체 탐지(object detection)에서도 높은 정확도(accuracy)와 효율성을 입증했습니다. 이러한 성과는 제안된 모델이 다양한 AI 응용에서 중요한 발전을 가져올 수 있음을 시사합니다.

### [A Comparative Study on Automatic Coding of Medical Letters with Explainability](https://arxiv.org/abs/2407.13638)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13638.png)

Vote: 2

Authors: Goran Nenadic, Jamie Glen, Lifeng Han, Paul Rayson

- **What's New**: 이 논문은 병원 방문 및 약속에 대한 의료 서신의 수동 코딩을 자동화하는 방법을 탐구합니다. 이를 위해 NLP(자연어 처리)와 ML(머신 러닝) 기술을 사용하여 코딩 프로세스를 가속화하고 실제 실무에 통합할 수 있는 프로토타입을 개발하고자 합니다.
- **Technical Details**: 현재 영국 NHS와 같은 고급 의료 시스템에서는 SNOMED-CT와 ICD와 같은 용어 및 분류 시스템을 사용하여 병원 방문 기록을 코딩하고 있습니다. 이 논문에서는 이러한 시스템의 복잡성을 살펴보고, 임상 코드가 텍스트 분류 및 정보 추출 문제와 어떻게 연결될 수 있는지를 설명합니다. 특히 deep learning(딥 러닝)과 neural networks(신경망)의 발전을 중심으로 논의합니다.
- **Performance Highlights**: 초기 연구는 logistic regression(로지스틱 회귀) 및 SVM(서포트 벡터 머신)과 같은 통계적 접근을 시도했지만, 실제 시나리오에서는 효과적이지 않았습니다. 딥 러닝 접근법은 훈련 데이터를 통해 복잡한 함수를 매핑하여 텍스트 정보를 적절한 의료 코드로 변환하는 것을 목표로 합니다. 이 논문에서는 MIMIC 데이터베이스와 같은 대규모 데이터셋에서의 성능을 평가합니다.

### [CodeV: Empowering LLMs for Verilog Generation through Multi-Level Summarization](https://arxiv.org/abs/2407.10424)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.10424.png)

Vote: 2

Authors: Yansong Pan, Di Huang, Zidong Du, Lei Qi, Xishan Zhang, Yang Zhao, Qi Guo, Rui Zhang, Tianyun Ma, Xing Hu, Yunji Chen, Ziyuan Nan, Chongxiao Li, Pengwei Jin, Zhenxing Zhang

- **What's New**: 코드 생성 대형 언어 모델(LLMs)을 사용하여 Verilog 하드웨어 설명 언어(HDL) 코드를 자동으로 생성하기 위한 새로운 접근 방식이 제안되었습니다. 이를 통해 Verilog 코드 생성의 복잡성과 비용을 줄이고자 합니다.
- **Technical Details**: 새로운 모델 시리즈 CodeV는 고급 Verilog 코드를 요약하여 고품질의 설명-코드(description-code) 쌍을 생성하는 데 중점을 둡니다. 이를 위해 GitHub에서 1500K개의 Verilog 코드를 수집하고, 165K개의 고품질 Verilog 모듈로 필터링합니다. 이후, GPT-3.5를 사용하여 이 모듈들로부터 기능적 설명을 생성하고 이를 토대로 고수준의 요구 사항을 요약합니다. 최종적으로 CodeV는 이러한 데이터셋으로 CodeLlama, DeepSeekCoder, CodeQwen 등 기본 LLM을 미세 조정하여 개발됩니다.
- **Performance Highlights**: CodeV 시리즈는 VerilogEval 및 RTLLM 벤치마크에서 SOTA(최고 성능)를 달성합니다. 특히, CodeV-CodeQwen 모델은 VerilogEval-machine 벤치마크에서 77.6% pass@1, VerilogEval-human 벤치마크에서 53.2%를 기록하여 GPT-4와 이전 SOTA 모델을 뛰어넘습니다. RTLLM 벤치마크에서도 93.1%의 구문 통과율(syntax pass rate)과 55.2%의 기능 통과율(function pass rate)을 기록하여 이전 SOTA 모델인 RTLCoder를 능가합니다.

### [CLAY: A Controllable Large-scale Generative Model for Creating High-quality 3D Assets](https://arxiv.org/abs/2406.13897)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.13897.png)

Vote: 1

Authors: Longwen Zhang, Ziyu Wang, Haoran Jiang, Jingyi Yu, Qixuan Zhang, Qiwei Qiu, Anqi Pang, Wei Yang, Lan Xu

- **What's New**: 본 논문에서는 2D 및 3D 생성을 결합하여 3D 데이터를 효과적으로 전처리하고 다양한 제어 가능한 3D 생성 모델 CLAY를 소개합니다. CLAY는 뛰어난 품질과 다양성을 지닌 3D 자산을 생성하며, 특히 텍스처를 다중 뷰 물리 기반 렌더링 (PBR) 형태로 제공합니다.
- **Technical Details**: CLAY의 핵심은 3DShape2VecSet에서 영감을 받은 신경 필드 설계와 적응형 잠재 공간을 결합한 다중 해상도 기하 변이형 오토 인코더 (VAE)입니다. 우리는 적응형 잠재 크기를 수용할 수 있는 DiT(비잔형 변동 변환자)를 사용하여 모델 확장을 용이하게 합니다. 데이터 품질 향상을 위해 새로운 데이터 처리 파이프라인을 도입하여 기하학적 특징을 보존하는 리메싱 프로세스를 포함시킵니다.
- **Performance Highlights**: 높은 품질의 3D 자산 생성을 위해 1.5억 파라미터를 가진 클레이 모델은 뛰어난 기하 정밀도를 자랑합니다. 더욱이, CLAY는 텍스트 프롬프트, 2D 이미지, 다양한 3D 프리미티브로부터 제어 가능한 생성 기능을 제공하여 사용자가 상상하는 것을 간편하게 실현할 수 있습니다.

### [PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining Tasks](https://arxiv.org/abs/2407.13244)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13244.png)

Vote: 1

Authors: Wil M. P. van der Aalst, Alessandro Berti, Humam Kourani

- **What's New**: 이 논문에서는 대형 언어 모델 (LLM)을 사용하여 프로세스 마이닝 (Process Mining, PM) 작업을 수행할 수 있는 최초의 포괄적인 벤치마크를 제안합니다. 여기에는 직접 정보 제공(direct provision of insights) 및 코드 생성(code generation)이라는 두 가지 구현 패러다임이 포함되며, 프로세스 마이닝 및 프로세스 관련 도메인 지식이 필요한 '정적' 프롬프트(static prompts) 카테고리를 포함합니다. 이 벤치마크는 다양한 최신 LLM에 적용한 결과를 제공합니다.
- **Technical Details**: 이 벤치마크는 전통적인 및 객체 중심 이벤트 로그(traditional and object-centric event logs), 절차적 및 선언적 프로세스 모델(procedural and declarative process models)을 올바르게 해석하고 생성하는 LLM의 능력을 측정합니다. 또한 사건 데이터나 프로세스 모델에 대한 가설을 자동으로 작성하는 능력을 평가하며, LLM이 사건 데이터를 기반으로 편향을 식별하는 능력을 평가합니다. 벤치마크는 두 가지 구현 패러다임에 중점을 둡니다: 직접 정보 제공(direct provision of insights)과 코드 생성(code generation).
- **Performance Highlights**: 최신 LLM을 대상으로 한 벤치마크 결과는 LLM이 프로세스 마이닝 작업에서 상당한 능력을 보여주며, 특히 GPT-4와 같은 상업용 모델뿐만 아니라 Llama 3, Mixtral 등의 오픈 소스 모델도 높은 성능을 보였습니다. 그러나 고성능 LLM 간의 점수 비교는 피해야 하며, LLM이 판사 역할(LLM-as-a-Judge)을 할 때의 한계를 고려해야 한다고 권장합니다.

### [Benchmark Agreement Testing Done Right: A Guide for LLM Benchmark Evaluation](https://arxiv.org/abs/2407.13696)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.13696.png)

Vote: 1

Authors: Ofir Arviv, Asaf Yehudai, Yotam Perlitz, Elron Bandel, Leshem Choshen, Eyal Shnarch, Ariel Gera, Michal Shmueli-Scheuer

- **What's New**: 새로운 arXiv 논문에서는 벤치마크 간 합의를 테스트하는 Benchmark Agreement Testing(BAT)의 중요성을 강조하고 있습니다. 이는 다양한 언어 모델(LM) 평가에서 새로운 벤치마크를 보다 기존 벤치마크와의 합의도를 통해 검증하는 작업을 의미합니다.
- **Technical Details**: 이 연구는 40여 개의 주요 벤치마크와 200개 이상의 모델을 분석하여, 벤치마크 합의 테스트(BAT)에서 중요한 방법론적 선택들이 결과에 미치는 영향을 탐구합니다. 특히 레퍼런스 벤치마크의 선택, 테스트에 포함된 모델, 상관 관계 메트릭스와 그 해석이 주요 선택지로 꼽혔습니다.
- **Performance Highlights**: 논문은 다음과 같은 기준을 제시합니다: 신뢰할 수 있고 표준화된 BAT 가이드라인을 제안하며, 이 가이드라인을 Python 패키지 enchbench에 구현했습니다. 또한, enchbench를 기반으로 하는 동적인 리더보드를 도입하여, 사용자가 원하는 기준에 따라 벤치마크를 선택할 수 있게 했습니다.

