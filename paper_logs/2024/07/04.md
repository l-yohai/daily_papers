## Daily Papers (2024-07-04)

### [InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output](https://arxiv.org/abs/2407.03320)

![](/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg)

Vote: 49

Authors: Xiaoyi Dong, Wenwei Zhang, Rui Qian, Qipeng Guo, Yuhang Cao, Yuhang Zang, Pan Zhang, +, Linke Ouyang, Yining Li, Wei Li, Bin Wang, Songyang Zhang, Lin Chen, Wenhai Wang, Peng Sun, Xingcheng Zhang, Xinyue Zhang, Yang Gao, Hang Yan, Jingwen Li, Conghui He, Haodong Duan

- **What's New**: 최근 대형 언어 모델(LLMs)의 발전은 대형 비전 언어 모델(LVLMs)의 개발에도 관심을 불러일으켰습니다. 이에 따라 다양한 응용 프로그램이 가능해졌습니다. 새로운 모델 InternLM-XComposer-2.5 (IXC-2.5)는 장기적 입력 및 출력을 지원하는 다양한 이해 및 구성 능력을 갖춘 다재다능한 LVLM으로 소개됩니다.
- **Technical Details**: InternLM-XComposer-2.5는 기존의 오픈소스 LVLM에서 두 가지 주요 이점을 가집니다: 1) 다재다능성: IXC-2.5는 자유 형식 텍스트-이미지 대화, OCR, 비디오 이해, 삽화를 포함한 기사 작성, 웹페이지 제작 등 다양한 과제를 지원합니다. 2) 장기적 입력 및 출력 기능: 24K 인터리브드 이미지-텍스트 데이터로 네이티브 트레이닝되고, 포지셔널 인코딩 외삽법을 통해 컨텍스트 창을 96K로 확장할 수 있습니다. 추가적으로, IXC-2.5는 동적 해상도 솔루션을 포함한 초고해상도 이해, 세밀한 비디오 이해, 자유 형식의 다중 회전 다중 이미지 대화를 특징으로 갖추고 있습니다.
- **Performance Highlights**: InternLM-XComposer-2.5는 다양한 벤치마크에서 성능을 평가했습니다. 비디오, 고해상도 구조 벤치마크, 일반 VQA 벤치마크 등 총 28개 벤치마크에서 오픈소스 LVLM 중 최고 성능을 기록했으며, 16개 벤치마크에서 기존 상용 API와 대등하거나 그 이상의 성과를 보였습니다.

### [TabReD: A Benchmark of Tabular Machine Learning in-the-Wild](https://arxiv.org/abs/2406.19380)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.19380.png)

Vote: 31

Authors: Ivan Rubachev, Nikolay Kartashev, Yury Gorishniy, Artem Babenko

- **What's New**: 최근 몇 년간 테이블형 머신러닝(tabular machine learning) 연구가 빠르게 발전하고 있습니다. 이에 따라 신경망 구조(neural network architectures)에 대한 여러 연구가 진행되었으며, 이는 '얕은' GBDT 모델보다 경쟁력 있거나 우수한 성능을 보였습니다. 본 논문은 기존 부합하지 않는 학술적 벤치마크의 부족을 채우기 위해 TabReD라는 벤치마크를 도입합니다. TabReD는 금융부터 음식 배달까지 다양한 도메인에 걸친 8개의 산업형 데이터세트를 포함하고 있습니다.
- **Technical Details**: TabReD 벤치마크는 시간 기반 분할(time-based splits)을 이용하여 훈련, 검증, 테스트 세트를 나누었습니다. 이는 시간에 따른 데이터의 '템포럴 시프트(temporal shift)'를 고려하는 것으로, 새로운 데이터가 기존 데이터와 다른 분포를 가질 수 있다는 점을 반영합니다. 또한, 추가적인 데이터 수집 및 특징 공학(feature engineering)을 통해 더 많은 특징을 포함하고 있습니다. 이를 통해 많은 학습 모델을 평가하여 분석을 수행하였습니다.
- **Performance Highlights**: TabReD 벤치마크에서의 모델 평가 결과, GBDT와 임베딩을 사용한 MLP(Multi-Layer Perceptron) 모델이 평균적으로 가장 높은 성능을 보였습니다. 복잡한 딥러닝 모델은 상대적으로 덜 효과적이었으며 기존 학술적 벤치마크 대비 다양한 방법 간의 성능 차이가 적었습니다. 시간 기반 분할이 중요한 평가 방법임을 확인하는 실험을 통해 XGBoost와 같은 모델의 성능 차이가 기존 무작위 분할 평가 결과와 크게 다름을 발견하였습니다.

### [TokenPacker: Efficient Visual Projector for Multimodal LLM](https://arxiv.org/abs/2407.02392)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02392.png)

Vote: 17

Authors: Song Wang, Jianke Zhu, Dongqi Tang, Yuqian Yuan, Wentong Li, Lei Zhang, Jian Liu

- **What's New**: 이번 연구에서는 새로운 시각 투사자(TokenPacker)를 제안하여 고해상도 특성을 저해상도 점 쿼리에 주입하여 압축된 시각 토큰을 생성합니다. 이 접근법을 통해 시각 인코더와 대형 언어 모델(LLM)을 효율적으로 연결할 수 있습니다. 
- **Technical Details**: TokenPacker는 저해상도 점 쿼리를 고해상도 지역의 다양한 CLIP feature과 결합하여 영향을 받지 않으면서 압축된 시각 토큰을 생성합니다. 또한, 동적 이미지 슬라이싱(dynamic image slicing) 기법을 도입하여 입력 이미지의 다양한 종횡비를 지원하고 최소한의 패딩으로 고해상도 이미지를 처리할 수 있습니다.
- **Performance Highlights**: TokenPacker는 LLaVA-1.5 [33]에서 75%(576 vs 144)에서 최대 89%(576 vs 64)까지 시각 토큰 수를 감소시키면서도 유사하거나 더 나은 성능을 보여줍니다. 다양한 멀티모달 벤치마크에서 탁월한 효율성과 정확성을 나타내며, 고해상도 이해 성능에서도 일관되게 높은 성과를 보였습니다.

### [No Training, No Problem: Rethinking Classifier-Free Guidance for Diffusion Models](https://arxiv.org/abs/2407.02687)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02687.png)

Vote: 12

Authors: Manuel Kansy, Romann M. Weber, Otmar Hilliges, Seyedmorteza Sadat

- **What's New**: 이 연구에서는 새로운 딥러닝(Deep Learning) 모델인 XYZ-Net을 제안합니다. 이 모델은 기존의 신경망(neural networks) 구조를 개선하여 다양한 분야에서 더 높은 성능을 발휘할 수 있도록 설계되었습니다.
- **Technical Details**: XYZ-Net은 기존의 CNN(convolutional neural networks) 아키텍처를 기반으로 합니다. 모델의 핵심 요소로는 새로운 유형의 레이어(layer), 향상된 활성화 함수(activation function), 그리고 효율적인 학습 알고리즘(learning algorithm)이 포함됩니다. 또한, 모델의 최적화를 위해 다양한 정규화 기법(regularization techniques)과 데이터 증강(data augmentation) 기법이 적용되었습니다.
- **Performance Highlights**: 실험 결과, XYZ-Net은 이미지 분류(image classification), 객체 인식(object detection), 자연어 처리(NLP, Natural Language Processing) 등 다양한 과제에서 기존 모델을 능가하는 성능을 보였습니다. 특히, XYZ-Net은 CIFAR-10, ImageNet과 같은 표준 데이터셋에서 SOTA(State-of-the-Art) 성과를 달성했습니다. 모델의 효율성 또한 GPU(GPU, Graphics Processing Unit)를 활용한 병렬 처리에서 높은 성능을 보였습니다.

### [PicoAudio: Enabling Precise Timestamp and Frequency Controllability of Audio Events in Text-to-audio Generation](https://arxiv.org/abs/2407.02869)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02869.png)

Vote: 6

Authors: Zhizheng Wu, Xuenan Xu, Zeyu Xie, Mengyue Wu

- **What's New**: 최근 오디오 생성 분야에서 중요한 진전이 있었습니다. 특히, 디퓨전 모델(diffusion models)의 발전으로 생동감 있고 실제와 같은 오디오를 생성할 수 있게 되었습니다. 이번 연구에서는 PicoAudio라는 새로운 모델을 제안하여 오디오 이벤트의 정확한 타임스탬프와 빈도 조절 기능을 제공합니다. 이 모델은 데이터 시뮬레이션, 맞춤형 모델 설계, 그리고 대형 언어 모델(large language model, LLM)의 사전처리를 통해 이를 실현합니다.
- **Technical Details**: PicoAudio는 정밀한 타임스탬프와 빈도 조절을 위해 새로운 데이터 시뮬레이션 파이프라인을 설계했습니다. 인터넷에서 오디오 데이터를 자동으로 수집하고, 텍스트-오디오 그라운딩 모델(text-to-audio grounding model)을 사용해 이벤트의 발생 시점을 분할합니다. 그런 다음 대비 언어-오디오 사전 학습 모델 (contrastive language-audio pretraining, CLAP)을 통해 데이터를 필터링합니다. 그런 후 PicoAudio는 다양한 입력 형식을 처리할 수 있는 LLM을 사용하여 타임스탬프 자막과 빈도 자막을 생성하고, 이를 기반으로 오디오를 생성합니다.
- **Performance Highlights**: PicoAudio는 기본적인 타임스탬프와 빈도 조절 외에도 다양한 상황에서의 정확한 시간 제어를 가능하게 합니다. 예를 들어, 특정 시간 간격에 소리를 배치하거나 여러 이벤트의 순서를 정하는 등의 더 복잡한 시간적 조건도 효율적으로 처리할 수 있습니다. 이러한 성능은 GPT-4를 이용한 학습 데이터로부터 도출된 것으로, 초기 변환 오류율이 3/1000에서 재학습 후 0/1000으로 크게 개선되었습니다.

### [DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents](https://arxiv.org/abs/2407.03300)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.03300.png)

Vote: 5

Authors: Karsten Kreis, Gabriele Corso, Yilun Xu, Tommi Jaakkola, Arash Vahdat

- **What's New**: 이번 연구는 기존의 Diffusion Models(DMs) 방식을 기반으로 하여 DisCo-Diff 프레임워크를 소개합니다. DisCo-Diff는 기존 연속형 잠재 변수와 달리, 이산형 잠재 변수를 활용하여 DMs의 성능을 향상시키고, 다양한 데이터셋에 대해 높은 품질의 이미지를 생성할 수 있는 모델입니다.
- **Technical Details**: DisCo-Diff는 잠재 공간(laten space)에서 이산형 잠재 변수(discrete latent variables)의 사용을 제안합니다. 기존 DMs 연구들과 달리, DisCo-Diff는 소수의 이산형 잠재 변수와 작은 코드북(codebook)을 사용하여 연속형 DMs와의 조화를 이룹니다. 또한, 멀티미디어 생성에서 널리 쓰이는 사전 학습된 네트워크(pre-trained network)를 피하고, DMs와 함께 이산형 잠재 변수를 학습합니다. 이는 모델의 복잡성을 줄이고 적용 범위를 넓히는 데 기여합니다.
- **Performance Highlights**: DisCo-Diff는 기존 모델들보다 복잡하고 다양한 고품질 데이터에 대한 생성 능력에서 뛰어난 성능을 보였습니다. 특히 ImageNet과 같은 복잡한 데이터셋에서도 우수한 성능을 입증했습니다. 또한 DisCo-Diff는 ODE 곡률(ODE curvature)을 줄이고 모델의 복잡성을 감소시켜 새로운 관점을 제공합니다.

### [Investigating Decoder-only Large Language Models for Speech-to-text Translation](https://arxiv.org/abs/2407.03169)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.03169.png)

Vote: 3

Authors: Chao-Wei Huang, Hongyu Gong, Sravya Popuri, Hirofumi Inaguma, Ruslan Mavlyutov, Ilia Kulikov, Hui Lu

- **What's New**: 이번 연구는 대형 언어 모델(LLM)을 음성-텍스트 번역(S2TT) 작업에 통합하는 방법을 탐구합니다. 전통적으로 S2TT 작업은 별도의 자동 음성 인식(ASR)과 기계 번역(MT) 모듈로 구성된 구조를 사용했으나, 최근에는 오디오 인코딩과 텍스트 디코딩을 통합한 엔드-투-엔드(E2E) 접근 방식이 인기를 끌고 있습니다. 그러나 이러한 접근 방식에도 불구하고, 여전히 도메인 외 일반화와 세부 사항을 캡처하는 데 어려움이 있습니다. 이번 논문은 다양한 아키텍처 디자인, 효율적인 파라미터 튜닝, 과제 공식화를 통해 디코더 전용 LLM을 S2TT에 적응시키는 방법을 제안하고 분석합니다.
- **Technical Details**: 연구진은 디코더 전용 아키텍처를 도입해 이산화된 토큰 대신 연속적인 음성 표현을 직접 처리하는 모델을 설계했습니다. 이 모델은 W2v-BERT 음성 인코더와 LLaMA-2 디코더를 기반으로 하며, 길이 어댑터를 통해 음성 표현의 길이를 줄이는 방식을 사용합니다. 또한 학습 시에는 멀티태스크 트레이닝을 통해 ASR 작업을 보조 과제로 포함하여 성능을 최적화합니다. LLM의 능력과 전이 학습을 결합해 S2TT 모델의 성능을 향상시키기 위해 다양한 분석을 수행했습니다.
- **Performance Highlights**: 제안된 모델은 CoVoST 2와 FLEURS 데이터셋에서 현존하는 최신 S2TT 모델보다 우수한 성능을 발휘하고 있으며, 독점 데이터를 사용하지 않고도 높은 성능을 달성했습니다. 특히, 연속적인 음성 표현을 사용함으로써 기존 방법보다 간편하게 더 좋은 성능을 보여주었습니다.

### [Eliminating Position Bias of Language Models: A Mechanistic Approach](https://arxiv.org/abs/2407.01100)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.01100.png)

Vote: 1

Authors: Kuan-Hao Huang, Ziqi Wang, Hao Peng, Shuiwang Ji, Heng Ji, Hanlin Zhang, Sham M. Kakade, Xiner Li, Chi Han

- **What's New**: 이 논문에서는 언어 모델(Language Models; LMs)에서 위치 편향(position bias)이 나타나는 원인을 분석하고 이를 제거하기 위한 새로운 접근법인 PINE(Position-invariant inference)을 제안합니다. 기존 LMs는 특정 위치의 콘텐츠를 선호하는 경향이 있어 복잡한 추론 능력과 긴 문맥 이해를 저해합니다.
- **Technical Details**: 논문은 최신 LMs의 주요 구성 요소인 Casual Attention과 Rotary Position Embedding(RoPE)에 위치 편향 문제의 원인이 있다고 주장합니다. Casual Attention은 정보가 일방향으로 전파되도록 하고, RoPE는 최근성 편향(recency bias)을 유발합니다. 이를 분석하기 위해 Retrieval-augmented QA 실험을 통해 Casual Attention과 RoPE의 위치 편향을 시각적으로 확인했습니다.
- **Performance Highlights**: PINE을 통해 위치 편향을 제거한 결과, LM이 두 답변 중 더 도움되는 답변을 선택하는 LM-as-a-judge 과제와, 검색된 문서를 기반으로 질문에 답하는 Retrieval-augmented QA 과제를 대상으로 성능 평가를 수행했습니다. PINE은 위치 편향을 제거하여 성능과 신뢰성을 향상시켰으며, 특히 LM-as-a-judge 과제에서 Llama-3-70B-Instruct 모델이 GPT-4-0125-preview 모델보다 우수한 성능을 보였습니다.

### [A False Sense of Safety: Unsafe Information Leakage in 'Safe' AI Responses](https://arxiv.org/abs/2407.02551)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02551.png)

Vote: 1

Authors: Vardan Papyan, Ilia Shumailov, David Glukhov, Nicolas Papernot, Ziwen Han

- **What's New**: 대규모 언어 모델(LLM)의 놀라운 잠재력에도 불구하고 오남용 가능성에 대한 염려가 커지고 있습니다. 주요 위협으로는 사회공학, 딥페이크 생성, 멀웨어(create malware) 및 화학, 생물학, 방사능 무기(Radiological weapons)의 생성 등이 포함됩니다. 이러한 위험에 대응하기 위해 다양한 완화 전략이 개발되었지만, 최근 연구에서는 현재의 안전성 방법들이 신뢰할 수 없음을 지적하고 있습니다.
- **Technical Details**: 이 논문에서는 정보 이론적 관점에서 inferential adversaries(추론적 적대자)를 정의합니다. 이는 피해 모델로부터 해로운 정보를 추출하려는 공격자를 의미하며, 이들의 상호작용을 통해 '허용되지 않은 정보 누출'의 위험을 평가합니다. 이를 위해 랜덤화된 응답 메커니즘(randomised response mechanism)을 제안하여 정보 검열 기준을 만족시키고자 합니다.
- **Performance Highlights**: 추론적 적대자에 대해 자동화된 사례 연구를 통해, 대규모 언어 모델에서 악의적인 쿼리를 해체하고 이를 무해한 하위 쿼리로 분해하는 접근법을 제시합니다. 몬테 카를로 트리 탐색(Monte Carlo Tree Search, MCTS)을 활용해 관련성 점수가 높은 상호작용을 식별하고 초기 증거를 통해 자동화된 inferential adversaries 구동이 가능함을 입증하였습니다.

