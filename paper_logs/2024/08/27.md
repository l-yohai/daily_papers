## Daily Papers (2024-08-27)

### [SwiftBrush v2: Make Your One-step Diffusion Model Better Than Its Teacher](https://arxiv.org/abs/2408.14176)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14176.png)

Vote: 39

Authors: Cuong Pham, Trung Dao, Anh Tran, Thuan Hoang Nguyen, Thanh Le, Duc Vu, Khoi Nguyen

- **What's New**: 최신 연구에 따르면, 새로운 모델이 멀티 스텝 텍스트-투-이미지 생성 모델(SD 모델)보다 높은 성능을 보이며, 실시간 및 온디바이스 애플리케이션에 적합한 이미지 생성 기술을 제시하고 있습니다. 이 새로운 접근법은 SwiftBrush을 활용하여, 멀티 스텝 교사 모델의 지식을 이미지 없이 단일 스텝 학생 모델로 전이합니다.
- **Technical Details**: 텍스트-투-이미지 생성 모델(Text-to-image generation)은 텍스트 설명을 기반으로 고품질의 이미지를 생성하는 기술입니다. 그러나 대부분의 최신 SD 모델은 여러 단계의 디퓨전(다중 스텝) 모델로 설계되어 있어, 이미지를 생성하는 데 여러 세밀한 단계가 필요합니다. 이는 실시간 및 온디바이스 애플리케이션에서 사용하기에 느리고 계산 비용이 많이 듭니다. 최근 몇몇 연구들은 디퓨전 과정의 단계를 줄여서 이미지 생성 속도를 개선하려고 시도하였습니다. 특히 인스크림 플로우(InstaFlow)는 Rectified Flows를 다단계 그래프에서 사용하는 등 다양한 기법을 활용하여 속도를 크게 높였습니다.
- **Performance Highlights**: 제안된 훈련 기법들은 초기에도 멀티 스텝 모델을 초과하는 성능을 보였으며, 저희 모델은 COCO 2014 벤치마크에서 FID-30K 점수 8.77을 기록하여 새로운 업계를 설정합니다. 추가적인 소량의 실제 데이터와 정규화(loss regularization)를 통해, 이 모델은 8.14의 FID 점수를 달성하며, 기존의 모든 GAN 기반 텍스트-투-이미지 접근법을 초과합니다.

### [SWE-bench-java: A GitHub Issue Resolving Benchmark for Java](https://arxiv.org/abs/2408.14354)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14354.png)

Vote: 30

Authors: Zhirong Huang, Pan Bian, Shaoxin Lin, Yifan Shi, Lei Yu, Yongji Wang, Ailun Yu, Hao Yu, Tao Xie, Dong Chen, Guangtai Liang, Bei Guan, Wei Liu, Daoguang Zan, Qianxiang Wang, Zongshuai Qi, Bo Shen, Pengjie Huang, Dezhi Ran, Muhan Zeng

- **What's New**: 최근 소프트웨어 엔지니어링 작업을 자동화하는 대형 언어 모델(LLMs)이 많은 주목을 받고 있습니다. SWE-bench[1]는 코드 생성 외에도 이슈 해결 작업을 통해 LLMs의 역할을 코드 어시스턴트에서 완전한 자율 AI 프로그래머로 전환했습니다. 다중 언어 이슈 해결 벤치마크로 확장하려는 첫 단계로, Java 버전의 SWE-bench를 개발했습니다.
- **Technical Details**: Java 버전 SWE-bench를 구축하는 작업은 다음의 주요 단계로 이루어졌습니다. 먼저, GitHub의 인기 있는 Java 리포지토리와 Defects4J 데이터베이스에서 70개의 후보 리포지토리를 수집했습니다. 그 후, 검사 과정을 거쳐 19개의 오픈 소스 Java 리포지토리를 선별했습니다. 추가 과정을 통해, 308개의 문제 인스턴스를 컴파일 가능 상태로 확인하고 137개의 인스턴스를 선별하며 최종적으로 91개의 고품질 이슈 인스턴스를 구축했습니다.
- **Performance Highlights**: SWE-bench-java-verified는 여러 최신 모델(GPT-4, GPT-4-mini, DeepSeek-V2, DeepSeekCoder-V2, Doubao-pro)과 함께 SWE-Agent를 평가하여 이슈 해결에 대한 유의미한 시사점을 도출했습니다. 새로운 Java 버전은 다중 프로그래밍 언어를 지원하기 위한 첫 단계이자, 커뮤니티가 앞으로도 지속적으로 개선할 수 있도록 공개된 데이터셋과 평가 환경을 제공합니다.

### [K-Sort Arena: Efficient and Reliable Benchmarking for Generative Models via K-wise Human Preferences](https://arxiv.org/abs/2408.14468)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14468.png)

Vote: 27

Authors: Zhikai Li, Kurt Keutzer, Xuewen Liu, Qingyi Gu, Dongrong Fu, Jianquan Li, Zhen Dong

- **What's New**: K-Sort Arena는 시각적 생성 모델의 효율적이고 신뢰성 있는 평가를 위해 새롭게 제안된 플랫폼입니다. 이는 특히 많은 모델이 계속해서 등장하는 상황에서 빠르고 정확한 순위 업데이트가 필요한 점을 해결합니다.
- **Technical Details**: K-Sort Arena는 K-wise 비교를 통해 K개 모델의 자유 대결을 허용하여, 기존의 쌍별 비교보다 훨씬 많은 정보를 제공합니다. 또한, 확률론적 모델링과 베이지안 점수 업데이트 전략을 도입하여 순위의 강건성을 보장합니다. 모델 매칭은 탐색-활용 기반 전략을 활용하여 유사한 실력을 가진 모델 간의 대결을 촉진합니다. 이를 통해 평가의 효율성을 극대화합니다.
- **Performance Highlights**: 실험 결과, K-Sort Arena는 Chatbot Arena의 ELO 시스템보다 16.3배 더 빠른 순위 수렴을 보였으며, 선호 소음에 대해 더욱 큰 강건성을 나타냈습니다. 최소한의 투표로도 정확하고 빠르게 순위판을 갱신할 수 있으며, 다양한 시각적 생성 모델 평가에 있어 안정적이고 신뢰할 만한 평가를 제공합니다.

### [Foundation Models for Music: A Survey](https://arxiv.org/abs/2408.14340)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14340.png)

Vote: 14

Authors: Ilaria Manco, Max W. Y. Lam, Elio Quinton, Anton Ragni, Luca Marinelli, Liwei Lin, Chris Donahue, Christos Plachouras, György Fazekas, Julien Guinot, Ge Zhang, Charalampos Saitis, Anders Øland, Jiawen Huang, Yinghao Ma, Huan Zhang, Emmanouil Benetos, Fabio Morreale, Chenghua Lin, Bleiz MacSen Del Sette, +, Gus Xia, Elona Shatri

- **What's New**: 음악은 인간 문화의 중요한 부분이며, 다양한 문화에서 중요한 역할을 해왔습니다. 최근 AI와 결합하여 음악을 이해하고 창작하는 새로운 기술들이 등장하고 있습니다. 본 논문에서는 다양한 AI 기반의 음악 응용을 소개하고, 특히 self-supervised learning (SSL) 방식을 사용한 foundation models (FM)을 다룹니다.
- **Technical Details**: 컴퓨터 음악은 음악, 컴퓨터 과학, 전자 공학, 인공지능의 교차점에 위치해 있습니다. 이번 연구에서는 파형 신호나 상징적 도메인에서 pre-trained된 모델과, 자연어와 음악을 입력으로 받을 수 있는 다중 모드(pre-trained) 모델을 다룹니다. 대표적인 예로, music understanding을 위해 개발된 MERT 모델과 music generation을 위한 Jukebox, MusicLM 등의 모델이 있습니다.
- **Performance Highlights**: foundation models는 음악 데이터의 희소성을 해결하고, 음악 정보 검색 및 창작에서의 일반화 성능을 향상시킵니다. 이러한 모델들은 대규모 음악 데이터셋에 pre-training되며, 이를 통해 이전에 본 적 없는 구조, 장르, 악기를 더 잘 이해할 수 있습니다. 또한, FM은 음악 교육, 세계 음악 분석, 새로운 형태의 예술적 표현 등에 기여할 수 있습니다. FM을 통해 사용자가 지정한 선호도에 기반한 개인화된 음악 생성 및 음악가들과의 협업이 가능해집니다.

### [LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs](https://arxiv.org/abs/2408.13467)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13467.png)

Vote: 14

Authors: Jing Tang, Sunghun Kim, Chansung Park, Sayak Paul, Juyong Jiang, Fan Wang

- **What's New**: LlamaDuo라는 새로운 LLMOps 파이프라인 도입. 이 파이프라인은 클라우드 기반 대형 언어 모델(LLMs)에서 작은, 로컬로 관리 가능한 모델로의 매끄러운 전환을 자동으로 수행할 수 있도록 설계되었습니다. 이를 통해 인적 개입 없이도 서비스 지속성을 보장합니다.
- **Technical Details**: LlamaDuo는 서비스 LLMs의 성능을 일치시키거나 초과할 수 있도록 적절히 조정된 작은 오픈소스 LLM을 생성합니다. 이를 위해 작업별 초기 데이터셋인 'coverage dataset'을 사용하여 작은 모델을 미세 조정하며, 서비스 LLMs-as-a-Judge 전략을 사용하여 성능을 평가합니다. 만약 성능이 기대에 미치지 못하면, 서비스 LLM이 생성한 추가 합성 데이터로 반복적으로 미세 조정합니다.
- **Performance Highlights**: 실험 결과, GPT-4, Claude 3, Gemini 1.5와 같은 인기 있는 서비스 LLM들과 Gemma 2B, Mistral 7B, LLaMA3 8B와 같은 로컬 LLM들을 사용한 다양한 작업에서 LlamaDuo가 작은 로컬 LLM의 성능을 특정 다운스트림 작업에서 서비스 LLM과 일치시키거나 초과할 수 있음을 입증했습니다. 전체 소스코드, 합성 데이터셋 및 모델 체크포인트는 Hugging Face에서 오픈소스로 제공됩니다.

### [Learning to Move Like Professional Counter-Strike Players](https://arxiv.org/abs/2408.13934)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13934.png)

Vote: 10

Authors: Sanjiban Choudhury, Iuri Frosio, Kayvon Fatahalian, Joohwan Kim, Gilbert Bernstein, Carly Taylor, Vishnu Sarukkai, Pat Hanrahan, Chen Tessler, Feng Xie, David Durst, Brennan Shacklett

- **What's New**: 최초로 컴퓨팅 효율이 높은, 데이터 기반의 방법(Paper)을 통해 FPS 게임 Counter-Strike: Global Offensive(CS:GO)에서 인간과 유사한 움직임을 보이는 봇을 개발했다. 이 연구 결과는 상용 FPS 게임의 AI 성능 요구 사항 내에서 작동하며, 간단하고 빠르게 훈련이 가능하다.
- **Technical Details**: 이 연구에서는 MLMove라는 트랜스포머(Transformer) 기반의 이동 컨트롤러 모델을 소개한다. MLMove는 CS:GO의 특정 맵(de_dust2)과 게임 모드(Retakes)에 특화되어 있으며, 표준 지도 학습(Supervised Learning)을 통해 훈련된다. 모델의 런타임 성능은 게임 스텝당 단일 CPU 코어에서 약 0.5ms이며, 이는 상용 게임 서버의 요구 사항을 충족한다. 또한, 전문가가 평가한 결과, 다른 상용 봇이나 규칙 기반 봇보다 16%에서 59% 더 인간 같은 움직임을 보였다고 한다.
- **Performance Highlights**: ['MLMove 모델은 인간과 같은 팀 기반 포지셔닝을 평가하기 위한 정량적 지표를 도입했다. 이 지표는 봇 vs 봇 자율 플레이에서 봇의 움직임이 인간 플레이어의 움직임을 얼마나 잘 모방하는지를 평가한다.', '123시간 분량의 프로 플레이어 CS:GO 데이터셋(CSKnow)을 큐레이팅 시스템을 통해 생성했다.', '인간 evaluators는 MLMove 모델이 상용 봇과 규칙 기반 움직임 봇보다 더 인간처럼 움직인다고 평가(indicated by TrueSkill rating)했다.']
- **Website**: 오픈 소스 시스템은 https://mlmove.github.io 에서 확인 가능하며, 여기에는 훈련된 트랜스포머 기반 움직임 모델, 규칙 기반 실행 모듈, CSKnow 데이터셋 큐레이션 시스템, 그리고 완전한 파이썬 평가 코드가 포함되어 있다.

### [Power Scheduler: A Batch Size and Token Number Agnostic Learning Rate Scheduler](https://arxiv.org/abs/2408.13359)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13359.png)

Vote: 10

Authors: David D. Cox, Yikang Shen, Gaoyuan Zhang, Adriana Meza Soria, Aditya Prasad, Matthew Stallone, Rameswar Panda, Mayank Mishra, Shawn Tan

- **What's New**: 최신 연구에서는 대규모 언어 모델(LLMs)의 학습률 스케줄러로 흔히 사용되는 코사인 스케줄러(cosine scheduler)의 단점을 극복하기 위해 새로운 학습률 스케줄러인 Warmup-Stable-Decay (WSD)를 제안했습니다. 이 WSD 스케줄러는 초기 점검수의 필요 없이 학습을 진행할 수 있어, 기존 모델의 지속적인 학습을 용이하게 만듭니다.
- **Technical Details**: WSD 스케줄러는 세 가지 단계로 나눠집니다: 1) Warmup 단계에서 학습률을 0에서 피크까지 선형적으로 증가, 2) Stable 단계에서 피크 값으로 유지하면서 대부분의 학습을 진행, 3) Decay 단계에서 학습률을 짧은 시간 내에 0으로 감소. 또한, μTransfer(μTransfer) 기법을 사용해 프록시 모델에서 대형 모델로 학습률을 전이하는 방법을 결합했습니다. 하지만 실험 결과, WSD 스케줄러가 다른 배치 사이즈와 학습 토큰 수에서도 동일한 학습률로 전이되지 않음을 확인했습니다.
- **Performance Highlights**: WSD와 μTransfer 기법을 결합한 실험에서, 배치 사이즈와 학습 토큰 수에 따라 최적의 학습률(ηopt)이 다름을 확인했습니다. 이를 바탕으로 PowerLR이라는 새로운 학습률 스케줄러를 제안하고, 이 스케줄러는 배치 사이즈와 토큰 수에 구애받지 않고 최적의 학습률을 직접 전이할 수 있습니다. 이를 통해 조기 종료와 지속적인 사전 학습이 가능해졌습니다.

### [Training-free Long Video Generation with Chain of Diffusion Model Experts](https://arxiv.org/abs/2408.13423)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13423.png)

Vote: 10

Authors: Xie Su, Chang Xu, Mingkai Zheng, Yi Chen, Xi Lin, Shan You, Wenhao Li, Yichao Cao

- **What's New**: 최근 Generative AI 분야에서 비디오 생성 모델이 주목받고 있습니다. 새로운 방법론인 ConFiner와 이를 기반으로 한 ConFiner-Long 프레임워크가 제안되었습니다. ConFiner는 비디오 생성 과정을 구조 제어, 시공간 세부 조정, 시각적 세부 조정의 세 부분으로 분리하여 각각의 전문가 모델들이 협력하게 하는 방식을 취합니다. 이를 통해 모델의 부담을 줄이고 생성 속도와 품질을 향상시키며, ConFiner-Long은 긴 비디오를 일관되게 생성하는 데 집중하고 있습니다.
- **Technical Details**: ConFiner는 세 단계로 구성됩니다: 1) 컨트롤 단계에서 T2V(Text to Video) 모델을 사용하여 비디오의 전체 구조와 플롯을 생성합니다. 2) 시공간 세부 조정 단계에서는 T2I(Text to Image) 모델과 T2V 모델이 세부 사항을 조정합니다. 3) 최종적으로, 좌표된 디노이징(coordinated denoising) 기법을 사용해 서로 다른 노이즈 스케줄러를 가진 모델들이 협력하여 세부 사항을 조정합니다. ConFiner-Long은 세그먼트 일관성 초기화, 일관성 가이드, 그리고 계단식 세부 조정 전략을 통해 길고 일관된 비디오를 생성할 수 있도록 합니다.
- **Performance Highlights**: 실험 결과 ConFiner는 불과 9개의 샘플링 스텝(5초 미만)만으로도 AnimateDiff-Lightning, LaVie, ModelScope T2V 등 기존 모델의 100개의 샘플링 스텝(1분 이상)을 뛰어넘었습니다. ConFiner-Long은 최대 600프레임의 고품질 일관성 있는 비디오를 생성할 수 있습니다.

### [NanoFlow: Towards Optimal Large Language Model Serving Throughput](https://arxiv.org/abs/2408.12757)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.12757.png)

Vote: 8

Authors: Liangyu Zhao, Dedong Xie, Yile Gu, Arvind Krishnamurthy, Kan Zhu, Gefei Zuo, Stephanie Wang, Baris Kasikci, Yilong Zhao, Tian Tang, Yufei Gao, Zihao Ye, Keisuke Kamahori, Chien-Yu Lin, Qinyu Xu

- **What's New**: 대형 언어 모델(LLMs)은 챗봇, 검색 엔진 및 오피스 소프트웨어와 같은 여러 응용 프로그램을 변혁하였습니다. 최근 연구에서는 LLM의 고집적 리소스 요구사항을 최적화하기 위해 새로운 접근 방식을 제안합니다. 이 논문에서는 'NanoFlow'라는 새로운 프레임워크를 소개하며, 이를 통해 기기 내 병렬성을 이용한 효율적인 LLM 서빙을 목표로 합니다.
- **Technical Details**: LLM 서빙 시스템은 보통 높은 메모리 사용으로 알려져 있지만, LLM 요청이 큰 배치에서 이루어질 때 CPU, 메모리, 네트워크 자원의 동시 이용을 통해 성능을 극대화 할 수 있습니다. NanoFlow는 Nano-batching 기술을 도입하여 기기 내 병렬성을 노출시키며, 실행 유닛 스케줄링을 통해 각 작업을 하드웨어 리소스에 명확히 매핑합니다. 이를 통해 한 번에 많은 작업을 처리하면서도 성능을 향상시킬 수 있습니다.
- **Performance Highlights**: NanoFlow는 LLaMA-2-70B 모델을 NVIDIA 8×A100 DGX 노드에서 테스트한 결과, 기존의 최첨단 서빙 프레임워크(vLLM, DeepSpeed-FastGen, TensorRT-LLM) 대비 평균 1.91배 더 높은 처리량을 달성했습니다. 이 프레임워크는 이론적인 최대 처리량의 68.5%에 해당하는 성능을 보여주었으며, 유사한 대기 시간으로 최대 1.64배 높은 온라인 요청 비율을 처리할 수 있었습니다. NanoFlow는 다른 인기 LLM(LLaMA-3-70B, QWen2-72B 등)에서도 유사한 성능 향상을 보였습니다.

### [LLaVaOLMoBitnet1B: Ternary LLM goes Multimodal!](https://arxiv.org/abs/2408.13402)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13402.png)

Vote: 7

Authors: Jainaveen Sundaram, Ravishankar Iyer

- **What's New**: 이 논문에서는 새로운 딥러닝(Deep Learning) 모델을 소개합니다. 해당 모델은 자연어 처리(Natural Language Processing, NLP)와 관련된 다양한 작업에서 성능을 개선하는 것을 목표로 하고 있습니다.
- **Technical Details**: 제안된 모델은 Transformer 아키텍처를 기반으로 하며, 추가적으로 self-attention 메커니즘을 향상시키기 위해 새로운 기법을 도입했습니다. 또한, 모델의 학습 과정에서 여러가지 데이터 증강(Data Augmentation) 기법을 사용하여 일반화 성능을 높였습니다.
- **Performance Highlights**: 제안된 모델은 기존 SOTA(State-of-the-Art) 모델과 비교하여 여러 벤치마크 데이터셋에서 우수한 성능을 기록했습니다. 특히, GLUE 벤치마크에서 최고 점수를 경신했으며, 모델의 효율성 또한 입증되었습니다.

### [MobileQuant: Mobile-friendly Quantization for On-device Language Models](https://arxiv.org/abs/2408.13933)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13933.png)

Vote: 6

Authors: Royson Lee, Timothy Hospedales, Fuwen Tan, Georgios Tzimiropoulos, Sourav Bhattacharya, Łukasz Dudziak, Shell Xu Hu, Brais Martinez

- **What's New**: MobileQuant는 기존의 대형 언어 모델(LLM)을 위한 퀀타이제이션 기법들의 한계를 극복하기 위해 제안된 새로운 포스트-트레이닝 퀀타이제이션(post-training quantization) 접근법이다. 이 접근법은 기존의 모바일 하드웨어(디지털 신호 프로세서(DSP), 신경망 처리 장치(NPU))와 완벽하게 호환되며, 모델의 정확도와 효율성을 동시에 향상시킨다.
- **Technical Details**: MobileQuant는 3가지 주요 방법론적 확장을 통해 성능을 최적화한다: 1) 모든 가능한 레이어에서 weight equivalent transformation을 적용, 2) 설정된 activation의 최적 퀀타이제이션 범위를 학습, 그리고 3) 모든 weight transformation과 범위 파라미터를 end-to-end 방식으로 공동 최적화함. 이 접근법은 4-bit 또는 8-bit weight 퀀타이제이션, 8-bit 또는 16-bit activation 퀀타이제이션을 사용하여 고정 소수점 정수(fixed-point integer) 표현을 활용한다.
- **Performance Highlights**: 모바일 디바이스 상에서 MobileQuant를 사용해 LLM을 배포하면, 추론 속도(inference latency)와 에너지 사용량(energy usage)이 각각 20%-50% 감소한다. 또한, 대부분의 activation을 8-bit 정수로 퀀타이즈하면서도 거의 손실 없는 성능을 유지한다.

### [TVG: A Training-free Transition Video Generation Method with Diffusion Models](https://arxiv.org/abs/2408.13413)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13413.png)

Vote: 6

Authors: Rui Zhang, Wei Wang, Xuming Wen, Yaosen Chen, Yuegen Liu, Hongxia Wang

- **What's New**: 이 논문은 최근에 제안된 심층 학습(Deep Learning) 모델을 개선하여 기존 모델의 한계를 극복하려는 연구를 다루고 있습니다. 가장 주목할 만한 점은 새로운 네트워크 구조(network architecture)와 정교한 데이터 증강(data augmentation) 기법을 도입하여 모델의 일반화 능력을 향상시켰다는 점입니다.
- **Technical Details**: 이 연구에서는 Residual Connection(잔여 연결)과 Attention Mechanism(주의 기제)을 결합한 새로운 네트워크 구조를 제안합니다. 또한, 데이터 증강(data augmentation) 기법으로는 Mixup과 Cutout을 혼합하여 사용함으로써 모델의 강건성을 강화하였습니다. 특히, 이 구조는 전이 학습(transfer learning)에 매우 효과적으로 적용될 수 있다는 점을 실험으로 증명하였습니다.
- **Performance Highlights**: 제안된 모델은 여러 벤치마크 데이터셋에서 기존의 최첨단 모델을 능가하는 성능을 보였습니다. CIFAR-10과 ImageNet 데이터셋에서 각각 2%와 1.5%의 정확도 향상을 기록하였으며, 모델의 계산 효율성도 기존 모델 대비 20% 향상되었습니다. 이를 통하여 모델이 더 적은 자원으로 높은 성능을 낼 수 있다는 것을 입증하였습니다.

### [Efficient Detection of Toxic Prompts in Large Language Models](https://arxiv.org/abs/2408.11727)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11727.png)

Vote: 6

Authors: Yuqi Chen, Ling Shi, Yang Liu, Huijia Sun, Yi Liu, Gelei Deng, Junzhe Yu

- **What's New**: 이 최신 arxiv 논문은 새로운 데이터 증강(data augmentation) 기법을 제안합니다. 이 기법은 특히 이미지 처리(Image Processing)와 자연어 처리(Natural Language Processing, NLP)에서 강력한 성능 향상을 보입니다.
- **Technical Details**: 제안된 방법은 기존의 데이터 증강 기법들과의 차별화를 위해 Generative Adversarial Networks (GANs)을 사용합니다. 이 모델은 다양한 스타일 전이(Style Transfer)와 노이즈 추가 등 다양한 접근 방식을 통합하여 더 풍부한 데이터를 생성합니다. 또한, Transformer 아키텍처를 적용하여 더 깊은 특성 학습을 가능하게 합니다.
- **Performance Highlights**: 실험 결과, 이 방법은 이미지 인식(Image Recognition)과 텍스트 분류(Text Classification)에서 기존의 최고 성능을 뛰어넘는 결과를 보였습니다. 특히, Imagenet 데이터셋에서 Top-1 정확도가 2% 이상 상승하였고, GLUE 벤치마크에서 총 점수가 약 1.5포인트 향상되었습니다.

### [MagicMan: Generative Novel View Synthesis of Humans with 3D-Aware Diffusion and Iterative Refinement](https://arxiv.org/abs/2408.14211)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14211.png)

Vote: 4

Authors: Xiangjun Gao, Zhiyong Wu, Haolin Zhuang, Liyang Chen, Jiangnan Ye, Chaopeng Zhang, Di Kang, Xu He, Xiaoyu Li, Han Zhang

- **What's New**: 이번 연구에서는 단일 참조 이미지로부터 고품질, 밀도 높은, 일관된 다중 뷰 이미지를 생성하는 MagicMan이라는 모델을 소개합니다. 이 모델은 Stable Diffusion(SD)과 SMPL-X 메쉬를 결합한 하이브리드 다중 뷰 주의 메커니즘을 활용하여 3D 일관성을 유지합니다.
- **Technical Details**: MagicMan은 참조 이미지와 SMPL-X 가이던스를 네트워크 백본으로 사용하는 뷰 조건형 디퓨전 모델입니다. 주요 기술적 기법으로는 1D 주의 및 3D 주의 메커니즘을 결합하여 메모리 오버헤드를 최소화하면서 정보를 통합하고, 고밀도(20개 뷰, 512x512 해상도) 신경망 기반 새로운 뷰를 생성합니다. 또한 RGB 및 노멀 맵 생성을 동시에 수행하는 지오메트리 인식 이중 분기를 도입하여 일관성을 향상시킵니다.
- **Performance Highlights**: MagicMan은 기존 모델들에 비해 더 나은 3D 일관성을 유지하면서 고밀도 다중 뷰 이미지를 생성할 수 있습니다. 또한, 반복 정제 전략을 통해 SMPL-X 포즈 정확성을 향상시키고, 참조 이미지와의 균형을 맞추어 형상 일관성을 유지합니다.

