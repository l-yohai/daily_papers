## Daily Papers (2024-08-28)

### [Writing in the Margins: Better Inference Pattern for Long Context Retrieval](https://arxiv.org/abs/2408.14906)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14906.png)

Vote: 100

Authors: Axel Magnuson, Umar Jamil, Waseem AlShikh, Kiran Kamble, Melisa Russak, Mateusz Russak, Christopher Bryant

- **What's New**: 이번 연구에서는 인공지능과 관련된 최신 논문을 통해 새로운 기법을 제시하였습니다. 특히, Transformer-based(GPT)을 이용한 텍스트 생성 모델(Text Generation Model)에서의 혁신적인 접근법을 소개하였습니다.
- **Technical Details**: 본 논문에서는 주로 Transformer 모델의 성능을 향상시키기 위해 Multi-Head Attention과 Positional Encoding을 개선하는 방안을 다루었습니다. 또한, 데이터 전처리(Data Preprocessing)와 모델 튜닝(Model Tuning)에 관한 구체적인 방법론도 자세히 설명하고 있습니다.
- **Performance Highlights**: 제안된 방법론을 적용한 결과, 기존의 Transformer 모델 대비 텍스트 생성의 정확도(Accuracy)와 속도(Speed)에서 크게 향상된 성능을 보였습니다. 특히, 다양한 벤치마크(Benchmark) 테스트에서 최고 성적을 기록하며 그 우수성을 입증했습니다.

### [Diffusion Models Are Real-Time Game Engines](https://arxiv.org/abs/2408.14837)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14837.png)

Vote: 74

Authors: Dani Valevski, Yaniv Leviathan, Shlomi Fruchter, Moab Arar

- **What's New**: 최근 몇 년 간, 생성 모델(generative models)은 멀티모달 입력(ex. 텍스트, 이미지)에 조건부로 이미지와 비디오를 생성하는데 큰 성과를 이루었습니다. 특히 확산 모델(diffusion models)이 미디어 생성의 표준이 되어가고 있습니다. 이 연구에서는 그와 같은 생성 모델을 활용해, 복잡한 비디오 게임인 DOOM을 실시간으로 뉴럴 네트워크 상에서 실행할 수 있음을 시연합니다. 이는 게임 엔진의 새로운 패러다임을 제시하며, 게임을 자동으로 생성하는 시대가 올 수 있음을 보여줍니다.
- **Technical Details**: 이 연구에서 보여주는 시스템은 기존의 오픈 Stable Diffusion v1.4 모델을 확장해, 실시간으로 고품질의 비디오 게임인 DOOM을 실행합니다. 인터랙티브 환경 모의(interactive world simulation)를 위해 다양한 상태 공간(𝒮), 관찰 공간(𝒪), 행동 집합(𝒜), 전이 확률 함수(p)와 같은 수식을 정의합니다. 해당 모델은 플레이어의 입력(actions)에 따른 게임 상태 업데이트를 신속하고 안정적으로 수행하며, 지속적인 게임 상태 보존이 가능합니다.
- **Performance Highlights**: 이 시스템은 DOOM과 같은 복잡한 게임을 실시간으로 실행하며, 원래 게임과 유사한 시각적 품질을 달성합니다. 또한, 건강 상태 및 탄약 수 계산, 적 공격, 물체 손상, 문 열기 등 복잡한 게임 상태 업데이트도 가능합니다.

### [The Mamba in the Llama: Distilling and Accelerating Hybrid Models](https://arxiv.org/abs/2408.15237)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.15237.png)

Vote: 20

Authors: Tri Dao, Junxiong Wang, Alexander M. Rush, Avner May, Daniele Paliotta

- **What's New**: 최근 연구는 대형 언어 모델에서 Transformer의 고착 상태를 해결하고자 Linear RNN (Mamba, Mamba2 등) 모델들이 등장했습니다. 이러한 모델들은 Transformer에 비해 훨씬 빠른 추론 속도를 제공하며, 특히 긴 시퀀스 생성 작업에서 유리합니다. 새로운 접근 방식으로는 큰 규모의 사전 학습된 Transformer 모델을 Linear RNN으로 증류(distillation)하는 기술이 지원됩니다.
- **Technical Details**: 이 논문에서는 Transformer의 Attention 레이어의 가중치를 사용하는 방법으로 Linear RNN을 초기화하고, 점진적 증류, 지도학습(fine-tuning), 선호 최적화(preference optimization)를 결합한 다단계 증류 접근 방식을 제안합니다. 이를 통해 사전 학습된 모델과 유사한 참조 값을 유지하는 Hybrid Mamba 구조를 개발합니다. 핵심 기술로는 연속 시간 상태 공간 모델(SSM)을 통해 동작하는 Mamba 아키텍처를 사용하여 모델의 용량을 확장합니다.
- **Performance Highlights**: 우리는 Zephyr-7B와 Llama-3 8B와 같은 다양한 대규모 오픈챗 LLM을 Linear RNN 모델로 증류했습니다. 그 결과, 증류된 모델은 표준 Chat 벤치마크에서 교사 모델과 유사한 성능을 보여주었습니다. 또한 MMLU, TruthfulQA 등의 평가에서 기존의 Mamba 7B 모델과 비교하여 더 나은 결과를 나타냈습니다. 전체적으로 하드웨어 인식적 추측 샘플링 알고리즘과 결합하여 300 tokens/second 이상의 처리 속도(throughput)를 달성했습니다.

### [Generative Inbetweening: Adapting Image-to-Video Models for Keyframe Interpolation](https://arxiv.org/abs/2408.15239)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.15239.png)

Vote: 13

Authors: Aleksander Holynski, Boyang Zhou, Ira Kemelmacher-Shlizerman, Brian Curless, Steven M. Seitz, Xiaojuan Wang

- **What's New**: 최근 서드파티(Open source)의 대규모 텍스트-비디오 및 이미지-비디오 모델들이 높은 해상도의 동적 비디오를 생성하는 능력을 보여주었음에도 불구하고, 대부분의 모델이 키프레임 보간(Keyframe Interpolation)에 적합하지 않았습니다. 본 논문에서는 기존 이미지-비디오 모델을 활용하여 키프레임 보간을 가능하게 하는 새로운 접근 방식을 제안합니다. 이 방법은 퍼워드 및 백워드 모션 예측을 결합하여 일관성 있는 비디오를 생성합니다.
- **Technical Details**: 기존의 이미지-to 비디오 모델을 사용하여 키프레임 보간을 달성하기 위해 새로운 라이트웨이트 세부 조정 메커니즘을 제안하였습니다. 이는 시간적 자기 주의 맵(Temporal Self-Attention Maps)의 회전을 통해 시간의 화살표를 반전시키는 방식으로 구현됩니다. 또한, 퍼워드 및 백워드 모션 예측을 동기화시키는 샘플링 메커니즘을 제안하였습니다. 이는 중간 노이즈 예측을 융합하여 제공된 프레임으로 시작하고 끝나는 일관된 비디오를 생성합니다.
- **Performance Highlights**: 제안된 방법을 기존 키프레임 보간 관련 방법들과 정성적 및 정량적으로 비교한 결과, 우리 방법이 주어진 시간적으로 먼 키프레임에서 보다 일관된 동적 모션을 갖춘 고품질 비디오를 생성함을 보였습니다. 자세한 비디오 결과는 svd-keyframe-interpolation.github.io에서 확인할 수 있습니다.

### [GenCA: A Text-conditioned Generative Model for Realistic and Drivable Codec Avatars](https://arxiv.org/abs/2408.13674)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13674.png)

Vote: 13

Authors: Amin Jourabloo, Yu Rong, Jiu Xu, Zhengyu Yang, Sam Johnson, Moustafa Meshry, Hongsheng Li, Thu Nguyen-Phuoc, Sofien Bouaziz, Riddhish Bhalodia, Keqiang Sun, Christian Haene

- **What's New**: 최신 연구 활동으로 소개된 GenCA(Generative Codec Avatars)는 텍스트 설명만으로 운전 가능한(drivable) 3D 아바타를 생성하는 두 단계 프레임워크입니다. 이 프레임워크는 새로운 텍스트 기반 아바타 생성 접근방식을 통해 VR 및 MR에서 높은 정확도를 갖춘 아바타 생성을 가능하게 합니다.
- **Technical Details**: 연구는 두 단계로 이루어집니다. 첫 번째 단계는 Codec Avatar Auto-Encoder(CAAE)를 도입하여 3D 인간 캡처 데이터셋에서 기하학과 텍스처 잠재 공간을 학습합니다. 이 잠재 공간들은 아바타의 신원 분포를 모델링하고, Universal Prior Model(UPM)로부터의 표현(Expression) 잠재 공간과 결합하여 신원별 표현이 가능한 고품질 렌더링을 구현합니다. 두 번째 단계에서는 Identity Generation Model을 제시합니다. 여기서 Geometry Generation 모듈은 입력 텍스트 프롬프트를 기반으로 중립 기하학 코드를 생성하며, Geometry Conditioned Texture Generation 모듈은 기하학과 텍스트 모두를 조건으로 하여 중립 텍스처를 생성합니다.
- **Performance Highlights**: GenCA는 이전의 기술보다 눈, 혀와 같은 세밀한 부분까지 표현할 수 있으며, 단 한 장의 이미지로부터도 아바타를 복원할 수 있는 능력을 보여줍니다. 또한, 생성된 아바타의 운전 능력을 크게 개선하여 다양한 표정을 반영할 수 있으며, 훈련 데이터 너머의 아바타 편집 결과를 시연하였습니다.

### [Build-A-Scene: Interactive 3D Layout Control for Diffusion-Based Image Generation](https://arxiv.org/abs/2408.14819)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14819.png)

Vote: 12

Authors: Peter Wonka, Abdelrahman Eldesokey

- **What's New**: 최신 딥러닝 연구에서 소개된 새로운 접근법, Build-A-Scene,은 Text-to-Image(T2I) 확산 모델을 이용하여 3D 레이아웃 제어를 위한 인터랙티브한 방식으로 이미지를 생성할 수 있게 합니다. 이 방법은 기존의 2D 레이아웃 접근법의 한계를 극복하고, 사용자가 3D 공간에서 객체를 배치하고 회전시키며, 이를 실시간으로 반영할 수 있도록 돕습니다. 
- **Technical Details**: Build-A-Scene은 기존의 깊이 조건 모델(LossControl, LC)을 확장하여 2D 경계 상자를 3D 상자로 교체하는 방식으로 수행됩니다. 또한, Dynamic Self-Attention (DSA) 기술을 도입하여 객체를 추가할 때 기존 내용을 유지하면서 이미지를 생성할 수 있습니다. 이 외에도 일관된 3D 변환을 위한 전략을 도입하여 레이아웃 변경 시 객체의 신원을 보호합니다. 
- **Performance Highlights**: 실험 결과, Build-A-Scene은 복잡한 이미지를 생성하는 데 있어 LC를 2배 이상 능가하며, 객체 생성 성공률에서 Layout-Guidance보다 약 15% 더 높은 성능을 보였습니다. 또한, 레이아웃 변경 시 객체 유지 면에서도 Layout-Guidance와 LC 모두를 능가하는 성능을 나타냈습니다.

### [Text2SQL is Not Enough: Unifying AI and Databases with TAG](https://arxiv.org/abs/2408.14717)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14717.png)

Vote: 10

Authors: Liana Patel, Asim Biswal, Matei Zaharia, Joseph E. Gonzalez, Siddarth Jha, Amog Kamsetty, Carlos Guestrin, Shu Liu

- **What's New**: 새로운 테이블-증강 생성 모델(TAG)을 제안합니다. TAG 모델은 사용자 자연어 질문에 응답함에 있어 자연어 처리 모델(LM)과 데이터베이스 시스템의 논리적 추론 능력을 통합하여 이전의 Text2SQL 및 Retrieval-Augmented Generation(RAG) 방법론의 한계를 극복하고자 합니다.
- **Technical Details**: TAG 모델은 세 가지 주요 단계를 거칩니다: 쿼리 생성(query synthesis), 쿼리 실행(query execution), 및 응답 생성(answer generation). 쿼리 생성 단계에서는 사용자의 자연어 요청을 데이터베이스 시스템에서 실행 가능한 쿼리로 번역합니다. 쿼리 실행 단계에서는 해당 쿼리를 실행하여 관련 데이터를 얻습니다. 마지막으로, 응답 생성 단계에서는 얻은 데이터를 이용해 모델이 최종 자연 언어 응답을 생성합니다.
- **Performance Highlights**: 기본 Text2SQL 및 RAG 모델과 비교한 TAG 모델의 성능은 매우 우수합니다. 기본 방법론들이 다양한 쿼리 유형에서 20%의 정확도를 넘지 못하는 반면, TAG 파이프라인은 최대 65% 높은 정확도를 달성했습니다. 이는 TAG 시스템 구현의 가능성을 시사합니다.

### [Platypus: A Generalized Specialist Model for Reading Text in Various Forms](https://arxiv.org/abs/2408.14805)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14805.png)

Vote: 6

Authors: Zhaohai Li, Fei Huang, Zhibo Yang, Cong Yao, Jun Tang, Peng Wang, Humen Zhong

- **What's New**: 이 논문은 'Platypus'라는 새로운 일반화된 전문 텍스트 읽기 모델을 소개합니다. 기존의 Optical Character Recognition(OCR) 시스템의 한계를 극복하고, 다양한 텍스트 읽기 시나리오에 대응할 수 있는 통합 솔루션을 제공합니다.
- **Technical Details**: Platypus 모델은 인코더-디코더(encoder-decoder) 프레임워크로 구성되어 있습니다. 이미지 인코더(Image Encoder)는 Swin-B Transformer를 사용하여 다양한 스케일과 해상도의 비주얼 피처를 추출합니다. 프롬프트 인코더(Prompt Encoder)는 다양한 프롬프트를 인코딩하여 모델에게 작업 범주, 글쓰기 유형, 출력 세분도 등을 알려줍니다. 인식 디코더(Recognition Decoder)는 텍스트 시퀀스를 생성하여 최종 텍스트 인식 결과를 도출합니다.
- **Performance Highlights**: Platypus는 여러 텍스트 읽기 시나리오에서 전문화된 모델과 멀티모달 대형 언어 모델(Multi-modal Large Language Models, MLLMs)을 뛰어넘는 성능을 보여줍니다. 다양한 실험을 통해 Platypus 모델의 우수한 정확도와 적응성을 입증했습니다.

### [LLM-3D Print: Large Language Models To Monitor and Control 3D Printing](https://arxiv.org/abs/2408.14307)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14307.png)

Vote: 1

Authors: Yayati Jadhav, Peter Pak, Amir Barati Farimani

- **What's New**: 새로운 연구는 Fused Deposition Modeling (FDM) 기반의 적층 제조(Additive Manufacturing, AM)에서 발생하는 오류를 실시간으로 감지하고 수정하기 위해 딥러닝(Deep Learning)과 카메라 기반 모니터링 시스템을 결합하는 접근 방식을 제시합니다. 특히, 영상 기반 폐루프(closed-loop) 품질 관리 시스템을 통해 다양한 부품, 재료 및 프린터 시스템에 걸쳐 오류를 발견하고 이론값을 최적화하는 머신러닝(Machine Learning) 기술을 활용합니다.
- **Technical Details**: FDM은 열가소성 필라멘트를 가열된 노즐을 통해 층별로 출력하는 방식이며, 일반적으로 부품 제어 파라미터를 최적화하기 위한 시뮬레이션은 비용이 많이 들고 비효율적입니다. 연구자들은 여기서 카메라 기반 모니터링을 통해 오류 감지에 머신러닝, 특히 컨벌루션 신경망(Convolutional Neural Networks, CNN)을 활용하여 출력 비율, 변형, 표면 결함 및 층 결함을 예측하고 수정합니다. 변환기 아키텍처(transformer architecture)와 대규모 데이터셋을 활용하는 방법도 논의되며, LLM(Large Language Models)과 같은 최신 모델이 높은 일반화 능력을 보였습니다.
- **Performance Highlights**: 최근 연구는 FDM에서 20% 이상의 프린트 오류율을 보였으며, ABS 출력에서는 재료 손실율이 34%에 달하는 등 다양한 오류가 발생함을 나타냈습니다. 머신러닝 모델은 버전 비교를 필요로 하는 작업에서 제한적인 성능을 보였으나, 지리적으로 다른 형태의 부품 출력에서도 오류를 줄이고 효율성을 향상시키는 새로운 방법을 제시합니다. LLM 기반의 접근 방식은 첨단 과학 및 공학 응용 분야에서 높은 성능을 기록하며, 그 적용 가능성을 더욱 넓히고 있습니다.

### [Project SHADOW: Symbolic Higher-order Associative Deductive reasoning On Wikidata using LM probing](https://arxiv.org/abs/2408.14849)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14849.png)

Vote: 1

Authors: Hanna Abi Akl

- **What's New**: 새로운 연구인 SHADOW는 지식 베이스(knowledge base) 삼중(completing triples)을 완성하기 위해 LLM을 미세 조정한 모델입니다. 이 모델은 LM-KBC(Language Model Knowledge Base Construction) 챌린지에서 평가됩니다.
- **Technical Details**: SHADOW 모델은 기본 flan-t5-small 모델을 기반으로 하며, 주어진 데이터에 맞춰 미세 조정되었습니다. 훈련 하이퍼파라미터는 다음과 같습니다: {learning_rate: 1e-04, train_batch_size: 4, eval_batch_size: 4, num_epochs: 20}. 여러 관계 유형에 대한 템플릿을 생성하고 실험을 통해 이를 평가합니다. 실험은 Google Colab과 L4 High-RAM GPU에서 수행되었습니다.
- **Performance Highlights**: SHADOW 모델은 템플릿 식별 작업에서 전반적으로 좋은 성능을 보여주었습니다. 그러나 특정 관계인 'countryLandBordersCountry'에서 낮은 정밀도를 보였으며, 이는 관계의 특수성에서 기인합니다. 'seriesHasNumberOfEpisodes' 관계의 경우, 높은 정밀도와 낮은 재현율로 인해 신중한 분류가 이루어졌음을 알 수 있습니다. 전반적인 성능은 기본 모델을 약 20% 초과했지만, 최고의 성능과 비교했을 때는 아직 일부 개선이 필요합니다.

### [Temporally-consistent 3D Reconstruction of Birds](https://arxiv.org/abs/2408.13629)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.13629.png)

Vote: 1

Authors: Bastian Wandt, Johannes Hägerlind, Jonas Hentati-Sundberg

- **What's New**: 이 논문에서는 뿔총알새(common murre)의 3D 자세와 형태를 복원하는 새로운 접근 방법을 제시합니다. 이 접근법은 탐지(detection), 추적(tracking), 세분화(segmentation) 및 시간 일치 3D 재구성을 포함하는 다단계 파이프라인을 포함합니다.
- **Technical Details**: 제안된 방법론은 다음 단계들을 포함합니다: 1) 알바레즈 페르난데즈 델 발라도(Álvarez Fernández Del Vallado)가 제공한 세분화 네트워크를 사용하여 이미지를 세그먼트화 합니다. 2) DeepLabCut과 Resnet50을 미세 조정(fine-tuning)하여 키포인트 탐지기를 교육시킵니다. 3) 중점 필터링을 통한 키포인트 오류를 감지하고 보정합니다. 4) IoU를 기반으로 한 추적기를 사용해 프레임 간의 일관된 추적을 유지합니다. 마지막으로, 3D 새 모델을 2D 키포인트와 2D 마스크에 맞추기 위한 배치 최적화(batch-optimization)를 수행합니다.
- **Performance Highlights**: 이 논문의 중요한 성과 중 하나는 Baltic Seabird 프로젝트에서 수집한 10K 연속 프레임 실세계 데이터셋의 도입입니다. 이 데이터셋은 다양한 행동을 수행하는 9마리의 뿔총알새를 평균적으로 포착하며, 이는 강한 폐색과 큰 자세 변화를 시뮬레이션합니다. 또한 제안된 방법론을 통해 시간 일관성 가정이 도입되어 새의 동적인 움직임을 더욱 정밀하게 캐치할 수 있게 되었습니다.

### [DSTI at LLMs4OL 2024 Task A: Intrinsic versus extrinsic knowledge for type classification](https://arxiv.org/abs/2408.14236)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.14236.png)

Vote: 1

Authors: Hanna Abi Akl

- **What's New**: 이 연구에서는 대규모 언어 모델(LLMs)을 활용하여 온톨로지(ontology)와 관련된 다양한 작업을 수행하는 시스템의 성능을 평가하고 비교합니다. 특히, LLMs와 외부 지식 소스를 사용하여 'semantic towers'라는 개념을 정의하고 이를 활용한 성능 평가를 수행합니다.
- **Technical Details**: 세맨틱 타워(Semantic tower) 구축 방법론에 대해 설명합니다. 위키데이터 쿼리 서비스, WordNet 및 GeoNames 데이터셋을 사용하여 도메인 세맨틱 원시 요소를 추출하고 이를 벡터 임베딩으로 변환하여 저장합니다. 모델 학습에는 flan-t5-small 모델을 기본으로 사용하며, 학습 하이퍼파라미터는 동일하게 설정되었습니다.
- **Performance Highlights**: WordNet 및 GeoNames 데이터셋에서 실험을 수행한 결과, 기본 LLM 모델만을 사용한 실험(WN1, GN1)이 세맨틱 타워를 함께 사용한 실험(WN2, GN2)보다 약 10% 높은 성능을 보였습니다. 하지만 세맨틱 타워가 특정 세맨틱 개념을 보다 효과적으로 모델에 반영하여, 기존 지식만으로는 놓칠 수 있는 올바른 분류를 가능하게 함을 확인했습니다.

