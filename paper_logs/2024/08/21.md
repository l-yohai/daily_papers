## Daily Papers (2024-08-21)

### [TableBench: A Comprehensive and Complex Benchmark for Table Question Answering](https://arxiv.org/abs/2408.09174)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.09174.png)

Vote: 32

Authors: Tongliang Li, Di Liang, Guanglin Niu, Xianfu Cheng, Tianzhen Sun, Jiaheng Liu, Xianjie Wu, Jian Yang, Zhoujun Li, Ge Zhang, Xinrun Du, Daixin Shu, Linzheng Chai

- **What's New**: 최신 연구에 따르면 대형 언어 모델(large language models, LLMs)이 TableQA(테이블 질문 답변)와 같은 테이블 작업에서 뛰어난 성능을 보였으며, 구조 인식 프롬프트(prompt)를 사용해 더 나은 해석을 가능하게 합니다. 본 논문에서는 이러한 능력을 평가하기 위한 종합적이고 복잡한 벤치마크 TableBench를 소개했습니다. 이 벤치마크는 네 가지 주요 카테고리와 18개의 하위 카테고리를 포함하여 LLM의 TableQA 수행 능력을 체계적으로 분석하고 평가합니다.
- **Technical Details**: TableBench는 실세계의 테이블 응용 프로그램 관련 도전 과제를 포괄적으로 분석하여 네 가지 주요 카테고리와 18개의 특정 하위 카테고리로 분류하고, 문제 해결에 필요한 추론 단계 수를 기반으로 작업 복잡성을 정의했습니다. 또한, 수작업 및 자동 방법을 결합한 주석 프레임워크를 도입하여 주석 효율성을 높였습니다. 이 과정에서 총 3681개의 테이블을 수집했으며, 이는 재정, 경쟁, 스포츠, 과학 등 20개의 주요 주제를 포함합니다. 이어서 TableInstruct라는 대규모 TableQA 지시 코퍼스를 생성하여 LLM이 다양한 추론 방법을 습득하도록 했습니다.
- **Performance Highlights**: TableBench와 TableInstruct를 기반으로 한 TableLLM은 GPT-3.5와 비교 가능한 성능을 보이는 강력한 기준선을 제시합니다. 또한 30개 이상의 LLM을 평가하여 실세계 요구를 충족시키기 위해서는 여전히 많은 개선이 필요함을 밝혔습니다. 특히, 가장 진보된 모델인 GPT-4마저도 인간 성능과 비교했을 때 겸손한 점수만을 기록했습니다. TableBench는 사실 확인, 수치 추론, 데이터 분석 및 시각화 작업을 포함하는 886개의 샘플을 포함한 복잡한 TableQA 벤치마크로, 인간 주석을 통해 고품질을 유지합니다.

### [To Code, or Not To Code? Exploring Impact of Code in Pre-training](https://arxiv.org/abs/2408.10914)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.10914.png)

Vote: 23

Authors: Marzieh Fadaee, Adrien Morisot, Sara Hooker, Yixuan Su, Viraat Aryabumi, Ahmet Üstün, Acyr Locatelli, Raymond Ma, Ivan Zhang

- **What's New**: 최근 데이터의 역할은 중요한 의미를 가지게 되었습니다. 최신 모델들은 데이터의 다양성과 전처리 데이터의 중요성을 강조하고 있으며, 컴퓨팅 성능과도 연관이 깊다고 밝혀졌습니다. 이번 연구에서는 코드 데이터가 일반 성능에 미치는 영향을 체계적으로 조사하였습니다. 연구 결과, 코드 데이터를 포함한 학습이 자연어 추론 및 세계 지식 등의 비코드(task)의 성능을 상당히 개선시키는 것으로 나타났습니다.
- **Technical Details**: 이번 연구에서는 대규모 제어된 전훈련 실험을 통해 코드 데이터를 추가하는 것이 훈련 과정에서 어느 지점에서 유익한지, 코드 데이터의 비율, 스케일링의 역할, 추가되는 코드의 품질과 특성을 고려했습니다. SlimPajama 전훈련 코퍼스를 자연 언어 텍스트 데이터로 사용하고, Stack 데이터셋 및 다양한 코드 소스를 코드 데이터로 사용했습니다.
- **Performance Highlights**: 코드 데이터 추가는 비코드 성능을 크게 개선시켰습니다. 텍스트 전용 전훈련 대비, 코드 데이터 추가로 인해 NL 추론은 8.2%, 세계 지식은 4.2% 개선되었습니다. 또한, 생성적 성능에서 6.6% 개선, 코드 성능에서는 12배 향상을 보였습니다. 쿨다운(cooldown) 과정에서 코드 데이터를 포함할 경우, NL 추론이 3.7%, 세계 지식이 6.8%, 코드 성능이 20% 향상되었습니다.

### [Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model](https://arxiv.org/abs/2408.11039)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11039.png)

Vote: 21

Authors: Leonid Shamis, Arun Babu, Lili Yu, Michihiro Yasunaga, Xuezhe Ma, Luke Zettlemoyer, Jacob Kahn, Omer Levy, Chunting Zhou, Kushal Tirumala

- **What's New**: Transfusion 모델을 소개하며, 단일 모델에서 텍스트와 이미지를 동시에 예측하고 생성하는 새로운 접근법을 제안합니다. 이 모델은 텍스트를 위한 토큰 예측과 이미지를 위한 확산(diffusion) 방식을 혼합하여 정보를 잃지 않고 두 가지 모달리티를 완벽하게 통합하는 것을 목표로 하고 있습니다.
- **Technical Details**: Transfusion은 포머(transformer) 모델을 기반으로 하며, 텍스트 데이터와 이미지 데이터를 각각 50%씩 사용하여 사전 학습합니다. 각 모달리티에 대해 다른 목표(텍스트의 다음 토큰 예측, 이미지의 확산)를 사용합니다. 텍스트 토큰을 벡터로 변환하기 위해 표준 임베딩 레이어를 사용하고, 이미지는 패치 벡터로 표현합니다. 텍스트 토큰에는 인과적 주의(causal attention)를 적용하고, 이미지 패치에는 양방향 주의(bidirectional attention)를 적용합니다.
- **Performance Highlights**: Transfusion은 텍스트에서 이미지로 변환하는 작업에서 Chameleon 접근법보다 훨씬 적은 연산량(FLOPs)으로도 더 나은 성능을 보여주며, FID 및 CLIP 점수에서도 뛰어납니다. 텍스트 생성 작업에서도 Chameleon과 비슷한 성능을 유지하면서 연산량을 절반 이하로 줄였습니다. GenEval 벤치마크에서 Transfusion은 DALL-E 2 및 SDXL 등 기존 모델보다 우수한 성능을 보여주었으며, 텍스트 생성에서도 Llama 1과 비슷한 수준의 성능을 달성했습니다.

### [MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding](https://arxiv.org/abs/2408.11049)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11049.png)

Vote: 7

Authors: Ian En-Hsu Yen, Vashisth Tiwari, Ranajoy Sadhukhan, Jian Chen, Zhuoming Chen, Jinyuan Shi, Beidi Chen

- **What's New**: 최근 언어 모델(Language Model) 분야에서는 매우 긴 컨텍스트를 처리할 수 있는 모델들이 점점 더 많아지고 있습니다. 특히, 채팅 봇처럼 상호작용이 필요한 경우에는 낮은 지연 시간(low latency)이 중요하며, 배경 데이터 처리 작업은 높은 처리량(high throughput)을 우선시 합니다. 두 목표를 동시에 달성하는 것은 여전히 어려운 과제입니다.
- **Technical Details**: 스펙큘러티브 디코딩(Speculative Decoding, SD)은 지연 시간을 줄이기 위한 기술로, 빠른 초안 모델(draft model)을 사용해 여러 토큰을 생성한 후, LLM이 이를 병렬로 검증하는 방식입니다. 이는 토큰 하나를 디코딩하는 것과 비교해 약간의 추가 비용만 필요합니다. 그러나 기존 연구들은 SD가 큰 배치 사이즈에서는 처리량을 크게 향상시키지 못한다고 여겼습니다. 본 연구에서는 중간에서 긴 시퀀스 길이에 대해 SD가 높은 처리량, 낮은 지연 시간, 손실 없는 정확성을 모두 달성할 수 있음을 보여줍니다. 주요 기여사항은 KV 캐시 병목 문제를 해결하기 위한 초안 모델 사용과 다양한 GPU와 LLM을 통한 실증 평가입니다.
- **Performance Highlights**: 실험 결과, SD는 자가 회귀 디코딩(autoregressive decoding)보다 두 배 더 빠른 성능을 보였으며, LLaMA-2-7B-32K 모델에서는 2배, LLaMA-3.1-8B 모델에서는 1.84배 더 빠른 속도를 기록했습니다. 이 실험은 8개의 A100 GPU에서 수행되었습니다.

### [MegaFusion: Extend Diffusion Models towards Higher-resolution Image Generation without Further Tuning](https://arxiv.org/abs/2408.11001)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11001.png)

Vote: 7

Authors: Qiang Hu, Xiaoyun Zhang, Yanfeng Wang, Ya Zhang, Shaocheng Shen, Haoning Wu

- **What's New**: MegaFusion이라는 새로운 접근방식을 통해 기존의 Diffusion 모델을 튜닝 없이도 고해상도 및 다양한 비율의 이미지 생성이 가능하도록 개선했습니다. MegaFusion은 특정한 모델에 한정되지 않고, Latent-space 및 Pixel-space Diffusion 모델 모두와 호환되어 다양한 확장 조건과 함께 사용할 수 있습니다.
- **Technical Details**: MegaFusion은 트렁케이트 및 릴레이 전략을 사용하여 고해상도 이미지를 효율적으로 생성합니다. 또한, Dilated Convolutions 및 Noise Re-scheduling 기법을 도입해 생성된 이미지의 품질과 디테일을 향상시킵니다. MegaFusion의 원칙은 IP-Adapter, ControlNet 등 다른 Diffusion 기반 프레임워크로도 확장 가능합니다.
- **Performance Highlights**: MegaFusion은 MegaPixels 단위의 고해상도 이미지를 약 40%의 원래 계산 비용으로 생성할 수 있도록 하여 효율성을 크게 향상시킵니다. 고해상도 이미지의 생성에서 기존 모델들이 겪는 해상도 제한과 이미지 품질 저하 문제를 해결했으며, 이는 앞선 실험 결과에서 입증되었습니다.

### [NeCo: Improving DINOv2's spatial representations in 19 GPU hours with Patch Neighbor Consistency](https://arxiv.org/abs/2408.11054)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11054.png)

Vote: 6

Authors: Valentinos Pariza, Francesco Locatello, Yuki M. Asano, Mohammadreza Salehi, Gertjan Burghouts

- **What's New**: 새로운 연구는 최근 주목받고 있는 밀집 자가 지도 학습(dense self-supervised learning)의 기술을 발전시키기 위해 Nearest-Neighbor Retrieval 기법을 훈련 메커니즘으로 사용하는 방법을 제안합니다. 이 기법은 기존의 평가 방식에서 한 단계 나아가, 효율적이고 견고한 고성능 모델을 훈련시키는 방법을 제시합니다. 이를 통해 더 자연스럽게 클러스터링하고 정교한 시각적 유사성을 구분할 수 있는 모델을 만들 수 있습니다.
- **Technical Details**: 이 연구에서는 다음과 같은 기술적 세부 사항을 포함합니다. 우선, 이미지 레벨에서 미리 훈련된 모델(pretrained models)을 사용하여 그 대상을 더 정교하게 조정하는 과정을 도입했습니다. 이를 'dense post-pretraining'이라고 부르며, 이는 ViT-S/16 모델을 단일 GPU에서 19시간 동안 튜닝하는 데 있어서 효과적입니다. 또 하나의 도전 과제는 Nearest-Neighbor Retrieval의 불연속성을 극복하기 위해, 역전파 가능하도록 차별화된 소팅 기법(differentiable sorting method)을 적용했습니다. 이 연구에서는 Patch Neighbor Consistency를 적용했으며, 이 방법이 DINO, iBOT, Leopart, CrIBO, DINOv2 등 여러 기존 모델에서 우수한 특징을 얻는 데 기여한다고 밝히고 있습니다.
- **Performance Highlights**: 제안된 방법은 여러 평가 프로토콜과 데이터셋에서 평균 6%에서 16%의 성능 향상을 달성했습니다. 특히, 이전 방법들보다 Pascal VOC와 ADE20k에서 4%에서 13%의 성능 향상을 보여주며, 몇 가지 새로운 state-of-the-art 성과를 설정했습니다. 예를 들어, in-context segmentation 벤치마크에서 CrIbo와 DINOv2를 능가하는 성과를 보였습니다.

### [Ferret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique](https://arxiv.org/abs/2408.10701)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.10701.png)

Vote: 4

Authors: Rishabh Bhardwaj, Tej Deep Pala, Vernon Y. H. Toh, Soujanya Poria

- **What's New**: 이 논문은 새로운 Transformer 아키텍처를 소개합니다. 이 아키텍처는 기존의 모델보다 빠르고 효율적입니다.
- **Technical Details**: 새로운 아키텍처는 Attention 메커니즘을 개선하여 연산 복잡성을 줄였습니다. 또한, Layer Normalization과 같은 기술들을 최적화하였습니다.
- **Performance Highlights**: 이 모델은 다양한 벤치마크에서 기존 최첨단 모델들을 능가하는 성능을 보여주었으며, 특히 파인 튜닝 없이도 뛰어난 결과를 기록했습니다.

### [Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model](https://arxiv.org/abs/2408.10764)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.10764.png)

Vote: 4

Authors: Jingren Zhou, Bowen Yu, Keming Lu, Chang Zhou, Ru Peng, Chenhan Yuan, Fei Huang

- **What's New**: 새로운 방법 Otter는 LLMs(대형 언어 모델)의 추론 개입 시 원래 출력과 지식을 방해하지 않고 보정 신호를 예측할 수 있는 기술입니다. 이는 LLM의 각 트랜스포머 블록에 새로운 학습 가능한 파라미터를 삽입하여 보정 신호를 예측하는 프로세스를 설명합니다.
- **Technical Details**: Otter는 트랜스포머 기반의 LLM에 새로운 학습 가능한 파라미터를 삽입하여 원래의 숨겨진 상태를 확장합니다. 예를 들어, i번째 트랜스포머 블록의 숨겨진 상태 hij는 h~i=[hi, hi′]로 확장됩니다. 이를 통해 마지막 레이어의 hn'을 기반으로 추론 개입 신호를 예측할 수 있습니다. 이는 피드포워드 네트워크(FFN)와 멀티헤드 어텐션(MHA) 레이어에 새로운 파라미터를 추가하여 이루어집니다.
- **Performance Highlights**: Otter는 기존 최첨단 추론 개입 방법들과 유사한 성능을 제공하면서도 최대 86.5%의 추가 공간과 98.5%의 추가 시간을 절약합니다. 이 방법은 생성 디톡스화, 선호도 정렬, 추론 가속화와 같은 고수요 작업에서 비교 가능한 성과를 낸다는 점이 특징입니다.

### [Audio Match Cutting: Finding and Creating Matching Audio Transitions in Movies and Videos](https://arxiv.org/abs/2408.10998)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.10998.png)

Vote: 4

Authors: Lie Lu, Venu Govindaraju, Dennis Fedorishin, Srirangaraj Setlur

- **What's New**: 본 논문에서는 자동화된 오디오 매치 컷(Audio Match Cut) 생성 문제를 소개하고, 이를 평가하기 위한 두 가지 데이터셋을 구축했다. 또한, 다양한 소리를 대상으로 고품질 오디오 매치 컷을 자동으로 찾아내고 생성하는 셀프-슈퍼바이즈드(Self-supervised) 검색 및 전환 프레임워크를 제안한다.
- **Technical Details**: 본 연구는 오디오 매치 컷 문제를 단일 모달 오디오 검색 과제로 모형화하며, 주어진 쿼리 비디오 클립과 n개의 다른 비디오 클립 컬렉션에서 최대 내부 곱셈(MIPS)을 사용하여 검색한다. 상위 k개의 가장 유사한 갤러리 클립을 검색한 후, 쿼리와 검색된 클립을 블렌딩하는 과정을 통해 최종 오디오 매치 컷을 생성한다. Audioset과 Movieclips111 데이터셋의 서브셋을 기반으로 평가세트를 개발하여, 각 비디오를 1초의 겹치지 않는 이미지-오디오 쌍으로 분할하고 검색 과정을 수행한다.
- **Performance Highlights**: 본 논문에서는 쿼리 및 매칭 후보를 레이블링하여 평가 세트를 구축하고, 검색된 오디오 샘플과 쿼리의 음이 비슷한지, 리듬이나 음색 등이 유사한지를 기준으로 매칭 후보를 선정한다. 레이블링은 실현 불가능한 검색 공간을 줄이기 위해 기존 오디오 표현을 사용하여 수행되었다. 이 프레임워크는 기존의 여러 베이스라인보다 우수한 성능을 보여준다.

### [PhysBERT: A Text Embedding Model for Physics Scientific Literature](https://arxiv.org/abs/2408.09574)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.09574.png)

Vote: 3

Authors: Andrea Pollastro, João Montenegro, Thorsten Hellert

- **What's New**: 물리학 분야에 특화된 문장 임베딩 모델인 PhysBERT가 소개되었습니다. 이 모델은 arXiv에서 제공하는 120만 개의 물리학 논문 코퍼스를 기반으로 훈련되었습니다.
- **Technical Details**: PhysBERT는 BERT 아키텍처를 활용하여 훈련되었으며, 먼저 128 토큰 길이로 Masked Language Modeling(MLM)을 수행한 후, 512 토큰으로 확장하는 방식으로 훈련되었습니다. 또한, SimCSE 기법을 적용하여 모델의 문장 임베딩 성능을 향상시켰습니다.
- **Performance Highlights**: PhysBERT는 정보 검색, 분류, 그리고 의미 유사도 측정 등의 물리학 관련 NLP 작업에서 일반 목적으로 사용되는 모델을 뛰어넘는 성능을 보였습니다. 더불어, 물리학의 특정 하위 도메인에 대한 세밀한 튜닝이 가능하도록 높은 수준의 적응성과 잠재력을 지니고 있습니다.

### [The Brittleness of AI-Generated Image Watermarking Techniques: Examining Their Robustness Against Visual Paraphrasing Attacks](https://arxiv.org/abs/2408.10446)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.10446.png)

Vote: 3

Authors: Krish Sharma, Aman Chadha, Amit Sheth, Vinija Jain, Niyar R Barman, Ashhar Aziz, Vasu Sharma, Amitava Das, Shashwat Bajpai, Shwetangshu Biswas

- **What's New**: 이 논문은 새로운 AI 모델을 도입하여 기존 방법보다 더 효율적이고 정확한 결과를 달성했습니다. 이 모델은 특히 NLP (Natural Language Processing) 작업에서 두각을 나타냅니다.
- **Technical Details**: 제안된 모델은 Transformer 아키텍처를 기반으로 하며, 개선된 embedding 기법과 attention 메커니즘을 사용합니다. 또한, 다양한 데이터셋을 활용하여 성능을 평가하고, Fine-tuning 기술로 특정 작업에 맞춤화를 시도했습니다.
- **Performance Highlights**: 실험 결과, 제안된 모델은 BLEU 와 ROUGE 스코어에서 기존 최고 성능을 능가하였습니다. 특히 텍스트 요약 및 기계 번역 작업에서 탁월한 성능을 보였습니다.

### [MambaEVT: Event Stream based Visual Object Tracking using State Space Model](https://arxiv.org/abs/2408.10487)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.10487.png)

Vote: 3

Authors: Shiao Wang, Lin Zhu, Bo Jiang, Xiao Wang, Zhicheng Zhao, Xixi Wang, Chao wang

- **What's New**: 최근 들어 이벤트 카메라를 기반으로 한 시각 객체 추적 (Visual Object Tracking, VOT)이 주목받고 있으며, 대규모 벤치마크 데이터셋(예: EventVOT, VisEvent 등)의 출시에 힘입어 발전하고 있습니다. 본 논문에서는 이벤트 카메라를 활용한 새로운 Mamba 기반 시각 객체 추적 알고리즘인 MambaEVT를 제안합니다. 이는 추적 정확도와 계산 비용 간의 최적의 절충점을 도모하는 최초의 Mamba 기반 이벤트 추적 프레임워크입니다.
- **Technical Details**: 기존의 이벤트 기반 추적기와 달리 MambaEVT는 이벤트 스트림에서 정적 템플리트와 검색 영역을 추출하여 이벤트 토큰으로 변환한 후, VisMamba를 사용하여 특징 추출 및 상호 학습을 진행합니다. 특히, 양방향 정보를 고려하여 더욱 정밀하고 견고한 시각 특징을 학습합니다. 또한, 메모리 Mamba를 사용한 동적 템플리트 생성 전략을 도입하여, 객체의 외관 변화에 적응할 수 있도록 합니다. 이는 트랙의 정확성과 견고성을 높이는데 기여합니다.
- **Performance Highlights**: 다양한 대규모 이벤트 기반 추적 데이터셋(EventVOT, VisEvent, FE240hz)에서 광범위한 실험을 통해 제안된 Mamba 기반 추적 프레임워크의 효과성과 효율성을 검증했습니다. 우리의 동적 템플리트 업데이트 모듈은 학습 가능하여 최종 추적 성능을 더욱 향상시킵니다.

### [RP1M: A Large-Scale Motion Dataset for Piano Playing with Bi-Manual Dexterous Robot Hands](https://arxiv.org/abs/2408.11048)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.11048.png)

Vote: 2

Authors: Le Chen, Quankai Gao, Jan Schneider, Dieter Büchler, Joni Pajarinen, Juho Kannala, Bernhard Schölkopf, Yi Zhao

- **What's New**: 이 논문에서는 Robot Piano 1 Million (RP1M) 데이터셋을 제안합니다. 이 데이터셋은 고품질의 양손 로봇 피아노 연주 모션 데이터를 포함하고 있으며, 2,000곡 이상의 음악 조각과 이를 통한 RL 에이전트의 정책 결과물을 포함하고 있습니다.
- **Technical Details**: RP1M 데이터셋은 자동 피어링 알고리즘을 사용하여 생성됩니다. 이 알고리즘은 손가락 배치를 최적 수송(Optimal Transport, OT) 문제로 공식화하여, 손가락이 거리를 최소화하면서 올바른 키를 누를 수 있도록 합니다. 기존의 인간 주석자에 의한 피어링 라벨링 대신, 자동 피어링으로 로봇의 형태에 관계없이 피아노 연주를 학습할 수 있습니다.
- **Performance Highlights**: RP1M을 사용한 다양한 행동 복제(Behavior Cloning) 접근 방식을 벤치마크한 결과, 기존의 모방 학습(Imitation Learning) 방법들이 여러 곡에 대한 피아노 연주에서 최첨단 성능을 달성했습니다. 이로써 새로운 음악 조각에서도 높은 일반화 성능을 보여주었습니다.

### [ShapeSplat: A Large-scale Dataset of Gaussian Splats and Their Self-Supervised Pretraining](https://arxiv.org/abs/2408.10906)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.10906.png)

Vote: 2

Authors: Qi Ma, Theo Gevers, Luc Van Gool, Danda Pani Paudel, Nicu Sebe, Yue Li, Ender Konukoglu, Bin Ren

- **What's New**: 이번 arXiv 논문에서는 최첨단 자연어 처리(Neural Language Processing) 모델의 혁신적인 변화를 소개합니다. 연구진은 새로운 Transformer 기반 아키텍처를 통해 언어 모델의 효율성과 정확도를 크게 향상시켰습니다.
- **Technical Details**: 주요 기술적 세부 사항으로는 강화된 self-attention 메커니즘, 다층 피드포워드 네트워크(multi-layer feedforward network), 새로운 positional encoding 방식 등이 포함됩니다. 특히, self-attention 메커니즘은 기존 모델보다 계산 효율성을 높이고, 긴 문맥을 잘 이해할 수 있게 개선되었습니다.
- **Performance Highlights**: 이 모델은 여러 벤치마크 데이터셋에서 최첨단 성능을 기록하였습니다. 예를 들어, GLUE Benchmark에서 이전 모델 대비 평균 2% 이상의 정확도 향상을 보였습니다. 또한, 학습 속도도 기존 모델 대비 1.5배 빠르게 나타났습니다.

### [Recent Surge in Public Interest in Transportation: Sentiment Analysis of Baidu Apollo Go Using Weibo Data](https://arxiv.org/abs/2408.10088)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.10088.png)

Vote: 1

Authors: Yuhang Xie, Tianyi Li, Zhouye Zhao, Zeyu Wang, Bohao Su, Zirui Chen, Shiqi Wang, Mingchuan Ma, Wenrui Xu

- **What's New**: 소개된 논문은 Baidu의 자율주행 호출 서비스인 Apollo Go의 혁신과 최근 중국 도시에서의 광범위한 배치에 대해 다룹니다. 이 서비스는 도시 교통 혼잡을 줄이고 교통 효율성을 높이는 잠재력을 가진 자율주행 기술의 가능성을 보여줍니다. 논문은 또한 이러한 자율주행 기술이 도시 교통 시스템을 혁신할 것이라고 예측하며 향후 연구 방향을 제안합니다.
- **Technical Details**: 이 연구는 중국 소셜 미디어 플랫폼인 Weibo에서 수집된 데이터를 사용하여 Baidu Apollo Go에 대한 공공의 의견을 분석합니다. 구체적으로, 자연어 처리(NLP)와 감성 분석(Sentiment Analysis)을 통해 공개된 데이터에서 정서적 반응과 태도를 파악합니다. 이를 위해 BERT, BiLSTM, BiGRU와 같은 선진 딥러닝 모델을 활용합니다. 감성 분석은 NLP의 주요 응용 분야로, 텍스트를 긍정, 부정, 중립 등의 감정 카테고리로 분류하는 기술을 포함합니다.
- **Performance Highlights**: 최근 연구에 따르면, Apollo Go와 같은 자율주행 호출 서비스는 전통적인 택시 및 차량 호출 서비스와 비교하여 더 안전하고 신뢰할 수 있으며 경제적인 교통 수단을 제공합니다. 자율주행차의 높은 시장 침투율(MPR)이 교통 흐름을 크게 개선할 수 있습니다. 감성 분석 결과, 공공은 기술의 안전성과 효과에 긍정적으로 반응하지만, 교통사고, 해킹, 직업 상실 등의 문제에 대한 걱정도 있습니다.

