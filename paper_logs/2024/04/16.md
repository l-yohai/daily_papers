## Daily Papers (2024-04-16)

### [Learn Your Reference Model for Real Good Alignment](https://arxiv.org/abs/2404.09656)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09656.png)

Vote: 54

Authors: Alexey Gorbatovski, Alexey Malakhov, Boris Shaposhnikov, Yaroslav Aksenov, Daniil Gavrilov, Nikita Balagansky, Nikita Surnachev, Ian Maksimov

- 본 논문에서는 기존 언어 모델의 정렬 문제의 복잡성을 다루며, 기존 방법들이 불안정하다는 문제점을 개선하기 위한 여러 기법들이 소개됩니다.
- 언어 모델 정렬을 위한 기본적인 강화학습(Human Feedback) 기법은 보상 최대화와 함께, 훈련 가능한 정책과 SFT 정책 간의 쿨백-라이블러 발산을 최소화하여 보상 모델(RM)에 대한 과적합과 범위 이탈 텍스트 생성을 방지합니다.
- 직접 선호 최적화(DPO) 방식은 보상 모델을 배제하면서도 SFT 정책에 가까운 정책 유지 요구를 간접적으로 유지하여 RLHF의 최적화 작업을 재구성합니다.
- 본 논문은 DPO 방식의 이러한 내재된 한계가 성과를 저하시킨다고 주장하며, 훈련 중 참조 정책을 업데이트하는 새로운 방법인 Trust Region DPO(TR-DPO)를 제안합니다.
- 이 간단한 업데이트를 통해 TR-DPO가 DPO에 비해 Anthropic HH와 TLDR 데이터셋에서 최대 19% 높은 성능을 보이는 것을 GPT-4를 이용한 자동 평가로 입증합니다.
- 제안하는 새로운 정렬 접근 방식은 일관성, 정확성, 세부 수준, 유용성 및 무해성과 같은 여러 파라미터에서 모델의 품질을 향상시킬 수 있습니다.

### [Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length](https://arxiv.org/abs/2404.08801)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08801.png)

Vote: 29

Authors: Omer Levy, Lili Yu, Xuezhe Ma, Chunting Zhou, Jonathan May, Luke Zettlemoyer, Hao Zhang, Wenhan Xiong, Xiaomeng Yang, Beidi Chen

- 트랜스포머의 제곱 복잡도와 약한 길이 외삽이 긴 시퀀스 확장을 제한하는 문제를 해결하기 위해, Megalodon이라는 새로운 신경 아키텍처가 소개되었습니다.
- Megalodon은 Mega 아키텍처(지수 이동 평균과 게이트어텐션)를 상속받고, 성능과 안정성을 개선하기 위해 여러 기술적 구성요소를 추가로 도입하였습니다.
- 복합 지수 이동 평균(CEMA), 타임스텝 정규화 레이어, 정규화된 어텐션 메커니즘, 이중 홉 잔류 구성을 포함한 전처리 방식 등이 포함됩니다.
- 제어된 비교에서 Megalodon은 7억 개의 파라미터와 2조 개의 훈련 토큰이 있는 스케일에서 트랜스포머보다 더 나은 효율성을 달성했습니다.
- 훈련 손실은 1.70으로 Llama2-7B(1.75)와 13B(1.67) 사이에 위치합니다, 이는 Llama2 모델들과의 중간 성능을 보여줍니다.
- 관련 코드는 [이 링크](https://github.com/XuezheMax/megalodon)에서 확인할 수 있습니다.

### [TransformerFAM: Feedback attention is working memory](https://arxiv.org/abs/2404.09173)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09173.png)

Vote: 26

Authors: Dongseong Hwang, Khe Chai Sim, Pedro Moreno Mengibar, Zhuoyuan Huo, Weiran Wang

- 트랜스포머는 딥러닝을 혁신하였지만, 그들의 제곱 관심 복잡성으로 인해 무한히 긴 입력을 처리하는 데 한계가 있습니다.
- 우리는 자체 잠재 표현에 주목할 수 있도록 피드백 루프를 활용하는 새로운 트랜스포머 구조인 피드백 주의 기억(Feedback Attention Memory, FAM)을 제안합니다.
- 이 설계는 트랜스포머 내에서 작업 기억의 출현을 촉진하여, 무기한 긴 시퀀스를 처리할 수 있게 합니다.
- TransformerFAM은 추가적인 가중치가 필요 없으며, 기존에 훈련된 모델과의 원활한 통합을 가능하게 합니다.
- 실험 결과, TransformerFAM은 다양한 모델 크기(1B, 8B, 24B)에서 장문의 맥락 작업에 대한 트랜스포머 성능을 크게 향상시킴을 보여줍니다.
- 이러한 결과는 대규모 언어 모델(Large Language Models, LLMs)이 제한 없는 길이의 시퀀스를 처리할 수 있는 잠재력을 보여줍니다.

### [Compression Represents Intelligence Linearly](https://arxiv.org/abs/2404.09937)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09937.png)

Vote: 18

Authors: Junxian He, Jinghan Zhang, Zifei Shan, Yuzhen Huang

- 압축을 잘 배우는 것이 지능을 끌어내는 데 도움이 될 수 있다는 믿음이 있습니다.
- 최근 언어 모델링이 압축과 동등하다는 것이 밝혀졌으며, 이는 대규모 언어 모델(LLMs)의 성공을 설명하는 설득력 있는 근거를 제공합니다.
- 이 연구는 LLM을 데이터 압축기로 보고, 지능과 관련된 여러 지식, 상식, 코딩 및 수학적 추론을 포함한 다운스트림 벤치마크 점수를 지능의 대리 지표로 사용합니다.
- 12개의 벤치마크를 통해 다양한 조직에서 개발된 30개의 공개 LLM을 조사한 결과, LLM의 지능은 외부 텍스트 코퍼스의 압축 능력과 거의 선형적으로 상관관계가 있는 것으로 나타났습니다.
- 우수한 압축이 더 높은 지능을 나타낸다는 믿음을 뒷받침하는 구체적인 증거를 제공하며, 압축 효율성은 모델 능력과 선형적으로 관련되는 신뢰할 수 있는 평가 척도로 작용할 수 있음을 시사합니다.
- 연구자들이 압축을 적절히 평가할 수 있도록 압축 데이터셋과 데이터 수집 파이프라인을 오픈소스로 제공합니다.

### [Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video](https://arxiv.org/abs/2404.09833)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09833.png)

Vote: 16

Authors: Zhi-Hao Lin, Wei-Chiu Ma, Hongchi Xia, Shenlong Wang

- 복잡하고 비용이 많이 드는 수동 모델링 과정을 포함하는 고품질 대화형 가상 환경을 개발하는 것은 종종 도전적입니다.
- 이 논문에서는 실제 세계의 장면 비디오를 현실적이고 상호 작용 가능한 게임 환경으로 자동 변환하는 새로운 접근 방식인 Video2Game을 소개합니다.
- 시스템의 핵심 구성요소로는 장면의 기하학적 및 시각적 외관을 효과적으로 포착하는 신경 광선 필드(NeRF) 모듈, 더 빠른 렌더링을 위해 NeRF에서 지식을 추출하는 메쉬 모듈, 객체 간의 상호 작용과 물리적 동역학을 모델링하는 물리 모듈이 있습니다.
- 잘 설계된 파이프라인을 따르면 사용자는 실제 세계의 상호작용 가능하고 실행 가능한 디지털 복제본을 구축할 수 있습니다.
- 우리는 실내 및 대규모 실외 장면 모두에서 시스템을 벤치마킹하였고, 실시간에서 고도로 현실적인 렌더링을 생성할 뿐만 아니라 상호 작용 가능한 게임을 구축할 수 있음을 보여줍니다.

### [Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model](https://arxiv.org/abs/2404.09967)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09967.png)

Vote: 12

Authors: Han Lin, Mohit Bansal, Abhay Zala, Jaemin Cho

- Ctrl-Adapter는 이미지 및 비디오 확산 모델에 다양한 제어를 추가하여 사전 교육된 ControlNet을 적용하는 효율적이고 범용적인 프레임워크입니다.
- 이 프레임워크는 사전 교육된 ControlNet의 특징을 동결된 확산 모델과 통합하면서 새로운 이미지/비디오 확산 모델에 ControlNet을 연결하는 어댑터 계층을 훈련합니다.
- Ctrl-Adapter는 비디오의 시간적 일관성을 유지하기 위해 시간적 및 공간적 모듈을 포함하고 있으며, 다양한 조건의 제어를 단순히 ControlNet 출력의 (가중)평균을 취함으로써 실행할 수 있습니다.
- 또한, 이 프레임워크는 다양한 이미지/비디오 확산 백본(예: SDXL, Hotshot-XL, I2VGen-XL, SVD)과 호환되며, 제어를 위한 기존 조건에 대한 적응 능력을 지니고 있습니다.
- Ctrl-Adapter는 비디오 제어에서 모든 기준 모델을 능가하며, DAVIS 2017 데이터셋에서 최고의 정확도를 달성했으며, 10 GPU 시간 미만의 상당히 낮은 계산 비용을 필요로 합니다.

### [HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing](https://arxiv.org/abs/2404.09990)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09990.png)

Vote: 9

Authors: Yuyin Zhou, Cihang Xie, Peng Wang, Heng Wang, Bingchen Zhao, Siwei Yang, Yichun Shi, Mude Hui

- 이 연구에서는 약 20만 개의 편집과 함께 고품질 지시 기반 이미지 편집 데이터셋인 HQ-Edit을 소개합니다.
- 기존의 속성 안내나 인간의 피드백에 의존하는 방식과 달리, GPT-4V와 DALL-E 3와 같은 고급 기초 모델을 활용하는 확장 가능한 데이터 수집 파이프라인을 개발하였습니다.
- 다양한 예제를 온라인에서 수집하고 확장하여, 상세한 텍스트 프롬프트와 함께 입력 및 출력 이미지를 특징으로 하는 고품질의 이중 화상을 만들어 내고, 후처리를 통해 정밀한 정렬을 보장합니다.
- 또한, 이미지 편집 쌍의 품질을 정량적으로 평가하기 위해 'Alignment'와 'Coherence'라는 두 가지 평가 지표를 제안합니다.
- HQ-Edit는 고해상도 이미지와 자세한 편집 프롬프트를 특징으로 하여 기존 이미지 편집 모델의 기능을 크게 향상시킵니다.
- 예를 들어, HQ-Edit으로 미세 조정된 InstructPix2Pix는 인간이 주석을 단 데이터로 미세 조정된 모델들을 능가하는 최첨단 이미지 편집 성능을 달성할 수 있습니다.
- 프로젝트 페이지는 https://thefllood.github.io/HQEdit_web에서 확인할 수 있습니다.

### [Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization](https://arxiv.org/abs/2404.09956)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09956.png)

Vote: 8

Authors: Rada Mihalcea, Chia-Yu Hung, Soujanya Poria, Deepanway Ghosal, Wei-Ning Hsu, Navonil Majumder

- 본 연구는 텍스트에서 오디오로의 생성을 위해, 기존의 Tango 텍스트-오디오 모델을 사용하여 선호 데이터셋을 인공적으로 생성하고, 이를 통해 오디오 출력의 개선을 목표로 합니다.
- 선호 데이터셋은 각 프롬프트에 대해 우수한 오디오 출력과 떨어지는 오디오 출력들을 포함하며, 이는 모델이 프롬프트의 개념이 누락되거나 순서가 잘못된 오디오를 학습하는 데 도움을 줍니다.
- 공개적으로 이용 가능한 Tango 모델을 우리의 선호 데이터셋을 사용하여 직접적 선호 최적화(DPO) 손실을 적용하여 미세 조정함으로써, Tango와 AudioLDM2를 능가하는 오디오 출력을 달성했습니다.
- 개선된 오디오 출력은 자동 및 수동 평가 방법 모두에서 측정되었습니다.

### [TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models](https://arxiv.org/abs/2404.09204)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09204.png)

Vote: 7

Authors: Wei Zeng, Minghui Liao, Yongxin Liao, Ya-Qi Yu, Jihao Wu, Xiaoyu Zheng

- 다양한 모달 작업에서 인상적인 결과를 보여준 다모달 대형 언어 모델(MLLM)은 문서 지향 작업에 적합하지 않은 경우가 많아, 세밀한 이미지 인식과 정보 압축이 요구된다.
- 본 논문에서는 문서 지향 작업에 특화되면서도 MLLM의 일반적인 기능을 유지하는 TextHawk를 소개하며, 효율적인 세밀한 인식을 위해 네 가지 전용 구성 요소를 설계했다.
- 먼저, 문서 텍스트의 중복을 줄이고 MLLM의 계산 비용을 낮추기 위해 재샘플링 및 재배열(ReSA) 모듈을 제안한다.
- 다양한 이미지 크기의 확장성을 보존할 수 있는 확장 가능한 위치 임베딩(SPE)을 통해 각 로컬 특징의 위치를 인코딩하는 방법을 탐구한다.
- 쿼리 제안 네트워크(QPN)를 사용하여 서브 이미지 간에 동적으로 쿼리를 초기화한다.
- MLLM의 세밀한 시각적 인식 능력을 더욱 강화하기 위해 문서 이미지의 계층 구조와 의미 관계를 포착하는 다중 레벨 크로스 어텐션(MLCA) 메커니즘을 설계했다.
- 또한, 젬나이 프로로 다모달 문서 데이터를 풍부하게 하여 문서 지향 작업을 위한 새로운 지시 튜닝 데이터 세트를 만들었다.
- 일반 및 문서 지향 MLLM 벤치마크 모두에서 광범위한 실험을 수행하고, TextHawk가 최신 방법보다 우수한 성능을 보여주며, 세밀한 문서 인식과 일반 능력에서의 효과성과 우수성을 입증한다.

### [On Speculative Decoding for Multimodal Large Language Models](https://arxiv.org/abs/2404.08856)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08856.png)

Vote: 6

Authors: Junyoung Park, Wonseok Jeon, Christopher Lott, Mukul Gagrani, Raghavv Goel, Mingu Lee

- 다양한 모드의 대규모 언어 모델(MLLM)의 추론 속도는 큰 언어 모델 백본과 자동 회귀 토큰 생성으로 인해 느려집니다.
- 이 논문에서는 LLaVA 7B 모델의 추론 효율성을 향상시키기 위해 추측 디코딩(speculative decoding)의 적용을 탐구합니다.
- 언어만을 사용하는 모델이 LLaVA 7B의 추측 디코딩을 위한 초안 모델로서 이미지 토큰 및 관련 처리 구성 요소를 배제할 수 있다는 것을 보여줍니다.
- 세 가지 다른 작업에 걸쳐 수행된 실험은 자체적으로 훈련한 115M 파라미터 언어 모델을 사용하여 최대 2.37배의 메모리 바운드 속도 향상을 달성할 수 있음을 보여줍니다. 
- 또한 이미지 어댑터를 통합한 컴팩트 LLaVA 초안 모델을 소개하며, 이는 이미지 캡셔닝에서 약간의 성능 향상을 보이면서 다른 작업에서도 비슷한 결과를 유지합니다.

### [CompGS: Efficient 3D Scene Representation via Compressed Gaussian Splatting](https://arxiv.org/abs/2404.09458)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09458.png)

Vote: 5

Authors: Xiangrui Liu, Shiqi Wang, Zhu Li, Sam Kwong, Pingping Zhang, Xinju Wu

- 가우시안 스플래팅은 뛰어난 렌더링 품질과 효율성으로 유명하며 3D 장면 표현에서 주요 기술로 부상하였습니다.
- 기존의 가우시안 스플래팅은 데이터 양이 많아 실제 응용에 제약이 있는데, 이를 해결하기 위해 압축된 가우시안 기본 요소를 사용하는 새로운 방식인 CompGS를 제안합니다.
- 이 방법은 각 기본 요소들 사이의 예측 관계를 포착하는 하이브리드 기본 구조를 개발하여 가우시안 기본 요소의 컴팩트함을 확보합니다.
- 소수의 앵커 기본 요소를 사용하여 예측함으로써 대부분의 기본 요소를 매우 컴팩트한 잔여 형태로 묶을 수 있습니다.
- 또한, 하이브리드 기본 요소 내의 중복을 제거하기 위한 비트레이트 제한 최적화 방식을 개발하여 비트 소모와 표현 효과 사이의 최적의 균형을 추구합니다.
- 실험 결과에 따르면 제안된 CompGS는 기존 방법들을 뛰어넘어 모델 정확성과 렌더링 품질을 저하시키지 않으면서 3D 장면 표현에서 뛰어난 컴팩트성을 달성했습니다.
- 해당 코드는 추가 연구를 위해 GitHub에 공개될 예정입니다.

### [Taming Latent Diffusion Model for Neural Radiance Field Inpainting](https://arxiv.org/abs/2404.09995)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.09995.png)

Vote: 5

Authors: Chieh Hubert Lin, Hung-Yu Tseng, Chih-Yao Ma, Changil Kim, Qinbo Li, Johannes Kopf, Ming-Hsuan Yang, Jia-Bin Huang

- Neural Radiance Field (NeRF)는 다중 시점 이미지로부터 3D 재구성을 위한 표현 방법으로 사용된다.
- 기존의 연구들이 NeRF의 편집에 일부 성공을 보였음에도 불구하고, 완전히 덮이지 않은 영역에서의 합리적인 지오메트리 생성에는 어려움이 있다.
- 확산 모델에서의 높은 다양성은 NeRF의 명확하고 결정적인 지오메트리 수렴을 방해한다.
- 실제 데이터에 대한 잠재 확산 모델의 적용은 자동 인코딩 오류로 인해 이미지 조건과 불일치하는 질감 이동을 초래한다.
- 이 두 가지 문제는 픽셀 거리 손실 사용으로 더욱 강화된다.
- 우리는 확산 모델의 확률성을 각 장면별 맞춤형으로 조절하고, 마스크된 적대적 훈련을 통해 질감 이동을 완화하는 방법을 제안한다.
- 또한, 흔히 사용되는 픽셀 및 지각 손실이 NeRF 인페인팅 작업에 해롭다는 것을 분석을 통해 발견했다.
- 철저한 실험을 통해, 우리의 프레임워크는 다양한 실제 세계 장면에서 최첨단 NeRF 인페인팅 결과를 제공한다.

