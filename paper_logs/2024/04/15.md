## Daily Papers (2024-04-15)

### [COCONut: Modernizing COCO Segmentation](https://arxiv.org/abs/2404.08639)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08639.png)

Vote: 22

Authors: Qihang Yu, Liang-Chieh Chen, Xiaohui Shen, Peng Wang, Xueqing Deng

- 최근 수십 년 동안 데이터셋 벤치마크의 발전으로 시각 인식 연구가 눈부신 진전을 이루었으며, 특히 COCO 벤치마크는 현대의 탐지 및 분할 시스템 개발을 촉진하였습니다.
- 그러나 COCO 분할 벤치마크는 지난 10년간 비교적 느린 개선을 보여왔으며, 물체 인스턴스에 대한 거친 폴리곤 주석들로 시작하여, 점차적으로 스터프(stuff) 영역에 대한 거친 슈퍼픽셀 주석이 추가되었습니다.
- 이들 주석은 후에 융합되어 전경(foreground)과 배경(background)을 포함한 범위를 가진 팬옵틱 분할 주석을 생성하였으나, 다양한 평가자 그룹에 의해 수행되어 주석의 일관성이 떨어지고 주석의 질이 낮아졌습니다.
- 본 연구에서는 COCO 분할 주석을 종합적으로 재평가하고 주석의 질을 향상시킨 COCONut, 즉 COCO Next Universal segmenTation 데이터셋을 도입합니다.
- COCONut는 의미론적, 인스턴스, 팬옵틱 분할에 걸쳐 고도로 정제된 고품질 마스크를 통해 주석을 조화롭게 통합하며, 모든 분할 작업에 대한 강력한 벤치마크를 설정합니다.
- COCONut은 대규모 범주의 범용 분할 데이터셋으로서 첫선을 보이며, 인간 평가자에 의해 검증된 데이터셋입니다.
- COCONut의 출시가 커뮤니티의 신경망 진화 평가 능력을 크게 향상시킬 것으로 기대합니다.

### [Pre-training Small Base LMs with Fewer Tokens](https://arxiv.org/abs/2404.08634)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08634.png)

Vote: 22

Authors: Sunny Sanyal, Sujay Sanghavi, Alexandros G. Dimakis

- 본 연구는 기존의 큰 기본 언어 모델(LM)에서 몇 개의 트랜스포머 블록을 상속받고, 이 작은 모델을 원본 사전 훈련 데이터의 매우 작은 부분집합(0.1%)에서 훈련하는 간단한 접근 방식의 효과를 평가합니다.
- 이 방법을 'Inheritune'이라고 명명하고, 3B 매개변수의 큰 LM 초기 몇 층을 사용하여, 1B 토큰을 사용하는 1.5B 매개변수의 소형 기본 LM을 구축하는 데 처음 적용해 봤습니다; 이 작업은 A6000 GPU 단일 대에서 반나절 이내에 수행되었습니다.
- 결과 모델은 다양한 평가 데이터셋과 MMLU 벤치마크에서 1B-2B 크기의 공개적으로 사용 가능한 기본 모델들과 비교해 유리하게 나타났으며, 이는 일부 모델이 50-1000배 많은 토큰을 사용하여 훈련된 점을 고려할 때 주목할 만한 결과입니다.
- 또한 전체 사전 훈련 데이터셋을 사용하고 더 큰 LM의 일부 계층을 활용하여 소형 LM을 훈련하는 다소 다른 설정에서 Inheritune을 조사했으며, 이 경우 GPT-2-medium(355M)과 GPT-2-large(770M)의 모델들이 OpenWebText 데이터셋의 9B 토큰에 대해 같은 수의 훈련 스텝으로 처음부터 훈련된 상대 모델과 동등한 val 손실을 달성할 수 있음을 보여주었습니다.
- 다양한 설정에서의 실험을 통해 이 방법을 분석하고 그 효과를 입증했으며, 관련 코드는 https://github.com/sanyalsunny111/LLM-Inheritune 에서 확인할 수 있습니다.

### [Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies](https://arxiv.org/abs/2404.08197)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08197.png)

Vote: 16

Authors: Cihang Xie, Ekin Dogus Cubuk, Zichao Li

- 이 논문은 제한된 계산 예산으로 축소된 대조 언어-이미지 사전학습(CLIP)의 성능을 조사합니다.
- 데이터 측면에서, 고품질 학습 데이터의 중요성을 보여주고, 고품질의 작은 데이터 세트가 낮은 품질의 큰 데이터 세트보다 우수한 성능을 낼 수 있음을 입증합니다.
- 다양한 데이터 세트 크기에서 모델 성능이 어떻게 변하는지 조사하며, 작은 데이터 세트에는 작은 ViT 모델이, 큰 데이터 세트에서는 큰 모델이 고정된 계산에서 더 낫다고 제안합니다.
- CLIP 트레이닝에 CNN 기반 아키텍처와 ViT 기반 아키텍처 중 언제 어느 것을 선택할지에 대한 지침을 제공합니다.
- 네 가지 CLIP 훈련 전략(SLIP, FLIP, CLIP, CLIP+데이터 증강)을 비교하고, 훈련 전략의 선택이 사용 가능한 계산 자원에 따라 달라짐을 보여줍니다.
- CLIP+데이터 증강이 CLIP과 비슷한 성능을 달성하면서 훈련 데이터의 절반만을 사용할 수 있음을 분석합니다.
- 이 연구는 다양한 응용 프로그램에서 CLIP 모델을 효과적으로 훈련하고 배포하는 데 실용적인 통찰력을 제공하여, CLIP 모델을 더 접근하기 쉽고 비용 효율적으로 사용할 수 있게 합니다.

### [On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation](https://arxiv.org/abs/2404.08540)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08540.png)

Vote: 9

Authors: Tejas Gokhale, Chitta Baral, Agneet Chatterjee, Yezhou Yang

- 단안 깊이 추정 분야의 최근 발전은 추가적인 안내로 자연 언어를 도입하여 이루어졌습니다.
- 이 연구는 언어 선행의 영향, 특히 일반화 및 견고성 측면을 탐구하고 다양한 설정에서의 효과를 평가하는 방법을 소개합니다.
- "저수준" 문장을 생성하여 객체 중심의 3차원 공간 관계를 전달하고 깊이 추정에 미치는 영향을 평가합니다.
- 주요 발견은 현재의 언어 가이드 깊이 추정기가 장면 수준의 설명과 함께 최적으로 작동하며, 저수준 설명과 함께는 더 나쁜 결과를 보인다는 것입니다.
- 추가 데이터를 활용함에도 불구하고, 이러한 방법들은 직접적인 적대 공격에 견고하지 못하고 분포 변화가 증가함에 따라 성능이 저하됩니다.
- 미래 연구를 위한 기반을 제공하기 위해 실패 지점을 식별하고 이러한 단점을 더 잘 이해할 수 있는 통찰력을 제공합니다.
- 깊이 추정을 위해 언어를 사용하는 방법이 점점 더 많아짐에 따라, 실제 환경에서의 효과적인 배치를 위해 신중한 고려가 필요한 기회와 함정을 강조합니다.

### [Probing the 3D Awareness of Visual Foundation Models](https://arxiv.org/abs/2404.08636)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08636.png)

Vote: 8

Authors: Varun Jampani, Amit Raj, Kevis-Kokitsi Maninis, Michael Rubinstein, Yuanzhen Li, Justin Johnson, Deqing Sun, Leonidas Guibas, Mohamed El Banani, Abhishek Kar

- 최근 대규모 사전 학습의 진보는 강력한 능력을 가진 시각적 기초 모델들을 만들어냈습니다.
- 이 연구에서는, 해당 모델들이 2D에서 객체를 분류, 선명하게 하고, 위치를 지정할 수 있는지를 넘어, 그들이 객체의 3D 구조를 어떻게 표현하는지를 분석하였습니다.
- 3D 인식은 장면의 3D 구조를 부호화하고, 다양한 관점에서 표면을 일관되게 표현한다는 것을 의미한다고 가정합니다.
- 우리는 특정 작업을 위한 탐침법과 동결된 기능에 대한 제로샷 추론 절차를 사용하여 일련의 실험을 수행했습니다.
- 실험을 통해 현재 모델의 여러 제한 사항을 밝혀냈습니다.
- 연구의 코드와 분석은 https://github.com/mbanani/probe3d에서 확인할 수 있습니다.

### [Dataset Reset Policy Optimization for RLHF](https://arxiv.org/abs/2404.08495)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08495.png)

Vote: 7

Authors: Wenhao Shan, Jonathan D. Chang, Wen Sun, Jason D. Lee, Kianté Brantley, Dipendra Misra, Owen Oertell

- 인간 우선순위 기반 피드백으로부터의 강화학습(RL)은 GPT-4 및 Claude3 Opus와 같이 인상적인 생성 모델을 미세 조정하는 인기 있는 패러다임입니다.
- 이 연구에서는 리셋의 아이디어를 활용하여 개선된 RLHF 알고리즘인 'Dataset Reset Policy Optimization (DR-PO)'을 제안합니다.
- DR-PO는 오프라인 선호 데이터셋이 제공하는 정보적 상태를 활용하여, 항상 초기 상태 분포에서 시작하는 대신 오프라인 데이터셋의 상태로 정책 최적화기를 직접 리셋합니다.
- 이론적으로 DR-PO는 유한 샘플 복잡성을 가진 일반 함수 근사 아래에서 오프라인 데이터셋에 포함된 정책만큼의 성능을 배우는 것으로 보입니다.
- 실험에서는 DR-PO가 TL;DR 요약 및 Anthropic Helpful Harmful(HH) 데이터셋에서 'Proximal Policy Optimization (PPO)' 및 'Direction Preference Optimization (DPO)'보다 더 나은 성능을 보였음을 시연합니다.
- 이 연구의 코드는 https://github.com/Cornell-RL/drpo에서 확인할 수 있습니다.

### [MonoPatchNeRF: Improving Neural Radiance Fields with Patch-based Monocular Guidance](https://arxiv.org/abs/2404.08252)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.08252.png)

Vote: 4

Authors: Derek Hoiem, Jae Yong Lee, Chuhang Zou, Yuqun Wu, Shenlong Wang

- 다중 시점 스테레오(MVS) 벤치마크인 ETH3D에서 정규화된 신경 복사 필드(NeRF) 방법은 열악한 기하학 및 시점 외 보간을 생성합니다.
- 연구팀은 정확한 기하학 및 시점 합성을 제공하는 3D 모델을 생성하여 NeRF와 전통적인 MVS 방법 간의 큰 기하학적 성능 격차를 줄이고자 합니다.
- 단안 표면 법선 및 상대적 깊이 예측을 효과적으로 활용하는 패치 기반 방식을 제안합니다.
- 패치 기반 빛선 샘플링은 무작위 샘플링된 가상 및 훈련 시점 간의 정규화된 크로스-상관(NCC) 및 구조적 유사성(SSIM)의 모양 규제를 가능하게 합니다.
- 희소 구조 기반 동작(SfM) 포인트에 기반한 "밀도 제한"이 기하학적 정확도를 크게 향상시킬 수 있으며, 새로운 시점 합성 지표에서 약간의 감소가 발생합니다.
- 실험 결과, 이 방법은 ETH3D MVS 벤치마크에서 RegNeRF보다 4배, FreeNeRF보다 8배 개선된 평균 F1@2cm 성능을 보여줍니다.
- 이 연구는 NeRF 기반 모델의 기하학적 정확성을 향상시키는 유망한 연구 방향을 제시하고, 최종적으로 전통적인 MVS를 능가할 수 있는 NeRF 기반 최적화를 가능하게 하는 미래의 접근 방식에 대해 조명합니다.

