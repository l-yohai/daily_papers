## Daily Papers (2024-04-10)

### [OmniFusion Technical Report](https://arxiv.org/abs/2404.06212)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06212.png)

Vote: 60

Authors: Andrey Kuznetsov, Maxim Kurkin, Denis Dimitrov, Irina Abdullaeva, Matvey Skripkin, Ivan Oseledets, Anton Razzhigaev, Elizaveta Goncharova, Matvey Mikhalchuk

- 지난해, 다양한 모달성을 가진 구조가 인공지능 기반 접근법과 솔루션에서 혁명을 일으켰으며, 이는 대형 언어 모델의 기능을 확장했습니다.
- 우리는 사전 학습된 대형 언어 모델(LLM)에 기반을 둔 OmniFusion 모델을 제안하고, 여기에 시각적 모달을 위한 어댑터를 결합하였습니다.
- 텍스트와 시각 데이터의 더 나은 결합을 위해, MLP와 트랜스포머 어댑터, 다양한 CLIP ViT 기반 인코더(SigLIP, InternVIT 등) 등 여러 아키텍처 디자인 원칙을 평가하고 비교했습니다.
- 이미지 인코딩 방법인 전체 이미지 혹은 타일 인코딩, 그리고 두 개의 7B LLM(자체 개발된 모델과 오픈소스 Mistral)을 이용한 접근 방식을 평가했습니다.
- 8개의 시각-언어 벤치마크에서 OmniFusion 설정이 VizWiz, Pope, MM-Vet, ScienceQA, MMBench, TextVQA, VQAv2, MMMU 등과 같은 오픈소스 LLaVA와 비교하여 다양한 VQA 작업에 대한 최고 점수를 얻었습니다.
- OmniFusion은 가사, 관광, 문화, 의료, 수기 및 스캔된 방정식 인식 등 다양한 분야에서 상세한 답변을 제공한다는 점을 제안합니다.
- Mistral 기반 OmniFusion 모델은 https://github.com/AIRI-Institute/OmniFusion 에서 가중치, 훈련 및 추론 스크립트와 함께 오픈소스로 제공됩니다.

### [LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders](https://arxiv.org/abs/2404.05961)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.05961.png)

Vote: 36

Authors: Parishad BehnamGhader, Dzmitry Bahdanau, Marius Mosbach, Vaibhav Adlakha, Siva Reddy, Nicolas Chapados

- 대규모 디코더 전용 언어 모델(LLMs)이 현재 대부분의 NLP 작업과 벤치마크에서 최신 모델임에도 불구하고, 커뮤니티는 이러한 모델을 텍스트 임베딩 작업에 천천히 채택하고 있습니다.
- 본 논문에서는 'LLM2Vec'이라는 간단한 비지도 학습 방법을 소개하여, 어떠한 디코더 전용 LLM도 강력한 텍스트 인코더로 변환할 수 있는 방법을 제안합니다.
- LLM2Vec은 양방향 주의를 활성화시키고(masked next token prediction), 비지도 대조 학습을 포함하는 세 가지 간단한 단계로 구성됩니다.
- 1.3B에서 7B 매개변수에 이르기까지 3개의 인기 있는 LLM에 LLM2Vec을 적용하고, 영어 단어 및 시퀀스 레벨 태스크에서 변환된 모델을 평가하여 그 효과를 입증합니다.
- LLM2Vec은 단어 수준의 작업에서 인코더 전용 모델을 큰 차이로 능가하고, Massive Text Embeddings Benchmark (MTEB)에서 새로운 비지도 상태의 최상급 성능을 달성합니다.
- 또한, 감독된 대조 학습과 LLM2Vec을 결합 할 때, 공개적으로 사용 가능한 데이터만으로 훈련하는 모델 중 MTEB에서 최고의 성능을 달성합니다.
- 우리의 강력한 실증적 결과와 광범위한 분석은 LLM을 비용 효율적인 방식으로 범용 텍스트 인코더로 효과적으로 변환할 수 있다는 것을 보여줍니다.

### [InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD](https://arxiv.org/abs/2404.06512)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06512.png)

Vote: 19

Authors: Jingwen Li, Bin Wang, Zhe Chen, Wenhai Wang, Xiaoyi Dong, Wei Li, Jifeng Dai, Yining Li, Linke Ouyang, Yuhang Zang, Hang Yan, Wenwei Zhang, +, Songyang Zhang, Yu Qiao, Yuhang Cao, Conghui He, Xingcheng Zhang, Pan Zhang, Haodong Duan, Kai Chen, Xinyue Zhang, Yang Gao

- 최신 비전-언어 모델(Vision-Language Model, 이하 LVLM) 분야에서는 고해상도 이해 능력을 강화하기 위한 노력에도 불구하고, 그동안의 모델들은 대략 1500 x 1500 픽셀의 해상도와 좁은 범위에 제한되어 있었습니다.
- 본 논문은 InternLM-XComposer2-4KHD를 소개하며, 이는 LVLM의 해상도 기능을 4K HD (3840 x 2160) 이상으로 확장하는 독창적인 탐구입니다.
- 해당 연구는 극한의 고해상도가 모든 시나리오에서 필요하지 않다는 점을 고려하여, 336 픽셀부터 4K 표준까지 다양한 해상도 범위를 지원합니다.
- 특히, 이미지의 종횡비를 유지하며 패치 수를 자동으로 변화시키고 레이아웃을 구성하는 새로운 방법인 동적 해상도와 자동 패치 구성을 소개합니다.
- 연구 결과에 따르면, 교육 해상도를 4K HD로 확장하는 것이 성능 향상을 가져오며 아직 개선 가능성의 한계에 도달하지 않았습니다.
- InternLM-XComposer2-4KHD는 GPT-4V와 Gemini Pro를 포함한 16개 벤치마크 중 10개에서 뛰어난 성능을 보여주었습니다.
- 7B 매개변수를 갖는 InternLM-XComposer2-4KHD 모델 시리즈는 https://github.com/InternLM/InternLM-XComposer에서 공개적으로 제공됩니다.

### [Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence](https://arxiv.org/abs/2404.05892)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.05892.png)

Vote: 16

Authors: Eugene Cheah, Ronald McClelland Jr., Ruichong Zhang, Kranthi Kiran GV, Eric Alcaide, Quentin Anthony, Haoqin Tu, Stella Biderman, Satyapriya Krishna, Jan Kocoń, Guangyu Song, Teddy Ferdinan, Bo Peng, Fares Obeid, Przemysław Kazienko, +, Bartłomiej Koptyra, Alon Albalak, Niklas Muennighoff, Haowen Hou, Stanisław Woźniak, Atsushi Saito, Daniel Goldstein

- 이 논문은 RWKV(Recurrent Weighted Kernel Vector) 아키텍처의 개선 버전인 Eagle (RWKV-5)과 Finch (RWKV-6) 시퀀스 모델을 소개한다.
- 새로운 아키텍처는 다중 헤드 행렬-값 상태와 표현력을 향상시키면서도 RNN의 추론 효율성을 유지하는 동적 반복 메커니즘을 도입하였다.
- 저자들은 1.12 조 토큰을 포함하는 새로운 다국어 코퍼스와, 고급 다국어 지원을 위한 탐욕적 매칭 기반의 빠른 토크나이저를 소개한다.
- 연구팀은 0.46억에서 75억 매개변수에 이르는 네 가지 Eagle 모델과 16억 및 31억 매개변수의 두 Finch 모델을 훈련시켰으며, 다양한 벤치마크에서 경쟁력 있는 성능을 달성하였다고 한다.
- 모든 모델은 아파치 2.0 라이선스 하에 HuggingFace에서 공개되었으며, 훈련 코드와 추론 코드, 시간병렬 훈련 코드는 각각의 깃허브 저장소를 통해 제공된다.

### [Hash3D: Training-free Acceleration for 3D Generation](https://arxiv.org/abs/2404.06091)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06091.png)

Vote: 12

Authors: Xingyi Yang, Xinchao Wang

- 본 논문에서는 모델 훈련 없이 3D 생성 속도를 향상시키기 위한 Universal acceleration 방법인 Hash3D를 소개합니다.
- Hash3D의 핵심 아이디어는 근접한 카메라 위치와 확산 시간 단계에서 생성된 이미지의 피쳐 맵 중복이 빈번한 점에 기반합니다.
- 해싱 기법을 이용하여 이 피쳐 맵들을 효과적으로 재활용함으로써, 인접한 시간 단계 및 카메라 각도에 걸쳐 중복 계산을 대폭 방지하고, 3D 생성 작업에서 확산 모델 추론의 속도를 크게 높입니다.
- 적응형 그리드 기반 해싱을 통해 이루어지며, 이러한 피쳐 공유 메커니즘은 생성 속도를 높이는 것뿐만 아니라 합성된 3D 객체의 부드러움과 시점 일관성을 개선합니다.
- 다양한 텍스트-투-3D 및 이미지-투-3D 모델을 포함한 실험을 통해, Hash3D가 최적화 속도를 높이며 효율성을 1.3배에서 4배까지 향상시킨다는 것을 입증했습니다.
- Hash3D의 3D 가우시안 스플래팅과의 통합은 3D 모델 생성을 크게 가속화하여, 텍스트-투-3D 처리를 대략 10분으로, 이미지-투-3D 변환을 약 30초로 줄일 수 있습니다.
- 프로젝트 페이지는 https://adamdad.github.io/hash3D/에서 확인할 수 있습니다.

### [MuPT: A Generative Symbolic Music Pretrained Transformer](https://arxiv.org/abs/2404.06393)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06393.png)

Vote: 12

Authors: Xinrun Du, Jiaheng Liu, Ziyang Ma, Yinghao Ma, Ruibin Yuan, Shangda Wu, Yiming Liang, Shuyue Guo, Ziya Zhou, Wei Xue, Tianyu Zheng, Xueling Liu, Gus Xia, Emmanouil Benetos, Junting Zhou, Lejun Min, +, Ka Man Lo, Xingwei Qu, Tianyu Zhang, Yuelin Bai, Yizhi Li, Fengze Han

- 이 논문에서는 거대 언어 모델들(Large Language Models, LLMs)을 음악의 사전 훈련(pre-training)에 적용하는 것을 탐구합니다.
- 음악 모델링에서 MIDI의 사용이 일반적이지만, LLM의 설계와 강점에 더 잘 부합하는 ABC 표기법(ABC Notation)이 모델의 음악 작곡 성능을 향상시킨다는 것을 발견했습니다.
- 다른 트랙의 미조정된 조치들을 생성하는 동안 발생하는 문제를 해결하기 위해, 다중 음악 트랙 간의 일관성을 유지하는 Synchronized Multi-Track ABC Notation (SMT-ABC Notation)을 개발할 것을 제안합니다.
- 우리의 기여 중 하나는 훈련 세트에 있는 상징적 음악 데이터의 90%를 포괄할 수 있는 최대 8192 토큰을 다룰 수 있는 일련의 모델입니다.
- 또한, Symbolic Music Scaling Law (SMS Law)가 모델 성능에 미치는 영향을 탐구합니다.
- 연구 결과는 음악 생성 분야의 미래 연구 방향을 제시하며, 우리의 오픈 소스 기여를 통해 커뮤니티 주도의 연구에 광범위한 자원을 제공합니다.

### [MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies](https://arxiv.org/abs/2404.06395)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06395.png)

Vote: 11

Authors: Yewei Fang, Guoyang Zeng, Zhi Zheng, Ning Ding, Yuxiang Huang, Xinrong Zhang, Jie Zhou, Yuge Tu, Chongyi Wang, Kaihuo Zhang, Shengding Hu, Yuan Yao, Xu Han, Xiang Long, Zhongwu Zhai, Zheng Leng Thai, Jie Cai, Ganqu Cui, +, Chao Jia, Chenyang Zhao, Chaoqun He, Weilin Zhao

- 대규모 언어 모델(LLMs)에 대한 관심이 증가하는 가운데, 자원 효율성과 실험 비용에 대한 우려가 커지면서, 작은 언어 모델(SLMs)의 잠재력 탐구의 중요성이 강조되고 있습니다.
- 연구자들은 MiniCPM이라는 모델을 소개하고 있으며, 특히 1.2B와 2.4B 비임베딩 파라미터 버전은 각각의 범주에서 뛰어난 성능을 보이고, 7B-13B LLM들과 비교해도 동등한 능력을 발휘함을 보여줍니다.
- SLM에 초점을 맞추면서 모델과 데이터 차원에서 확장 가능성을 보여주었으며, 안정적이고 최적의 확장을 위해 모델 윈드 터널 실험을 광범위하게 진행했습니다.
- 데이터 스케일링을 위해, 연속적인 훈련과 도메인 적응에 적합한 Warmup-Stable-Decay (WSD) 학습률 스케줄러를 소개합니다.
- WSD 학습률 스케줄러를 통해, 데이터-모델 스케일링 법칙을 효율적으로 연구할 수 있게 되었으며, Chinchilla Optimal보다 훨씬 높은 컴퓨트 최적 데이터-모델 비율을 도출해냈습니다.
- 또한, MiniCPM-DPO, MiniCPM-MoE, MiniCPM-128K를 포함하는 MiniCPM 패밀리를 소개하며, 이 모델들은 다양한 SLM 응용 분야에서 MiniCPM의 효과적인 성능을 더욱 확고히 해줍니다.
- MiniCPM 모델은 https://github.com/OpenBMB/MiniCPM 에서 공개적으로 이용할 수 있습니다.

### [CodecLM: Aligning Language Models with Tailored Synthetic Data](https://arxiv.org/abs/2404.05875)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.05875.png)

Vote: 9

Authors: Vincent Perot, Chen-Yu Lee, Long T. Le, Chun-Liang Li, Tomas Pfister, Zifeng Wang, Jin Miao, Zizhao Zhang

- 대규모 언어 모델(Large Language Models, LLMs)을 특정 작업 지시에 맞게 조정하는 과정에서 지시 튜닝(instruction tuning)이 중요한 방법으로 떠오르고 있으며, 이는 사용자의 실제 목적과 다음 토큰 예측 목표 사이의 불일치를 완화하는 데 도움이 됩니다.
- 이러한 지시 튜닝을 위해, 연구자들은 고품질의 합성 데이터를 생성해내는 언어 모델의 능력을 활용하기 시작했는데, 기존 연구들은 대부분 다양한 지시문을 생성하고 지시문의 복잡성을 높이는 데 집중하고 있었습니다.
- 하지만, 특정 대상 지시 분포(target instruction distributions)와 언어 모델에 맞는 고품질의 데이터를 맞춤화하는 방법이 명확하지 않아, 더 나은 지시 따르기 능력을 유도하는 데 필요한 데이터를 조작하는 방법이 불투명했습니다.
- 우리는 다양한 대상 지시 분포와 LLMs에 맞게 고품질의 합성 데이터를 적응적으로 생성하는 일반적인 프레임워크인 CodecLM을 소개합니다.
- CodecLM은 인코딩-디코딩 원리를 활용하여, 핵심 키워드로 이루어진 메타데이터를 실시간으로 생성하고, 이를 바탕으로 맞춤형 지시문을 만드는 방식으로 데이터 생성 과정을 가이드합니다.
- 또한, 맞춤형 데이터의 효율적인 샘플을 생성하기 위해 디코딩 과정 중에 자체 평가 기준(Self-Rubrics)과 대조 필터링(Contrastive Filtering)을 도입했습니다.
- 네 개의 개방형 지시 따르기 벤치마크에서 실시한 광범위한 실험을 통해 CodecLM이 현재 최고 수준의 기술보다 더 효과적임을 입증하고 있습니다.

### [SambaLingo: Teaching Large Language Models New Languages](https://arxiv.org/abs/2404.05829)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.05829.png)

Vote: 8

Authors: Leon Zhang, Urmish Thakker, Pian Pawakapan, Jonathan Li, Qiantong Xu, Yun Du, Bo Li, Changran Hu, Hengyu Zhao, Zoltan Csaki

- 대규모 언어 모델(LLMs)은 널리 사용되고 있음에도 불구하고, 다양한 언어 사이에서 여전히 능력과 접근성에 큰 격차가 있다.
- 기존의 대규모 언어 모델에 새로운 언어를 지속적으로 학습시키는 방법이 이러한 문제를 해결하기 위한 접근법 중 하나다.
- 이전의 연구들이 언어 적응에 대해 실험을 해왔지만, 최선의 방법론과 실천에 대한 많은 질문들이 남아있다.
- 본 논문에서는 대규모 언어 모델이 새로운 언어에 적용되는 방법에 대한 포괄적인 조사를 발표한다.
- 어휘 확장, 직접 우선순위 최적화, 저자원 언어에서 인간 정렬을 위한 데이터 부족 문제 등 적응 과정의 주요 구성 요소들을 다룬다.
- 7B와 70B의 두 가지 파라미터 규모에서 9개 언어에 걸친 실험을 확대하였다.
- Llama 2, Aya-101, XGLM, BLOOM 및 기존 언어 전문가들과 비교하여 우리 모델이 모든 기존에 발표된 베이스라인을 능가한다.
- 미래의 연구를 촉진하기 위해 모든 평가 코드와 체크포인트를 공개한다.

### [Revising Densification in Gaussian Splatting](https://arxiv.org/abs/2404.06109)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06109.png)

Vote: 5

Authors: Lorenzo Porzi, Peter Kontschieder, Samuel Rota Bulò

- 본 논문은 Adaptive Density Control (ADC)이 가진 3D Gaussian Splatting (3DGS)의 한계를 다루며, 이는 향상된 뷰 합성을 위해 사실적인 화질을 달성하는 3D 장면 표현 방법에 사용된다.
- ADC는 자동적인 3차원 점 원시 관리를 위해 도입되었으나, 본래의 농도 조절 로직에 몇 가지 제한이 있었다.
- 이 논문의 주요 기여는, 보조 픽셀-오류 함수를 기준으로 이용하여 3DGS에서 더 원칙적이고 픽셀-오류 기반의 밀도 관리를 위한 새로운 공식을 제시한다.
- 또한, 장면당 생성되는 프리미티브의 총 수를 조절하는 메커니즘을 소개하고, ADC의 복제 동작 중 투명도 처리 전략의 편향을 수정한다.
- 제안된 접근법은 다양한 벤치마크 장면에서 일관된 품질 향상을 이끌어내면서도 방법의 효율성을 희생하지 않는다.

### [Reconstructing Hand-Held Objects in 3D](https://arxiv.org/abs/2404.06507)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06507.png)

Vote: 5

Authors: Jitendra Malik, Jane Wu, Georgia Gkioxari, Georgios Pavlakos

- 손으로 조작되는 물체(즉, 조작물)는 손에 의해 대부분 가려지고 이미지 픽셀에서 단지 소수에만 보이기 때문에 야생에서 찍힌 RGB 이미지나 비디오로부터 3D로 재구성하는 것이 특히 도전적입니다.
- 이 설정에서 두 가지 강력한 단서가 나타나는데, (1) 추정된 3D 손이 물체의 위치와 크기를 알아내는 데 도움이 되고 (2) 조작물의 집합은 가능한 모든 물체에 비해 상대적으로 작습니다.
- 이러한 통찰을 바탕으로, 저희는 최신의 대규모 언어/비전 모델과 3D 물체 데이터셋의 돌파구를 활용하여 소형 물체 재구성을 위한 확장 가능한 패러다임을 제시합니다.
- 우리의 모델인 MCC-Hand-Object (MCC-HO)는 단일 RGB 이미지와 추론된 3D 손을 입력으로 사용하여 손과 물체의 기하학적 구조를 공동으로 재구성합니다.
- 이후에, 우리는 GPT-4(V)를 사용하여 이미지의 물체와 일치하는 3D 물체 모델을 검색해내고, 이를 네트워크가 추론한 기하학에 따라 강건하게 정렬시키는데, 이를 검색-보강된 재구성(Retrival-Augmented Reconstruction, RAR)이라고 부릅니다.
- 실험 결과 MCC-HO는 실험실과 인터넷 데이터셋에서 최첨단 성능을 달성하는 것이 확인되었으며, RAR를 사용하여 손-물체 상호작용의 야생 이미지에 대한 3D 라벨을 자동으로 얻는 방법을 보여줍니다.

### [Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models](https://arxiv.org/abs/2404.06209)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06209.png)

Vote: 4

Authors: Besmira Nushi, Sebastian Bordt, Harsha Nori, Vanessa Rodrigues, Rich Caruana

- 대규모 언어 모델(Large Language Models, LLMs)의 데이터 오염 및 암기 문제를 탐구한다.
- 훈련 중 본 적이 있는 표 형식 데이터셋이 언어 모델에 의해 암기되었는지 검증하는 여러 기법을 소개한다.
- LLM이 유명한 표 데이터셋을 직접 암기한 사례가 많다는 것을 발견했다.
- 훈련 데이터셋에서 본 데이터셋과 훈련 후 출시된 데이터셋의 few-shot 학습 성능을 비교하여 영향을 분석했다.
- LLM이 훈련 중 본 데이터셋에서 더 나은 성능을 보이며, 이는 암기가 과적합을 초래할 수 있음을 시사한다.
- LLM은 처음 접하는 데이터셋에서도 상당한 성능을 보이며 데이터 변형에도 강건함을 보인다.
- 훈련 없이도 LLM의 컨텍스트 내 통계적 학습 능력을 조사하였으나, 이는 제한적임을 발견했다.
- LLM의 few-shot 성능은 대부분 세계 지식에 기인한다고 추정된다.
- 사전 훈련 중 평가 데이터셋을 본 적이 있는지 테스트하는 것의 중요성을 강조하며, 개발된 노출 테스트 도구를 'tabmemcheck' 파이썬 패키지로 공개한다.

### [Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion](https://arxiv.org/abs/2404.06429)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06429.png)

Vote: 4

Authors: Chenxu Zhang, Xiaofeng Yang, Bowen Chen, Guosheng Lin, Huichao Zhang, Jianfeng Zhang, Jiashi Feng, Fan Yang, Yichun Shi

- 2D 확산 모델의 급속한 발전에 힘입어 최근 3D 콘텐츠 생성이 크게 진전을 이루었습니다.
- 기존 방법은 훈련된 2D 확산 모델을 미세조정하여 다시점 이미지를 생성하고, 이를 fast-NeRFs나 대규모 복원 모델을 통해 정확한 3D 모델로 변환하지만, 일관성이 결여되고 해상도가 제한적이라는 문제점이 있습니다.
- 이를 해결하고자 본 논문에서는 'Magic-Boost'라는 다시점 조건 확산 모델을 제안하여 거친 생성 결과를 짧은 SDS 최적화(약 15분) 기간을 통해 크게 개선합니다.
- Magic-Boost는 가짜로 합성된 다시점 이미지로부터 일관성 있는 고화질 이미지를 생성하는 강력한 능력을 보여주며, 입력 이미지의 정체성과 잘 일치하는 정밀한 SDS 안내를 제공합니다.
- 이를 통해 초기 생성 결과의 기하학적 및 질감의 지역적인 디테일을 풍부하게 만듭니다.
- 광범위한 실험을 통해 Magic-Boost가 거친 입력을 크게 향상시키고, 풍부한 기하학적 및 질감 디테일을 갖춘 고품질의 3D 자산을 생성함을 보여줍니다.
- 프로젝트 페이지는 다음과 같습니다: [https://magic-research.github.io/magic-boost/](https://magic-research.github.io/magic-boost/).

