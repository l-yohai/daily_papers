## Daily Papers (2024-04-29)

### [PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning](https://arxiv.org/abs/2404.16994)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.16994.png)

Vote: 20

Authors: Jiashi Feng, Lin Xu, Yilin Zhao, Zhijie Lin, Daquan Zhou, See Kiong Ng

- 시각-언어 사전 학습은 다양한 이미지-언어 응용 분야에서 성능을 크게 향상시켰지만, 비디오 관련 작업의 사전 학습 과정은 막대한 계산 및 데이터 자원을 요구하여 비디오-언어 모델의 발전을 저해합니다.
- 이 논문은 기존의 이미지-언어 사전 훈련 모델을 비디오 데이터셋에서 다중 프레임 입력으로 직접 미세 조정할 때 성능 포화 또는 하락이 발생함을 발견하였습니다.
- 높은 노름을 가진 시각적 특징의 편향 때문에 이러한 문제가 발생한다는 것을 확인한 후, 우리는 시간적 차원을 따라 특징 분포를 평활화하고 극단적인 특징들의 지배적인 영향을 줄이는 간단하지만 효과적인 풀링 전략을 제안합니다.
- 새로운 모델인 Pooling LLaVA(PLLaVA)는 비디오 질문-응답 및 캡션 작업에 대한 현대 벤치 마크 데이터셋에서 새로운 최첨단 성능을 달성했습니다.
- 최근 인기 있는 Video ChatGPT 벤치마크에서 PLLaVA는 평가된 다섯 가지 차원의 평균 3.48의 점수를 기록하여 이전 GPT4V(IG-VLM)의 상태 결과보다 9% 높았습니다.
- 최신 멀티 초이스 벤치마크 MVBench에서는 20개 하위 작업 평균 58.1%의 정확도를 달성하여 GPT4V(IG-VLM)보다 14.5% 높은 성능을 보였습니다.
- 관련 코드는 https://github.com/magic-research/PLLaVA에서 확인할 수 있습니다.

### [AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs](https://arxiv.org/abs/2404.16873)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.16873.png)

Vote: 15

Authors: Arman Zharmagambetov, Yuandong Tian, Brandon Amos, Chuan Guo, Anselm Paulus

- 최근 큰 언어 모델(Large Language Models, LLMs)은 높은 성공을 거두고 있지만, 부적절하거나 해로운 내용을 생성하도록 유도하는 대항적 공격(jailbreaking attacks)에 취약하다.
- 수동적인 red-teaming 접근은 프롬프트를 통해 모델을 오도하도록 만드는 데 시간이 많이 소요되며 비효율적이다.
- 자동 대항적 프롬프트 생성은 문법적으로 의미 없는 공격을 유발하거나, 대상 LLM의 기울기 정보가 필요하거나, 토큰 공간에 대한 시간 소모적인 이산 최적화 과정을 필요로 하는 문제가 있다.
- 본 논문에서는 AdvPrompter라는 새로운 LLM을 사용하여 초당 몇 초 만에 인간이 읽을 수 있는 대항적 프롬프트를 생성하는 새로운 방법을 제시한다.
- AdvPrompter는 대상 LLM의 기울기에 대한 접근 없이도 학습이 가능하며, 높은 질의 대항적 접미사를 생성하고 이를 이용하여 저랭크로 미세 조정하는 단계를 반복하는 새로운 알고리즘을 사용한다.
- 훈련된 AdvPrompter는 입력 지시문의 의미를 변경하지 않으면서 대상 LLM이 해로운 반응을 유도하도록 입력 지시문을 가린 접미사를 생성한다.
- AdvPrompter는 오픈 소스 대상 LLM에 대한 실험 결과에서 최고의 성능을 보이며, 비공개 상자형 LLM API에서도 결과가 전이된다.
- 또한, AdvPrompter가 생성한 합성 데이터셋을 이용한 미세 조정을 통해 LLM이 면역력을 갖추도록 하여 성능을 유지하면서 대항적 공격에 대한 robustness를 향상시킬 수 있다.

### [MaPa: Text-driven Photorealistic Material Painting for 3D Shapes](https://arxiv.org/abs/2404.17569)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.17569.png)

Vote: 7

Authors: Sida Peng, Nan Xue, Hujun Bao, Ruizhen Hu, Tianrun Chen, Yuanbo Yang, Shangzhan Zhang, Yujun Shen, Xiaowei Zhou, Tao Xu

- 이 논문은 텍스트 설명에서 3D 메시(mesh)의 재질을 생성하고자 합니다.
- 기존의 텍스처 맵을 합성하는 방법과 달리, 높은 품질의 렌더링을 지원하고 편집에 유연성을 제공하는 세그먼트별 절차적 재질 그래프를 생성하는 새로운 접근 방식을 제안합니다.
- 3D 메시와 재질 그래프 그리고 해당 텍스트 설명이 포함된 광범위한 쌍 데이터에 의존하는 대신, 텍스트와 재질 그래프를 연결하기 위해 사전 훈련된 2D 확산 모델을 활용합니다.
- 접근법에서는 형상을 여러 세그먼트로 분해하고, 각 메시 부분과 일치하는 2D 이미지를 합성하기 위해 세그먼트 제어 확산 모델을 설계합니다.
- 생성된 이미지를 바탕으로 재질 그래프의 매개변수를 초기화하고, 텍스트 설명에 부합하는 재질을 생산하기 위해 차별화 가능한 렌더링 모듈을 통해 이를 세밀하게 조정합니다.
- 광범위한 실험을 통해 우리 프레임워크가 기존 방법보다 사진적 리얼리즘, 해상도 및 편집 가능성 면에서 우수한 성능을 보여줌을 입증합니다. 
- 프로젝트 페이지: https://zhanghe3z.github.io/MaPa/

### [HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained Photo Collections](https://arxiv.org/abs/2404.16845)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.16845.png)

Vote: 4

Authors: Hadar Averbuch-Elor, Itai Lang, Chen Dudai, Rana Hanocka, Hana Bezalel, Morris Alper

- 이 연구는 대규모 관광 명소의 사진을 포함한 인터넷 이미지 컬렉션을 디지털로 탐색하는 데 유용하다고 제시합니다.
- 기존 작업은 주로 기하학적 재구성과 시각화에 초점을 맞추었지만, 언어의 역할을 활용하여 탐색 및 세밀한 이해를 도모하는 시맨틱 인터페이스 제공에 소홀했습니다.
- 본 연구에서는 대규모 랜드마크를 묘사하는 장면의 신경 표현과 장면 내 시맨틱 지역을 설명하는 텍스트를 연결하는 지역화 시스템을 소개합니다.
- 상태 최고의 비전 및 언어 모델의 힘을 활용하고 랜드마크 장면 시맨틱을 이해하기 위한 적응을 통해 세밀한 지식을 보강합니다.
- 인터넷에서 비슷한 랜드마크의 이미지와 약하게 관련된 텍스트 정보를 포함하는 대규모 데이터를 활용합니다.
- 이미지가 공간에 물리적으로 구현될 때 새로운 개념을 지역화하는 데 강력한 감독 신호를 제공할 수 있다고 가정합니다.
- 이러한 시맨틱은 큰 언어 모델로 인터넷 텍스트 메타데이터에서 잠금해제될 수 있으며, 장면의 뷰 사이의 대응 관계를 사용하여 이 시맨틱의 공간 이해를 부트스트랩합니다.
- 3D 호환 세분화에 대한 지침을 제공하고, 결국 부피 있는 장면 표현으로 리프팅합니다.
- HaLo-NeRF는 건축 랜드마크에 관련된 다양한 시맨틱 개념을 정확하게 지역화할 수 있으며, 기타 3D 모델과 강력한 2D 세분화 기준을 뛰어넘는 결과를 보여줍니다.
- 프로젝트 페이지는 https://tau-vailab.github.io/HaLo-NeRF/에서 확인할 수 있습니다.

