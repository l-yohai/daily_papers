## Daily Papers (2024-04-24)

### [OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework](https://arxiv.org/abs/2404.14619)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.14619.png)

Vote: 58

Authors: Chenfan Sun, Yanzi Jin, Mahyar Najibi, Iman Mirzadeh, Maxwell Horton, Dmitry Belenko, Qingqing Cao, Mohammad Hossein Sekhavat, Peter Zatloukal, Mohammad Rastegari, Sachin Mehta

- OpenELM은 투명성과 검증 가능성이 중요한 대규모 언어 모델의 개방형 연구를 발전시키기 위하여 고안된 최신 오픈 언어 모델입니다.
- 이 모델은 트랜스포머 모델의 각 레이어 내에서 효율적으로 파라미터를 배분하는 계층적 스케일링 전략을 사용하여, 약 10억 개의 파라미터를 가진 예산으로 2.36%의 정확도 향상을 달성했습니다.
- OpenELM은 과거의 연구와 달리 단순히 모델 가중치와 추론 코드만 제공하는 것이 아니라, 공개 데이터 세트에서의 전체 훈련 및 평가 프레임워크를 포함합니다.
- 이 릴리스는 훈련 로그, 다양한 체크포인트, 사전 훈련 구성뿐만 아니라, 애플 디바이스에서의 추론 및 미세조정을 위한 MLX 라이브러리로 모델을 변환하는 코드도 포함하고 있습니다.
- 이러한 광범위한 공개는 개방형 연구 커뮤니티를 강화하고 미래의 개방형 연구 노력을 위한 길을 마련하는 것을 목표로 합니다.
- 출시된 소스 코드, 사전 훈련된 모델 가중치 및 훈련 레시피는 https://github.com/apple/corenet 에서 확인할 수 있으며, HuggingFace에서도 OpenELM 모델을 찾아볼 수 있습니다: https://huggingface.co/apple/OpenELM.

### [Multi-Head Mixture-of-Experts](https://arxiv.org/abs/2404.15045)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.15045.png)

Vote: 29

Authors: Xun Wu, Shaohan Huang, Furu Wei, Wenhui Wang

- Sparse Mixture of Experts (SMoE) 모델의 용량을 증가시킬 수 있으나 전문가 활성화가 낮고 개별 토큰 내 다중 의미 개념에 대한 세밀한 분석 능력이 부족한 문제가 있습니다.
- 다중 헤드 방식을 도입한 Multi-Head Mixture-of-Experts (MH-MoE)는 각 토큰을 여러 서브 토큰으로 분할하고, 이를 다양한 전문가에 할당하여 병렬 처리 후 원래 토큰 형태로 재통합합니다.
- 이 다중 헤드 메커니즘은 모델이 다양한 전문가의 표현 공간에서 정보를 종합적으로 수집할 수 있게 하여 전문가 활성화를 크게 향상시키고, 문맥 이해를 깊게하며 과적합을 완화합니다.
- MH-MoE는 구현이 간단하며, 다른 SMoE 최적화 방법과 독립적이어서 기존 SMoE 모델과의 통합이 용이합니다.
- 영어 중심 언어 모델링, 다국어 언어 모델링, 마스크된 다중 모달 모델링 작업에서의 광범위한 실험 결과가 MH-MoE의 효과를 입증합니다.

### [Pegasus-v1 Technical Report](https://arxiv.org/abs/2404.14687)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.14687.png)

Vote: 21

Authors: Hyojun Go, Jae Lee, Abraham Jo, SJ Kim, Aiden Lee, Jiho Jang, Lucas Lee, Wade Jeong, Jin-Young Kim, Junwan Kim, +, Minjoon Seo, Ed Park, Tony Moon, Jeff Kim, Mars Ha, Jaehyuk Yi, Kyle Park, Daniel Kim, Raehyuk Jung, Hassan Kianinejad, Jay Suh, Cooper Han

- 이 기술 보고서는 자연어를 통해 비디오 콘텐츠의 이해와 상호작용을 전문으로 하는 다중 모달 언어 모델인 Pegasus-1을 소개합니다.
- Pegasus-1은 시공간 정보를 해석하는 것과 같은 비디오 데이터에 의해 제기된 독특한 도전을 해결하기 위해 설계되었습니다.
- 이 보고서는 Pegasus-1의 아키텍처, 훈련 전략, 비디오 대화, 제로샷 비디오 질문 응답, 그리고 비디오 요약에 대한 벤치마크에서의 성능을 개관합니다.
- 또한, Pegasus-1의 현재 상태와 미래 방향에 대한 균형 잡힌 시각을 제공하기 위해, 이 모델의 능력과 한계를 설명하는 질적 특성을 탐구합니다.

### [SnapKV: LLM Knows What You are Looking for Before Generation](https://arxiv.org/abs/2404.14469)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.14469.png)

Vote: 19

Authors: Patrick Lewis, Yuhong Li, Hanchen Ye, Bowen Yang, Tianle Cai, Bharat Venkitesh, Deming Chen, Acyr Locatelli, Yingbing Huang

- 'SnapKV'라는 새로운 시스템은 키-값(KV) 캐시의 크기를 효율적으로 줄이면서 실제 애플리케이션에서 경쟁력 있는 성능을 유지합니다.
- 이 시스템은 모델의 각 주의력 헤드가 생성 중 특정 프롬프트 주의력 특성에 일관되게 집중하는 것을 발견하고, 이 패턴을 '관찰' 창을 통해 얻을 수 있습니다.
- SnapKV는 중요한 KV 위치를 클러스터링하여 자동으로 KV 캐시를 압축하고, 긴 입력 시퀀스를 처리할 때 컴퓨터 비용과 메모리 사용을 크게 줄입니다.
- 구체적으로, SnapKV는 입력 길이가 16K 토큰일 때 기존 모델 대비 생성 속도는 3.6배, 메모리 효율성은 8.2배 향상되었습니다.
- 또한, SnapKV는 HuggingFace 구현을 소폭 변경하여 단일 A100-80GB GPU에서 최대 380K 컨텍스트 토큰을 처리할 수 있으며, Needle-in-a-Haystack 테스트에서 정확도 저하가 거의 없습니다.
- 이 연구는 SnapKV가 실용적인 애플리케이션에 매우 유용할 잠재력을 가지고 있음을 제안합니다.

### [Transformers Can Represent $n$-gram Language Models](https://arxiv.org/abs/2404.14994)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.14994.png)

Vote: 14

Authors: Ryan Cotterell, Anej Svete

- 본 논문에서는 언어 모델을 언어 수용의 관점에서만 평가해 온 기존 연구들의 한계를 지적하며, 트랜스포머 언어 모델과 n-gram 언어 모델과의 관계에 집중합니다.
- 트랜스포머 언어 모델이 하드 또는 스파스 주의 메커니즘을 사용할 경우, 어떤 n-gram 언어 모델도 정확히 표현할 수 있음을 보여주어, 그들의 확률적 표현 능력에 대한 구체적인 하한을 제공합니다.
- 이는 트랜스포머 언어 모델이 문자열 위의 확률 분포를 어떻게 표현할 수 있는지 이해하는 첫 걸음을 제공합니다.

### [FlashSpeech: Efficient Zero-Shot Speech Synthesis](https://arxiv.org/abs/2404.14700)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.14700.png)

Vote: 14

Authors: Zhen Ye, Jiahao Pan, Yiwen Lu, Qifeng Liu, Wei Xue, Weizhen Bian, Haohe Liu, Shulin He, Xu Tan, Jianyi Chen, Yike Guo, Zeqian Ju, Peiwen Sun

- 최근 대규모 제로샷 음성 합성의 진보는 언어 모델과 확산 모델에 의해 크게 발전했으나, 이들 방법의 생성 과정은 느리고 계산 집약적이다.
- 본 논문에서는 기존 연구 대비 약 5%의 추론 시간으로 가능한 대규모 제로샷 음성 합성 시스템인 FlashSpeech를 제시한다.
- FlashSpeech는 잠재 일관성 모델을 기반으로 하며, 사전 학습된 확산 모델 없이도 처음부터 학습할 수 있는 새로운 적대적 일관성 훈련 접근법을 적용한다.
- 새로운 프로조디 생성 모듈은 프로조디의 다양성을 증가시켜 음성의 리듬을 더 자연스럽게 만든다.
- FlashSpeech의 생성 과정은 높은 오디오 품질과 음성 프롬프트에 대한 높은 유사성을 유지하면서 한두 단계의 샘플링으로 효율적으로 달성된다.
- 실험 결과는 FlashSpeech의 우수한 성능을 입증하며, 기타 제로샷 음성 합성 시스템보다 약 20배 빠르면서도 음질과 유사성에서 비슷한 성능을 유지한다.
- FlashSpeech는 목소리 변환, 음성 편집 및 다양한 음성 샘플링과 같은 작업을 효율적으로 수행함으로써 다재다능함을 보여준다.

### [Align Your Steps: Optimizing Sampling Schedules in Diffusion Models](https://arxiv.org/abs/2404.14507)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.14507.png)

Vote: 14

Authors: Amirmojtaba Sabour, Karsten Kreis, Sanja Fidler

- 확산 모델(DMs)은 시각 분야 및 그 이상에서 최첨단 생성 모델링 접근법으로 자리 잡고 있습니다.
- DMs에서 샘플링 속도의 느린 문제점이 있으며, 이는 여러 나선형 함수 평가에 의존합니다.
- DMs에서 샘플링은 이산화된 노이즈 레벨로 구성된 '샘플링 일정'을 통해 미분 방정식을 풀어가는 것으로 볼 수 있습니다.
- 이전연구들은 효율적인 해결책 개발에 중점을 두었지만, 최적 샘플링 일정을 찾는 데는 상대적으로 적은 주의를 기울였으며, 연구는 주로 수작업으로 만든 게슈를 사용했습니다.
- 이 작업에서는 첫 번째로 고품질 출력을 위한 DMs의 샘플링 스케줄 최적화에 대한 일반적이고 원칙적인 접근 방식을 제안합니다.
- 불확정 계산 방법을 활용하여 다양한 풀이기, 훈련된 DMs 및 데이터 세트에 특화된 최적의 스케줄을 찾습니다.
- 이미지, 비디오, 2D 토이 데이터 합성 벤치마크에서 다양한 샘플러를 사용해 평가하였으며, 최적화된 스케줄이 거의 모든 실험에서 이전의 수작업 스케줄을 능가했습니다.
- 본 연구는 특히 몇 단계 합성 영역에서 샘플링 일정 최적화의 미개척 잠재력을 보여줍니다.

