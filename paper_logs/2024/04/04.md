## Daily Papers (2024-04-04)

### [Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](https://arxiv.org/abs/2404.02258)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02258.png)

Vote: 43

Authors: Timothy Lillicrap, Peter Conway Humphreys, David Raposo, Sam Ritter, Blake Richards, Adam Santoro

- 트랜스포머 기반 언어 모델들은 일반적으로 입력 시퀀스에 걸쳐 연산량을 균등하게 분배하지만, 본 연구에서는 대신 트랜스포머가 시퀀스 내 특정 위치에 대해서 동적으로 연산량(FLOPs)을 할당하도록 학습할 수 있다는 것을 보여준다.
- 이 방법은 모델의 다른 레이어에 걸쳐 시퀀스별로 최적의 연산량 할당을 가능하게 하며, 전체 연산 예산 제약하에 특정한 계층에서 자기 주의(self-attention)와 MLP 계산에 참여할 수 있는 토큰의 수(k)를 한정한다.
- 처리할 토큰들은 네트워크가 top-k 라우팅 메커니즘을 사용하여 결정하며, k는 사전에 정의되므로, 다른 조건부 계산 기법들과 달리 정적인 계산 그래프와 알려진 텐서 크기를 사용하는 간단한 절차를 이용한다.
- k 토큰의 정체성이 유동적이므로, 이 방법은 시간과 모델 깊이의 차원에서 비균일한 연산량을 소모할 수 있다.
- 전체적으로 연산량은 예측 가능하지만, 토큰 수준에서는 동적이고 문맥에 민감하게 계산이 이루어진다.
- 이 방식으로 훈련된 모델들은 동적으로 연산을 효율적으로 할당하는 법을 배울 뿐만 아니라, 동일한 연산량과 훈련 시간의 벽시계 시간을 가진 기준 모델의 성능에 맞추면서도 전달 단계 마다 소요되는 FLOPs의 일부만을 요구하고, 후속 훈련 샘플링 중에 최대 50% 더 빠르게 처리할 수 있다.

### [Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction](https://arxiv.org/abs/2404.02905)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02905.png)

Vote: 34

Authors: Zehuan Yuan, Bingyue Peng, Yi Jiang, Liwei Wang, Keyu Tian

- 저희는 에서 이미지 생성을 위한 새로운 접근 방식인 시각적 단방향 자동 회귀 모델링(VAR)을 제시합니다.
- VAR는 표준 래스터 스캔 방식과 달리, 이미지의 자동 회귀 학습을 조밀하게 미세한 "다음 스케일 예측" 또는 "다음 해상도 예측"으로 재정의합니다.
- 이 직관적인 방법론을 통해 자동 회귀(AR) 트랜스포머가 빠르게 시각적 분포를 학습하고 잘 일반화할 수 있으며, 이미지 생성에서 확산 트랜스포머를 처음으로 능가했습니다.
- ImageNet 256x256 벤치마크에서 VAR는 프레쳇 인셉션 거리(FID)를 18.65에서 1.80으로, 인셉션 점수(IS)를 80.4에서 356.4로 개선시키며, 추론 속도도 약 20배 빨라졌습니다.
- VAR가 이미지 품질, 추론 속도, 데이터 효율성 및 확장성을 포함한 여러 측면에서 확산 트랜스포머(DiT)를 능가하는 것이 실증적으로 확인되었습니다.
- VAR 모델을 확장함에 따라 대규모 언어 모델(LLMs)에서 관찰된 것과 유사한 분명한 스케일링 법칙이 나타나며, -0.998에 가까운 선형 상관 계수가 이를 견고한 증거로 제시합니다.
- VAR는 또한 이미지의 내부 수정, 외부 확장, 편집과 같은 다운스트림 작업에서 제로샷 일반화 능력을 보여줍니다.
- 이러한 결과들은 VAR가 LLMs의 두 가지 중요한 속성인 스케일링 법칙 및 제로샷 작업 일반화를 초기 단계에서 모방했다는 것을 제시합니다.
- 모든 모델과 코드를 공개하여 시각적 생성과 통합된 학습을 위한 AR/VAR 모델의 탐색을 촉진시키고 있습니다.

### [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](https://arxiv.org/abs/2404.02575)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02575.png)

Vote: 30

Authors: Beong-woo Kwak, Moohyeon Kim, Youngjae Yu, Yeonghyeon Kim, Seonghwan Kim, Taeyoon Kwon, Jinyoung Yeo, Seungone Kim, Kai Tzu-iunn Ong, Hyungjoo Chae, Jiwan Chung

- 알고리즘적 추론은 복잡한 문제 패턴을 이해하고 해결책으로 나아가기 위한 일련의 추론 단계로 분해하는 능력을 말하며, 대규모 언어 모델(LLMs)에게도 큰 도전 과제입니다.
- 최근 연구들은 정교하고 정확한 문법을 지닌 프로그래밍 언어(예: 파이썬)를 사용하여 주어진 인스턴스/질문에 필요한 논리를 표현하려고 시도하였지만, 한 번의 추론 호출 내에서 실행 가능한 코드를 즉석에서 작성하는 것은 간단하지 않습니다.
- 인스턴스 특화 코드를 생성하는 것은 동일한 작업에 속하고 동일한 논리를 해결하는 데 필요할 수 있는 다른 인스턴스에 대해 재사용이 불가능합니다.
- 본 논문은 언어 모델의 추론 과정을 두 단계로 분해하는 신규 프레임워크인 'Think-and-Execute'를 제시합니다: (1) Think 단계에서는 특정 작업을 해결하기 위해 모든 인스턴스에 공유되는 작업 수준 논리를 찾고, 가상 코드로 표현합니다; (2) Execute 단계에서는 생성된 가상 코드를 각 인스턴스에 맞춰 추가로 조정하고 코드 실행을 시뮬레이션합니다.
- 7개의 알고리즘적 추론 작업에 대한 광범위한 실험을 통해 Think-and-Execute의 효과를 입증하였고, 이는 인스턴스-특화 추론(예: CoT, PoT)을 수행하는 강력한 기준들을 웃도는 개선을 보여줍니다.
- 연구 결과는 자연 언어 지시문을 따르도록 훈련된 언어 모델이라 할지라도, 자연 언어와 비교하여 가상 코드가 모델의 추론을 더 잘 안내할 수 있음을 시사합니다.

### [On the Scalability of Diffusion-based Text-to-Image Generation](https://arxiv.org/abs/2404.02883)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02883.png)

Vote: 14

Authors: Zhuowen Tu, Hao Li, Stefano Ermon, Orchid Majumder, Yang Zou, Yusheng Xie, R. Manmatha, Ashwin Swaminathan, Ying Wang, Stefano Soatto

- 텍스트-이미지(T2I) 모델의 확장법칙에 대한 연구가 아직 충분히 이루어지지 않았으며, 효율적인 모델 스케일링 방법고 고안하는 것이 중요함.
- 다양한 훈련 설정과 높은 훈련 비용으로 인해 모델 간 공정한 비교가 매우 어려움.
- 본 연구에서는 확산 기반 T2I 모델의 스케일링 특성에 대해 광범위하고 철저한 실험을 통해 클리닝 백본과 훈련 데이터 셋의 스케일링을 탐구함.
- 0.4B에서 4B 매개변수에 이르기까지 다양한 크기의 UNet과 트랜스포머 변형을 최대 6억 개의 이미지 데이터셋에 적용함.
- 모델 스케일링에서는 교차 주의(cross attention) 위치와 양이 기존 UNet 디자인 성능을 결정짓는 중요한 요소임을 발견함.
- 채널 수 증가보다 트랜스포머 블록 증가가 텍스트-이미지 정렬 개선에 더 매개변수-효율적임을 확인함.
- 또한, SDXL의 UNet보다 45% 더 작고 28% 더 빠른 효율적인 UNet 변형을 발견함.
- 데이터 스케일링 측면에서는 단순 데이터셋 크기보다 훈련 세트의 품질과 다양성이 더 중요함을 보임.
- 캡션 밀도와 다양성을 높이는 것이 텍스트-이미지 정렬 성능과 학습 효율성을 향상시킴.
- 마지막으로, 모델 크기, 계산 및 데이터셋 크기의 스케일에 대한 텍스트-이미지 정렬 성능을 예측하는 스케일링 함수를 제공함.

### [ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline](https://arxiv.org/abs/2404.02893)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02893.png)

Vote: 12

Authors: Zhenyu Hou, Xiao Liu, Yifan Xu, Zihan Wang, Aohan Zeng, Yueyan Li, Jie Tang, Wenyi Zhao, Xiaohan Zhang, Zhengxiao Du, Yuxiao Dong, Xinghan Liu

- 대규모 언어 모델(LLMs)은 인간 언어를 뛰어나게 습득했으나, 실제 수학 문제 해결과 같은 응용 분야에서는 여전히 어려움을 겪고 있다.
- LLMs의 수학 능력을 향상시키기 위한 많은 전략 및 데이터셋이 개발되었지만, 언어 능력과 수학 능력을 동시에 유지하며 개선하는 것은 어려운 과제이다.
- 본 연구에서는 LLMs의 수학 문제 해결 능력을 향상시키기 위한 ‘자체 비판(Self-Critique) 파이프라인’을 개발하고 적용하였다.
- LLM 자체가 제공하는 피드백 신호를 이용해 일반적인 '수학 비판(Math-Critique) 모델'을 훈련시킨 후, 거부 기반 미세조정(rejective fine-tuning)과 직접적인 선호 최적화(direct preference optimization)를 순차적으로 적용하였다.
- ChatGLM3-32B라는 모델을 기반으로, 학술적 데이터셋과 새롭게 제작한 도전적인 데이터셋인 MathUserEval에서 일련의 실험을 진행하였다.
- 실험 결과, 개발한 파이프라인은 LLM의 수학 문제 해결 능력을 상당히 향상시킬 뿐만 아니라 언어 능력도 개선되는 것을 확인했다. 해당 기법은 크기가 2배나 큰 다른 LLMs보다 더 우수한 성능을 보였다.
- 관련 기술은 온라인 서비스 모델인 ChatGLM(https://chatglm.cn)에 적용되어 있으며, 관련 평가 데이터셋과 스크립트는 GitHub에서 공개되어 있다(https://github.com/THUDM/ChatGLM-Math).

### [InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation](https://arxiv.org/abs/2404.02733)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02733.png)

Vote: 12

Authors: Anthony Chen, Haofan Wang, Xu Bai, Zekui Qin, Qixun Wang

- 본 논문에서는 이미지 개인화 및 맞춤화 분야에서 강력한 잠재력을 보여주고 있는 조정이 필요 없는 확산 기반 모델들이 스타일 일관성 있는 이미지 생성의 여러 복잡한 도전에 직면해 있음을 지적한다.
- 스타일 개념이 다양한 요소를 포함하여 정의하기 어렵고, 인버전 기반 방법이 세부적인 스타일을 유지하지 못하며, 어댑터 기반 접근법은 참조 이미지마다 무게 조정을 세심하게 해야 하는 문제가 있음을 언급한다.
- 이에, 본 논문은 이러한 문제들을 해결하기 위한 InstantStyle 프레임워크를 제안하며 이는 두 가지 주요 전략을 구현하고 있다: 1) 스타일과 내용을 참조 이미지에서 특성 공간 내에서 분리하는 단순한 메커니즘, 2) 스타일 특정 블록에만 참조 이미지 특성을 주입하여 스타일 유출 방지 및 복잡한 무게 조정 필요성을 배제한다.
- InstantStyle은 스타일의 강도와 텍스트 요소의 조절성 사이에서 최적의 균형을 이루는 우수한 시각적 스타일화 결과를 보여준다고 주장한다.
- 관련 코드는 https://github.com/InstantStyle/InstantStyle 에서 공개될 예정이다.

### [Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models](https://arxiv.org/abs/2404.02747)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02747.png)

Vote: 9

Authors: Jinheng Xie, Mike Zheng Shou, Wentian Zhang, Haozhe Liu, Francesco Faccio, Jürgen Schmidhuber

- 본 연구는 텍스트 조건부 확산 모델에서 추론 중 크로스-어텐션의 역할을 탐구합니다.
- 크로스-어텐션 결과는 몇 단계의 추론 후 고정점으로 수렴하는 것으로 나타났습니다.
- 이로 인해 전체 추론 과정은 두 단계로 자연스럽게 나뉘며, 초기의 의미 계획 단계에서는 모델이 텍스트 지향 시각 의미를 계획하기 위해 크로스-어텐션에 의존합니다.
- 이어진 충실도 향상 단계에서 모델은 이전에 계획된 의미에서 이미지를 생성하려고 합니다.
- 놀랍게도, 충실도 향상 단계에서 텍스트 조건을 무시하면 계산 복잡성이 줄어들 뿐만 아니라 모델 성능도 유지됩니다.
- 이는 TGATE라는 효율적인 생성을 위한 간단하고 교육이 필요 없는 방법으로 이어졌으며, 크로스-어텐션 출력이 수렴하면 캐시하고 나머지 추론 단계에서 고정된 상태를 유지합니다.
- MS-COCO 검증 세트에 대한 경험적 연구는 TGATE의 효과를 확인합니다.
- TGATE의 소스 코드는 https://github.com/HaozheLiu-ST/T-GATE 에서 이용할 수 있습니다.

### [Freditor: High-Fidelity and Transferable NeRF Editing by Frequency Decomposition](https://arxiv.org/abs/2404.02514)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02514.png)

Vote: 8

Authors: Weihao Yuan, Siyu Zhu, Liefeng Bo, Qixing Huang, Yisheng He, Zilong Dong

- 본 논문은 주파수 분해를 통해 고품질이며 이전 가능한 NeRF 편집 기술을 제공한다.
- 기존의 NeRF 편집 파이프라인은 2D 스타일링 결과를 3D 씬으로 옮기는 과정에서 흐릿한 결과를 초래하며, 2D 편집 사이의 불일치 때문에 세부 구조를 포착하지 못하는 문제를 가지고 있다.
- 저자들은 이미지의 저주파수 성분이 편집 후 다시점 일관성이 더 높고, 외관 스타일이 주로 저주파수 성분에 나타나며, 내용의 세부사항은 고주파수 부분에 존재한다는 중요한 인사이트를 발견했다.
- 이를 바탕으로, 저주파수 성분에 대한 편집을 수행함으로써 고품질의 편집된 장면을 결과로 얻을 수 있었다.
- 또한, 저주파수 특징 공간에서 편집을 수행함으로써 안정적인 강도 조절과 새로운 장면 전이를 가능하게 했다.
- 포토리얼리스틱 데이터셋에 대한 광범위한 실험을 통해 고품질 및 이전 가능한 NeRF 편집의 우수한 성능을 입증하였다.
- 프로젝트 페이지는 https://aigc3d.github.io/freditor/ 에서 확인할 수 있다.

