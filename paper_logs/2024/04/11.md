## Daily Papers (2024-04-11)

### [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](https://arxiv.org/abs/2404.07143)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.07143.png)

Vote: 37

Authors: Tsendsuren Munkhdalai, Manaal Faruqui, Siddharth Gopal

- 이 연구는 메모리와 연산이 적당한 범위 내에서 무한히 긴 입력을 처리할 수 있는 트랜스포머 기반 대규모 언어 모델(LLMs)의 효율적인 확장 방법을 소개합니다.
- 새로운 주목 기술인 '인피니-어텐션(Infini-attention)'은 기존 주목 메커니즘에 압축 메모리를 통합하며 마스크된 로컬 주목 및 장기간 선형 주목 메커니즘을 하나의 트랜스포머 블록 안에 결합합니다.
- 이 방법은 긴 컨텍스트 언어 모델링 벤치마크, 백만 길이 시퀀스의 패스키 컨텍스트 블록 검색과 오십만 길이 책 요약 작업에서 1B 및 8B 대규모 언어 모델들의 효과를 입증합니다.
- 우리의 접근 방식은 최소한의 제한된 메모리 파라미터를 도입하고 대규모 언어 모델들에 대해 신속한 스트리밍 추론을 가능하게 합니다.

### [RULER: What's the Real Context Size of Your Long-Context Language Models?](https://arxiv.org/abs/2404.06654)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06654.png)

Vote: 21

Authors: Simeng Sun, Dima Rekesh, Samuel Kriman, Fei Jia, Boris Ginsburg, Shantanu Acharya, Cheng-Ping Hsieh

- 장문의 문맥(Language Models, LMs)을 평가하기 위한 '바늘과 건초더미(Needle-in-a-Haystack, NIAH)' 테스트는 간단한 검색 능력만을 평가하는데, 이는 좀 더 심오한 형태의 장문 텍스트 이해를 반영하지 않는다.
- 본 논문에서는 맞춤형 시퀀스 길이 및 과제 복잡도에 대한 설정이 가능한 새로운 합성 벤치마크 RULER를 개발하여 장문 모델의 종합적인 평가를 제안한다.
- RULER는 기본적인 NIAH 테스트를 다양한 유형 및 수량의 바늘을 포함하는 변형으로 확장하고, 맥락 속에서 단순히 검색하는 것 이상의 행위를 테스트하기 위한 다중 트레이싱 및 집계와 같은 새로운 과제 유형을 도입한다.
- RULER를 사용하여 13개의 대표 과제를 포함한 10개의 장문 모델을 평가한 결과, 모든 모델은 문맥 길이가 증가함에 따라 성능이 크게 떨어짐을 보였다.
- 공식적으로 32K 토큰 이상의 문맥 크기를 지원한다고 주장하는 모델들 중 GPT-4, Command-R, Yi-34B, Mixtral만이 32K 길이에서 만족스러운 성능을 유지한다.
- 200K 토큰까지 문맥 길이를 지원하는 Yi-34B 모델을 분석한 결과, 입력 길이와 과제 복잡성이 증가함에 따라 개선의 여지가 많다는 것이 밝혀졌다.
- RULER는 장문의 모델에 대한 종합적인 평가를 위한 기여를 촉진하기 위해 오픈 소스로 공개되었다.

### [RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion](https://arxiv.org/abs/2404.07199)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.07199.png)

Vote: 15

Authors: Ravi Ramamoorthi, Alex Trevithick, Jaidev Shriram, Lingjie Liu

- RealmDreamer는 텍스트 설명으로부터 일반 전방향 3D 장면을 생성하는 새로운 기술을 소개합니다.
- 이 기술은 복잡한 텍스트 프롬프트와 매치되도록 3D 가우시안 스플래팅 표현을 최적화합니다.
- 텍스트-이미지 생성기 최신 기술을 이용하여 초기 스플랏들을 생성하고, 이를 3D로 올려놓고, 가리기 부피를 계산합니다.
- 다중 시점에서 3D 인페인팅 작업으로 이 표현을 최적화하고, 이미지 조건부 확산 모델을 사용합니다.
- 정확한 기하 구조를 학습하기 위해, 인페인팅 모델에서의 샘플들을 조건으로 하는 깊이 확산 모델을 도입합니다.
- 최종적으로, 이미지 생성기에서 얻은 선명한 샘플들을 이용하여 모델을 미세 조정합니다.
- 중요하게도, 이 기술은 비디오 또는 멀티 뷰 데이터를 요구하지 않으며, 다양한 스타일의 고품질 3D 장면을 하나의 이미지에서 합성할 수 있는 일반성을 가집니다.

### [Adapting LLaMA Decoder to Vision Transformer](https://arxiv.org/abs/2404.06773)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06773.png)

Vote: 9

Authors: Songyang Zhang, Chengyue Wu, Ping Luo, Kaipeng Zhang, Wenqi Shao, Mengzhao Chen, Kai Chen, Yong Liu, Jiahao Wang

- 이 연구는 원래 대규모 언어 모델(LLM)용으로 설계된 디코더 전용 트랜스포머인 LLaMA를 컴퓨터 비전 영역에 적용할 수 있는지를 탐구한다.
- 표준 ViT을 LLaMA의 아키텍처와 일치시키기 위해 단계적으로 "LLaMA화"하는 과정을 거쳤으며, 셀프 어텐션에 일반적인 캐주얼 마스크를 직접 적용하면 주목 붕괴 문제가 발생하여 네트워크 훈련 실패로 이어질 수 있음을 발견했다.
- 이러한 문제를 극복하기 위해 클래스 토큰을 이미지 토큰 뒤에 배치하는 '후반부 시퀀스 클래스 토큰' 기법을 제안, 이를 통해 인과적(Self-causal) 셀프 어텐션이 전체 이미지 정보를 효과적으로 포착할 수 있도록 한다.
- 또한, 훈련 초기에 점진적으로 셀프 어텐션에 캐주얼 마스크를 도입하는 소프트 마스크 전략을 개발하여 최적화 작업을 용이하게 한다.
- 맞춤형 모델인 이미지 LLaMA(iLLaMA)는 LLaMA의 아키텍처를 닮아 직접적인 감독 학습이 가능하며, 인과적 셀프 어텐션은 계산 효율을 높이고 더 복잡한 표현을 학습한다.
- iLLaMA는 인코더 전용 대응 모델과 경쟁력을 가지며, 단 5.7M 파라미터로 ImageNet top-1 정확도 75.1%를 달성하고, ImageNet-21K에서 사전 학습을 통해 모델을 ~310M 규모로 확장하면 정확도가 86.0%로 향상된다.
- iLLaMA는 교정, 형태-질감 편향, 양자화 호환성, ADE20K 세분화 및 CIFAR 전이 학습에서 신뢰할 수 있는 성질을 보여준다는 점이 광범위한 실험을 통해 입증되었다.
- 저자들은 이 연구가 LLM의 물결에서 시각 모델 디자인에 새로운 시각을 불어넣을 수 있기를 기대하며, 사전 훈련된 모델과 코드를 제공한다.

### [DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting](https://arxiv.org/abs/2404.06903)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06903.png)

Vote: 8

Authors: Haoran Chang, Zhiwen Fan, Zhangyang Wang, Dejia Xu, Shijie Zhou, Suya You, Pradyumna Chari, Achuta Kadambi, Tejas Bharadwaj

- 가상 현실 애플리케이션에 대한 증가하는 수요에 부응하여, 저자들은 몇 분 내에 야외 환경에 대해 포괄적인 360도 장면을 생성할 수 있는 새로운 텍스트에서 3D 360도 장면 생성 파이프라인을 제시합니다.
- 이 방법은 2D 확산 모델의 생성력과 프롬프트 자기개선을 이용하여 고품질이고 전역적으로 일관된 파노라믹 이미지를 만듭니다.
- 생성된 파노라믹 이미지는 초기 "평면" (2D) 장면 표현으로서 작용하며, 이후에 3D 가우시안으로 전환되어 실시간 탐색을 가능하게 합니다.
- 일관된 3D 기하학 구조를 생성하기 위해, 파이프라인은 2D 단안 깊이를 전역적으로 최적화된 포인트 클라우드로 정렬합니다.
- 단일 시점 입력에서 내재된 불가시 문제를 해결하기 위해, 최적화 과정에 의미론적 및 기하학적 제약조건을 적용하여 보이지 않는 영역의 재구성을 돕습니다.
- 요약하자면, 이 방법은 현재 기술보다 향상된 몰입 경험을 제공하는 전역적으로 일관된 360도 관점의 3D 장면을 제공합니다.
- 프로젝트 웹사이트: http://dreamscene360.github.io/

### [BRAVE: Broadening the visual encoding of vision-language models](https://arxiv.org/abs/2404.07204)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.07204.png)

Vote: 8

Authors: Petra Poklukar, Alessio Tonioni, Achin Kulshrestha, Federico Tombari, Amir Zamir, Oğuzhan Fatih Kar

- 시각-언어 모델(VLMs)은 일반적으로 비전 인코더(예: CLIP)와 인코딩된 특징을 해석하여 다운스트림 작업을 해결하는 언어 모델(LM)로 구성되어 있다.
- 현재 VLMs는 비전 인코더의 제한된 능력, 예를 들어 특정 이미지 특징에 대한 "눈먼점", 시각적 환각 등으로 인해 여러 단점을 지니고 있다.
- 이러한 문제를 해결하기 위해, 다양한 유도적 편향을 가진 여러 비전 인코더들을 벤치마킹하고 VLM 작업을 해결하기 위한 시각적 인코딩 능력을 확장하는 방법을 연구했다.
- 실험을 통해 단일 인코딩 구성이 다양한 작업에 걸쳐 일관되게 최고 성능을 달성하지는 못하며, 서로 다른 편향을 가진 인코더가 놀랍도록 유사하게 수행할 수 있음을 발견했다.
- 이에 동기를 얻어, 여러 개의 고정된 인코더로부터 특징을 결합하여 고정된 LM에 직접적으로 입력할 수 있는 더 다재다능한 표현을 생성하는 방법, BRAVE를 도입했다.
- BRAVE는 캡셔닝 및 VQA 벤치마크의 광범위한 범위에서 최고의 성능을 달성하고, VLMs의 앞서 언급한 문제들을 상당히 감소시켰다.
- 또한, BRAVE는 기존의 방법들보다 적은 수의 학습 가능한 매개변수와 더 압축된 표현을 필요로 한다.
- 이 연구 결과는 VLMs의 더 넓고 맥락화된 시각적 이해를 위해 다양한 시각적 편향을 통합하는 잠재력을 강조한다.

### [Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior](https://arxiv.org/abs/2404.06780)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.06780.png)

Vote: 7

Authors: Fan Lu, Guang Chen, Kwan-Yee Lin, Yan Xu, Hongsheng Li, Changjun Jiang

- 텍스트에서 3D 생성 분야에서 큰 성공을 거둔 텍스트 대 이미지 확산 모델과 달리, 이 연구는 도시 규모로의 방법론 확장에 대한 패러다임이 없음을 지적한다.
- 도시 장면은 수많은 요소, 복잡한 배열 관계 및 광대한 규모로 인해 모호한 텍스트 설명의 해석 가능성이 낮아 효과적인 모델 최적화에 어려움을 겪고 있다.
- 이 연구에서는 추가적인 사전 정보로서 구성적인 3D 레이아웃 표현을 텍스트에서 3D 패러다임에 도입함으로써 제한을 극복한다고 설명한다.
- 이 레이아웃은 단순한 기하학적 구조와 명확한 배열 관계를 가진 일련의 의미론적 원시체로 구성되어 텍스트 설명을 보완하는 한편, 조정 가능한 생성을 가능하게 한다.
- 모델 최적화의 부족을 해결하기 위해, 이 논문은 레이아웃에 의해 안내된 변이 학습 점수 증류(Layout-Guided Variational Score Distillation)를 도입한다.
- 도시 장면의 무한한 특성을 처리하기 위해, 저자들은 성장하는 도시 장면의 규모에 점진적으로 적응하는 확장 가능한 해시 그리드(Scalable Hash Grid) 구조로 3D 장면을 나타낸다.
- 광범위한 실험을 통해 본 프레임워크가 처음으로 1000m 이상의 운전 거리를 포함하는 대규모 도시 장면으로 텍스트에서 3D 생성을 확장할 수 있는 능력을 입증한다.
- 또한, 조정 가능한 도시 장면 생성의 강력함을 보여주는 다양한 장면 편집 데모를 제시한다.
- 해당 논문과 연구에 대한 자세한 정보는 연구팀의 웹사이트에서 제공된다.

