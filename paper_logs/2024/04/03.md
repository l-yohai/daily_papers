## Daily Papers (2024-04-03)

### [Advancing LLM Reasoning Generalists with Preference Trees](https://arxiv.org/abs/2404.02078)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02078.png)

Vote: 28

Authors: Yankai Lin, Huimin Chen, Boji Shan, Zhiyuan Liu, Ruobing Xie, Jia Deng, Ganqu Cui, Xingyao Wang, Zhenghao Liu, Bowen Zhou, Hao Peng, Maosong Sun, Ning Ding, Hanbin Wang, Lifan Yuan

- 본 논문에서는 이유화(Reasoning)에 최적화된 대규모 언어 모델(Large Language Models, LLMs) 모음인 '유러스(Eurus)'를 소개합니다.
- '미스트랄-7B(Mistral-7B)'와 '코드라마-70B(CodeLlama-70B)'에서 미세 조정을 거쳐, 유러스 모델은 수학, 코드 생성 및 논리적 추론 문제를 포함한 다양한 벤치마크에서 오픈 소스 모델 중 최고의 성능을 달성합니다.
- 유러스-70B는 GPT-3.5 터보를 이유화 작업의 포괄적인 벤치마킹을 통해 12개의 테스트에서 능가하며, LeetCode에서 33.3% 그리고 TheoremQA에서 32.6%의 통과 정확도를 기록하여 기존 오픈 소스 모델들을 13.3% 이상의 큰 차이로 능가합니다.
- 유러스의 뛰어난 성능은 복잡한 이유화 작업을 위해 특별히 설계된 대규모 고품질 정렬 데이터셋인 '울트라인터랙트(UltraInteract)' 덕분입니다.
- 울트라인터랙트는 감독학습 및 선호 학습 둘 다에 사용될 수 있으며, 각 지시사항에는 (1) 통합된 형식의 다양한 계획 전략을 포함하는 추론 체인, (2) 환경 및 비평과의 멀티 턴 상호 작용 궤적, (3) 선호 학습을 용이하게 하는 쌍대 데이터를 포함하는 선호 트리가 포함되어 있습니다.
- 이 연구는 이유화 작업을 위한 선호 학습의 심층적인 탐색을 가능하게 하며, 일부 잘 알려진 선호 학습 알고리즘들이 이유화 작업에서는 일반 대화에서 보여주는 효과에 비해 적합하지 않을 수 있다는 것을 밝힙니다.
- 이에 영감을 받아, 우리는 울트라인터랙트와 함께 사용되는 새로운 보상 모델링 목표를 도출하여, 강인한 보상 모델을 이끌어 냅니다.

### [Octopus v2: On-device language model for super agent](https://arxiv.org/abs/2404.01744)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.01744.png)

Vote: 21

Authors: Wei Chen, Zhiyuan Li

- 언어 모델은 자동 워크플로우와 관련된 작업에서 효과적임을 보여줬고, AI 에이전트 생성에 필수적인 함수 호출 기능을 가지고 있다.
- 대규모 언어 모델은 클라우드 환경에서 높은 성능을 보이지만, 프라이버시와 비용에 대한 우려가 있다.
- 기존의 기기 내부(Function-calling) 모델은 지연 시간과 정확성 문제를 겪고 있다.
- 본 연구는 20억 매개변수를 가진 기기 내부 모델이 GPT-4의 정확성과 지연 시간을 모두 뛰어넘는 새로운 방법을 제시한다.
- 이 방법은 맥락 길이를 95% 감소시켜줄 뿐만 아니라, Llama-7B와 RAG 기반 호출 메커니즘을 비교했을 때 지연 시간을 35배 개선한다.
- 제안된 방법은 다양한 엣지(edge) 디바이스에서 실제 애플리케이션에의 적용을 위한 성능 요구 사항에 부합하는 수준으로 지연 시간을 줄인다.

### [LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model](https://arxiv.org/abs/2404.01331)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.01331.png)

Vote: 17

Authors: Matthew L. Olson, Shao-Yen Tseng, David Cobbley, Musashi Hinck, Vasudev Lal

- LLaVA 프레임워크를 사용하여 대규모 언어 모델(Large Language Models, LLMS)인 Gemma 패밀리와 함께 다양한 멀티모달 파운데이션 모델(MMFM)을 훈련하였습니다.
- 특히 20억 파라미터를 가진 Gemma 모델에 주목하여, 더 작은 규모의 유능한 MMFM을 구축할 기회를 탐구하였습니다.
- 이전 연구들의 결과에 따라, 세 가지 설계 특징을 제거하는 효과를 실험해 보았는데, 커넥터의 사전 훈련 여부, 더 강력한 이미지 백본(image backbone) 사용 여부, 언어 백본(language backbone) 크기 증가가 그것입니다.
- 이렇게 생성된 LLaVA-Gemma 모델은 다양한 평가에서 중간 수준의 성능을 보였으나, 현재의 비슷한 크기의 최고 성능 모델(State of the Art, SOTA)들을 넘어서는 개선을 보이지는 못했습니다.
- 성능에 대한 면밀한 분석 결과, 사전 훈련을 건너뛰는 것은 성능을 저하시키는 경향이 있었으며, 더 큰 비전 모델은 때때로 성능을 향상시켰고, 언어 모델의 크기를 늘리는 것은 일관되지 않은 효과를 보였습니다.
- LLaVA-Gemma 모델에 대한 훈련 레시피, 코드 및 가중치를 공개하였습니다.

### [Long-context LLMs Struggle with Long In-context Learning](https://arxiv.org/abs/2404.02060)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02060.png)

Vote: 17

Authors: Quy Duc Do, Tianle Li, Ge Zhang, Xiang Yue, Wenhu Chen

- 대규모 언어 모델(LLM)은 32K 토큰을 초과하는 장문의 시퀀스 처리에 상당한 발전을 이루었습니다.
- 그러나 LLM의 성능 평가는 대체로 난이도가 있는 텍스트나 인공 작업에 국한되어, 실제 상황에서의 능력을 완전히 나타내지 못했습니다.
- 이 연구는 극단적 레이블 분류를 내용으로 하는 긴 인-컨텍스트 학습에 초점을 맞춘 특화된 벤치마크(LIConBench)를 도입했습니다.
- 2K에서 50K에 이르는 다양한 입력 길이와 28개에서 174개에 이르는 레이블 범위를 가진 여섯 개 데이터셋을 세심히 선별하였습니다.
- 벤치마크는 LLM이 전체 입력을 이해하고 방대한 레이블 공간을 인식하여 올바른 예측을 하도록 요구합니다.
- 13개의 긴-컨텍스트 LLM을 평가한 결과, 토큰 길이가 20K 이하일 때 상대적으로 잘 수행하지만, 이상의 경우 GPT-4를 제외한 대부분의 모델의 성능이 급격히 떨어지는 것을 발견했습니다.
- 이는 LLM이 길고 포괄적인 시퀀스를 처리하고 이해하는 데에 있어 현재 능력에 중요한 격차가 있음을 시사합니다.
- 추가 분석에서 모델들은 시퀀스 끝 부분에 제시된 레이블을 예측하는 경향이 있으며, 긴 시퀀스의 여러 부분에 대한 추론 능력이 아직 개선되어야 한다는 것을 발견했습니다.
- 이 연구는 현존하는 LLM들에게 긴 컨텍스트 이해와 추론이 여전히 어려운 과제임을 밝히며, LIConBench는 미래의 긴 컨텍스트 LLM 평가를 위한 더 현실적인 도구가 될 수 있을 것이라 믿습니다.

### [Bigger is not Always Better: Scaling Properties of Latent Diffusion Models](https://arxiv.org/abs/2404.01367)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.01367.png)

Vote: 13

Authors: Zhengzhong Tu, Kangfu Mei, Hossein Talebi, Peyman Milanfar, Vishal M. Patel, Mauricio Delbracio

- 본 연구에서는 잠재 확산 모델(LDMs)의 스케일링 특성과 샘플링 효율성에 중점을 두고 연구를 진행하였습니다.
- 개선된 네트워크 아키텍처와 추론 알고리즘이 확산 모델의 샘플링 효율성을 향상시키는 데 효과적이라는 것이 밝혀졌음에도 불구하고, 샘플링 효율성에 중요한 영향을 미치는 모델 크기에 대한 철저한 검토는 이루어지지 않았습니다.
- 본 논문에서는 텍스트-이미지 확산 모델을 대상으로 실증적 분석을 수행함으로써, 다양한 샘플링 단계에서 모델 크기가 샘플링 효율성에 미치는 영향에 대해 심도있게 조사하였습니다.
- 연구 결과, 주어진 추론 예산하에서, 작은 모델이 자주 더 큰 모델보다 고품질의 결과를 생성하는 데 더 효율적이라는 놀라운 경향을 발견하였습니다.
- 또한, 다양한 확산 샘플러 적용, 다양한 하류 작업 탐구, 모델 후처리 평가, 그리고 훈련 계산과의 성능 비교를 통해 이러한 발견 사항의 일반화 가능성을 입증하는 연구를 확장하였습니다.
- 이러한 발견은 제한된 추론 예산 내에서 생성 능력을 향상시키기 위한 LDM 스케일링 전략 개발을 위한 새로운 길을 열어줍니다.

### [CameraCtrl: Enabling Camera Control for Text-to-Video Generation](https://arxiv.org/abs/2404.02101)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02101.png)

Vote: 11

Authors: Gordon Wetzstein, Hao He, Hongsheng Li, Yuwei Guo, Yinghao Xu, Bo Dai, Ceyuan Yang

- 본 연구에서는 사용자가 원하는 내용의 비디오를 생성할 수 있도록 하는 요소 중 하나인 제어 가능성에 중점을 두고, 텍스트-비디오(T2V) 모델에서 정확한 카메라 포즈 제어를 가능하게 하는 CameraCtrl을 제시했습니다.
- 기존 모델들은 영상 표현의 더 깊은 서사적 뉘앙스를 전달하는 카메라 포즈의 정밀한 제어를 대체로 간과하였으나, CameraCtrl은 카메라 궤적을 정확하게 파라미터화하고, T2V 모델에 플러그 앤 플레이 가능한 카메라 모듈을 추가하여 이를 개선했습니다.
- 본 연구는 다양한 데이터셋의 영향에 대한 포괄적인 연구를 수행하였으며, 카메라 분포가 다양하고 외관이 유사한 비디오가 실제로 제어 가능성과 일반화를 향상시키는 것으로 나타났습니다.
- 실험 결과는 CameraCtrl이 텍스트 및 카메라 포즈 입력으로부터 동적이고 맞춤화된 비디오 스토리텔링에서 정밀하고 도메인 적응적인 카메라 제어를 달성하는 데 있어 그 효과를 입증하였습니다.
- 프로젝트 웹사이트는 https://hehao13.github.io/projects-CameraCtrl/ 에서 확인할 수 있습니다.

### [Poro 34B and the Blessing of Multilinguality](https://arxiv.org/abs/2404.01856)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.01856.png)

Vote: 10

Authors: Aarne Talman, Elaine Zosa, Jonathan Burdge, Risto Luukkonen, Sampo Pyysalo, Peter Sarlin, Väinö Hatanpää, Ville Komulainen

- 최신 대규모 언어 모델의 프리트레이닝은 기존 언어들에 비해 상대적으로 대량의 텍스트 데이터가 필요한데, 특히 대부분의 언어들에 대한 데이터는 그 양이 부족합니다.
- 이 연구에서는 다언어를 포함하여 더 많은 사전 훈련 데이터를 얻을 방식을 제시하면서, 다언어성이 난점이라기보다는 장점이 될 수 있다고 주장합니다.
- 연구팀은 핀란드어, 영어, 프로그래밍 언어로 구성된 1조 개 토큰의 데이터를 가지고 34억 개의 파라미터를 가진 'Poro 34B'라는 모델을 트레이닝했습니다.
- 이 다언어 트레이닝 접근법은 핀란드어를 위한 기존 모델들의 능력을 상당히 뛰어넘는 것뿐만 아니라 번역에서도 뛰어나고, 영어와 프로그래밍 언어 생성에서 경쟁력 있는 퍼포먼스를 보여줌을 입증했습니다.
- 연구팀은 모델 파라미터, 스크립트, 데이터를 오픈 라이선스 하에 https://huggingface.co/LumiOpen/Poro-34B 에 공개하였습니다.

### [HyperCLOVA X Technical Report](https://arxiv.org/abs/2404.01954)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.01954.png)

Vote: 8

Authors: Sumin Byeon, Sookyo In, Se Jung Kwon, Baeseong Park, Hanock Kwak, Hyunwook Kim, Donghyun Kwak, Kang Min Yoo, Gichang Lee, Jooho Lee, Bado Lee, Seongjin Shin, Joonsang Yu, +, Heewon Jeon, Kyung-Min Kim, Sungju Kim, Munhyong Kim, Jaewook Kang, Dongsoo Lee, Seolki Baek, Jaegeun Han, Jisu Jeong

- 저희는 한국어와 문화에 맞춰진 대규모 언어 모델인 HyperCLOVA X를 소개합니다; 이 모델은 영어, 수학, 코딩 능력 또한 경쟁력 있습니다.
- HyperCLOVA X는 한국어, 영어, 코드 데이터의 균형잡힌 혼합물에 대한 훈련을 거친 후, 책임 AI에 대한 우리의 약속을 반영한 엄격한 안전 지침을 준수하며 고품질의 인간 주석 데이터 세트를 사용하여 지도 튜닝되었습니다.
- 이 모델은 추론, 지식, 상식, 사실성, 코딩, 수학, 대화, 지시 사항 따르기, 무해함을 포함하는 다양한 벤치마크를 통해 한국어와 영어로 평가되었습니다.
- HyperCLOVA X는 언어와 문화적 미묘함에 대한 깊은 이해를 바탕으로 한국어 추론 능력에서 강력한 성능을 보입니다.
- 모델의 내재된 양언어성과 다언어로의 확장에 대한 추가 분석은 목표로 하지 않은 언어에 대한 강력한 일반화 능력과 다수의 언어 쌍 간의 기계 번역 및 언어 간 추론 작업에 대한 모델의 교차 언어 전문성을 강조합니다.
- HyperCLOVA X는 지역이나 국가가 독자적인 대규모 언어 모델을 개발하는 데 유용한 안내를 제공할 수 있다고 믿습니다.

### [Are large language models superhuman chemists?](https://arxiv.org/abs/2404.01475)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.01475.png)

Vote: 8

Authors: Maximilian Greiner, Aswanth Krishnan, Christina Glaubitz, Amir Mohammad Elahi, Santiago Miret, Jakob Meyer, Fabian Alexander Kreth, Yannik Köster, Macjonathan Okereke, Nawaf Alampara, +, Lea C. Klepsch, Benedict Emoekabu, Adrian Mirza, Sreekanth Kunchapu, Nicole Roesner, Juliane Eberhardt, Mara Wilhelmi, Tanya Gupta, Caroline T. Holick, Michael Ringleb, Tim Hoffmann, Mehrdad Asgari

- 대규모 언어 모델(LLM)은 인간의 언어를 처리하고 명시적으로 훈련받지 않은 작업을 수행함으로써 관심을 끌고 있다.
- 화학 과학 분야는 텍스트 형태의 작고 다양한 데이터셋 문제에 직면해 있으며, LLM은 이러한 문제를 해결하고 화학 특성을 예측하며 반응을 최적화하고 실험을 설계하고 자율적으로 수행하는 데 약속을 보여주고 있다.
- 그러나 LLM의 화학 추론 능력을 체계적으로 이해하는 데 여전히 한계가 있으며, 이는 모델을 개선하고 잠재적 해를 줄이기 위해 필요하다.
- 연구진은 "ChemBench"라는 자동화된 프레임워크를 도입하여 최신 LLM의 화학 지식과 추론 능력을 인간 화학자의 전문성과 비교하여 철저하게 평가한다.
- 연구진은 7,000개가 넘는 화학 과학의 다양한 하위 분야에 대한 질문-답변 쌍을 만들고, 선도적인 오픈 소스 및 클로즈드 소스 LLM을 평가하여 가장 우수한 모델이 평균적으로 연구에 참여한 최고의 인간 화학자들을 능가함을 발견했다.
- 그러나 이 모델들은 인간 전문가들에게는 쉬운 몇몇 화학 추론 작업에서 어려움을 겪으며, 화학 물질의 안전성 프로파일에 대해 자신감이 넘치지만 현혹하는 예측을 제공한다.
- 이 결과는 LLM이 화학 작업에서 놀라운 숙련도를 보이지만, 화학 과학 분야에서의 안전성과 유용성을 향상시키기 위해 추가 연구가 매우 중요함을 강조한다.
- 또한, 이 연구는 화학 교육과정에 대한 조정의 필요성을 시사하며, 안전하고 유용한 LLM을 개선하기 위한 평가 프레임워크 개발을 계속해서 강조한다.

### [3D Congealing: 3D-Aware Image Alignment in the Wild](https://arxiv.org/abs/2404.02125)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.02125.png)

Vote: 5

Authors: Andreas Engelhardt, Varun Jampani, Tingbo Hou, Amit Raj, Jiajun Wu, Yuanzhen Li, Zizhang Li, Yunzhi Zhang

- 본 연구에서는 2D 이미지상 동일 개념의 객체들을 위한 새로운 3D 혼합 문제를 제안합니다.
- 무작위 인터넷 이미지 컬렉션에서 공유되는 의미 있는 부분들을 연관시키고 2D 이미지의 지식을 공유하는 3D 표준 공간으로 집계하는 것이 목표입니다.
- 우리는 형태 템플릿, 자세 또는 카메라 매개변수에 대한 가정 없이 이 작업을 처리하는 일반적인 프레임워크를 도입합니다.
- 이 프레임워크의 핵심은 기하학적 및 의미적 정보를 포함하는 표준 3D 표현입니다.
- 프레임워크는 각 입력 이미지에 대한 표준 표현, 자세 및 2D 픽셀 좌표를 3D 표준 프레임으로 변형하는 이미지별 좌표 맵을 최적화합니다.
- 최적화 절차는 사전 학습된 이미지 생성 모델로부터의 사전 지식과 입력 이미지로부터의 의미 정보를 융합합니다.
- 전자는 이 제한된 임무에 대한 강력한 지식 안내를 제공하며, 후자는 사전 학습된 모델의 훈련 데이터 편향을 완화하는 데 필요한 정보를 제공합니다.
- 저희 프레임워크는 대응하는 매칭, 자세 추정 및 이미지 편집과 같은 다양한 작업에 사용될 수 있으며, 도전적인 조명 조건과 온라인에서의 실제 이미지 데이터셋에 대해 강력한 결과를 달성합니다.

### [LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models](https://arxiv.org/abs/2404.01617)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.01617.png)

Vote: 5

Authors: Francis Y. Yan, Zhiyuan He, Aashish Gottipati, Yuqing Yang, Lili Qiu, Kenuo Xu, Xufang Luo

- 이 논문은 다양한 네트워크 특성에 적응할 수 있도록 대규모 언어 모델(LLMs)의 생성 능력을 활용하여 적응형 비트레이트(ABR) 알고리즘을 자율적으로 설계하는 최초의 시스템인 LLM-ABR을 제시합니다.
- LLM-ABR은 강화 학습 프레임워크 내에서 LLM을 활용하여 상태와 신경망 아키텍처와 같은 핵심 구성 요소를 설계할 수 있게 해줍니다.
- 광대역, 위성, 4G, 5G를 포함한 다양한 네트워크 환경에서 LLM-ABR을 평가한 결과, 기존의 ABR 알고리즘보다 일관되게 더 우수한 성능을 보였습니다.

