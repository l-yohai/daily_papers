## Daily Papers (2024-12-07)

### [Establishing Task Scaling Laws via Compute-Efficient Model Ladders](https://arxiv.org/abs/2412.04403)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.04403.png)

Vote: 2

Authors: Akshita Bhagia, David Heineman, Jiacheng Liu, Oyvind Tafjord, Ananya Harsh Jha, Luca Soldaini, Jesse Dodge, Dirk Groeneveld, Hannaneh Hajishirzi, Noah A. Smith, Pang Wei Koh, Alexander Wettig

- ***What's New***: 이 연구는 과대훈련된 언어 모델(LM)의 개별 과제 성능을 예측하기 위해 작업 확장 법칙과 모델 사다리(Model Ladder)를 개발하였습니다. 이를 통해 LMs의 특정 작업 성능을 사전 훈련 없이 예측할 수 있습니다.
- ***Technical Details***: 두 단계 예측 방법을 사용합니다. 첫 번째 단계에서는 모델 크기와 데이터 크기를 사용하여 작업별 손실을 예측하고, 두 번째 단계에서는 이 작업 손실을 바탕으로 작업 성능을 예측합니다. '사다리' 모델을 소규모로 훈련하여 이 예측을 위한 매개변수식의 함수에 데이터를 맞춥니다. 목표 모델로는 7B 모델과 13B 모델을 테스트합니다. 사다리 모델의 훈련은 목표 모델의 훈련에 필요한 연산의 1% 미만만 사용합니다.
- ***Performance Highlights***: 4개의 선택형 과제에서 목표 모델의 정확성을 절대 오차 2포인트 내로 예측할 수 있었으나, 변동성이 큰 4개의 다른 과제에서는 평균 6.9의 절대 오차가 있었습니다. 연산을 줄여 더 적은 사다리 모델을 훈련할수록 예측 정확성이 떨어졌습니다.

