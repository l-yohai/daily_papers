## Daily Papers (2024-12-31)

### [Edicho: Consistent Image Editing in the Wild](https://arxiv.org/abs/2412.21079)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.21079.png)

Vote: 13

Authors: Qiuyu Wang, Ceyuan Yang, Qifeng Chen, Yinghao Xu, Ka Leong Cheng, Yujun Shen, Hao Ouyang, Qingyan Bai

- ***What's New***: Edicho는 훈련이 필요 없는 확산 모델(diffusion models)에 기반하여, 이미지 간의 명확한 대응을 활용하여 '야생' 이미지에서 일관된 편집을 가능하게 합니다. 특히 주의(attention) 조작 모듈과 분류기 비자유 가이드(classifier-free guidance; CFG) 제거 전략을 제안하여 다양한 환경에서도 일관된 이미지를 만들 수 있습니다.
- ***Technical Details***: Edicho는 기존의 시각적 이해 방법을 사용하여 입력 이미지 간 명확한 의미적 대응을 추출한 후, 사전 훈련된 편집 모델로 확산 안정화(Stale Diffusion)를 통해 편집을 진행합니다. 주의 메커니즘에서 쿼리 기능을 변형하고, CFG의 설계는 대응 정보를 사용하여 조정하여 고품질 그림을 보장합니다.
- ***Performance Highlights***: 실험 결과, Edicho는 이전의 암시적(attention-based) 방법보다 더 높은 일관성을 제공하였으며, 사용자 연구(User Studies)에서도 높은 사용자 만족도를 기록했습니다. 이는 일관된 이미지 편집 작업에서 양적, 질적 평가 모두에서 우수한 성능을 보여줍니다.

### [Bringing Objects to Life: 4D generation from 3D objects](https://arxiv.org/abs/2412.20422)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.20422.png)

Vote: 23

Authors: Ori Malca, Dvir Samuel, Ohad Rahamim, Gal Chechik

- ***What's New***: 이 논문에서는 3차원 물체를 텍스트 프롬프트(Textual Prompt)를 통해 4차원(dynamic 3D content) 콘텐츠로 변환하는 새로운 방법, 3to4D를 소개합니다. 기존 3D 객체의 정체성을 유지하면서도 새롭고 역동적인 움직임을 추가하여 4차원 애니메이션을 생성할 수 있습니다.
- ***Technical Details***: 제안된 방법은 3D 메쉬를 '정적' 4D Neural Radiance Field (NeRF)로 변환한 후, 이미지-비디오 확산 모델(Image-to-Video Diffusion Model)을 활용하여 객체를 애니메이션화합니다. 이 과정에서 주어진 텍스트 프롬프트를 기반으로 한 마스킹된 점수 증류 샘플링(Masked Score Distillation Sampling; SDS) 손실 함수를 도입하여 모델 최적화를 강화합니다. 또한, 점진적 시점 선택 프로토콜(Viewpoint Selection Protocol)을 제안하여 실사감 있는 움직임을 촉진합니다.
- ***Performance Highlights***: 3to4D는 기존 방법론에 비해 주어진 3D 객체와의 정체성 보존 성능이 3배 향상되었습니다(LPIPS 점수 기준). 생성된 비디오는 시간적 일관성(Temporal Coherence), 프롬프트 준수, 및 시각적 충실성 측면에서 탁월한 성능을 보여주며, 입력 객체와의 높은 일치율도 유지합니다.

### [Training Software Engineering Agents and Verifiers with SWE-Gym](https://arxiv.org/abs/2412.21139)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.21139.png)

Vote: 4

Authors: Navdeep Jaitly, Xingyao Wang, Heng Ji, Graham Neubig, Yizhe Zhang, Alane Suhr, Jiayi Pan

- ***What's New***: SWE-Gym은 소프트웨어 엔지니어링(SWE) 에이전트를 훈련하기 위한 최초의 오픈 환경입니다. 여기에는 GitHub 이슈에서 추출한 2,438개의 실제 Python 작업이 포함되어 있으며, 각 작업은 실행 가능한 런타임 환경과 테스트 검증이 사전에 설정되어 있습니다.
- ***Technical Details***: SWE-Gym은 GitHub의 11개의 인기 오픈 소스 저장소에서 소프트웨어 의존성을 사전 설치하고 실행 가능한 테스트를 통해 검증된 2,438개의 Python 작업으로 구성되어 있습니다. 에이전트는 자연어로 지정된 과제를 해결하기 위해 주어진 코드베이스와 환경에서 작업해야 하며, 테스트 통과 솔루션을 개발하기 위해 주어진 코드베이스 및 실행 환경을 활용해야 합니다.
- ***Performance Highlights***: SWE-Gym을 활용한 언어 모델 기반 SWE 에이전트는 SWE-Bench 검증 및 라이트 테스트 세트에서 최대 19%의 해결률을 달성했으며, 에이전트 경로 궤적을 사용하여 학습한 검증기를 활용하여 높은 성능을 기록했습니다. 특히, SWE-Bench 검증에서는 32.0%, Lite에서는 26.0%의 성능을 달성하여 새로운 최고 수준을 기록했습니다.

### [On the Compositional Generalization of Multimodal LLMs for Medical Imaging](https://arxiv.org/abs/2412.20070)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.20070.png)

Vote: 28

Authors: Junying Chen, Zixu Zhang, Dingjie Song, Rongsheng Wang, Weihong Wang, Benyou Wang, Yize Chen, Zhenyang Cai, Yonglin Deng

- ***What's New***: 이 논문은 의료 이미징 분야에서 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)의 조합적 일반화(Compositional Generalization, CG) 능력을 조사합니다. 연구에서는 의료 영상 데이터를 모델이 어떻게 새로운 조합으로 이해할 수 있는지를 탐구하기 위해 106개의 의료 데이터세트를 수집하여 Med-MAT을 구축했습니다.
- ***Technical Details***: Med-MAT은 11가지 의료 모달리티(Modality), 14개 해부학적 영역(Anatomical area), 13개 의료 과제(Task)로 구성된 53개의 하위 집합으로, 각 이미지는 이러한 MAT-Triplet을 기반으로 정의됩니다. 실험에서는 CG가 MLLM의 여러 과제를 이해하는 데에 있어 어떻게 상호 보완적인 역할을 하는지 확인하기 위해 다양한 데이터셋을 사용하여 분석을 수행하였습니다.
- ***Performance Highlights***: MLLMs는 CG를 활용하여 보기 어려웠던 의료 이미지를 이해할 수 있으며, 실험 결과 이러한 조합적 일반화가 다중 과제 학습에서 주요한 일반화의 형태 중 하나임을 확인했습니다. CG는 제한된 데이터의 데이터세트를 지원하여 일관된 성능을 제공하며, 다양한 모델 백본(Backbone)에서도 유사하게 적용 가능합니다.

### [OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System](https://arxiv.org/abs/2412.20005)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.20005.png)

Vote: 4

Authors: Zhiqiang Zhang, Haofen Wang, Huajun Chen, Jun Zhou, Ningyu Zhang, Lanning Wei, Yujie Luo, Lei Liang, Da Zheng, Mengshu Sun, Xiangyuan Ru, Lin Yuan, Kangwei Liu

- ***What's New***: OneKE는 처음으로 Dockerized Schema-Guided LLM Agent 기반 지식 추출 시스템을 도입했습니다. 이 시스템은 웹과 원본 PDF 책 등 다양한 도메인(과학, 뉴스 등)에서 지식을 효과적으로 추출할 수 있도록 설계되었습니다. 다중 에이전트와 구성 가능한 지식 베이스를 통해 각 에이전트가 자신의 역할을 수행하며 다양한 추출 시나리오를 지원합니다.
- ***Technical Details***: OneKE 시스템은 다양한 데이터 형식을 처리할 수 있으며(예: HTML, PDF), LLaMA, Qwen, ChatGLM, GPT-4 등의 모델을 활용하여 지식을 추출합니다. Schema Agent는 사전 정의된 스키마와 사용자가 정의할 수 있는 스키마를 통해 다양한 실세계 데이터를 지원하며, Extraction Agent는 유사한 케이스를 학습하여 성능을 향상시킵니다. Reflection Agent는 오류를 디버깅하고 수정하여 정확성을 높입니다.
- ***Performance Highlights***: OneKE는 CrossNER와 NYT-11-HRL 데이터셋에서 평가되었으며, 특히 Case Retrieval 방법이 성능 향상에 기여하였습니다. 이러한 방법은 복잡한 정보 추출 시나리오에서 중간 추론 단계가 중요할 때 효과적임을 보여주었습니다.

### [HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation](https://arxiv.org/abs/2412.21199)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.21199.png)

Vote: 5

Authors: Xiao-Ping Zhang, Yilun Zhao, Zhaojian Yu, Arman Cohan

- ***What's New***: 인터넷에서 레거시 평가를 벗어나 대형 언어 모델(Large Language Models; LLMs)의 자기 호출 코드 생성(Self-invoking Code Generation) 능력을 평가하는 HumanEval Pro와 MBPP Pro라는 새로운 벤치마크를 소개합니다. 기존의 단순한 문제 해결을 넘어, 기초 문제의 해결을 바탕으로 더 복잡한 문제를 해결해야 하는 능력을 요구합니다.
- ***Technical Details***: 이 평가에는 기존 HumanEval과 MBPP 벤치마크의 문제들에 더해 복잡한 자기 호출 문제들이 추가됩니다. 이를 통해 LLMs가 자신의 생성 코드를 어떻게 활용하여 더 복잡한 문제를 해결할 수 있는지를 보게 됩니다. DeepSeek-V2.5와 같은 최신 오픈 소스 모델을 활용하여 기존 데이터셋을 기반으로 새로운 자기 호출 문제와 해답을 생성합니다.
- ***Performance Highlights***: HumanEval과 MBPP와 같은 전통적인 코드 생성 벤치마크에서는 평균 10%~15%의 성능 하락이 나타났으며 DeepseekCoder-V2-instruct 같은 오픈 소스 모델이 HumanEval Pro에서 77.4%로 높은 성능을 보였습니다. 또한 기존 모델과 지시조정 모델 간의 성능 차이는 자기 호출 코드 생성에서 크게 나타나지 않았습니다. 여러 LLMs가 복잡한 문제에서 자기 호출 코드를 효과적으로 활용하는 데 어려움을 겪고 있는 것으로 나타났습니다.

### [PERSE: Personalized 3D Generative Avatars from A Single Portrait](https://arxiv.org/abs/2412.21206)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.21206.png)

Vote: 3

Authors: Inhee Lee, Hyunsoo Cha, Hanbyul Joo

- ***What's New***: PERSE는 단일 참조 초상화 이미지로부터 애니메이션 가능한 개인 맞춤형 생성 아바타를 구축하는 방법을 제안합니다. 이 모델은 얼굴 속성 편집을 다중 속성 잠재 공간에서 수행할 수 있는 능력을 제공하여 개인의 정체성을 유지하면서도 다양한 얼굴 속성의 제어를 가능하게 합니다.
- ***Technical Details***: PERSE는 대규모 합성 2D 비디오 데이터셋을 생성하여 얼굴 표현과 시점에서의 일관된 변화를 포함하며, 원본 입력의 특정 얼굴 속성을 변형시킵니다. 새로운 파이프라인을 제안하여 고품질의 사진 같은 2D 비디오를 생성하고 3D Gaussian Splatting을 기반으로 맞춤형 아바타를 생성합니다. 얼굴 속성의 매끄러운 전이는 2D 얼굴 이미지의 보간을 통해 잠재 공간을 규제하여 이루어지며, 추가적인 세부적 얼굴 속성 통합은 LoRA(저랭크 적응기법)를 통해 이루어집니다.
- ***Performance Highlights***: PERSE는 새로운 또는 보간된 얼굴 속성의 표현력을 향상시키기 위한 연속적이고 매끄러운 잠재 공간을 통한 얼굴 재현을 보여줍니다. 기존의 방법과 비교하여 높은 품질의 아바타를 생성하며 참조 인물의 정체성을 보존하여, 모델은 보간된 예제를 통해서도 더 나은 품질과 리얼리즘을 제공합니다.

### [TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization](https://arxiv.org/abs/2412.21037)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.21037.png)

Vote: 13

Authors: Navonil Majumder, Ambuj Mehrish, Zhifeng Kong, Soujanya Poria, Rafael Valle, Chia-Yu Hung, Bryan Catanzaro

- **What's New**: TangoFlux는 빠른 텍스트-오디오(Text-to-Audio; TTA) 생성을 위해 혁신적인 플로우 매칭(Flow Matching)과 CLAP-순위 선호 최적화(CLAP-Ranked Preference Optimization; CRPO)를 도입했습니다. 515M 파라미터로 A40 GPU를 이용해 3.7초 만에 최대 30초 길이의 44.1kHz 오디오를 생성할 수 있으며, 기존 모델보다 2배 빠르게 고품질 오디오를 생성합니다.
- **Technical Details**: TangoFlux는 플럭스 변환기 블록(FluxTransformer Blocks)을 사용하여 텍스트와 지속 시간 임베딩을 결합한 오디오 생성을 진행합니다. 트레이닝 파이프라인은 사전 훈련, 미세 조정, 선호 최적화의 단계로 진행됩니다. 특히, 클랩을 보상 모델로 활용해 생성된 오디오의 선호 데이터세트를 구축하여 최적화합니다. 오프라인 데이터에 의존하지 않고 각 이터레이션별로 새로운 데이터를 생성하여 CRPO를 수행합니다.
- **Performance Highlights**: TangoFlux는 AudioLDM2와 Tango2 같은 기존의 텍스트-오디오 생성 모델들보다 CLAP 및 FD 점수가 향상되었으며, 멀티이벤트 입력에서 더욱 뛰어난 성능을 발휘했습니다. TANGOFLUX는 경쟁 모델들과 비교했을 때 오디오 캡슐 테스트 세트에서 거의 모든 객체적 메트릭에서 뛰어난 성능을 발휘했으며 특히 CLAP 점수에서 선두를 달성했습니다. 또한, 모델의 효율성 덕에 가장 적은 추론 시간으로 고품질의 오디오를 생성할 수 있습니다.

### [Explanatory Instructions: Towards Unified Vision Tasks Understanding and Zero-shot Generalization](https://arxiv.org/abs/2412.18525)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18525.png)

Vote: 39

Authors: Yuxin Song, Errui Ding, Heyang Xu, Tao Yuan, Yifan Sun, Yazhou Yao, Yang Shen, Xiu-Shen Wei, Jian Jin

- ***What's New***: 이 논문은 컴퓨터 비전(CV)에서 제로샷 일반화(Zero-shot Generalization)의 새로운 경지를 탐색하기 위해 설명적 지시사항(Explanatory Instructions)을 도입하였습니다. 이는 기존의 용어적 작업 정의를 넘어서 다양한 비전 작업의 목표를 설명하는 방식으로 데이터셋을 구성하며, 새로운 작업에 대해 제로샷 일반화 성능을 보여줍니다.
- ***Technical Details***: 저자들은 설명적 지시사항을 포함한 약 1200만 개의 '이미지 입력 → 설명적 지시사항 → 출력' 쌍으로 구성된 대규모 데이터셋을 구축했습니다. 이러한 데이터를 활용하여 오토리그레시브 기반의 비전-언어 모델(AR-based VLM)을 학습시킵니다. 모델은 주어진 이미지와 설명적 지시사항을 입력으로 받아 학습과 추론을 진행합니다.
- ***Performance Highlights***: 설명적 지시사항을 기반으로 학습된 모델은 기존에 보지 못한 비전 작업에 대한 제로샷 일반화 능력을 보여줍니다. 실험을 통해 이 모델이 여러 비전 작업에서 효과적으로 일반화할 수 있음을 확인했습니다. 하지만, 특정 제로샷 설정에서의 성능은 여전히 향상될 여지가 있습니다.

### [Slow Perception: Let's Perceive Geometric Figures Step-by-step](https://arxiv.org/abs/2412.20631)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.20631.png)

Vote: 4

Authors: Zheng Ge, Jia Wang, Xiangyu Zhang, Youyang Yin, Jianjian Sun, Liang Zhao, Yumeng Li, Haoran Wei

- ***What's New***: 이 연구에서는 LVLMs (Large Vision Language Models)가 지각적 논리 및 공간 관계를 이해하는 데 어려움을 겪고 있다는 문제를 해결하기 위해 'Slow Perception'이라는 새로운 개념을 소개합니다. 이 개념은 지오메트릭 도형을 점과 선 단위로 점진적으로 해체하는 접근법으로, 인간이 지오메트릭 구조를 분석하는 방식과 유사합니다.
- ***Technical Details***: Slow Perception에는 두 가지 주요 단계가 있습니다. 첫 번째는 'Perception Decomposition' 단계로, 복잡한 지오메트릭 형태를 기본 시각 단위로 분해하여 지오메트릭 표상형태를 통일하는 것입니다. 두 번째는 'Perception Flow' 단계로, 제안된 'Perceptual Ruler'를 사용하여 각 선분을 '스트로크-by-스트로크' 방식으로 추적하여 긴 선의 정확한 트레이싱을 돕습니다.
- ***Performance Highlights***: Slow Perception 방법을 통해 F1-score가 6% 향상되었으며, 특히 Perception Flow 방법이 consistently (일관되게) 정확성을 향상시키며, 단일 인식 거리인 'Perceptual Ruler'가 짧아질수록 계산 비용은 증가하지만 성능은 지속적으로 개선되었습니다.

### [Efficiently Serving LLM Reasoning Programs with Certaindex](https://arxiv.org/abs/2412.20993)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.20993.png)

Vote: 19

Authors: Yichao Fu, Hao Zhang, Aurick Qiao, Siqi Zhu, Zheyu Fu, Zhongdongming Dai, Junda Chen

- ***What's New***: 이 연구는 대형 언어 모델(LLM)이 높은 추론 요구 작업을 효율적으로 처리할 수 있도록 하는 Dynasor 시스템을 소개합니다. 이는 기존 시스템의 한계를 극복하고 당면한 문제의 난이도에 따라 컴퓨팅 자원을 효율적으로 조절합니다. 새로운 프록시 변수인 certaindex를 도입하여 모델의 신뢰도를 기반으로 자원 할당을 동적으로 최적화합니다.
- ***Technical Details***: Dynasor는 추론 쿼리 내의 요청을 추적 및 스케줄하는 혁신적인 시스템입니다. 이는 모델의 확신도를 측정해주는 프록시 certaindex를 활용해 컴퓨팅 자원을 동적으로 관리합니다. 어려운 쿼리에는 더 많은 자원을, 간단한 쿼리에는 적은 자원을 할당하고, 기대 결과가 없는 쿼리는 조기 종료를 통해 자원을 절약합니다. 이러한 방식을 통해 다양한 데이터셋과 알고리즘에서 최대 50%의 컴퓨팅 자원을 절감할 수 있습니다.
- ***Performance Highlights***: Dynasor는 오프라인 환경에서는 50%까지 컴퓨팅 부담을 줄이고, 온라인 서비스에서는 기존 시스템보다 최대 3.3배 더 많은 쿼리 비율 이나 4.7배 더 엄격한 지연 시간 SLOs를 달성할 수 있습니다. 평가 결과는 Dynasor가 LLM 추론 쿼리의 처리 효율성을 크게 향상시킬 수 있음을 보여줍니다.

### [Facilitating large language model Russian adaptation with Learned Embedding Propagation](https://arxiv.org/abs/2412.21140)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.21140.png)

Vote: 6

Authors: Mikhail Tikhomirov, Daniil Chernyshev

- ***What's New***: 이 논문에서는 대형 언어 모델(Large Language Model; LLM)의 러시아어 적응을 위한 새로운 방법인 학습된 임베딩 전파(Learned Embedding Propagation; LEP)를 도입하였습니다. LEP는 적은 훈련 데이터로도 기존 LLM 지식을 방해하지 않으면서 언어 적응을 가능하게 하고, 러시아어 적응을 위한 경량 벤치마크 '다루메루(Darumeru)'를 개발하였습니다.
- ***Technical Details***: LEP는 새로운 언어 지식을 기존의 명령어 설정된 LLM 변형에 직접 통합하는 혁신적인 임베딩 전파 기술을 사용합니다. 기존 LLM의 지식에 대한 영향을 최소화하면서 낮은 비용으로 언어 적응을 가능하게 합니다. Mistral-7B와 LLaMa-3-8B 모델을 러시아어에 맞게 적응하기 위해 네 가지 어휘 적응 시나리오를 테스트했습니다. Darumeru에서 벤치마킹하여 모델의 성능을 평가했습니다.
- ***Performance Highlights***: LEP를 적용한 러시아어 적응 모델은 OpenChat 3.5 및 LLaMa-3-8B-Instruct와 비교 가능한 성능 수준을 달성했습니다. 특히 Extended 및 Optimized 옵션으로 어휘 변형을 시도했을 때 가장 높은 성능을 나타냈습니다. 이 외에도 자가 보정(self-calibration) 및 추가 명령어 튜닝으로 성능이 더욱 향상되었습니다.

### [Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs](https://arxiv.org/abs/2412.21187)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.21187.png)

Vote: 2

Authors: Xingyu Chen, Dian Yu, Jianhui Pang, Qiuzhi Liu, Haitao Mi, Dong Yu, Rui Wang, Linfeng Song, Mengfei Zhou, Tian Liang, Zhaopeng Tu, Jiahao Xu, Zhiwei He, Zhuosheng Zhang

- ***What's New***: 이 연구는 o1-Like 모델들이 간단한 문제에도 불필요하게 많이 생각하고 자원을 소비하는 현상을 처음으로 포괄적으로 분석하였습니다. o1-Like 모델들은 코딩에서 인간과 유사한 긴 사고 체인을 통해 문제 해결 능력을 강화하는데, 이 과정에서 단순한 문제에 대해 과도한 계산 자원을 할당하는 'overthinking' 문제를 보입니다.
- ***Technical Details***: 연구진은 o1-Like 모델들이 테스트 중 자원을 지능적이고 효율적으로 사용하는지를 평가하기 위해 새로운 효율성 지표를 제시하였습니다. 제안된 자가 학습(self-training) 패러다임을 통해 불필요한 계산을 줄이면서도 정확도를 유지하는 방법론이 개발되었습니다. 이는 테스트 세트의 난이도(GSM8K, MATH500, GPQA, AIME)에 관계없이 모델 성능을 유지하는 데 성공했습니다.
- ***Performance Highlights***: 제안된 방법은 o1-Like 모델의 연산 오버헤드를 성공적으로 줄이면서 성능 유지를 보여주었습니다. 예를 들어, MATH500 테스트 세트에서 'overthinking'을 완화하여 토큰 출력을 48.6% 감소시키면서도 정확도를 유지할 수 있었습니다.

