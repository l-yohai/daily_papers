## Daily Papers (2024-12-23)

### [Multi-LLM Text Summarization](https://arxiv.org/abs/2412.15487)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.15487.png)

Vote: 3

Authors: Nedim Lipka, Puneet Mathur, Nesreen K. Ahmed, Hanieh Deilamsalehy, Franck Dernoncourt, Jiangnan Fang, Yash Bhedaru, Jieun Kim, Ethan Liu, Nikhil Singh, Cheng-Tse Liu, Ryan A. Rossi

- ***What's New***: 이 논문에서는 복수의 대형언어모델(Multi-LLM)을 이용한 텍스트 요약 프레임워크를 제안하며, 중앙집중형(centralized)과 분산형(decentralized) 두 가지 전략을 탐구합니다. 이 접근법은 단일 LLM 사용보다 요약 성능을 최대 3배 향상시킵니다.
- ***Technical Details***: 복수의 LLM이 서로 다른 텍스트 요약을 생성하고, 이러한 요약은 중앙집중형에서는 단일 LLM이 평가하여 가장 좋은 요약을 선택하고, 분산형에서는 여러 LLM이 평가에 참여해 합의에 이르는 방식입니다. 각 라운드에서의 생성(generation)과 평가(evaluation) 과정을 거쳐 최종적으로 높은 품질의 요약을 얻습니다.
- ***Performance Highlights***: 실험 결과, 이 프레임워크는 ROUGE, BLEU 등 다양한 평가 지표에서 단일 LLM 방식 대비 평균 70% 이상 성능 향상을 보였으며, 특히 짧은 텍스트 요약에서는 더욱 두드러진 성능 향상이 관찰되었습니다. 추가 라운드가 필수적이지 않으며, 최소한의 비용으로 높은 성능을 유지합니다.

### [IDOL: Instant Photorealistic 3D Human Creation from a Single Image](https://arxiv.org/abs/2412.14963)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.14963.png)

Vote: 2

Authors: Jiaxi Lv, Hao Zhu, Yiyu Zhuang, Shifeng Chen, Qing Shuai, Yujiu Yang, Hao Wen, Xun Cao, Wei Liu, Ailing Zeng

- ***What's New***: IDOL은 단일 이미지로부터 즉각적으로 포토리얼리스틱한 3D 인간 아바타를 생성하는 혁신적인 파이프라인을 소개합니다. 이는 HuGe100K라는 대규모 데이터셋을 활용하여 다양한 인간 형태와 포즈를 처리할 수 있습니다.
- ***Technical Details***: IDOL 모델은 피드 포워드 트랜스포머(feed-forward transformer) 방식을 채택하여 단일 이미지로부터 3D 인간 가우시안 표현(Gaussian Representation)을 예측합니다. SMPL-X 모델의 2D UV 공간을 사용하여 3D 특징을 관리 가능한 2D 문제로 변환함으로써 복잡성을 줄입니다. 또한 HuGe100K 데이터셋은 100K 이상의 다양한 주제와 높은 해상도의 이미지를 포함하고 있어 모델의 일반화 능력을 크게 향상시킵니다.
- ***Performance Highlights***: IDOL 모델은 단일 A100 GPU를 사용해 1K 해상도로 1초 이내에 포토리얼리스틱한 인간을 재구성할 수 있습니다. IDOL은 경쟁 모델들과 비교하여 MSE, PSNR, LPIPS 지표에서 우수한 성능을 보여주며, 텍스처와 형태 편집에도 효율적입니다.

### [MixLLM: LLM Quantization with Global Mixed-precision between Output-features and Highly-efficient System Design](https://arxiv.org/abs/2412.14590)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.14590.png)

Vote: 4

Authors: Xiaonan Song, Chuanjie Liu, Zhen Zheng

- ***What's New***: MixLLM은 출력 특징들 사이의 전역 혼합 정밀도(Globally Mixed-precision)를 활용하여 LLM을 양자화하는 혁신적인 방법을 제안하여, 뛰어난 정확도와 시스템 효율성을 제공합니다. 특히 각 출력 특징의 중요도를 전역적으로 식별하여, 필요한 부분에 큰 비트너비를 할당함으로써 메모리 소모는 낮추면서 높은 정확도를 달성합니다.
- ***Technical Details***: MixLLM은 출력 특징(Output Features) 간의 혼합 정밀도 양자화(Mixed-precision Quantization)와 GPU 커널 최적화를 결합하여 높은 시스템 효율성을 이끌어냅니다. 이 시스템은 8-bit의 대칭 양자화와 4-bit의 비대칭 양자화를 그룹 단위(group-wise)로 적용하여 양자화 초기화 및 처리 과정 내의 병목을 줄이고자 두 단계 해양자화(Two-step Dequantization)를 설계했습니다.
- ***Performance Highlights***: MixLLM은 GPTQ, AWQ 등 최신의 4-bit 양자화 솔루션보다 평균적으로 더 좋은 성능을 보이며, 변환의 손실을 최소화할 수 있음을 입증했습니다. 실험 결과 MixLLM의 W4.4A8 구성은 최소 메모리 소비량으로 최고의 정확도를 기록했으며, 각종 다운스트림 작업에서도 높은 성능을 유지했습니다.

### [Sequence Matters: Harnessing Video Models in 3D Super-Resolution](https://arxiv.org/abs/2412.11525)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.11525.png)

Vote: 4

Authors: Juhee Han, Byeonghyeon Lee, Youngin Park, Hyun-kyu Ko, Eunbyung Park, Dongheok Park

- **What's New**: 이 논문은 3D 초해상도(3D Super-Resolution) 분야에서 비디오 초해상도 모델(Video Super-Resolution; VSR)을 활용하는 새로운 방법을 제안합니다. 낮은 공간 정렬을 가진 시퀀스에서도 VSR 모델이 좋은 성능을 발휘할 수 있음을 발견하여, 추가적인 파인튜닝 없이 저해상도(Low-Resolution; LR) 이미지를 정렬하는 간단하면서도 실용적인 접근 방식을 제안합니다.
- **Technical Details**: 제안된 방법은 ORB(Oriented FAST and Rotated BRIEF) 특징을 사용하여 유사도를 측정하고, 그리디 알고리즘을 통해 비디오와 유사한 순서로 이미지를 배열합니다. 그 후, VSR 모델을 사용하여 순서화된 시퀀스를 고해상도(High-Resolution; HR) 영상으로 업샘플링 합니다. 이 과정에서 다중 임계값 방식의 적응형 시퀀싱을 사용하여 시퀀스의 평활도를 조절합니다.
- **Performance Highlights**: NeRF Synthetic 및 Mip-NeRF 360 데이터셋에서의 실험 결과, 제안된 방법이 모든 메트릭에서 기존 방법보다 우수한 성능을 나타냈으며, 특히 고주파수 정보를 더 잘 보존하였습니다. VSR 모델을 활용한 이 방법은 기존의 단일 이미지 초해상도(Single-image Super-Resolution; SISR) 모델들을 뛰어넘는 성능을 보였습니다.

### [CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up](https://arxiv.org/abs/2412.16112)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.16112.png)

Vote: 11

Authors: Songhua Liu, Zhenxiong Tan, Xinchao Wang

- ***What's New***: 이 논문에서는 사전 학습된 확산 트랜스포머(Diffusion Transformers; DiT)의 복잡도를 선형으로 줄이기 위해 CLEAR라는 새로운 주위 집중 메커니즘을 도입했습니다. CLEAR는 주어진 쿼리 토큰 주위의 지역 윈도우 내에서 특징 간 상호작용을 제한하여 선형 복잡도를 달성합니다.
- ***Technical Details***: CLEAR는 기존 효율적인 주의 메커니즘을 요약하고, 사전 학습된 DiT를 선형화하는 데 중요한 네 가지 요소: 지역성(Locality), 수식 일관성(Formulation Consistency), 고차원 주의 맵(High-Rank Attention Maps), 및 특징 무결성(Feature Integrity)을 확인합니다. 이를 바탕으로, 각 쿼리 토큰 주위의 지역 윈도우 내에서만 다른 토큰과 상호작용을 허용하는 컨볼루션과 유사한 지역 주의 전략을 제안합니다.
- ***Performance Highlights***: CLEAR는 8K 해상도 이미지 생성에서 주의 계산량을 99.5%까지 감소시키며, 원래의 DiT보다 6.3배 더 빠른 결과를 보여주었습니다. 또한, 여러 모델과 플러그인 간의 제로샷 일반화 가능성을 조사하며, 멀티 GPU 병렬 추론을 지원합니다.

### [TRecViT: A Recurrent Video Transformer](https://arxiv.org/abs/2412.14294)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.14294.png)

Vote: 4

Authors: Ross Goroshin, Chuhan Zhang, Artem Zholus, Mahdi Karami, João Carreira, Yutian Chen, Mehdi S. M. Sajjadi, Joseph Heyward, Viorica Pătrăucean, Simon Osindero, Razvan Pascanu, George-Cristian Muraru, Xu Owen He

- ***What's New***: TRecViT는 비디오 모델링을 위한 새로운 블록을 제안합니다. 이 아키텍처는 시간-공간-채널을 각각의 전용 블록으로 요약하여 처리합니다: 시간의 정보를 통합하는 데는 게이티드 선형 순환 장치(Gated Linear Recurrent Units; LRUs)를 사용하고, 공간에서는 셀프 어텐션(Self-Attention) 레이어를 사용하며, 채널에서는 MLP를 사용합니다. 이 구조는 Sparse와 Dense 작업 모두에서 뛰어난 성능을 발휘하며, 감독학습 및 자가지도 학습 셋업으로 훈련이 가능합니다.
- ***Technical Details***: TRecViT 구조는 각 비디오 프레임을 중첩되지 않는 패치로 나눈 후 이 패치들을 선형적으로 투영하여 토큰 임베딩(Token Embedding) 공간에 배치합니다. 이후 학습된 공간적 위치 인코딩을 추가합니다. 각 토큰은 매 프레임 내의 토큰에 걸쳐 LRU를 통해 시간적 튜브에서 처리되며, 셀프 어텐션과 MLP는 각각의 프레임 내 토큰에 걸쳐 적용됩니다. 주목할 것은, LRU와 ViT 블록 모두 매 프레임 및 튜브 간에는 정보를 혼합하지 않는다는 것입니다.
- ***Performance Highlights***: TRecViT 모델은 SSv2 및 Kinetics400과 같은 대규모 비디오 데이터셋에서 순수 어텐션 모델인 ViViT-L과 비교할 때 동일하거나 더 나은 성능을 보이면서도 3배 적은 매개변수, 12배 작은 메모리 크기, 5배 적은 FLOPs 카운트를 가집니다. 실험 결과, 제안된 모델은 최종 성능뿐만 아니라 메모리 상에서도 ViViT-L과 비교하여 효율적이며, 다양한 비디오 이해 작업에서 유리한 성능을 발휘합니다.

### [SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation](https://arxiv.org/abs/2412.13649)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.13649.png)

Vote: 16

Authors: Jialong Wu, Yulan He, Yilong Lai, Zhenglin Wang, Linhai Zhang, Deyu Zhou

- ***What's New***: SCOPE는 장문 생성에서 키-값(KV) 캐시 압축을 최적화하는 새로운 프레임워크로, 사전 채우기(prefill)와 디코딩(decoding) 단계에서 각각 별도로 최적화하는 접근법을 제시합니다. 이를 통해 LLM의 추론 작업 수행 시 발생하는 KV 캐시의 병목 문제를 해결합니다.
- ***Technical Details***: SCOPE는 사전 채우기 단계에서 생성된 KV 캐시를 그대로 보존하여 필수 정보를 유지하고, 디코딩 단계에서는 슬라이딩 전략을 기반으로 'heavy hitters'를 선택하여 메모리 사용을 최적화합니다. 메모리 사용량과 메모리 전송 효율을 향상시키기 위한 적응적(adaptive) 및 불연속적(discontinuous) 전략도 도입됩니다.
- ***Performance Highlights***: SCOPE는 LONGGENBENCH에서 실험한 결과, 전체 압축률이 35%일 때도 전체 KV 캐시 성능과 비슷한 성능을 달성했습니다. SCOPE는 특히 다중 질문 응답과 같은 장문 생성 작업에서 탁월한 성능을 보였고, 사전 채우기 전용 압축 방법과도 호환되어 모듈식 활용이 가능함을 확인했습니다.

### [Offline Reinforcement Learning for LLM Multi-Step Reasoning](https://arxiv.org/abs/2412.16145)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.16145.png)

Vote: 18

Authors: Shenao Zhang, Yilin Bao, Shibo Hao, Yi Wu, Huaijie Wang, Ziran Yang, Hanze Dong

- ***What's New***: 이 논문에서는 Large Language Models(LLMs)의 다단계 추론 능력을 향상시키기 위해 Offline Reinforcement Learning(RL) 방법론인 OREO(Offline REasoning Optimization)를 소개합니다. OREO는 최대 엔트로피 강화 학습의 통찰을 기반으로, 정책 모델과 가치 함수를 동시에 학습하여 소프트 벨만 방정식을 최적화합니다. 이는 쌍의 선호 데이터 수집 없이도 가능하며, 더 나은 성과 평가를 위한 세분화된 크레딧 할당을 가능케 합니다.
- ***Technical Details***: OREO는 비독립 데이터와 희소 보상을 효과적으로 활용할 수 있으며, 추론 궤도의 정당성은 종종 몇몇 핵심 토큰에 의존하기 때문에 세분화된 크레딧 할당이 특히 중요합니다. 이 방법론은 가치 함수를 활용하여 테스트 시 트리 탐색을 무료로 안내할 수 있어 성능을 더욱 향상시킵니다. 또한, OREO는 온라인 탐색을 위한 반복적 프레임워크로 확장 가능합니다.
- ***Performance Highlights***: OREO는 수학적 추론(GSM8K, MATH)과 구체화된 에이전트 제어(ALFWorld) 벤치마크에 대해 기존의 비동시 학습 방법을 능가합니다. 대표적인 예로, 1.5B 모델을 훈련시켜 MATH 데이터셋에서 52.5%의 정확도를 달성했으며, 기존의 거절 샘플링 방법이 포화 징후를 보이는 반면 OREO는 추가적인 훈련 단계에서도 꾸준히 성과를 향상시킵니다. 또한, 학습된 가치 함수는 테스팅 시 이론적 탐색에 활용되어 수학 문제 해결 정확도를 크게 향상시키는 것으로 나타났습니다.

### [Fietje: An open, efficient LLM for Dutch](https://arxiv.org/abs/2412.15450)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.15450.png)

Vote: 3

Authors: Bram Vanroy

- ***What's New***: Fietje는 네덜란드어에 최적화된 소형 언어 모델(Small Language Models; SLMs)로 공개 및 사용이 용이한 오픈 소스 모델입니다. Phi 2라는 27억 개 파라미터의 영어 중심 모델을 네덜란드어로 전환하여 제작되었습니다. 데이터, 모델 가중치, 학습 및 평가 코드가 모두 공개되어 투명성과 재현성을 강조합니다.
- ***Technical Details***: Fietje의 기본 모델은 Phi 2에 기반한 Transformer 디코더 모델로 구성되어 있으며, 2048 컨텍스트 길이를 가집니다. 280억 개의 네덜란드어 토큰에 계속 학습되었으며, 학습을 위해 네덜란드어 Wikipedia 및 CulturaX 데이터셋이 사용되었습니다. 모델은 Flemish Supercomputer Center에서 총 2주 동안 훈련되었습니다. 추가적으로, 명령문을 따르는 'Instruct' 버전과 챗봇 환경에 최적화된 'Chat' 버전이 제공됩니다.
- ***Performance Highlights***: Fietje는 모델 크기에 비해 기대 이상의 성능을 보였으며, 일부 더 큰 모델과도 경쟁할 수 있었습니다. 특히, 작은 다국어 모델들이 네덜란드어 처리에서 더 이전의 큰 모델들을 능가하는 경향을 보여주어, 언어 기술의 발전 가능성을 제시합니다. Fietje는 네덜란드어의 언어 처리에 중간 다리 역할을 수행하며, 모델 접근성과 적용 범위를 넓히기에 앞으로의 연구에 좋은 출발점이 됩니다.

### [Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis](https://arxiv.org/abs/2412.15322)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.15322.png)

Vote: 11

Authors: Akio Hayakawa, Masato Ishii, Yuki Mitsufuji, Alexander Schwing, Ho Kei Cheng, Takashi Shibuya

- ***What's New***: 이 연구에서는 비디오에서 오디오를 생성하는 멀티모달 합성(Multimodal Joint Training; MMAudio) 프레임워크를 제안합니다. 비디오로부터 고품질의 오디오를 동기화하여 생성할 수 있으며, 특히 텍스트와 오디오 데이터를 결합하여 학습함으로써 기존의 단일 모달리티 훈련법보다 더 높은 품질의 오디오를 생성할 수 있습니다.
- ***Technical Details***: MMAudio는 비디오, 오디오, 텍스트를 동시에 고려하는 단일 트랜스포머 네트워크 안에서 학습됩니다. 학습 시 누락된 모달리티는 마스킹 처리가 되어 결측치를 대체합니다. 또, 오디오-비디오 동기 강화를 위해 조건부 동기화 모듈을 도입하여 고해상도 프레임 비율의 시각적 특징을 사용하고, 적응형 레이어 정규화(adaptive layer normalization; adaLN)의 크기와 바이어스를 조정하여 정교한 동기를 구현합니다.
- ***Performance Highlights***: MMAudio는 프리셋된 공개 모델 중에서 오디오 품질, 의미적 정렬(semantic alignment), 오디오-비디오 동기화 측면에서 새로운 최첨단 성능을 달성했습니다. 또, MMAudio의 응답 시간은 8초짜리 클립을 생성하는데 1.23초에 불과하며 157M의 적은 파라미터로 구동됩니다. 이 모델은 텍스트-오디오 생성에서도 경쟁력 있는 성능을 보여주며, 이러한 멀티모달 공동 학습이 단일 모달 작업에 지장이 없다는 것을 확인했습니다.

### [LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps](https://arxiv.org/abs/2412.15035)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.15035.png)

Vote: 3

Authors: Felix Friedrich, Roberto Navigli, Patrick Schramowski, Simone Tedeschi, Bo Li, Huu Nguyen, Manuel Brack, Kristian Kersting

- ***What's New***: M-ALERT는 다국어 대형 언어 모델(Large Language Models; LLMs)의 안전성을 평가하기 위한 벤치마크로, 영어, 프랑스어, 독일어, 이탈리아어 및 스페인어로 구성된 75,000개의 고품질 프롬프트를 통해 다섯 가지 언어로 액세스할 수 있습니다. 이 벤치마크는 언어별 안전성 분석의 중요성을 강조하며 모델 간의 안전성 상의 불일치를 드러냅니다.
- ***Technical Details***: M-ALERT는 ALERT 택소노미를 기반으로 한 다국어 안전성 벤치마크로, 첨단 번역 파이프라인을 사용하여 영어, 프랑스어, 독일어, 이탈리아어, 스페인어의 프롬프트로 구성되어 있습니다. 각 프롬프트는 자세히 분류된 카테고리와 함께 언어 간 일관된 위협 분류를 보장합니다. 10개의 최신 LLMs을 평가하여 다언어 환경에서의 안전성 문제를 파악합니다.
- ***Performance Highlights***: Llama3.2 모델은 이탈리아어에서는 높은 범죄 카테고리의 불안전성을 보였으나, 다른 언어에서는 안전한 결과를 나타냈으며, Substanc_cannabis와 Crime_propaganda 같은 카테고리는 모든 언어와 모델에서 일관되게 불안전한 반응을 유발했습니다. 이는 다국어 안전성을 강화해야 할 필요성을 시사합니다.

### [Parallelized Autoregressive Visual Generation](https://arxiv.org/abs/2412.15119)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.15119.png)

Vote: 33

Authors: Jiashi Feng, Haoyuan Guo, Shuhuai Ren, Zhenheng Yang, Yujin Han, Xihui Liu, Difan Zou, Zhijie Lin, Yuqing Wang

- ***What's New***: 이 논문에서는 개선된 효율성을 제공하면서도 자동회귀(autoregressive) 모델의 장점을 유지하는 병렬화된 자동회귀 시각적 생성(parallelized autoregressive visual generation) 방법을 제안합니다. 이는 약한 의존성을 가진 토큰들을 병렬로 생성하고, 강한 의존성을 가지는 인접 토큰들은 순차적으로 생성하여, 시각적 토큰 간의 의존성을 조절하는 방식으로 병렬 생성을 구현합니다.
- ***Technical Details***: 이 방법은 일반적인 자동회귀 모델의 아키텍처나 토크나이저(tokenizer)를 수정하지 않고도 손쉽게 통합될 수 있습니다. 제안된 전략은 이미지를 국소 영역으로 나눈 뒤 각 지역의 초기 토큰을 순차적으로 생성하여 글로벌 문맥을 설정하고, 공간적으로 먼 지역에 있는 토큰의 위치를 식별하고 그룹화하여 병렬 생성을 수행합니다. 이는 특히 ImageNet와 UCF-101 데이터셋에서 테스트되었으며, 기존의 순차적인 생성보다 약 3.6배에서 9.5배의 속도 향상을 보였습니다.
- ***Performance Highlights***: 이 접근법은 비교할 만한 품질을 유지하면서 LlamaGen 대비 3.6배에서 9.5배의 속도 향상을 달성했습니다. 특히 PAR-4x 설정에서는 3.46초, PAR-16x 설정에서는 1.31초의 이미지 생성 시간이 소요되며, 이는 기존의 12.41초보다 상당히 빠른 결과입니다. 실험 결과는 이 방법이 다양한 시각적 도메인에서 효율적인 자동회귀 시각적 생성 모델의 가능성을 보여줍니다.

