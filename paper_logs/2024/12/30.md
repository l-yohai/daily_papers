## Daily Papers (2024-12-30)

### [From Elements to Design: A Layered Approach for Automatic Graphic Design Composition](https://arxiv.org/abs/2412.19712)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.19712.png)

Vote: 6

Authors: Jiang Bian, Ji Li, Danqing Huang, Ting Liu, Jiawei Lin, Shizhao Sun

- ***What's New***: 이 논문에서는 다중 모달 그래픽 요소(multimodal graphic elements)에서의 자동 디자인 구성(task of design composition)을 다루기 위해 LaDeCo라는 새로운 접근법을 제안합니다. 이는 기존의 그래픽 디자인 생성 모델들이 주로 특정 하위 작업에 집중하는 반면, 디자인 구성의 전체적인 임무를 해결하고자 하는 첫 번째 시도입니다.
- ***Technical Details***: LaDeCo는 레이어 계획(layer planning)을 통해 주어진 요소를 내용 별로 다른 의미적 레이어(semantic layers)로 나누고, 각 레이어의 속성을 예측함으로써 디자인을 구성하는 레이어 별 생성 프로세스를 수행합니다. 이는 GPT-4o와 같은 대형 멀티모달 모델(Large Multimodal Models; LMMs)을 사용하여 각 레이어의 요소 속성을 단계별로 예측하는 방식을 채택했습니다.
- ***Performance Highlights***: 실험 결과, LaDeCo는 Crello 데이터세트에서 기존의 최첨단 모델들을 뛰어넘는 디자인 구성을 보여주었습니다. 특히, 내용 인식 레이아웃 생성(content-aware layout generation)과 타이포그래피 생성(typography generation) 업무에서 전문화된 모델들보다 뛰어난 성능을 보였습니다. 또, LaDeCo는 해상도 조정, 요소 채우기, 디자인 변형 등 다양한 그래픽 디자인 애플리케이션을 지원할 수 있어 실용성과 다재다능성을 입증했습니다.

### [1.58-bit FLUX](https://arxiv.org/abs/2412.18653)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18653.png)

Vote: 13

Authors: Xueqing Deng, Xing Mei, Xiaohui Shen, Liang-Chieh Chen, Dongwon Kim, Celong Liu, Chenglin Yang

- ***What's New***: 1.58-bit FLUX는 최첨단 텍스트-이미지 생성 모델인 FLUX를 1.58비트 가중치를 활용해 양자화(Quantization)하는 성공적인 접근법을 제시합니다. 이 방법은 이미지 데이터에 접근하지 않고 자가학습(self-supervision) 방식으로 성능을 유지하면서도 1024 × 1024 이미지를 생성할 수 있습니다.
- ***Technical Details***: 1.58-bit FLUX는 FLUX 모델의 비전 트랜스포머(Vision Transformer) 가중치를 99.5%를 1.58비트로 양자화하며, 모든 선형 계층의 가중치를 +1, -1, 0의 값으로 제한합니다. 이를 위해 설계된 맞춤형 커넬(Kernel)은 모델 저장소를 기존보다 7.7배, 추론 메모리 사용량을 5.1배 줄여줍니다.
- ***Performance Highlights***: 1.58-bit FLUX는 T2I Compbench 및 GenEval 벤치마크에서 원본 정밀도 FLUX와 유사한 성능을 보여주며, GPU에서 추론 지연 시간을 크게 개선했습니다. 특히 L20 및 A10과 같은 GPU에서 더 높은 효율성을 발휘합니다.

### [VideoMaker: Zero-shot Customized Video Generation with the Inherent Force of Video Diffusion Models](https://arxiv.org/abs/2412.19645)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.19645.png)

Vote: 3

Authors: Yong Zhang, Xi Li, Ying Shan, Tao Wu, Xiaodong Cun, Zhongang Qi, Guangcong Zheng, Junfu Pu, Huanzhang Dou

- ***What's New***: VideoMaker는 비디오 확산 모델(Video Diffusion Models; VDM)의 고유한 능력을 활용하여 고품질 제로샷 맞춤형 비디오 생성을 가능케 하는 새로운 프레임워크입니다. 이는 추가 모델 없이 VDM 자체를 사용하여 세부적인 피처를 추출하고 피처 주입을 통해 생성된 콘텐츠와의 상호작용을 촉진합니다.
- ***Technical Details***: VideoMaker는 VDM이 참조 이미지에서 세부적인 피처를 추출할 수 있음을 이용합니다. 공간적 자가 주의(spatial self-attention)를 통해 VDM이 참조 피처를 생성 콘텐츠와 상호작용하게 하여 피처를 주입합니다. 이 과정에서 모델은 참조 정보와 생성된 콘텐츠를 구별하기 위한 간단한 학습 전략을 사용합니다. 학습 동안 모션 블록(motion block)을 미세 조정하여 비디오 동적성을 높이는 것도 가능합니다.
- ***Performance Highlights***: 영상 제작 실험 결과, VideoMaker는 Face Similarity, CLIP-I와 같은 주제 충실도 지표에서 기존 방법보다 우수한 성능을 보였습니다. 동적성(Dynamism) 측면에서도 더 높은 평가를 받았으며, 피처 주입과 관련된 고유 모델 기능을 활용하여 생성된 비디오의 일관성 및 품질을 개선했습니다.

### [HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs](https://arxiv.org/abs/2412.18925)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18925.png)

Vote: 51

Authors: Ke Ji, Jianye Hou, Wanlong Liu, Zhenyang Cai, Benyou Wang, Xidong Wang, Rongsheng Wang, Junying Chen

- ***What's New***: HuatuoGPT-o1은 복잡한 의학적 추론을 가능하게 하는 최초의 의료 전문 대형 언어 모델입니다. 이 모델은 40,000개의 검증 가능한 의학 문제를 통해 일반 및 의료 특화된 기존 모델보다 뛰어난 성능을 보여줍니다.
- ***Technical Details***: HuatuoGPT-o1은 두 단계의 학습 접근법을 사용하여 개발되었습니다. 첫 번째 단계에서는 검증기(verifier)를 이용한 전략 기반 검색을 통해 복잡한 추론 경로를 구성하고 이를 바탕으로 LLM을 정밀하게 조정합니다. 두 번째 단계에서는 검증기에 기반한 보상을 통해 강화 학습(RL)을 적용해 복잡한 추론 능력을 더욱 강화합니다. 이 과정에서 Proximal Policy Optimization(PPO) 알고리즘이 사용되었습니다.
- ***Performance Highlights***: HuatuoGPT-o1은 MedQA, MedMCQA, PubMedQA 등의 의료 벤치마크에서 8.5포인트의 향상을 보여주었으며, 70B 모델은 여러 척도에서 다른 오픈 소스의 일반 및 의료 특화 LLM보다 우수한 성능을 기록했습니다. 복잡한 추론은 의료 문제 해결에 효과적이며, RL 확장을 통해 더욱 향상됩니다.

### [SBS Figures: Pre-training Figure QA from Stage-by-Stage Synthesized Images](https://arxiv.org/abs/2412.17606)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.17606.png)

Vote: 2

Authors: Tosho Hirasawa, Kuniaki Saito, Shohei Tanaka, Yoshitaka Ushiku, Risa Shinoda

- ***What's New***: SBS Figures는 자동화된 문서 이해를 위한 중요 기술로서, 시각화된 데이터를 해석하는 모델을 사전 학습(pre-training)하기 위한 새로운 데이터셋입니다. 이 데이터셋은 완전한 주석이 달린 도표와 밀도 높은 질문-답변(QA) 쌍을 포함하여, 다양한 주제 및 외관의 차트를 생성할 수 있도록 설계된 단계적 파이프라인을 특징으로 합니다.
- ***Technical Details***: SBS Figures의 생성 파이프라인은 세 단계로 나누어집니다: 1단계에서는 LLM을 사용해 시각화 데이터를 생성하고, 2단계에서는 미리 정의된 Python 코드를 통해 데이터를 도표로 렌더링하며, 마지막 3단계에서는 LLM을 활용하여 시각화된 데이터에 기반한 QA 쌍을 생성합니다. JSON(파일 형식)을 활용한 데이터 포맷은 일관성을 유지하는 동시에, 각 단계에서 다양한 외관과 내용을 구현할 수 있게 합니다.
- ***Performance Highlights***: SBS Figures로 사전 학습된 모델은 실제 차트 데이터셋에서 강한 성능을 발휘하며, 제한된 수의 실제 차트 데이터로도 효과적인 학습을 지원합니다. 실험 결과, SBS Figures로 사전 학습한 모델은 기존 드문 템플릿 기반의 데이터셋보다 효과적인 사전 학습 효과를 보였습니다. 특히, ChartQA 테스트 세트에서 모델 성능이 눈에 띄게 향상되었습니다.

### [CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era](https://arxiv.org/abs/2412.18702)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18702.png)

Vote: 1

Authors: Simone Papicchio, Sajjadur Rahman, Yanlin Feng

- ***What's New***: CypherBench는 최신 지식 그래프(Knowledge Graph; KG)에서 정확한 정보를 검색하기 위한 혁신적인 벤치마크를 소개했습니다. 이는 RDF 기반의 대규모 그래프를 특화된 속성 그래프(Property Graphs)로 변환하여 LLM이 효율적으로 쿼리할 수 있도록 설계되었습니다.
- ***Technical Details***: CypherBench는 Wikidata에서 파생된 11개의 대규모, 다중 도메인 속성 그래프를 특징으로 하며 총 780만 개의 엔티티와 10,000개 이상의 질문을 포함합니다. RDF에서 속성 그래프로의 변환 엔진을 개발했으며, 텍스트를 사이퍼(Cypher) 쿼리로 변환하는 작업을 체계적으로 생성하는 파이프라인을 설계하였습니다.
- ***Performance Highlights***: 이 벤치마크에서 gpt-4o는 실행 정확도가 60.18%였으며, 10B 미만의 매개변수로 구성된 LLM들은 모두 20%를 넘지 못했습니다. 이는 현재의 LLM이 대규모 지식 그래프를 다루는 데 있어 여전히 많은 도전 과제를 가지고 있음을 보여줍니다.

### [Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment](https://arxiv.org/abs/2412.19326)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.19326.png)

Vote: 11

Authors: Ziang Yan, Yinan He, Chenting Wang, Yi Wang, Yu Qiao, Zhilin Li, Zilei Wang, Xinhao Li, Xiangyu Zeng, Yali Wang, Kunchang Li, Limin Wang

- ***What's New***: Task Preference Optimization (TPO)는 멀티모달 대형 언어 모델(Multimodal Large Language Models; MLLMs)이 비전 태스크와의 정렬을 통해 시각적 이해력을 향상시키는 혁신적인 방법론입니다. 이는 다중 태스크 구체화 및 코러닝을 통해 기존의 MLLMs 성능을 평균 14.6% 향상시켰습니다.
- ***Technical Details***: TPO는 학습 가능한 태스크 토큰을 도입하여 다중 태스크 전용 헤드와 MLLM 간의 연결을 만듭니다. 시각적 라벨링을 활용하여 다중 태스크의 상호 작용을 통해 모델의 성능을 향상시킵니다. 비디오 기반의 모델 VideoChat과 LLaVA에 구현되어 기존 베이스라인 모델 대비 한층 향상된 태스크 특정 성능을 보여줍니다.
- ***Performance Highlights***: VideoChat-TPO 모델은 다양한 비전 태스크에서 제로샷(Zero-shot) 능력을 보여주며, 여러 기준에서 최고 수준의 모델과 유사한 성능을 달성했습니다. 특히 MVBench에서 66.8점, Charades-STA에서 40.2 R@0.5 점을 기록하여 상용 모델보다 우수한 성능을 증명했습니다.

### [Orient Anything: Learning Robust Object Orientation Estimation from Rendering 3D Models](https://arxiv.org/abs/2412.18605)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18605.png)

Vote: 9

Authors: Zhou Zhao, Chao Du, Ziang Zhang, Hengshuang Zhao, Tianyu Pang, Zehan Wang

- ***What's New***: Orient Anything은 단일 이미지에서 객체의 3D 방향을 추정하는 최초의 전문 및 기초 모델입니다. 이는 대규모의 렌더링된 3D 데이터셋을 활용하여 정확한 방향 주석을 제공하고, 모델이 다양한 시나리오에서 제로샷 성능을 발휘할 수 있도록 합니다.
- ***Technical Details***: Orient Anything은 대량의 3D 객체를 필터링, 주석화, 렌더링하는 자동화된 파이프라인을 개발하고, 200만 개 이상의 이미지에서 정확한 방향 주석을 수집합니다. 모델은 세 각도의 확률 분포를 사용하여 방향을 예측하는 '확률 분포 피팅(probability distribution fitting)'을 도입하여, 학습 과정에서 모델의 강건성(stability)을 크게 향상시킵니다. 또한, 실세계 이미지로 전이 성능을 개선하기 위해 다양한 모델 초기화와 데이터 증강 전략(data augmentation strategies)을 조사했습니다.
- ***Performance Highlights***: Orient Anything은 렌더링된 이미지와 실이미지에서 전례 없는 방향 추정 정확성을 달성하였으며, 특히 실제 이미지에서 강력한 제로샷(zero-shot) 성능을 보여줍니다. 이전의 전문가 모델, Cube RCNN 및 발전된 VLM(GPT-4o, Gemini-1.5-Pro)보다 월등히 높은 정확도를 기록했습니다.

### [Safeguard Fine-Tuned LLMs Through Pre- and Post-Tuning Model Merging](https://arxiv.org/abs/2412.19512)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.19512.png)

Vote: 5

Authors: Shachi H Kumar, Saurav Sahay, Hung-yi Lee, Shang-Tse Chen, Hua Farn, Hsuan Su

- ***What's New***: 이 연구는 사전 및 사후 미세조정된 모델의 가중치를 병합하는 방법을 통해 대형 언어 모델(Large Language Models; LLMs)의 안전성을 유지하면서 다운스트림 작업 성능을 향상시킬 수 있는 단순하면서도 효과적인 방법을 제안합니다. 추가적인 안전 데이터 없이도 LLMs의 본래 안전성을 유지하면서 자율적인 과제 적응력을 제공할 수 있습니다.
- ***Technical Details***: 제안된 방법은 두 단계로 구성됩니다. 첫 번째 단계는 기본 모델을 대상 작업에 맞게 미세 조정하는 것입니다. 두 번째 단계는 미세 조정된 모델과 기본 모델의 가중치를 가중 평균(interpolation) 방식으로 병합하는 것입니다. 이 때 병합된 모델의 가중치는 두 모델 간의 기여도를 나타내는 λ(래머다) 값에 따라 결정됩니다. 여러 병합 기법들이 실험되어 최적의 λ 값을 찾습니다.
- ***Performance Highlights***: 제안된 방법은 공격 성공률(Attack Success Rate; ASR)을 최대 30%까지 감소시키면서 다운스트림 과제 성능을 효과적으로 향상시킵니다. 4개의 다운스트림 작업 및 2개의 안전 벤치마크에 대한 포괄적인 평가에서 모델 병합에 의한 안전성 유지의 견고함이 입증되었습니다. 예를 들어, 의료 보조 작업에서는 ASR이 기반 모델 수준에 더 가깝게 개선됨으로써 원래의 안전 기능이 상당 부분 보호되었습니다.

### [The Superposition of Diffusion Models Using the Itô Density Estimator](https://arxiv.org/abs/2412.17762)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.17762.png)

Vote: 8

Authors: Kirill Neklyudov, Alexander Tong, Marta Skreta, Lazar Atanackovic, Avishek Joey Bose

- ***What's New***: SUPERDIFF는 여러 사전 훈련된 확산 모델(Diffusion Models)을 효율적으로 결합할 수 있는 새로운 추론 프레임워크(superposition)를 도입하여, 대규모 모델의 재훈련 없이도 다양한 이미지를 생성할 수 있는 방법을 제시합니다. 이 프레임워크는 Itô 밀도 추정기(Itô Density Estimator)을 활용하여 확산 SDE의 로그 가능도를 새로운 방식으로 추정하며, 기존의 복잡한 밀도 추정 방식인 Hutchinson 추정기와 비슷한 수준의 성능을 제공합니다.
- ***Technical Details***: SUPERDIFF는 사전 훈련된 여러 확산 모델의 벡터 필드를 결합하여 이미지를 생성할 때 'OR' 연산(모델 밀도의 혼합)과 'AND' 연산(모든 밀도에서 동일한 확률을 갖는 샘플 생성)을 수행할 수 있도록 설계되었습니다. 이 알고리즘은 프로세스 상에서 실시간으로 Adaptive Re-weighting Scheme을 사용해 효과적으로 벡터 필드의 가중치를 조정합니다. Itô 밀도 추정기를 통해 밀도를 계산하여, 추론 중 비용을 절감하고 효율성을 높입니다.
- ***Performance Highlights***: CIFAR-10 데이터셋을 통한 실험에서, SUPERDIFF는 개별 모델보다 더 높은 성능을 보였으며, 기존 데이터셋 전체로 학습된 모델보다도 나은 결과를 도출하였습니다. 또한, 프로테인 구조 생성 실험에서는 두 모델의 결합을 통해 생성된 단백질의 디자인 가능성과 신뢰성을 높이며, 더욱 다양한 구조를 생성하는 데 성공하였습니다.

### [Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey](https://arxiv.org/abs/2412.18619)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18619.png)

Vote: 15

Authors: Andreas Vlachos, Yunshui Li, Jian Yang, Shuhuai Ren, Zekun Wang, Yichi Zhang, Shuai Bai, Tianyu Liu, Baobao Chang, Lingwei Meng, Liang Chen, Xu Tan, Aaron Yee, Hongcheng Guo, Lei Li, Minjia Zhang, Zefan Cai, Wen Xiao, Shujie Hu, Ruoyu Wu, Yulong Chen, Junyang Lin, Ge Zhang, Qingxiu Dong, Haozhe Zhao, Yizhe Xiong, Lei Zhang

- ***What's New***: 이번 설문 논문에서는 다양한 모달리티의 머신 러닝 작업에 응용되는 차세대 토큰 예측(Next Token Prediction; NTP) 프레임워크에 대한 포괄적인 조사를 제공합니다. 이는 대형 언어 모델(Large Language Models; LLMs)이 텍스트 모달리티 내의 이해 및 생성 작업을 통합한 데서 발전한 것으로서, 새로운 분류 체계를 소개합니다. 이 체계는 다중 모달 학습에서 NTP의 렌즈를 통해 이해와 생성을 통합하며, 다중 모달 토큰화(Multimodal Tokenization), MMNTP 모델 아키텍처, 통합 작업 표현, 데이터셋 및 평가, 열려 있는 과제를 다룹니다.
- ***Technical Details***: 설문 논문에서 제안된 체계는 다중 모달 정보의 토큰화를 다루며, 이를 통해 LLM들이 비텍스트 입력 및 출력 모달리티를 처리할 수 있는 범위를 확장합니다. 이를 위해 주로 벡터 양자화(Vector Quantization; VQ) 방법과 같은 토큰화 기술이 활용됩니다. 주요 구성 요소로는 토큰화, 모델링, 훈련 목표 설정이 있으며, 이러한 요소는 각 모달리티의 특성을 반영하기 위해 SEMANTIC 토큰화 및 명령과 선호도 학습을 활용합니다.
- ***Performance Highlights***: MMNTP 기반 모델은 VAQ 같은 효율적인 토큰화 방법을 통해 기존의 NLP 및 컴퓨터 비전 중심의 평가 기준에서 경쟁력 있는 성과를 보여 주며, 특히 객체 감지 및 텍스트 예상 작업뿐만 아니라 AI-과학 분야에서도 잠재적 응용 가능성을 보였습니다. 대규모 다중 모달 모델은 대부분의 이해 및 생성 작업에서 텍스트 기반 모델을 능가했으며, 표준 NTP 프레임워크의 확장성과 효율성을 입증하였습니다.

