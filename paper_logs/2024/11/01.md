## Daily Papers (2024-11-01)

### [DELTA: Dense Efficient Long-range 3D Tracking for any video](https://arxiv.org/abs/2410.24211)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.24211.png)

Vote: 3

Authors: Chaoyang Wang, Peiye Zhuang, Hsin-Ying Lee, Evangelos Kalogerakis, Chuang Gan, Tuan Duc Ngo, Sergey Tulyakov

- ***What's New***: DELTA는 동영상에서 각 픽셀을 3D 공간에서 효율적으로 추적할 수 있는 최초의 방법으로, 긴 비디오 시퀀스에서도 모든 픽셀을 3D로 추적할 수 있습니다. 이 방법은 최신 기술 수준의 정확도를 유지하면서 이전 방법에 비해 8배 이상 빠르게 작동합니다.
- ***Technical Details***: DELTA는 저해상도에서의 추적을 위한 공간-시간 주의 메커니즘(Global-Local Attention Mechanism)을 사용한 후, 변환기 기반 업샘플러(Transformer-based Upsampler)를 통해 고해상도 예측을 수행하는 단계로 구성됩니다. 이 과정은 로그 깊이 표현(Log-Depth Representation)이 최적의 성능을 제공한다는 연구 결과에 기반하여 설계되었습니다.
- ***Performance Highlights***: DELTA는 CVO 및 Kubric3D 데이터셋에서 최신 기술 수준의 결과를 기록하며 특히 2D 및 3D 밀집 추적 과제에서 10% 이상의 성능 향상을 보였습니다. 또한, DELTA는 100 프레임을 처리하는 데 2분 이내의 시간을 소비, 이전 방법 대비 8배 이상의 속도 개선을 이루었습니다.

### [Learning Video Representations without Natural Videos](https://arxiv.org/abs/2410.24213)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.24213.png)

Vote: 5

Authors: Xueyang Yu, Xinlei Chen, Yossi Gandelsman

- ***What's New***: 기존 자연 동영상 없이 합성 동영상 및 자연 이미지를 통해 유용한 비디오 표현을 학습할 수 있는 새로운 접근 방식을 제안합니다. 제안된 합성 비디오 데이터셋은 점차적으로 자연 비디오의 속성(예: 움직임, 가속도, 형태 변환)을 모델링하며, 이러한 데이터셋의 사전 학습을 통해 UCF101 및 HMDB51와 같은 데이터셋에서 높은 성능을 달성합니다.
- ***Technical Details***: 합성 비디오 생성은 정적인 색상 원을 시작으로 다양한 형태, 움직임, 가속도, 텍스처 등을 점진적으로 추가하여 변형시킵니다. VideoMAE 모델은 이러한 합성 동영상으로 사전 학습되어 테스트 시 다양한 행동 인식 작업에 적용됩니다. 이는 자연 비디오 대신 합성 데이터를 사용하여 투명하고 조절 가능한 비디오 데이터 큐레이션 프로세스를 제공합니다.
- ***Performance Highlights***: 사전 학습 모델이 UCF101에서 97.2%의 성능 격차를 줄였으며, HMDB51에서도 자연 비디오로 사전 학습한 모델을 능가하였습니다. 특히 UCF101-P의 14개 버전 중 11개에서 합성 데이터로 훈련된 모델이 더 나은 성능을 보였습니다. 이는 합성 데이터가 자연 비디오보다 비정상 데이터셋에서 더 나은 일반화 성능을 가짐을 시사합니다.

### [BenchX: A Unified Benchmark Framework for Medical Vision-Language Pretraining on Chest X-Rays](https://arxiv.org/abs/2410.21969)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.21969.png)

Vote: 7

Authors: Sicong Leng, Xinxing Xu, Tan Li Hui Faith, Yanyu Xu, Rick Siow Mong Goh, Yong Liu, Yang Zhou

- ***What's New***: BenchX는 의료 비전-언어 사전학습(Medical Vision-Language Pretraining; MedVLP) 메소드의 성능을 통일된 기준을 통해 평가할 수 있는 새로운 벤치마크 프레임워크입니다. 주로 가슴 방사선 사진(CXR) 데이터셋을 바탕으로 하며, 다양한 메소드 간의 직접적 비교와 체계적인 분석을 가능하게 합니다.
- ***Technical Details***: BenchX 프레임워크는 세 가지 주요 구성 요소로 나뉩니다: 1) 아홉 개의 데이터셋과 네 가지 의료 과제를 아우르는 포괄적인 데이터셋; 2) 데이터 전처리, 훈련-시험 분할 및 매개변수 선택을 표준화하는 벤치마크 스위트; 3) 다양한 MedVLP 방식을 지원하는 통일된 세부 조정 프로토콜, 각각 분류, 분할, 리포트 생성에 초점이 맞춰져 있습니다.
- ***Performance Highlights***: BenchX를 활용하여, 기존의 최첨단 MedVLP 방법들에 대해 새로운 기준선을 설정하였으며, 초기 MedVLP 방법의 성능이 최신 방법을 능가할 수 있도록 향상될 수 있다는 것을 발견했습니다. MGCA 및 MRM 메소드가 일관된 우수성을 보여주었으며, 방사선 보고 생성에서는 GLoRIA가 가장 높은 성능을 보였습니다. 전체적으로 MedVLP 방법들은 많은 데이터가 필요 없이 효율적인 데이터 전이를 가능케 함을 입증했습니다.

### [Language Models can Self-Lengthen to Generate Long Texts](https://arxiv.org/abs/2410.23933)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.23933.png)

Vote: 12

Authors: Dayiheng Liu, Yichang Zhang, Bofei Gao, Tianyi Tang, Bowen Yu, Junyang Lin, Shanghaoran Quan, Jingren Zhou, An Yang, Jianhong Tu

- ***What's New***: 이 논문에서는 대형 언어 모델(Large Language Models; LLMs)이 추가적인 데이터나 독점 모델 없이도 본래의 지식과 기술만으로 장문의 텍스트를 생성할 수 있는 Self-Lengthen이라는 혁신적인 반복 훈련 프레임워크를 소개합니다. 이 프레임워크는 Generator와 Extender라는 두 가지 역할로 구성되어 있으며, 실험 결과 기존의 방법보다 성능이 우수함을 보여줍니다.
- ***Technical Details***: Self-Lengthen은 이미 존재하는 지침 모델을 초기화하여 동작하는 Generator와 Extender 두 모델로 구성됩니다. Generator는 초기 응답을 생성하며, Extender는 이를 확대합니다. 각 훈련 반복에서 생성된 응답과 그 확장은 점점 길어집니다. 이를 통해 모델은 점진적으로 더 긴 응답을 생성할 수 있게 훈련됩니다. 이 기술을 통해 최대 8,000단어까지의 응답 길이를 구현할 수 있게 되었습니다.
- ***Performance Highlights***: Qwen2 및 LLaMA3과 같은 오픈소스 LLM 백본에 Self-Lengthen을 적용한 결과, 장문 생성을 위한 기존의 방법들보다 데이터의 질과 모델의 성능이 더 우수하게 나타났습니다. 본 연구의 테스트에서는 약 8배 더 긴 응답을 생성할 수 있었으며, 일반적인 작업 성능에서도 별다른 손실 없이 장문 출력을 구현할 수 있음을 입증했습니다.

### [A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents](https://arxiv.org/abs/2410.22476)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.22476.png)

Vote: 16

Authors: Pawan Goyal, Ankan Mullick, Sombit Bose, Gajula Sai Chaitanya, Abhilash Nandy

- ***What's New***: 이 연구는 다중 레이블 다중 클래스 의도 탐지를 위한 새로운 데이터셋(MLMCID-dataset)을 도입하고, 다중 언어 설정에서 다양한 기존 벤치마크 데이터셋을 활용하여 구성되었습니다. 이는 기존의 단순 쿼리가 아닌 복합 쿼리에서 다중 의도를 감지하고, 여러 의도 범위를 추출할 수 있는 포인터 네트워크(Pointer Network) 기반 아키텍처를 제안합니다.
- ***Technical Details***: 포인터 네트워크 기반의 아키텍처(MLMCID)는 주어진 쿼리에서 다중 의도 범위를 추출하고, 여섯 가지 요소로 구성된 코스 및 정밀 레이블을 가진 의도를 탐지할 수 있습니다. 이 모델은 BERT, RoBERTa, Electra 등의 임베딩을 사용하여 구성되며, LSTM 기반 시퀀스 생성기, 어텐션 모델, 피드 포워드 네트워크(FFN) 구조로 의도 범위를 식별하고, 코스 및 정밀 라벨을 예측합니다.
- ***Performance Highlights***: 로버타 기반의 포인터 네트워크 모델이 다양한 데이터셋에서 높은 정확도와 매크로 F1-점수를 기록하며 다른 베이스라인 접근법보다 우수함을 입증했습니다. 단일 의도가 아닌 다중 의도와 의도 범위를 효과적으로 추출함으로써, 제안된 MLMCID 아키텍처가 LLMs(예: GPT-3.5, GPT-4)와 비교하여 탁월한 성능을 보였습니다.

### [GlotCC: An Open Broad-Coverage CommonCrawl Corpus and Pipeline for Minority Languages](https://arxiv.org/abs/2410.23825)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.23825.png)

Vote: 2

Authors: François Yvon, Amir Hossein Kargaran, Hinrich Schütze

- ***What's New***: GlotCC는 소수 언어를 위한 굉장히 커버리지가 넓은 CommonCrawl 코퍼스이자 파이프라인입니다. 1000개 이상의 언어를 포함한 2TB 규모의 데이터를 제공하며, 이를 통해 소수 언어의 자연어 처리(NLP) 기술 개발에 기여합니다. 특히 이 데이터셋은 오픈 소스 파이프라인과 언어 식별 모델을 통해 생성되어 매우 신뢰할 수 있습니다.
- ***Technical Details***: GlotCC는 Ungoliant 파이프라인의 개선된 버전을 사용해 CommonCrawl에서 데이터를 수집합니다. 새로운 언어 식별 모델인 GlotLID v3.0을 활용하여 2000개 이상의 언어를 식별하며, 필터링 기술을 통해 잡음이 제거된 고품질의 문서 기반 데이터를 만들어냅니다. 각 문서에는 언어, 스크립트 일관성 점수, 품질 경고 메타데이터 등이 포함되어 있습니다.
- ***Performance Highlights***: GlotLID v3.0 모델은 GlotTest에서 F1 점수 0.991, FLORES-200에서 0.967의 성능을 보이며, UDHR 데이터셋에서도 이전 모델보다 높은 성능을 발휘합니다. 이는 다국어 코퍼스에서 다루지 않은 소수 언어까지 효과적으로 포함하는 향상된 언어 식별 능력을 보여줍니다.

### [Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders](https://arxiv.org/abs/2410.22366)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.22366.png)

Vote: 34

Authors: Viacheslav Surkov, Robert West, Caglar Gulcehre, Chris Wendler, Justin Deschenaux, Mikhail Terekhov

- ***What's New***: SDXL Turbo 모델의 내부 해석을 위한 새로운 접근 방식으로, 희소 오토인코더(Sparse Autoencoders; SAEs)를 사용하여 텍스트-이미지 변환 모델의 각 변환기 블록 내에서 해석 가능한 특징을 학습하는 방법을 제안하였습니다.
- ***Technical Details***: SDXL Turbo의 정규화 U-net의 변환기 블록 업데이트를 훈련한 SAEs를 활용하여, 이미지 생성 과정에 기여하는 학습된 특징들이 해석 가능하고, 블록들 간의 전문화를 드러냅니다. 하나의 블록은 주로 이미지 구성에 관여하고, 다른 블록들은 지역적 세부 사항 추가, 색상 및 스타일에 중점을 둡니다. SDLens 라이브러리를 개발하여 중간 결과를 캡처하고 조작할 수 있도록 하였습니다.
- ***Performance Highlights***: 총 네 개의 SDXL Turbo 변환기 블록에서 학습한 특징들을 통해, 해석 가능한 특징이 이미지 생성 프로세스에 기여함을 증명하였습니다. 각 변환기 블록이 이미지 구성, 스타일 및 디테일 추가에 특화된 역할을 수행한다는 것을 실증적으로 확인하였습니다.

### [Can Models Help Us Create Better Models? Evaluating LLMs as Data Scientists](https://arxiv.org/abs/2410.23331)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.23331.png)

Vote: 4

Authors: Aleksander Jędrosz, Łukasz Borchmann, Paweł Morawiecki, Michał Pietruszka

- ***What's New***: FeatEng은 대형 언어 모델(LLMs)이 피처 엔지니어링 코드 작성 능력을 테스트하기 위한 벤치마크로 소개되었습니다. 실세계 문제 적용성, 세계 지식의 활용, 복합 기술 통합 및 익스플로잇 저항성을 평가하는 데 중점을 두고 있습니다.
- ***Technical Details***: FeatEng은 다양한 도메인과 문제 크기를 아우르는 다양한 데이터셋으로 구성되어 있으며, 각 데이터셋에 대해 피처 엔지니어링 작업을 진행하도록 설계되었습니다. LLM은 주어진 문제 설명과 메타데이터를 바탕으로 피처를 변환하거나 추가하는 Python 코드를 생성해야 합니다. 결과 데이터셋에서 XGBoost 모델의 예측 성능이 향상되는지를 평가하여 모델의 능력을 측정합니다.
- ***Performance Highlights***: 최고의 성능을 보인 O1-PREVIEW 모델은 11% 이상의 성과를 기록했으며, GEMINI 및 GPT-4O와 같은 모델들이 그 뒤를 따랐습니다. 이러한 결과는 FeatEng 벤치마크가 LLM의 피처 엔지니어링 능력을 효과적으로 평가할 수 있음을 보여줍니다. 이 벤치마크는 기존 벤치마크보다 실제 문제 해결 능력을 더 잘 측정할 수 있습니다.

### [NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks](https://arxiv.org/abs/2410.20650)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.20650.png)

Vote: 1

Authors: Yongchang Hao, Lili Mou, Yanshuai Cao

- ***What's New***: NeuZip는 신경 네트워크의 메모리 효율적인 학습 및 추론을 위한 새로운 가중치 압축 기법을 제공합니다. 이 알고리즘은 부동 소수점의 지수 비트를 손실 없이 압축함으로써 VLLM (Very Large Language Models)과 같은 대규모 모델에서도 메모리를 절반 이하로 줄이면서 성능 손실 없이 훈련 및 추론이 가능하게 합니다.
- ***Technical Details***: NeuZip는 부동 소수점 숫자를 부호 비트, 지수 비트, 가수 비트로 나누어 처리하며, 앤트로피가 낮은 지수 비트를 비대칭 수치 시스템(Asymmetric Numeral System; ANS)으로 압축합니다. 이는 손실 없는 압축으로, 모든 파라미터 훈련을 가능하게 합니다. 추론 시에는 가수 비트의 상위-유의 비트만 저장하는 손실 압축 변형을 사용하여 추가적인 메모리 절약을 이룹니다.
- ***Performance Highlights***: NeuZip를 사용한 실험에서는, 라마(Llama)-2 13B과 같은 대형 모델을 손실 없는 NeuZip을 통해 20GB 이하의 메모리로 학습할 수 있었으며, 이는 소비자용 GPU에서도 가능하게 됩니다. 손실 있는 NeuZip은 추론 시 메모리 사용량을 50% 이상 줄이면서 거의 손실 없는 성능을 유지하였습니다.

### [Constraint Back-translation Improves Complex Instruction Following of Large Language Models](https://arxiv.org/abs/2410.24175)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.24175.png)

Vote: 12

Authors: Yunjia Qi, Lei Hou, Juanzi Li, Bin Xu, Xiaozhi Wang, Hao Peng

- ***What's New***: 이 논문에서는 복잡한 제약을 포함한 지시문을 따르는 대형 언어 모델(LLMs)의 능력을 개선하기 위한 새로운 데이터 생성 기법으로 '제약 역번역'(Constraint Back-translation)을 제안했습니다. 이 방법은 기존 데이터셋에서 고품질의 지시문-응답 쌍을 선정하고, 고급 LLM을 사용해 응답이 이미 충족한 복잡한 제약을 지시문에 추가함으로써 데이터 노이즈와 비용을 줄입니다.
- ***Technical Details***: 이 연구에서는 Llama3-70B-Instruct를 사용하여 제약을 역번역하는 방식으로 고품질의 복잡한 지시문-응답 데이터셋인 CRAB을 생성했습니다. CRAB에는 13,500개의 복잡한 지시문-응답 쌍이 포함되어 있으며, 제약 역번역과 역방향 훈련 기법을 통해 다양한 백본 LLMs의 성능을 향상시킵니다.
- ***Performance Highlights***: CRAB에서 훈련된 모델은 복잡한 지시문을 따르는 능력이 크게 향상되었으며, IFEval 및 FollowBench와 같은 벤치마크에서 여러 기준 모델들에 비해 월등한 성능을 보였습니다. 일반적인 지시문 추종 능력도 AlpacaEval에서 Conifer와 WizardLM 등 기존 모델들을 뛰어넘는 성과를 거두었습니다.

### [Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks](https://arxiv.org/abs/2410.24032)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.24032.png)

Vote: 5

Authors: Saravan Rajmohan, Qingwei Lin, Dongmei Zhang, Jue Zhang, Xu Yang, Qi Zhang, Yingzhe Peng, Xiaoting Qin, Zhiyang Zhang

- ***What's New***: 이 논문은 개인화된 탐색 작업을 위한 협력적 대화형 인터페이스 'CARE'를 소개합니다. 이는 다중 에이전트 LLM 프레임워크와 구조화된 사용자 인터페이스를 결합하여 사용자 필요에 따른 맞춤형 솔루션을 제공하는 시스템입니다.
- ***Technical Details***: CARE 시스템의 인터페이스는 Chat Panel, Solution Panel, Needs Panel로 구성되어 있으며, 다중 에이전트 구조를 통해 사용자 요구 사항을 명시적 및 암묵적으로 식별합니다. 각 패널은 사용자와의 동적인 상호작용과 반복적인 솔루션 세부조정 과정에서 중요한 역할을 합니다. 이 시스템은 또한 사용자 인터페이스와 연결된 다양한 LLM 기반 에이전트(Inquiry Agent, Needs Discovery Agent, Solution Craft Agent 등)로 구성되어 있습니다.
- ***Performance Highlights***: 22명의 참가자를 대상으로 CARE 시스템과 기존 LLM 기반 챗봇을 비교한 사용자 실험에서, CARE는 전반적인 사용자 만족도 및 경험에서 우수한 평가를 받았습니다. 특히, CARE는 인지적 부담을 줄이고 창의적인 탐구를 자극하며 더 개인화된 솔루션을 제공하여 16명의 참가자가 더 선호하는 시스템으로 평가되었습니다.

### [Minimum Entropy Coupling with Bottleneck](https://arxiv.org/abs/2410.21666)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.21666.png)

Vote: 0

Authors: Jun Chen, M. Reza Ebrahimi, Ashish Khisti

- ***What's New***: 이 논문에서는 재구성 분포가 소스 분포와 다른 경우에 유용한 로그 손실(logarithmic loss)을 사용한 새로운 손실 압축 프레임워크를 제안합니다. 이는 특히 합동 압축 및 검색이 필요한 시나리오와 처리에 따른 분포 변이가 발생하는 경우에 적합합니다. 제안된 프레임워크는 최소 엔트로피 결합(minimum entropy coupling) 구조를 확장하여 병목(bottleneck)을 통합하여 결합의 확률성을 제어합니다.
- ***Technical Details***: MEC-B(Minimum Entropy Coupling with Bottleneck)는 엔코더 최적화를 위한 엔트로피-제약 정보 극대화(Entropy-Bounded Information Maximization; EBIM)와 디코더를 위한 최소 엔트로피 결합(Minimum Entropy Coupling; MEC)으로 분해할 수 있습니다. EBIM에서는 엔코더에 대한 탐욕 알고리즘을 제공하여 성능을 보장하며, 함수형 매핑 근처의 최적 해를 특성화하였습니다.
- ***Performance Highlights***: 마르코프 코딩 게임들(Markov Coding Games; MCG) 속에서 이 프레임워크의 실질적 결과를 보여주었으며, 다양하게 압축 비율을 조절하면서 MDP(마르코프 결정 프로세스) 보상과 수신기 정확도 사이의 절충점을 하이라이트합니다. 이는 기존의 압축 기준선과 비교하여 메서드의 효능을 입증합니다.

### [Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use](https://arxiv.org/abs/2410.24218)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.24218.png)

Vote: 3

Authors: Jianing Yang, Yinpei Dai, Jiajun Xi, Yinong He, Joyce Chai

- ***What's New***: 이 연구는 자연어의 정보성과 다양성이 오프라인 강화학습(Offline Reinforcement Learning; RL) 에이전트의 학습 능력에 미치는 영향을 처음으로 상세히 조사하였으며, 다양한 정보성 언어 피드백을 통해 에이전트 성능, 적응성 및 강인성을 향상시키는 중요한 역할을 입증합니다. Language-Teachable Decision Transformer (LTDT)를 개발하여 인간과 유사한 언어 지시를 학습에 통합함으로써, 태스크 학습 향상에 있어 언어 사용의 중요한 역할을 강력히 보여줍니다.
- ***Technical Details***: 본 연구에서는 의사결정 변환기(Decision Transformer; DT)를 기반 구조로 사용하여, 언어의 정보성과 다양성이 에이전트 학습에 미치는 영향을 체계적으로 연구합니다. 전문가의 행동을 참조하여 수정된 언어 템플릿을 사용해 뒤돌아보기 및 전달하기 가이드를 생성하여 정보성을 제어하였으며, 거대한 자연어 모델(GPT–4)을 사용하는 언어 풀(LLMs)을 통해 다양성을 증가시켰습니다.
- ***Performance Highlights***: 다양하고 정보성 있는 언어 피드백으로 훈련된 에이전트는 그렇지 않은 에이전트에 비해 평균 9.86점 증가(37.95%에서 47.81%)하며, 더 높은 다양성을 통합했을 때 추가로 10.14점 증가(57.95%까지)했습니다. 이 결과는 언어의 정보성과 다양성이 오프라인 RL 에이전트 학습의 적응력과 일반화 능력을 크게 향상시킴을 나타냅니다.

### [AAAR-1.0: Assessing AI's Potential to Assist Research](https://arxiv.org/abs/2410.22394)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.22394.png)

Vote: 5

Authors: Lifu Huang, Xiaoxin Lu, Yusen Zhang, Jihyun Janice Ahn, Zhuoyang Zou, Wenpeng Yin, Hanzi Xu, Yuxuan Sun, Xi Li, Kai Zhang, Jiangshu Du, Wenchao Ma, Ryo Kamoi, Jian Xie, Renze Lou, Hongchao Fang, Congying Xia, Sijia Wang

- ***What's New***: AAAR-1.0은 연구 지원을 위한 AI의 잠재력을 평가하기 위한 새로운 벤치마크 데이터세트로, 연구자가 일상적으로 수행하는 네 가지 전문가 수준의 연구 작업에서 대형 언어 모델(LLMs)의 성능을 평가합니다. 이 데이터세트는 특히 연구 지향적이며, 깊은 도메인 전문성이 요구되는 작업으로 구성되어 현재 LLM의 가능성과 한계를 탐구합니다.
- ***Technical Details***: AAAR-1.0은 네 가지 주요 연구 작업으로 구성됩니다: (i) EQUATIONINFERENCE는 논문의 문맥에 기반하여 수식의 정확성을 평가하며, (ii) EXPERIMENTDESIGN는 연구 아이디어와 솔루션을 신뢰성 있게 검증할 실험을 설계하고, (iii) PAPERWEAKNESS는 논문 초안에서 발견한 약점을 분석하며, (iv) REVIEWCRITIQUE는 인간 리뷰의 각 부분이 부족한지를 평가합니다. 데이터의 품질을 보장하기 위해 심층적인 도메인 지식을 가진 AI 연구자들이 데이터 주석을 수행하였습니다.
- ***Performance Highlights***: EQINFER에서 대부분의 LLMs는 랜덤 추측 기준선인 25%에 비해 약간 높은 성능을 보였으며, 최상위 모델들은 약 60%에 도달했습니다. EXPDESIGN에서 LLM이 설계한 실험은 창의적이나 원래 연구 목표에서 벗어난 경우가 많아 트리비얼한 경우가 많았습니다. PAPERWEAKNESS에서 LLM이 식별한 약점은 깊이와 구체성이 부족한 경우가 많았습니다. REVIEWCRITIQUE에서는 LLM이 부족한 인간 리뷰를 효과적으로 식별하지 못해, 메타 리뷰어의 평가에 제한된 유용성을 보였습니다.

### [BitStack: Fine-Grained Size Control for Compressed Large Language Models in Variable Memory Environments](https://arxiv.org/abs/2410.23918)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.23918.png)

Vote: 6

Authors: Yunhua Zhou, Xinghao Wang, Xipeng Qiu, Pengyu Wang, Bo Wang, Dong Zhang

- ***What's New***: BitStack는 대형 언어 모델(LLMs)을 위해 메모리 사용량과 모델 성능 간의 세밀한 조절을 제공하는 획기적인 훈련 없는 중량 압축 방법입니다. 비트스택은 메모리 가변 환경에서 실행 중 메모리와 스토리지 장치 간에 잔차 블록을 동적으로 로드하거나 오프로드하도록 함으로써 모델 크기를 동적으로 조정할 수 있습니다.
- ***Technical Details***: BitStack는 중량 행렬을 분해하여 각 변수의 중요성을 고려하며 약 1비트/변수의 잔차 블록을 작성합니다. 이러한 블록은 저장 공간에서 정렬 및 스택되어 메모리 가용성에 따라 다양한 수량이 로드됩니다. 이는 메모리 사용량과 성능 간의 교환을 가능하게 하며, 복잡한 압축 비율을 피하고 모델을 한 번만 압축하여 다양한 메모리 예산 내에서 동적으로 로딩할 수 있게 합니다.
- ***Performance Highlights***: BitStack는 다양한 과업에서 강력한 양자화 기법과 비교하여 일관되거나 우수한 성능을 유지하며, 특히 극한의 압축 비율에서 두드러집니다. 평가 결과는 Llama 2, Llama 3, Llama 3.1 모델에서 우수한 성능을 입증하였으며, Llama 3.1 70B 모델에서 원본 FP16 모델 성능의 89%를 유지하면서도 가장 뛰어난 기준을 상당히 초과하였습니다.

### [What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective](https://arxiv.org/abs/2410.23743)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.23743.png)

Vote: 32

Authors: Ming Li, Yanhong Li, Tianyi Zhou

- ***What's New***: 이 논문은 신경망의 포스트 트레이닝(post-training) 중 대형 언어 모델(LLMs)의 레이어에서 '빠른 사고(fast thinking)'와 '느린 사고(slow thinking)'가 어떻게 다른지 gradient 분석을 통해 평가합니다.
- ***Technical Details***: 이 연구에서는 레이어별 gradient를 분석하여 여러 과제에서 각 유형의 사고가 미치는 영향을 조사합니다. Singular Value Decomposition(SVD) 및 Nuclear Norm을 사용하여 레이어별 gradient의 크기 및 변동성을 측정합니다.
- ***Performance Highlights***: 느린 사고는 다층에서 안정된 gradient norm을 제공하며, 이것이 학습의 안정성을 높이고 올바른 응답을 판별하는 데 도움이 됩니다. 반면, 빠른 사고는 학습 불안정을 유발합니다. 추가적으로, 지식 학습 과제에서는 반응 길이가 증가함에도 불구하고 이러한 gradient 패턴이 나타나지 않습니다.

### [SelfCodeAlign: Self-Alignment for Code Generation](https://arxiv.org/abs/2410.24198)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.24198.png)

Vote: 9

Authors: Yifeng Ding, Leandro von Werra, Yuxiang Wei, Jiawei Liu, Harm de Vries, Lingming Zhang, Zachary Mueller, Federico Cassano, Arjun Guha, Naman Jain

- ***What's New***: SelfCodeAlign은 코드 생성(Code Generation)에 대한 첫 번째 투명한 셀프 정렬(Transparent Self-Alignment) 파이프라인을 제안합니다. 이 방법은 인스트럭션 튜닝(Instruction Tuning) 동안 인간 주석이나 증류(Distillation) 없이 코드 LLMs을 자체적으로 조율할 수 있도록 설계되었습니다. SelfCodeAlign을 사용하여 새로 생성된 데이터셋을 훈련하며, CodeLlama-70B-Instruct보다 훨씬 작은 모델에서도 더 나은 성능을 달성했습니다.
- ***Technical Details***: SelfCodeAlign은 높은 품질의 시드 스니펫(Seed Snippets)에서 다양한 코딩 개념을 추출하여 새로운 작업을 생성합니다. 각 작업에 대해 여러 응답을 샘플링하고, 각각 테스트 케이스로 쌍을 이루며, 샌드박스 환경에서 유효성을 확인합니다. 주요 실험에서는 CodeQwen1.5-7B와 SelfCodeAlign을 사용하여 74k의 인스트럭션-응답 쌍을 생성한 데이터셋을 사용했습니다. 이 데이터셋으로 모델을 파인튜닝하면 HumanEval+에서 67.1 pass@1 점수를 달성했습니다.
- ***Performance Highlights***: SelfCodeAlign은 다양한 크기의 LLMs에 걸쳐 효과적이며, 특히 자체 데이터 분포에 맞춰 정렬되는 모델에서 더 큰 성능 향상을 확인했습니다. SelfCodeAlign-CQ-7B 모델은 GPT-3.5-Turbo를 사용한 기존의 최첨단 증류 기반 방법보다 높은 성능을 보였습니다. HumanEval+에서는 OSS-Instruct나 Evol-Instruct 같은 방법들보다 훨씬 더 높은 성능을 보여주었습니다.

