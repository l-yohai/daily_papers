## Daily Papers (2024-11-15)

### [Hermes: A Large Language Model Framework on the Journey to Autonomous Networks](https://arxiv.org/abs/2411.06490)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.06490.png)

Vote: 2

Authors: Antonio De Domenico, Fadhel Ayed, Ali Maatouk, Merouane Debbah, Nicola Piovesan, Zhi-Quan Luo

- ***What's New***: Hermes는 대형 언어 모델(LLMs)을 활용하여 네트워크 운영의 완전한 자율성을 향한 혁신적인 체인-오브-에이전트 프레임워크를 제공합니다. Hermes는 '설계도(blueprints)'를 통해 네트워크 디지털 트윈(NDT)의 인스턴스를 구축하고 구조화된 논리적 단계로 네트워크 모델링을 자동화합니다.
- ***Technical Details***: Hermes는 디자이너(Designer)와 코더(Coder)의 역할로 네트워크 모델링 작업을 분리하여, 네트워크 데이터와 도메인 지식을 기반으로 하여 NDT 설계도와 Python 코드를 생성합니다. 자체 반성 단계와 피드백 메커니즘을 통합하여 설계도의 유효성을 즉각적으로 평가하고 수정합니다.
- ***Performance Highlights***: Hermes는 다양한 네트워크 과제를 해결하는 데 있어 최대 80%의 정확도를 달성하였습니다. 이는 GPT-4o와 같은 상용 모델을 활용했을 때의 결과로, 내부 블록 설계와 피드백 메커니즘의 균형이 주요한 성능 향상을 가져왔습니다.

### [Cut Your Losses in Large-Vocabulary Language Models](https://arxiv.org/abs/2411.09009)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.09009.png)

Vote: 13

Authors: Brody Huval, Philipp Krähenbühl, Vladlen Koltun, Erik Wijmans, Alexander Hertzberg

- ***What's New***: 이 연구는 대형 어휘를 가진 언어 모델(Large-Vocabulary Language Models; LLMs)의 손실 계층, 특히 교차 엔트로피(cross-entropy) 손실의 메모리 사용량 문제를 해결하기 위해, '컷 크로스 엔트로피(Cut Cross-Entropy; CCE)'라는 새로운 방법을 제안합니다. CCE는 모든 토큰에 대해 로짓(logits)을 전역 메모리에 구체화하지 않고, 단일 정답 토큰에 대한 로짓만 계산하여 메모리 소모를 크게 줄입니다.
- ***Technical Details***: CCE는 단일 정답 레이블에 대한 인덱스 행렬 곱셈과 모든 어휘 항목에 대한 로그-섬-익스프 연산으로 교차 엔트로피 손실을 재구성합니다. 이를 위해 맞춤형 CUDA 커널을 사용하여, 필요한 만큼 로짓을 SRAM에서 계산하여 GPU 메모리에서 물리화하지 않고 교차 엔트로피 계산을 수행합니다. 또한 CCE는 소프트맥스(softmax)의 내재된 희소성을 활용하여 기울기 계산에서 무시할 수 있는 요소를 건너뛰도록 설계되었습니다.
- ***Performance Highlights***: Gemma 2 (2B) 모델을 예로 들어, CCE는 손실 계산의 메모리 사용량을 24GB에서 1MB로, 학습 시 전체 메모리 사용량을 28GB에서 1GB로 줄였습니다. 이러한 메모리 소모 감소는 학습 속도나 수렴도를 희생하지 않고 이루어졌으며, 기울기 필터링과 어휘 정렬이 성능에 크게 기여했습니다.

### [LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models](https://arxiv.org/abs/2411.09595)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.09595.png)

Vote: 22

Authors: Jun Zhu, Hang Su, Yikai Wang, Xiaohui Zeng, Jonathan Lorraine, Sanja Fidler, Zhengyi Wang

- ***What's New***: LLaMA-Mesh는 대형 언어 모델(Large Language Models; LLMs)을 이용하여 3D 메시 생성(3D Mesh Generation) 기능을 확장시키는 새로운 접근법을 제안합니다. 이를 통해 텍스트 설명에서 직접 3D 메시를 생성할 수 있으며, 3D와 텍스트 모달리티를 통합하는 모델로 발전시킵니다.
- ***Technical Details***: LLaMA-Mesh는 3D 메쉬 데이터를 토큰화(tokenize)하여 LLMs가 직접적으로 처리할 수 있도록 합니다. OBJ 파일 포맷을 텍스트로 변환하여 새로운 토크나이저를 사용할 필요성을 없애고 학습 오버헤드를 최소화합니다. 또한, 3D 대화(Fine-tuning) 슈퍼바이즈드 데이터셋을 구축하여 LLaMA-3.1-8B-Instruct 모델을 세밀하게 튜닝하였으며, 이를 통해 모델이 텍스트 프롬프트에 기반하여 3D 메시를 생성하고, 텍스트와 3D 메시의 상호작용을 이해할 수 있도록 합니다.
- ***Performance Highlights***: LLaMA-Mesh는 3D 메시 생성에 있어 기존에 사용되던 모델들과 유사한 품질을 유지하면서 강력한 텍스트 생성 능력을 보전합니다. 미세 조정 후에도, 모델의 언어 이해와 추론 능력은 기본 모델인 LLaMA 시리즈와 비슷한 성능을 나타내며, 3D 콘텐츠 생성 업무에 성공적인 확장을 보여줍니다.

### [Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples](https://arxiv.org/abs/2411.08954)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.08954.png)

Vote: 2

Authors: Gabriel Loaiza-Ganem, Brendan Leigh Ross, Noël Vouitsis, Rasa Hosseinzadeh, Satya Krishna Gorti, Jesse C. Cresswell, Valentin Villecroze

- ***What's New***: 이 논문은 일관성 모델(Consistency Models; CMs)에서 발생하는 문제와 더 나은 ODE 해결(Ode Solving)이 반드시 더 나은 샘플을 생성하는 것은 아니라는 점을 밝혀냅니다. Direct CMs는 이러한 ODE 해결 오류를 줄이기 위해 고안되었으나 오히려 샘플 품질이 악화되는 현상을 보입니다. 이는 ODE 기반 확산 모델 증류의 이해에 대한 도전에 해당합니다.
- ***Technical Details***: 일관성 모델은 확률 흐름 ODE(Probability Flow ODE)를 해결하기 위해 만들어졌으며, 확산 모델을 몇 단계로 축소하여 샘플링합니다. Direct CMs는 PF ODE의 오류를 줄이도록 만들어졌지만, 본 연구는 더 강력한 감독을 통해 ODE 오류를 줄이려 한 Direct CMs가 오히려 샘플 품질을 악화시킨다는 것을 보여줍니다.
- ***Performance Highlights***: CMs는 PF ODE를 덜 정확하게 해결하지만 더 높은 품질의 이미지를 생성합니다. 반면 Direct CMs는 ODE 해결 정확도는 높지만 이미지 품질은 낮았습니다. 예를 들어, 단일 단계 생성에서 CMs는 FID 103.9를 기록했으나 Direct CMs는 158.6를 기록했습니다. 이는 더 나은 ODE 해결이 더 높은 샘플 품질로 이어지지 않음을 의미합니다.

### [Sharingan: Extract User Action Sequence from Desktop Recordings](https://arxiv.org/abs/2411.08768)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.08768.png)

Vote: 3

Authors: Xiaoting Qin, Yi Ren, Jue Zhang, Dongmei Zhang, Qi Zhang, Kehong Yuan, Yanting Chen, Lu Han, Qingwei Lin, Saravan Rajmohan

- ***What's New***: 이 논문은 사용자 데스크탑 녹화 비디오에서 사용자 작업 추출을 위해 비전-언어 모델(Vision-Language Models; VLMs)을 활용한 두 가지 새로운 방법론인 Direct Frame-Based Approach(DF)와 Differential Frame-Based Approach(DiffF)를 제안합니다. 이는 데스크탑 녹화 비디오의 사용자 작업 시퀀스를 추출하는 첫 번째 시도로, 새로운 접근 방식과 벤치마크를 제공합니다.
- ***Technical Details***: Direct Frame-Based Approach(DF)는 VLM에 샘플링된 프레임을 직접 입력하여 사용자 작업 시퀀스를 생성하며, 차별적 프레임 기반 접근법(Differential Frame-Based Approach; DiffF)은 컴퓨터 비전 기술을 사용하여 프레임 간 명시적인 차이를 먼저 탐지합니다. 두 방법 모두 GUI-World에서 적응된 벤치마크 데이터셋으로 평가되었습니다. DF는 사용자 작업을 인식하는 데 있어 70% ~ 80%의 정확도를 나타냈으며, 추출된 작업 시퀀스는 RPA 프로세스를 통해 재생 가능했습니다.
- ***Performance Highlights***: 실험 결과 DF 접근법은 사용자 작업을 추출하는 데 있어 VLMs의 잠재력을 보여주며, DiffF는 Df보다 약간 낮은 precision을 나타냈습니다. GPT-4o는 DF와 DiffF 방법 중에서 가장 높은 성능을 기록했으며, 실험 결과는 각 데이터셋에서의 도전 과제를 나타냅니다. 특히, 더 작은 모델인 GPT-4o-mini와 Gemini1.5-Flash는 더 큰 모델에 비해 상당한 성능의 감소를 보였습니다.

### [MagicQuill: An Intelligent Interactive Image Editing System](https://arxiv.org/abs/2411.09703)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.09703.png)

Vote: 29

Authors: Ka Leong Cheng, Zhiheng Liu, Qiuyu Wang, Yue Yu, Zichen Liu, Hao Ouyang, Qifeng Chen, Wen Wang, Yujun Shen

- ***What's New***: MagicQuill은 사용자 친화적인 인터페이스를 통해 사용자의 창의성을 빠르게 실현할 수 있도록 설계된 통합 이미지 편집 시스템입니다. 이 시스템은 디퓨전 모델(difference models)을 기반으로 하며, 추가, 제거, 색상 변화의 세 가지 직관적인 브러시를 사용하여 이미지를 편집합니다. Multi-Modal Large Language 모델(MLLM)이 브러시 스트로크를 통해 사용자의 의도를 실시간으로 예측하여 사용자가 입력할 필요 없이 적합한 제안을 제공합니다.
- ***Technical Details***: MagicQuill은 세 가지 핵심 모듈을 포함합니다. Editing Processor는 고품질의 제어 가능 편집을 보장하며, Painting Assistor는 사용자 의도의 예측과 해석을 향상시킵니다. Idea Collector는 간단하고 효율적인 아이디어 입력 인터페이스를 제공하여 사용자가 브러시로 그리면서 배경을 조작하고 연속적인 편집을 수행할 수 있도록 지원합니다. 'Draw&Guess'라는 새로운 작업을 도입하여 사용자의 손으로 그려진 입력을 데이터세트로 구성해 MLLM의 이해를 보완합니다.
- ***Performance Highlights***: Editing Processor는 스마트에디트(SmartEdit) 및 브러시넷(BrushNet)과 같은 기존의 방법과 비교하여 엣지 정렬 및 색 충실도에서 우수한 성능을 보입니다. 또한, Painting Assistor는 LLaVA-1.5, LLaVA-Next, GPT-4o 등 최신 MLLM보다 사용자 의도 해석 능력이 뛰어납니다. 사용자 연구 결과, Idea Collector는 모든 시스템 사용성 측면에서 우수한 것으로 나타났습니다. MagicQuill의 사용자 중심 디자인은 상세한 이미지 편집에 필요한 시간과 전문성을 크게 줄이며, 디지털 이미지 편집 분야의 진보를 선도합니다.

### [ClinicalBench: Can LLMs Beat Traditional ML Models in Clinical Prediction?](https://arxiv.org/abs/2411.06469)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.06469.png)

Vote: 9

Authors: Shan Chen, Kai Shu, Canyu Chen, Danielle Bitterman, Che Liu, Jian Yu, Zhongwei Wan, Fei Wang

- ***What's New***: ClinicalBench는 대형 언어 모델(Large Language Models; LLMs)이 임상 예측에서 전통적인 기계학습 모델을 능가할 수 있는지를 종합적으로 연구하기 위한 새로운 벤치마크를 제안합니다. 이 벤치마크는 일반 목적 및 의료용 LLM과 11개의 전통적인 ML 모델을 포함하여 그들의 성능을 세 가지 주요 임상 예측 작업에서 비교합니다.
- ***Technical Details***: ClinicalBench는 입원 기간 예측, 사망률 예측, 재입원 예측 등 세 가지 임상 예측 작업을 포함하고 있으며, MIMIC-III 및 MIMIC-IV 데이터베이스를 사용합니다. 14개의 일반 목적 LLM과 8개의 의료용 LLM, 그리고 XGBoost, SVM, MLP와 같은 11개의 전통적인 ML 모델이 비교되었습니다. 각 작업에서는 매크로 F1 및 AUROC가 평가 메트릭으로 사용되었습니다.
- ***Performance Highlights***: 실험 결과에 따르면, 일반 목적 및 의료용 LLM은 여전히 임상 예측에서 전통적인 ML 모델에 비해 성능이 뒤떨어집니다. 반면 XGBoost 및 SVM 같은 전통적인 ML 모델이 세 가지 임상 예측 작업에서 우수한 성능을 보였습니다. LLM의 성능 향상을 위한 다양한 프롬프트 기법이나 매개 변수 스케일링조차도 전통적인 모델의 성능을 넘지 못했습니다.

