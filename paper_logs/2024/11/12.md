## Daily Papers (2024-11-12)

### [KMM: Key Frame Mask Mamba for Extended Motion Generation](https://arxiv.org/abs/2411.06481)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.06481.png)

Vote: 3

Authors: Zeyu Zhang, Hao Tang, Akide Liu, Hang Gao, Yiran Wang, Danning Li, Feng Chen, Qi Chen

- ***What's New***: KMM(Key Frame Mask Mamba)는 다양한 기간의 텍스트 프롬프트를 기반으로 연장된 인간 모션을 생성하는 새로운 구조입니다. Mamba의 메모리 감쇠 문제를 해결하기 위해 키 프레임 마스킹 모델을 도입하였으며, 멀티모달 퓨전 문제를 개선하기 위해 새로운 대조 학습 패러다임을 설계했습니다.
- ***Technical Details***: KMM은 키 프레임 선택과 마스킹을 위한 새로운 밀도 기반 전략을 채택했습니다. 각 프레임의 지역 밀도를 계산하고, 높은 밀도를 가지는 프레임을 찾아 이를 마스킹합니다. 대조 학습을 통해 CLIP 텍스트 인코더 대신 동적으로 텍스트 인코딩을 학습하여 텍스트와 모션의 정렬을 개선하였습니다.
- ***Performance Highlights***: KMM은 BABEL 데이터셋에서 기존 최첨단 방법보다 57% 이상의 FID 개선을 달성하였으며, 파라미터 수를 70% 줄였습니다. 추가적으로 BABEL-D 데이터셋에서 실험을 통해 의미 있는 텍스트-모션 정렬 개선을 입증하였습니다.

### [IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization](https://arxiv.org/abs/2411.06208)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.06208.png)

Vote: 14

Authors: Cheng Fu, Haiyang Yu, Yongbin Li, Fei Huang, Xinghua Zhang

- ***What's New***: 이 논문은 대형 언어 모델(LLMs)의 복잡한 지시사항를 따르는 능력을 향상하고 평가하는 TRACE 벤치마크를 소개합니다. TRACE는 120K 훈련 데이터와 1K 평가 데이터로 구성되어 있으며, LLMs가 복잡한 입력 및 출력 선호 최적화(Input-Output Preference Optimization; IOPO)를 통해 복잡한 지시사항를 효율적으로 따를 수 있게 합니다.
- ***Technical Details***: IOPO 정렬 방법은 입력과 출력 선호 쌍을 모두 고려하여 모델이 응답 선호에 빠르게 일치하도록 하고 세부적인 지시사항 선호를 탐구하도록 합니다. 이는 LLMs가 세분화된 제약조건을 효과적으로 인식하도록 돕습니다. TRACE 벤치마크는 5가지 제약 유형 내 26개 제약 차원으로 구성된 복잡한 지시사항의 수동 분류를 기반으로 자동으로 구축됩니다.
- ***Performance Highlights***: 대규모 실험에서 IOPO는 in-domain 데이터에서 SFT 대비 8.15%의 개선을, out-of-domain 데이터에서는 6.29%의 향상을 보여 줍니다. 이는 기존의 DPO 접근법에 비해 평균 7.22% 향상된 성능을 기록했습니다.

### [Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models](https://arxiv.org/abs/2411.07232)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.07232.png)

Vote: 41

Authors: Yoad Tewel, Gal Chechik, Dvir Samuel Yuval Atzmon, Rinon Gal, Lior Wolf

- ***What's New***: Add-it는 사전 학습된 확산 모델(pretrained diffusion models)을 사용하여 최적화나 사전 훈련 없이 이미지에 객체를 삽입하는 새로운 방법을 제안합니다. 기존 장면과 텍스트 프롬프트의 균형을 맞추면서 자연스럽게 새로운 객체를 이미지에 추가하는 것을 가능하게 합니다.
- ***Technical Details***: Add-it의 접근 방식은 장면 이미지(scene image), 텍스트 프롬프트(text prompt), 생성된 이미지(generated image)로부터 정보를 통합하기 위해 확산 모델의 주의(attention) 메커니즘을 확장합니다. 구조 전송(structure transfer)과 주제 가이드 잠재 혼합(subject-guided latent blending)을 통해 소스 이미지의 세부 사항을 유지하면서 필요한 조정을 수행할 수 있습니다. 'Additing Affordance Benchmark'를 소개하여 객체 배치의 타당성을 평가합니다.
- ***Performance Highlights***: Add-it는 기존의 감독 학습 방법을 능가하여 개체 삽입 벤치마크에서 83%의 높은 성능을 달성했습니다. 또한, 사람 평가에서 Add-it가 80% 이상의 경우에서 선호되었으며, 다양한 자동화된 메트릭에서도 개선 사항을 보여줍니다.

### [Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models](https://arxiv.org/abs/2411.07140)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.07140.png)

Vote: 29

Authors: Bo Zheng, Chengwei Hu, Jiaheng Liu, Hui Huang, Xingyuan Bu, Shilong Li, Hangyu Guo, Xuepeng Liu, Dekai Sun, Boren Zheng, Yancheng He, Yingshui Tan, Wenbo Su, Weixun Wang

- ***What's New***: Chinese SimpleQA는 대형 언어 모델(LLM)의 사실성 평가를 위한 첫 번째 포괄적인 중국어 벤치마크로, 짧은 질문에 대한 답변을 평가하기 위해 설계되었습니다. 주요 특징으로는 중국어 중심, 다양성, 높은 품질, 정적인 답변, 평가 용이성이 있습니다.
- ***Technical Details***: Chinese SimpleQA는 6개의 주요 주제와 99개의 하위 주제로 구성된 3000개의 고품질 질문으로 구성되어 있으며, 데이터 수집 과정에서 자동 생성과 사람 검증을 통해 데이터의 정확성 및 사실성을 검증합니다. 특히 검색 강화 생성(RAG) 전략을 활용하여 대형 언어 모델의 사실 정확성을 향상시켰습니다.
- ***Performance Highlights***: Chinese SimpleQA에서 'o1-preview' 모델이 최고 성능을 기록하였으며, 중국어에 특화된 여러 폐쇄형 LLM들도 높은 성과를 보였습니다. 모델의 크기가 클수록 성능에 긍정적 영향을 미쳤고, RAG 전략을 적용할 경우 대부분의 모델이 성능을 크게 향상시켰습니다.

### [Watermark Anything with Localized Messages](https://arxiv.org/abs/2411.07231)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.07231.png)

Vote: 11

Authors: Tom Sander, Pierre Fernandez, Teddy Furon, Alain Durmus, Matthijs Douze

- ***What's New***: 이 논문에서는 WAM(Watermark Anything Model)이라 불리는 새로운 이미지 워터마킹 모델을 소개합니다. 이 모델은 이미지의 로컬 영역에 워터마크를 삽입하고, 해당 영역을 효과적으로 탐지하는 기능을 갖추고 있습니다. 특히, 고해상도의 이미지에서도 인페인팅(impainter)이나 스플라이싱(Splcing)에 강인한 성능을 보입니다.
- ***Technical Details***: WAM은 두 가지 주요 모델로 구성됩니다: 워터마크를 이미지에 임베딩하는 embedder와 워터마크된 및 비워터마크된 구역을 세그멘테이션(segmentation)하고 메시지를 추출하는 extractor입니다. 이 모델은 낮은 해상도에서 훈련된 후 다중 워터마크를 포함해 고해상도로 포스트-트레이팅(post-training) 됩니다. 세그멘테이션, 글로벌 탐지 등 다양한 작업에서의 성능을 향상시키기 위해 DBSCAN 클러스터링 알고리즘이 사용됩니다.
- ***Performance Highlights***: WAM은 COCO 및 DIV2k와 같은 데이터셋에서 높은 무결성(High imperceptibility)과 강인성(robustness)을 보였습니다. 또한 다양한 이미지 변형에 대한 실험에서, WAM은 85% 이상의 mIoU와 95% 이상의 비트 정확도를 달성하였습니다. 이 결과는 기존의 워터마킹 기법들이 다루지 못했던 부분을 개선했음을 보여줍니다.

### [Ablation is Not Enough to Emulate DPO: How Neuron Dynamics Drive Toxicity Reduction](https://arxiv.org/abs/2411.06424)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.06424.png)

Vote: 2

Authors: Harry Mayne, Filip Sondej, Adam Mahdi, Yushi Yang

- ***What's New***: 이 논문에서는 직접 선호 최적화(Direct Preference Optimisation; DPO)를 통해 독성을 줄이는 방법에 대한 최신 연구를 소개합니다. 기존의 설명이 독성을 완화하는 방법으로 독성이 가장 높은 MLP 뉴런을 억제한다고 주장한 것과 달리, 연구자들은 DPO가 여러 뉴런 그룹에서 반독성 방향을 강화하여 독성을 줄이는 복합적인 효과를 가지고 있음을 발견했습니다. 이는 단순히 독성 뉴런을 억제하는 것만으로는 DPO의 전체 효과를 설명할 수 없음을 시사합니다.
- ***Technical Details***: DPO는 독성을 줄이기 위해 단일 뉴런보다 더 많은 뉴런 그룹의 누적 효과를 이용합니다. 뉴런 활성화 변화를 독성 탐지기로 투영함으로써, 뉴런 하나 당 독성을 조정하는 메커니즘을 정량화합니다. 연구 결과, 독성 방향으로의 글쓰기(GPT-2를 사용한)는 오히려 줄어들고, 반대로 반독성 방향이 장려됩니다. 이는 뉴런 그룹 간의 균형 잡기 과정으로 작용하며, 독성 감소를 전체적으로 달성합니다.
- ***Performance Highlights***: 실험 결과, 독성 뉴런을 고립시켜 억제하거나 활성화 패칭을 적용하더라도 DPO의 효과보다 낮은 독성 감소를 보였습니다. 또한, DPO는 전체 독성 감소 중 31.8%만 독성 뉴런 억제에서 오고, 나머지 68.2%는 여러 뉴런 집단의 누적 효과로 인해 발생합니다. 이는 독성 감소에 있어 교차 뉴런 효과가 중요함을 시사하며, DPO의 복잡한 메커니즘을 검증하는 데 도움을 줍니다.

### [Golden Touchstone: A Comprehensive Bilingual Benchmark for Evaluating Financial Large Language Models](https://arxiv.org/abs/2411.06272)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.06272.png)

Vote: 2

Authors: Huanyi Su, Yiyan Qi, Chengjin Xu, Fuwei Wang, Jiajun Su, Junxi Liu, Jian Guo, Zhouchi Lin, Jia Li, Jiajie Zhong, Fengrui Hua, Saizhuo Wang, Xiaojun Wu

- ***What's New***: Golden Touchstone는 금융 대형 언어 모델(Financial Large Language Models; FinLLMs)의 성능을 평가하기 위한 첫 번째 포괄적인 이중언어(중국어와 영어) 벤치마크로 소개되었습니다. 이 벤치마크는 8개의 핵심 금융 자연어 처리(NLP) 작업에 걸쳐 있는 데이터셋을 통합하여 모델들의 언어 이해 및 생성 능력을 철저히 평가합니다.
- ***Technical Details***: Golden Touchstone 벤치마크는 중국어와 영어로 구성된 22개의 데이터셋으로 구성되어 있으며, 금융 감정 분석, 내용 분류, 주체 인식, 주식 움직임 예측과 같은 하위 작업을 포함합니다. 또한, 지속적 사전 학습과 금융 지시 튜닝을 통해 훈련된 금융 LLM인 Touchstone-GPT를 오픈 소스화하였습니다.
- ***Performance Highlights***: 모델 평가 결과, GPT-4o와 같은 상업적 대형 모델들은 감정 분석과 같은 특정 작업에서 높은 성과를 보였으나, 세부적인 정보 추출이나 관계 추출에서는 한계를 드러냈습니다. Touchstone-GPT는 이러한 한계를 어느 정도 극복하며, 대다수 작업에서 경쟁력 있는 성능을 기록하였으나, 주식 예측과 같은 특정 작업에서의 향상 가능성이 있음을 보여주었습니다.

### [Energy Efficient Protein Language Models: Leveraging Small Language Models with LoRA for Controllable Protein Generation](https://arxiv.org/abs/2411.05966)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.05966.png)

Vote: 1

Authors: Aayush Shah, Shankar Jayaratnam

- ***What's New***: 이 연구는 최신 Llama-3-8B와 Phi-3-mini 아키텍처에 기반한 작은 단백질 언어 모델(protein language models)을 소개하며, 이 모델들은 비통제적(uncontrollable) 및 통제적(controllable) 단백질 생성 작업을 모두 수행할 수 있습니다. Energy 효율적인 하드웨어인 ET-SoC-1 칩을 사용하여 추론 시 소모되는 에너지를 60%까지 절감하였고, 연구자들은 이 모델들이 실제 연구 및 개발에 유용하게 사용될 수 있도록 지원합니다.
- ***Technical Details***: 연구는 Low-Rank Adaptor (LoRA) 기술을 통해 기존 모델 크기의 4%로 학습 가능한 파라미터를 줄였습니다. UniRef50 데이터셋의 일부와 소형 모델을 사용하여 전체 훈련 시간을 70% 줄였으며, Phi-3-mini는 Llama 3에 비해 훈련 비용을 30% 감소시켰습니다. 또한, 두 단계로 이루어진 훈련 프로세스를 사용하였으며, 첫 번째는 단백질 시퀀스에 기반한 비통제적 생성이고, 두 번째는 특성 기반의 통제적 생성입니다.
- ***Performance Highlights***: Llama 3 모델은 비통제적 생성 작업에서 평균 pLDDT 점수 69.75±12.74를 달성하며, 안정적인 단백질 구조를 생성하는 데에 있어서 기존 모델보다 뛰어납니다. 통제적 생성 작업에서는 평균 TM-Score 0.84를 기록하여 목표 단백질과 높은 구조적 유사성을 가집니다. ET-SoC-1 칩을 활용해 각종 성능 지표에서 효율성을 증대시켰으며, 특히 TPS/W에서 Llama 3는 60% 개선, Phi 3는 세 배 이상의 개선을 보여줍니다.

### [Counterfactual Generation from Language Models](https://arxiv.org/abs/2411.07180)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.07180.png)

Vote: 4

Authors: Shauli Ravfogel, Anej Svete, Ryan Cotterell, Vésteinn Snæbjarnarson

- ***What's New***: 이 논문은 언어 모델(Language Models; LMs)의 인과 생성 메커니즘을 이해하고 조작하기 위해 언어 모델을 일반화된 구조방정식 모델(Generalized Structural-equation Models; GSEMs)로 재구성하여 진정한 반사실(counterfactual)을 생성하는 새로운 프레임워크를 제안합니다. 이는 기존의 개입 기술들에 비해 모델의 예상치 못한 부작용을 줄이고 진정한 반사실적 분석을 가능하게 합니다.
- ***Technical Details***: 이 프레임워크는 Gumbel-max 기법을 활용하여 언어 모델을 GSEM으로 재구성하며, 각 원문 및 그에 대한 반사실적 문자열 쌍을 생성하기 위해 동일한 노이즈 샘플을 사용합니다. 이는 모델 개입 후의 텍스트하여 정확한 인과관계를 분석할 수 있도록 돕습니다. 실험에서는 '생성 후 되짚어 보기(Gumbel-Hindsight Sampling)' 알고리즘을 개발하여 관측된 문자열에 대한 노이즈 변수를 추론하고, 그에 기반해 반사실적 문자열을 생성합니다.
- ***Performance Highlights***: GPT2-XL 및 LLaMA3-8b 모델을 사용한 실험 결과, 반사실적 생성 기법은 기존 개입 기법이 초래할 수 있는 예기치 않은 의미적 변화와 그로 인한 부작용을 발견하는 데 효과적임을 보여주었습니다. 특히, 성별 기반의 반사실적 생성 실험에서는 기존 모델의 편향된 생성 결과가 드러나기도 했으며, 대부분의 경우 개입이 '최소'로 수행될 수 없음을 확인했습니다.

### [GitChameleon: Unmasking the Version-Switching Capabilities of Code Generation Models](https://arxiv.org/abs/2411.05830)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.05830.png)

Vote: 18

Authors: Eilif Muller, Irina Rish, Diganta Misra, Nizar Islah, Justine Gehring, Terry Yue Zhuo, Massimo Caccia

- ***What's New***: GitChameleon은 코드 생성 모델(Code Generation Models)이 최신 코드 라이브러리의 버전 변화에 얼마나 잘 적응할 수 있는지를 시험하기 위해 개발된 새로운 벤치마크 데이터셋입니다. 이 데이터셋은 116개의 파이썬 코드 완성 문제로 구성되어 있으며, 각 문제는 특정 라이브러리 버전에 따라 조건이 설정되고 실행 가능한 단위 테스트를 포함합니다.
- ***Technical Details***: GitChameleon 벤치마크는 PyTorch, NumPy, Scikit-Learn 등 총 11가지 인기 라이브러리의 버전 이력을 바탕으로 한 116개의 파이썬 문제를 포함합니다. 각 문제는 실행 기반 평가를 위해 손으로 작성된 단언 테스트를 포함하고 있으며, 다양한 API 변화 유형, 버전 출시 연도, 라이브러리에 따라 모델 성능을 체계적으로 분석합니다. 또한, 오류 로그를 피드백으로 활용하여 코드 생성 LLM의 버전 적응 성능을 향상시키는 방법의 효과를 입증하였습니다.
- ***Performance Highlights***: 실험 결과에 따르면, 현재의 대형 언어 모델(LLM)은 버전별로 정확한 코드 생성에 상당한 어려움을 겪고 있으며, 예를 들어 GPT-4o의 경우 Pass@10에서 39.9%의 성능을 보였습니다(오류 피드백을 제공할 경우 43.7%로 향상). 모델 크기와 성능 사이에 긍정적인 상관 관계가 나타났으며, DeepSeek-Coder 33B 모델이 Pass@1에서 가장 높은 35.7%의 점수를 기록하였습니다. 오류 피드백을 사용하면 Pass@1과 Pass@10에서 각각 평균 5.4%, 4.7%의 성능 향상이 있었습니다.

### [OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision](https://arxiv.org/abs/2411.07199)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.07199.png)

Vote: 37

Authors: Weiming Ren, Cong Wei, Ge Zhang, Wenhu Chen, Xinrun Du, Zheyang Xiong

- ***What's New***: OmniEdit는 이미지 편집 전문가 모델(Specialist Models)로부터 학습하여 다양한 편집 작업을 수행할 수 있는 범용 이미지 편집 모델(Image Editing Generalist)을 소개합니다. 이 모델은 다양한 해상도와 비율로 작업을 수행할 수 있으며, 7가지 이미지 편집 작업을 처리가 가능합니다.
- ***Technical Details***: OmniEdit 모델은 EditNet이라는 새로운 아키텍처를 제안하여 편집 성공률을 높였습니다. 중요도 샘플링(Importance Sampling)을 사용하여 고품질 데이터를 확보하고, 스타일 전환, 객체 제거 및 불투명도 조정과 같은 작업을 포함한 여러 전문가(Specialists) 모델의 감독 하에 학습되었습니다. 다양한 비율의 이미지를 처리할 수 있도록 다양한 비율의 고해상도 이미지로 학습되었습니다.
- ***Performance Highlights***: OmniEdit 모델은 다양한 자동 및 인간 평가에서 기존의 모든 모델을 상당히 능가했습니다. 인간 평가에서는 최고 Baseline 모델에 비해 전반적으로 20% 이상의 성능 향상을 보였으며, 두드러진 성능으로 PQ(Perceptual Quality) 점수에서 특히 높은 점수를 기록했습니다. 다양한 편집 작업을 다루며, 고해상도에서도 성능 저하 없이 작업을 수행할 수 있음을 검증하였습니다.

### [CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM](https://arxiv.org/abs/2411.04954)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.04954.png)

Vote: 5

Authors: Jingwei Xu, Shenghua Gao, Chenyu Wang, Wen Liu, Yi Ma, Zibo Zhao

- ***What's New***: CAD-MLLM은 사용자의 다양한 입력, 예를 들어 텍스트 설명, 이미지, 포인트 클라우드 등을 기반으로 매개변수 CAD 모델을 생성할 수 있는 최초의 시스템입니다. 이 시스템은 다중 모달 입력을 조건으로 한 CAD 모델을 생성하는 데 중점을 둔 새로운 접근 방식입니다.
- ***Technical Details***: CAD-MLLM 프레임워크에서는 CAD 모델의 명령 시퀀스를 활용하고, 고급 대형 언어 모델(LLMs)을 사용하여 다양한 다중 모달 데이터와 CAD 모델의 벡터화된 표현 공간을 정렬합니다. Omni-CAD라는 데이터셋을 설계하여 각 CAD 모델에 텍스트 설명, 다중 뷰 이미지, 포인트 및 명령 시퀀스와 같은 대응하는 다중 모달 데이터를 갖추도록 하여 모델 훈련을 촉진합니다. 또한 세그먼트 오류(SegE), 매달린 엣지 길이(DangEL), 스스로 교차 비율(SIR)의 토폴로지 품질을 평가하기 위해 새로운 평가 지표를 도입했습니다.
- ***Performance Highlights***: CAD-MLLM은 기존의 조건부 생성 방법을 크게 능가하며 잡음과 누락된 포인트에 대해 높은 강인성을 나타냅니다. Omni-CAD 데이터셋은 총 453,220개의 CAD 모델과 그들의 시퀀스를 포함하며, 이로 인해 CAD-MLLM은 다양한 조건에서 우수한 성능을 입증합니다.

### [Autoregressive Models in Vision: A Survey](https://arxiv.org/abs/2411.05902)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.05902.png)

Vote: 3

Authors: Lingpeng Kong, Shen Yan, Gongye Liu, Lun Huang, Hongxia Yang, Yao Mu, Ping Luo, Yuan Yao, Ngai Wong, Chaofan Tao, Hui Shen, Huaxiu Yao, Taiqiang Wu, Jing Xiong, Jiebo Luo, Chengyue Wu, Mi Zhang, Guillermo Sapiro, Jinfa Huang, Zhongwei Wan

- ***What's New***: 시계열 모델은 자연어 처리(NLP) 분야에서 큰 성공을 거둔 바 있으며, 최근 시계열 모델이 컴퓨터 비전 분야에서도 주목받고 있습니다. 시계열 모델은 고품질의 시각적 콘텐츠를 생성하는 데 뛰어나며, 시계열 모델의 다양한 표현 전략을 반영하여 픽셀, 토큰, 스케일의 세 가지 수준으로 나뉩니다. 이 기사에서는 비전을 위한 시계열 모델에 관한 주요 연구를 종합적으로 검토하고 있습니다.
- ***Technical Details***: 시계열 모델은 데이터의 각 요소가 이전 요소에 기반하여 조건부 확률을 예측함으로써 시퀀스 형태로 데이터를 생성합니다. 이 논문은 비전을 위한 시계열 모델을 기본적으로 픽셀 기반, 토큰 기반, 스케일 기반 모델로 구분하며, 각 카테고리의 장단점을 설명합니다. 또한, 시계열 모델이 기계 번역과 같이 특정 도메인에서 이해력을 높이는 데 사용될 수 있는 경우를 제시합니다.
- ***Performance Highlights***: 비전 시계열 모델은 ImageNet 등 대규모 데이터셋에서 태스크 성능을 효과적으로 개선합니다. 가장 최근에 소개된 VAR(Next-Scale Prediction)과 같은 모델은 이미지 생성에서 최고 수준의 결과를 보이며, 모델의 크기가 커짐에 따라 성능이 더 향상되는 것으로 보였습니다. 이러한 결과는 더 큰 데이터 세트와 모델 크기가 성능 향상에 지속적인 영향을 미친다는 것을 보여줍니다.

### [Game-theoretic LLM: Agent Workflow for Negotiation Games](https://arxiv.org/abs/2411.05990)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.05990.png)

Vote: 3

Authors: Lucas Jiang, Mingyu Jin, Lingyao Li, Xintong Wang, Alfonso Amayuelas, Ollie Liu, Julie Chen, William Wang, Fei Sun, Yongfeng Zhang, Lizhou Fan, Wenyue Hua

- ***What's New***: 새로운 연구에서는 대형 언어 모델(LLMs)을 전략적 의사결정 맥락에서 게임 이론에 기반한 워크플로우(workflow)를 통해 개선하는 방법을 탐구하고 있습니다. 이는 불완전 정보 게임(incomplete-information games)에서도 합리적인 선택을 더 잘 할 수 있도록 도와주는 것입니다.
- ***Technical Details***: 이 연구에서는 LLMs의 합리성을 평가하기 위해 여러 유형의 완전 정보 게임(complete-information games)과 불완전 정보 게임을 시험했습니다. 워크플로우는 최대 효용을 제공하는 전략을 찾기 위한 내쉬 균형(Nash Equilibrium) 및 베이즈 확률 갱신과 같은 게임 이론적 개념을 통합합니다. 또한, 워크플로우는 공정한 자원 할당을 고려하여 부러움이 없는(envy-free) 상태와 파레토 최적(Pareto optimal) 상태를 달성할 수 있도록 설계되었습니다.
- ***Performance Highlights***: 워크플로우를 적용했을 때, LLMs는 전략적 게임 과제에서 합리성뿐만 아니라 내구성이 크게 향상되었습니다. 특히 협상 시나리오에서 최적의 전략을 식별하고, 거의 최적의 자원 배분을 달성하며, 협상 중 착취에 대한 취약성을 줄이는 데 있어 눈에 띄는 개선이 보였습니다. 그러나 흥미롭게도, 워크플로우를 사용하지 않을 경우 종종 더 높은 개별 보상을 받는 경향이 있어 전략적 결정을 복잡하게 만듭니다.

### [Edify Image: High-Quality Image Generation with Pixel Space Laplacian Diffusion Models](https://arxiv.org/abs/2411.07126)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.07126.png)

Vote: 18

Authors: Pooya Jannaty, Arun Mallya, Siddharth Gururani, Ashlee Martino-Tarr, NVIDIA, J. P. Lewis, Ming-Yu Liu, Tiffany Cai, Qinsheng Zhang, Jiaming Song, Yen-Chen Lin, Maciej Bala, Xiaohui Zeng, Tero Karras, Yogesh Balaji, Jiaojiao Fan, Ronald Isaac, Grace Lam, Seungjun Nah, Fangyin Wei, Fitsum Reda, Yu Zeng, Ting-Chun Wang, Yunhao Ge, Doug Mendez, Chris Pruett, Aaron Licata, Yin Cui, Qianli Ma, Jacob Huffman, Yuval Atzmon

- ***What's New***: Edify Image는 새롭고 혁신적인 픽셀 공간 라플라시안 확산 모델(Pixel Space Laplacian Diffusion Model)을 사용하여 고해상도의 포토리얼리스틱 이미지를 생성할 수 있는 모델군을 제공합니다. 이 모델은 텍스트-이미지 합성(text-to-image synthesis), 4K 업스케일링, 다양한 제어 기능을 추가하는 ControlNets, 360도 HDR 파노라마 생성을 지원하며, 이미지 커스터마이즈를 위한 파인튜닝(finetuning)도 가능합니다.
- ***Technical Details***: Edify Image는 계단식으로 훈련된 다중 스케일 라플라시안 확산 프로세스를 사용하여 각기 다른 주파수 대역의 이미지 신호가 다양한 비율로 감쇠되도록 설계되었습니다. 기저 모델은 저해상도를 생성하고 후속 모델은 이를 업샘플링(upsampling)합니다. 네트워크 구조는 U-Net 기반이며, 텍스트 임베딩과 카메라 속성으로 조건이 부여됩니다. 원활한 학습을 위해 3단계 이미지 라플라시안 분해가 도입되었으며, 각 단계는 서로 다른 해상도로 작동합니다.
- ***Performance Highlights***: 모델은 다양한 카테고리에서 입력 텍스트 프롬프트에 맞춘 고품질 이미지를 생성하며, '자연', '인간', '동물', '음식' 등을 포괄합니다. 또한 다양한 종횡비에 걸쳐 우수한 이미지 생성 성능을 보였습니다. 장문의 기술적 설명을 통한 이미지 생성에서도 뛰어난 성능을 입증했습니다.

### [NeKo: Toward Post Recognition Generative Correction Large Language Models with Task-Oriented Experts](https://arxiv.org/abs/2411.05945)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.05945.png)

Vote: 2

Authors: Ke Hu, Szu-Wei Fu, Jun Wei Chiu, Yu-Chiang Frank Wang, Piotr Zelasko, Chao-Han Huck Yang, Yen-Ting Lin, Jagadeesh Balam, Xuesong Yang, Zih-Ching Chen, Boris Ginsburg, Zhehuai Chen, Krishna C Puvvada

- ***What's New***: 이 논문에서는 특히 중요한 질문에 답하고 있습니다: 어떻게 하면 다양한 분야의 데이터 셋트에서 모델을 효과적으로 훈련시킬 수 있을까? 이를 해결하기 위해 'NEKO'라는 개념을 도입하여 다양한 인식 후 에러 교정을 수행하는 대용량 언어 모델을 제시합니다. 이는 특정 작업에 맞춘 전문가(Task-Oriented Experts)를 활용하여 학습을 체계화하고 모델 파라미터의 증가 없이 효율성을 증가시키는 새로운 시도입니다.
- ***Technical Details***: NEKO(geNErative multi-tasK error cOrrection)는 Mixture-of-Experts(MoE)를 활용하여 다양한 작업에서 정확도를 높이도록 설계되었습니다. 각 전문가(Expert)는 특정 도메인에 특화된 학습을 하여, 음성 인식(ASR), 언어 번역(ST/MT), 시각 인식(OCR), 텍스트 에러 교정(TEC) 등의 다양한 작업에 대해서 교정 성능을 확보합니다. 이러한 MoE 구조 내에서는 입력 데이터를 적절한 전문가로 라우팅하여, 해당 작업에 대한 전문성을 최대로 끌어올립니다.
- ***Performance Highlights***: NEKO는 Open ASR Leaderboard와 Hyporadise 벤치마크에서 GPT-3.5와 Claude-Opus를 상회하는 성능을 보여줍니다. 특히, Hyporadise 벤치마크에서 단어 오류율(WER)이 15.5%에서 27.6%까지 감소하는 것을 보여주며, 다양한 인식 후 교정 작업에서 개별적으로 전통적인 방법이나 단순 모델을 능가하는 성능을 발휘합니다. 또한, 다양한 크기의 MoE 모델 시험 결과, 전문가 기반 학습(stop-1)과 비교하여 NEKO의 성능 향상이 두드러지는 것을 확인할 수 있습니다.

### [M-Longdoc: A Benchmark For Multimodal Super-Long Document Understanding And A Retrieval-Aware Tuning Framework](https://arxiv.org/abs/2411.06176)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.06176.png)

Vote: 28

Authors: Maojia Song, Liying Cheng, Lidong Bing, Yew Ken Chia, Sharifah Mahani Aljunied, Soujanya Poria, Hou Pong Chan, Chaoqun Liu

- ***What's New***: M-LongDoc는 문서 이해와 문서 기반 질문 응답(Task)에 대한 새로운 벤치마크로, 수백 페이지에 이르는 매우 긴 문서를 대상으로 한 첫 다중 모달(유형) 평가 도구입니다. 기존의 데이터세트가 짧은 문서와 간단한 추출형 질문에 집중했던 반면, M-LongDoc는 개방형 질문으로 심층적인 분석을 요구하여 대규모 다중 모달 모델의 성능을 평가합니다.
- ***Technical Details***: M-LongDoc는 텍스트, 그래프, 표가 포함된 다양하고 긴 문서로 구성되어 있습니다. 자동화된 평가 프레임워크를 도입하여 참조 답변이나 사람의 주석 없이도 모델의 개방형 솔루션을 스케일업하여 평가할 수 있습니다. 자동화된 평가 가이드라인과 다수의 판사 모델을 사용하여 평가가 이루어집니다. 또한, 문서의 내용에서 주제와 카테고리를 기반으로 질문을 생성하고 문제의 설명을 해결하기 위해 반향 없는 페이지를 포함시켜 모델의 몰입도를 향상시키는 정보 찾기 기반의 학습 프레임워크를 제안합니다.
- ***Performance Highlights***: 기존 모델이 텍스트 기반 질문보다 그림 및 표 기반 질문에서 성능이 낮아 멀티모달 편향과 처리 한계를 드러냈습니다. Retrieval-aware tuning 접근방식을 통해 개방형 오픈소스 모델의 정확성을 4.6% 향상시켰으며, 이러한 방식이 멀티모달 긴 문서의 이해를 더 효율적이고 효과적으로 만들어 줍니다. 다중 모달 모델의 학습과 평가에 중요한 향상을 제공함을 입증했습니다.

