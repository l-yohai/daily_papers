## Daily Papers (2023-12-12)

### [Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D Prior](https://arxiv.org/abs/2312.06655)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3X51nAmSqVYpWXFc4aZO2.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3X51nAmSqVYpWXFc4aZO2.mp4" muted="false"></video></div>

Vote: 16

Authors: Fangfu Liu, Diankun Wu, Yi Wei, Yongming Rao, Yueqi Duan

- 최근 텍스트 요구에 의한 3D 콘텐츠 생성이 2D 및 3D 확산 모델을 활용하여 눈에 띄는 진전을 보였지만, 제한적인 3D 데이터로 인해 고품질 및 다양한 3D 자산 생성에 어려움이 있습니다.
- 2D 확산 모델은 우수한 일반화와 세부 정보를 제공하지만, 다면체 일부가 되는 문제로 인해 일관된 3D 결과를 학습하는 데 필요한 충분한 가이드를 제공하지 못합니다.
- 본 논문에서는 3D 확산 모델에 의해 생성된 거친 3D 기초 지식을 최대한 활용하여 비용이 많이 드는 viewpoint-aware 모델을 재교육하는 대신 텍스트 힌트를 강화하고 2D 리프팅 최적화를 안내하는 방법에 대해 연구합니다.
- Sherpa3D, 새로운 텍스트-투-3D 프레임워크를 제안하여 동시에 높은 충실도, 일반성, 그리고 기하학적 일관성을 달성합니다.
- 구조적 가이드와 의미론적 가이드라는 3D 확산 모델에 의해 생성된 거친 3D 지식으로부터 유도된 두 가지 안내 전략을 디자인함으로써 2D 확산 모델은 다양화되고 고품질의 3D 콘텐츠를 풍부하게 만듭니다.
- 광범위한 실험을 통해 Sherpa3D가 품질과 3D 일관성면에서 최신 텍스트-투-3D 방법들을 뛰어넘는 우수성을 입증합니다.

### [Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models](https://arxiv.org/abs/2312.06109)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/omEsE9He5XHGv2TjzTnsM.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/omEsE9He5XHGv2TjzTnsM.mp4" muted="false"></video></div>

Vote: 15

Authors: Haoran Wei, Lingyu Kong, Jinyue Chen, Liang Zhao, Zheng Ge, Jinrong Yang, Jianjian Sun, Chunrui Han, Xiangyu Zhang

- 현대 대규모 시각-언어 모델(LVLMs)은 대부분의 일반적인 시각 작업을 수행할 수 있는 CLIP 스타일의 시각 어휘를 공유하고 있지만, 문서 수준의 OCR이나 차트 이해와 같은 밀도가 높고 세밀한 시각 인식이 필요한 특수한 시각 작업에는 효율이 낮고 어휘 밖의 문제가 발생할 수 있다.
- 이에 따라, 연구진은 LVLM의 시각 어휘를 효율적이고 효과적으로 확장하는 방법인 Vary를 제안하며, 이는 새로운 시각 어휘의 생성과 통합이라는 두 단계로 자연스럽게 나뉜다.
- 첫 번째 단계에서는 자동회귀를 통해 원하는 어휘를 생성하기 위해 어휘 네트워크와 소형 디코더 전용 트랜스포머를 고안한다.
- 다음 단계에서는 새 어휘와 원래의 어휘(CLIP)를 합쳐 LVLM이 빠르게 새로운 특징을 습득할 수 있게 함으로써 기존의 시각 어휘를 확장한다.
- Vary는 기존 기능을 유지하면서 더욱 뛰어난 세밀한 인식 및 이해 능력을 가질 수 있으며, 특히 OCR이나 markdown 변환과 같은 새로운 문서 구문 분석 기능에 능숙하며, DocVQA에서 78.2% ANLS, MMVet에서 36.2%를 달성한다.
- Vary의 코드는 홈페이지에서 공개될 예정이다.

### [Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models](https://arxiv.org/abs/2312.06585)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/kO7BX-OphrT_s-nBpiVf5.png)

Vote: 14

Authors: Avi Singh, John D. Co-Reyes, Rishabh Agarwal, Ankesh Anand, Piyush Patil, Peter J. Liu, James Harrison, Jaehoon Lee, Kelvin Xu, Aaron Parisi, Abhishek Kumar, Alex Alemi, Alex Rizkowsky, Azade Nova, Ben Adlam, Bernd Bohnet, Hanie Sedghi, Igor Mordatch, Isabelle Simpson, Izzeddin Gur, Jasper Snoek, Jeffrey Pennington, +

- 인간이 생성한 데이터에 기반한 언어 모델(LM)의 미세조정은 보편적인 관행이지만, 높은 품질의 인간 데이터의 수량 및 다양성에 의해 성능이 제한되곤 한다.
- 본 연구에서는 정확성을 검증할 수 있는 수학 문제와 같이 스칼라 피드백에 접근할 수 있는 작업에서 인간 데이터를 넘어설 수 있는지를 탐구한다.
- 모델에서 샘플을 생성하고 이진 피드백을 사용하여 필터링한 후 이 샘플들에 대해 모델을 미세조정하고 이 과정을 몇 차례 반복하는 간단한 자기 학습 방법인 ReST^EM을 조사한다.
- PaLM-2 모델을 사용하여 고급 MATH 추론 및 APPS 코딩 벤치마크를 테스트한 결과, ReST^EM은 모델 크기에 따라 유리하게 확장되며 인간 데이터만으로 미세조정할 때보다 크게 우수하다는 것을 발견하였다.
- 이러한 발견은 피드백을 활용한 자기 학습이 인간 생성 데이터에 대한 의존도를 크게 줄일 수 있음을 시사한다.

### [Photorealistic Video Generation with Diffusion Models](https://arxiv.org/abs/2312.06662)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/RaNvTjfckPvfb7f1s2Gfe.webm)

Vote: 12

Authors: Agrim Gupta, Lijun Yu, Kihyuk Sohn, Xiuye Gu, Meera Hahn, Li Fei-Fei, Irfan Essa, Lu Jiang, José Lezama

- 본 연구에서는 확산 모델링을 통한 사실적인 비디오 생성을 위해 W.A.L.T라는 트랜스포머 기반 접근법을 제시한다.
- 연구팀은 이미지와 비디오를 통합된 잠재 공간 내에서 함께 압축하는 인과적 인코더를 사용하여 다양한 형태의 학습 및 생성이 가능하게 했다.
- 기억체와 학습 효율성을 위해, 공간적 및 시공간적 생성 모델링에 적합한 윈도우 주의(attention) 구조를 도입했다.
- 이러한 설계 결정들을 결합함으로써, 분류자 없는 안내를 사용하지 않고도 UCF-101, Kinetics-600 (비디오), ImageNet (이미지) 벤치마크에서 최신 성능을 달성했다.
- 또한, 512x896 해상도와 초당 8 프레임의 비디오를 생성하기 위해 기본 잠재 비디오 확산 모델 및 두 개의 비디오 초고해상도 확산 모델로 구성된 모델 캐스케이드를 훈련시켰다.
- 이 연구는 텍스트로부터 비디오를 생성하는 작업에서도 적용 가능함을 보여주며, 사실적 비디오 생성 분야에서 중요한 진전을 의미한다.

### [From Text to Motion: Grounding GPT-4 in a Humanoid Robot "Alter3"](https://arxiv.org/abs/2312.06571)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DsQuQEGQLazo-shrUvF_4.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/DsQuQEGQLazo-shrUvF_4.mp4" muted="false"></video></div>

Vote: 9

Authors: Takahide Yoshida, Atsushi Masumori, Takashi Ikegami

- 이 연구는 Alter3라는 인간형 로봇이 대규모 언어 모델(Large Language Model, LLM)인 GPT-4를 사용해 자발적인 동작을 생성할 수 있는 능력을 개발했다고 보고한다.
- GPT-4를 기존의 안드로이드, Alter3에 통합함으로써 LLM을 Alter의 신체 움직임과 결합시켰으며, 이는 일반적으로 하드웨어에 의존하는 로봇 제어 범위를 초월한다.
- Alter3와 같은 인간형 로봇의 경우 사람의 동작을 의미하는 언어 표현을 프로그램 코드를 통해 로봇의 몸에 매핑함으로써 직접적인 제어가 가능하다.
- 이 기법을 통해 Alter3는 각 신체 부위마다 명시적인 프로그래밍 없이도 '셀카 취하기' 자세나 '유령 흉내 내기'와 같은 다양한 자세를 취하고 시간에 따른 행동 시퀀스를 만들어낼 수 있다.
- 로봇은 제로샷 학습 능력을 보여주며, 구두 피드백을 통한 자세 조정이 가능하여 세밀한 튜닝을 필요로 하지 않는다.
- Alter3의 생성된 동작 영상은 제공된 웹사이트에서 확인할 수 있다.

### [Context Tuning for Retrieval Augmented Generation](https://arxiv.org/abs/2312.05708)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/eMmZhB3xRemTqzlN3SJMw.png)

Vote: 9

Authors: Raviteja Anantha, Tharun Bethi, Danil Vodianik, Srinivas Chappidi

- 대규모 언어 모델(Large language models, LLMs)은 새로운 작업을 해결하기 위한 적절한 도구에 접근할 수 있다면 몇 가지 예시만으로 문제를 해결할 수 있으나, 적절한 도구를 검색하는 것이 중요합니다.
- Retrieval Augmented Generation(RAG) 시스템은 주어진 작업에 대해 관련 도구 목록을 검색하여 이러한 문제에 대응하나, 질의가 불완전하거나 맥락이 부족할 경우 시맨틱 검색이 실패할 수 있는 한계가 있습니다.
- 이러한 한계를 극복하기 위해 연구팀은 RAG 내에 스마트한 맥락 검색 시스템인 Context Tuning을 제안하여 도구 검색 및 계획 생성을 향상시킵니다.
- 경량 맥락 검색 모델은 수치, 범주, 습관적 사용 신호를 활용하여 관련 맥락 항목을 검색하고 순위를 매깁니다.
- Context Tuning은 RAG의 시맨틱 검색을 크게 향상시켜 맥락 검색에서 3.5배, 도구 검색 작업에서 1.5배의 Recall@K 개선을 달성하고, LLM 기반 계획 작성 정확도를 11.6% 증가시킨 실증 결과를 제공합니다.
- 또한 LambdaMART와 Reciprocal Rank Fusion(RRF)을 사용하는 경량 모델이 GPT-4 기반 검색보다 뛰어난 성능을 보임을 보여줍니다.
- 이 연구는 도구 검색 후 계획 생성 단계에서의 맥락 보완이 환상을 줄이는 효과가 있음을 관찰하였습니다.

### [Efficient Quantization Strategies for Latent Diffusion Models](https://arxiv.org/abs/2312.05431)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ldKaFMltEvvaxZJ4A3mxN.png)

Vote: 5

Authors: Yuewei Yang, Xiaoliang Dai, Jialiang Wang, Peizhao Zhang, Hongbo Zhang

- 잠재 확산 모델(LDM)은 시간에 따른 잠재 변수의 동적 변화를 포착하고 생성 시스템에서 패턴과 다모드 성을 혼합한다.
- LDM은 강인한 텍스트 인코더와 변분 오토인코더를 활용하여 텍스트-이미지 생성과 같은 다양한 응용 프로그램에서 능숙하나, 가장자리 기기에 대규모 생성 모델을 배포하는 중요성은 더욱 효과적이면서도 축소된 대안을 모색하게 한다.
- 포스트 트레이닝 양자화(PTQ)는 딥러닝 모델의 운영 크기를 압축하는 방법이지만, LDM에 적용할 때 시간적 및 구조적 복잡성으로 인해 도전을 겪는다.
- 이 연구는 평가를 위한 주요 지표로 신호 대 양자화 잡음 비율(SQNR)를 활용하여 LDM을 효율적으로 양자화하는 전략을 제안한다.
- 양자화 불일치를 상대적인 잡음으로 처리하고 모델의 민감한 부분을 식별함으로써, 우리는 전역 및 지역 전략을 모두 포함하는 효율적인 양자화 접근법을 제안한다.
- 전역 양자화 과정은 민감한 블록에서 더 높은 정밀도의 양자화를 시작함으로써 상대적 양자화 잡음을 완화하고, 지역 처치는 양자화 민감도가 높고 시간 민감성이 있는 모듈에서 특정 도전을 해결한다.
- 실험 결과에 따르면 전역 및 지역 처치 모두를 구현하면 LDM의 PTQ를 효율적이고 효과적으로 실행할 수 있다는 것이 밝혀졌다.

### [Evaluation of Large Language Models for Decision Making in Autonomous Driving](https://arxiv.org/abs/2312.06351)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/btMwR2w75rL6J81cx50cO.png)

Vote: 4

Authors: Kotaro Tanahashi, Yuichi Inoue, Yu Yamaguchi, Hidetatsu Yaginuma, Daiki Shiotsuka, Hiroyuki Shimatani, Kohei Iwamasa, Yoshiaki Inoue, Takafumi Yamaguchi, Koki Igari, Tsukasa Horinouchi, Kento Tokuhiro, Yugo Tokuchi, Shunsuke Aoki

- 대형 언어 모델(Large Language Models, LLMs)을 자율 주행에서 활용하는 다양한 방법이 제안되었다.
- 자율 주행에서 LLMs을 사용하는 전략 중 하나는 주변 물체를 좌표와 속도 정보와 함께 텍스트 프롬프트로 입력하여 차량의 다음 움직임을 출력하는 것이다.
- LLMs을 이용할 때 공간 인식 및 계획과 같은 능력이 필수적이며, 특히 충돌 회피를 위한 공간 인지 결정 능력과 교통 규칙 준수 능력이 요구된다.
- 다양한 LLMs가 이러한 문제를 얼마나 정확하게 처리할 수 있는지에 대한 정량적 연구가 이루어지지 않았다.
- 본 연구에서는 자율 주행 맥락에서 LLMs의 공간 인지 결정 능력과 교통 규칙 준수 능력을 정량적으로 평가했다.
- 실제 차량에 이러한 능력을 구현할 수 있는 가능성을 증명하기 위해, LLMs를 이용하여 차량을 운전하는 시스템을 개발했다.

### [Using Captum to Explain Generative Language Models](https://arxiv.org/abs/2312.05491)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/eXIT_o02-pNO-Ucc5zjhK.png)

Vote: 2

Authors: Vivek Miglani, Aobo Yang, Aram H. Markosyan, Diego Garcia-Olano, Narine Kokhlikyan

- Captum은 PyTorch 모델의 설명 가능성을 위한 종합적인 도구로, 이해력 향상을 위한 다양한 방법을 제공한다.
- 본 논문에서는 생성적 언어 모델의 행동을 분석하기 위해 특별히 고안된 Captum의 새로운 기능들을 소개한다.
- 사용 가능한 기능과 생성적 언어 모델 내에서 학습된 연관성을 이해하기 위한 그들의 잠재적인 응용 예시에 대한 개요를 제공한다.

### [Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes](https://arxiv.org/abs/2312.06353)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/LkJzIFGjABLgfZCmB6P1q.png)

Vote: -

Authors: Zhen Qin, Daoyuan Chen, Bingchen Qian, Bolin Ding, Yaliang Li, Shuiguang Deng

- 사전 훈련된 대형 언어 모델(LLM)의 자연어 지시에 대한 반응성을 향상시키기 위하여, 데이터 프라이버시를 유지하면서 풍부한 엔드 디바이스 데이터를 이용해 미세 조정을 진행하는 방식으로 연방 학습(FL)이 제안된다.
- 기존의 LLM을 위한 연방 미세 조정 방법들은 매개변수 효율적인 미세 조정 기법에 의존하지만, 전체 매개변수를 조정하는 것이 가능한 성능을 달성하는 데는 제한이 있다.
- 전체 매개변수 조정이 원활하게 이루어지는 것을 방해하는 주된 문제 중 하나는 서버와 클라이언트 간의 막대한 통신 부담이다.
- 본 연구에서는 'FedKSeed'라 불리는 새로운 접근법을 소개하며, 이는 제로오더 최적화(ZOO)에 임의의 시드들을 사용하는 방법이다.
- 이 방법은 서버와 클라이언트 간의 데이터 전송 요구사항을 몇 개의 스칼라 그래디언트와 랜덤 시드로 줄여서, 단 몇 천 바이트로만 통신 비용을 줄인다.
- 더 나아가, 이 접근법은 FL을 위한 ZOO의 변동성을 평가하는 전략을 개발하여, 모델 정확도에 더 큰 영향을 미치는 변동에 우선순위를 두는 확률 차별화된 시드 샘플링을 가능하게 한다.
- 다양한 LLM, 데이터셋, 데이터 분할을 사용한 여섯 가지 시나리오에 걸친 실험에서, 우리의 접근법은 통신 효율성과 새로운 작업에 대한 일반화 측면에서 기존의 연방 LLM 미세 조정 방법들을 능가하는 성능을 보였다.

### [Order Matters in the Presence of Dataset Imbalance for Multilingual Learning](https://arxiv.org/abs/2312.06134)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/EcwW4OxWmXl97-WlHFKut.png)

Vote: -

Authors: Dami Choi, Derrick Xin, Hamid Dadkhahi, Justin Gilmer, Ankush Garg, Orhan Firat, Chih-Kuan Yeh, Andrew M. Dai, Behrooz Ghorbani

- 이 논문에서는 데이터 불균형이 있는 다중 작업 학습의 최적화 동력을 실증적으로 연구하며 특히 많은 작업을 수행하는 과정에서 관리하는 부분에 주목합니다.
- 고자원 작업에서의 사전 훈련과 이후 고/저자원 작업의 혼합에 대한 미세 조정을 포함하는 간단하면서도 효과적인 방법을 제시합니다.
- 이 방법은 표준 정적 가중치 프로파일에 비해 일관된 성능 향상을 달성한다는 점에 대한 철저한 실증적 연구 및 분석을 제공합니다.
- 어떤 데이터 체제에서 이 방법이 적용 가능한지 분석하며 신경 기계 번역(NMT) 및 다국어 언어 모델링에서의 개선을 실증적으로 보여줍니다.

### [TCNCA: Temporal Convolution Network with Chunked Attention for Scalable Sequence Processing](https://arxiv.org/abs/2312.05605)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jXOaDm_Isia7nBekH96Mw.png)

Vote: -

Authors: Aleksandar Terzic, Michael Hersche, Geethan Karunaratne, Luca Benini, Abu Sebastian, Abbas Rahimi

- 순차 처리의 확장성을 높이기 위해 선형 순환 연산자를 특별한 시간적 합성곱 네트워크로 대체한 TCNCA(Temporal Convolutional Network with Chunked Attention) 모델을 개발했다.
- 새로운 모델은 더 큰 수용력을 가진 얕은 네트워크를 가능하게 하며, 계산 복잡도를 O(L)로 감소시켰다.
- TCNCA는 EnWik8 언어 모델링, long-range-arena (LRA) 시퀀스 분류, 연관 기억 소회등의 합성 추론 벤치마크에서 평가되었다.
- EnWik8에서 TCNCA는 MEGA를 능가하여 1.37배/1.24배 빠른 전/후방 통과 속도로 더 낮은 손실을 달성했다.
- TCNCA의 확장된 합성곱은 FFT 기반 병렬화된 순환과 비교할 때, GPU에서 대체로 훨씬 더 빠른 연산으로, 매우 큰 시퀀스 길이를 처리하는 데 있어 매력적인 대안이다.
- TCNCA는 LRA 벤치마크에서 MEGA와 유사한 정확도로 평균 1.28배 빠른 추론 속도를 달성하였다.
- 연관 기억 소회에서는 TCNCA의 단순화된 버전이 시퀀스 길이와 어휘 크기의 범위에 걸쳐 MEGA보다 우수하거나 경쟁력이 있는 것으로 나타났다.

### [Unlocking Anticipatory Text Generation: A Constrained Approach for Faithful Decoding with Large Language Models](https://arxiv.org/abs/2312.06149)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/0xLaZSLOFrgyXwqpD2gjQ.png)

Vote: -

Authors: Lifu Tu, Semih Yavuz, Jin Qu, Jiacheng Xu, Rui Meng, Caiming Xiong, Yingbo Zhou

- 대규모 언어 모델(Large Language Models, LLMs)은 강력한 텍스트 생성 능력을 보이지만, 주어진 프롬프트나 지시에 따른 최적 결과 도출이 어려울 때가 있습니다.
- 특히 수십억 규모의 모델들은 독성이나 오류 발생(hallucinations)과 같은 바람직하지 않은 행동을 나타낼 수 있는데, 이를 더 큰 모델 (예: ChatGPT)이 해결할 수 있음에도 완벽한 예방은 보장할 수 없습니다.
- 본 연구에서는 지시에 충실하고 바람직하지 않은 행동을 최소화하기 위해 텍스트 생성을 미래 제약이 있는 문제로 공식화하는 방법을 제안합니다.
- 미래 제약의 만족도 추정은 LLMs를 사용하여 수행되며, 이는 텍스트 생성 과정을 안내합니다.
- 제안된 접근법의 효과는 키워드 제약이 있는 생성, 독성 감소, 그리고 질문-답변에서의 사실 정확성 과제를 포함한 세 가지 다른 텍스트 생성 작업에서 실험을 통해 입증되었습니다.
