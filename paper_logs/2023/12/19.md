## Daily Papers (2023-12-19)

### [VecFusion: Vector Font Generation with Diffusion](https://arxiv.org/abs/2312.10540)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/54ffd_He171eccjxYBTeW.png)

Vote: 12

Authors: Vikas Thamizharasan, Vikas Thamizharasan, Difan Liu, Difan Liu, Shantanu Agarwal, Matthew Fisher, Michael Gharbi, Michael Gharbi, Oliver Wang, Oliver Wang, Alec Jacobson, Alec Jacobson, Evangelos Kalogerakis

- 본 논문에서는 다양한 토폴로지 구조와 정밀한 컨트롤 포인트 위치를 가진 벡터 폰트를 생성할 수 있는 새로운 신경망 구조인 VecFusion을 제시합니다.
- 접근 방식으로서 래스터 모델과 벡터 모델을 결합한 케스케이드 확산 모델을 제안합니다.
- 래스터 모델은 폰트의 글로벌 스타일과 모양을 포착하면서 보조 컨트롤 포인트 정보가 통합된 저해상도 래스터 폰트를 생성합니다.
- 벡터 모델은 첫 단계에서 생성된 저해상도 래스터 폰트를 기반으로 벡터 폰트를 합성합니다.
- 길고 복잡한 곡선을 합성하기 위해 벡터 확산 모델은 변환기 구조를 사용하며, 다양한 벡터 기하학을 모델링하고 컨트롤 포인트를 정밀하게 예측할 수 있는 새로운 벡터 표현을 채택합니다.
- 실험을 통해 기존 벡터 그래픽 생성 모델과 달리, 새로운 케스케이드 벡터 확산 모델이 복잡한 구조와 다양한 스타일을 가진 더 높은 품질의 벡터 폰트를 생성함을 보여줍니다.

### [G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model](https://arxiv.org/abs/2312.11370)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/_TUi_7G2-v9828Kmatpw8.png)

Vote: 12

Authors: Jiahui Gao, Jiahui Gao, Renjie Pi, Renjie Pi, Jipeng Zhang, Jipeng Zhang, Jiacheng Ye, Jiacheng Ye, Wanjun Zhong, Wanjun Zhong, Yufei Wang, Lanqing Hong, Jianhua Han, Hang Xu, Zhenguo Li, Lingpeng Kong

- 대규모 언어 모델들이 인간 수준의 추론 및 생성 능력을 보여주며 수학 문제 해결에 응용에 관한 연구가 활발히 진행되고 있지만, 기존 연구는 텍스트 기반 수학 문제에 중점을 두고 있고 기하학적 정보를 포함하는 문제에 대한 연구는 제한적입니다.
- 이러한 격차를 해소하기 위해, 우리는 대규모 언어 모델이 이미지 입력을 이해하면서 기하 문제를 해결할 수 있도록 하고자 합니다.
- 현재 다중모달 대규모 언어 모델(MLLMs)이 기본적인 기하학적 요소와 그 관계를 정확하게 이해하는 데 어려움을 겪고 있음을 분석했습니다.
- 이러한 도전을 극복하기 위해, 기하 문제의 고유한 특성(예: 고유한 기하학적 논리적 형태와 기하학적 확장성)과 텍스트 기반 LLM의 능력을 활용하여 기존 데이터에 기반한 풍부한 다중모달 기하 데이터셋을 구축했습니다.
- 이 데이터셋인 Geo170K는 17만 개가 넘는 기하 이미지-캡션 및 질문-답변 쌍을 포함하고 있습니다.
- 구축된 Geo170K 데이터셋을 활용하여 개발한 G-LLaVA는 기하 문제 해결에 있어 탁월한 성능을 보여주며, 단 7B 매개변수로 MathVista 벤치마크에서 GPT-4-V를 크게 능가하는 성능을 보였습니다.

### [SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing](https://arxiv.org/abs/2312.11392)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/NkA2TxCyT2-IHBsg3EmEM.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/NkA2TxCyT2-IHBsg3EmEM.mp4" muted="false"></video></div>

Vote: 11

Authors: Zeyinzi Jiang, Zeyinzi Jiang, Chaojie Mao, Chaojie Mao, Yulin Pan, Yulin Pan, Zhen Han, Jingfeng Zhang

- 최근 연구는 기본적인 생성 확산 모델의 세밀한 조정을 통해 특정 작업에 있어서 유망한 결과를 도출하였으며, 본 논문은 확산 모델의 주요 골격을 조정하는 것이 아니라 U-Net 구조 내의 스킵 연결이 이미지 생성의 내용과 질에 큰 영향을 미친다는 점을 발견하였습니다.
- 제안하는 SCEdit는 SC-Tuner라고 불리는 경량 튜닝 모듈을 활용하여 스킵 연결을 통합하고 편집하는 효율적인 생성 튜닝 프레임워크입니다.
- 더욱이 SCEdit는 다양한 조건을 주입함으로써 제어 가능한 이미지 합성으로 간단하게 확장될 수 있으며, Controllable SC-Tuner를 통해 다중 조건 입력에 대한 네트워크 설계를 단순화하고 통합합니다.
- 이 방법은 튜너가 가벼워 훈련 파라미터, 메모리 사용량, 그리고 계산 비용이 대폭 감소하며, 역전파는 디코더 블록만을 통과합니다.
- 텍스트-이미지 생성과 제어 가능한 이미지 합성 작업에 대한 광범위한 실험을 통해 SCEdit의 효율성 및 성능 면에서 우수함을 입증하였습니다.
- 프로젝트 페이지(https://scedit.github.io/)에서 SCEdit에 대한 추가 정보와 결과물을 확인할 수 있습니다.

### [Rich Human Feedback for Text-to-Image Generation](https://arxiv.org/abs/2312.10240)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/a8bxE5dILXgJa8WUUoiJ9.png)

Vote: 11

Authors: Youwei Liang, Youwei Liang, Junfeng He, Junfeng He, Gang Li, Peizhao Li, Peizhao Li, Arseniy Klimovskiy, Nicholas Carolan, Nicholas Carolan, Jiao Sun, Jiao Sun, Jordi Pont-Tuset, Sarah Young, Feng Yang, Junjie Ke, Junjie Ke, Krishnamurthy Dj Dvijotham, Katie Collins, Katie Collins, Yiwen Luo, Yang Li, Kai J Kohlhoff, Deepak Ramachandran, Vidhya Navalpakkam

- 최근 Stable Diffusion 및 Imagen과 같은 텍스트-이미지(T2I) 생성 모델들이 텍스트 설명을 기반으로 고해상도 이미지를 생성하는 데 있어 현저한 진전을 이루었으나, 여전히 일부 생성된 이미지들은 인공적 요소/비현실성, 텍스트 설명과의 부조화, 그리고 낮은 미적 품질과 같은 문제에 직면해 있다.
- 이전 연구에서는 인간이 제공하는 점수를 피드백으로 수집하여 T2I 생성을 개선하기 위해 보상 모델을 훈련시켰지만, 본 논문에서는 이미지의 부적절하거나 텍스트와 부조화되는 영역에 표시를 하는 것과 이미지 내에서 잘못 표현되거나 누락된 텍스트 프롬프트의 단어를 주석하는 것을 포함하여 피드백 신호를 풍부하게 만드는 방법을 제시한다.
- 연구팀은 18K 개의 생성된 이미지에 대한 풍부한 인간 피드백을 수집하고, 이 피드백을 자동으로 예측하기 위해 다중모달 변환기를 훈련시켰다.
- 예측된 풍부한 인간 피드백을 활용하여, 예를 들어 생성 모델을 미세조정하여 고품질 훈련 데이터를 선택하거나, 예측된 열 지도로 문제가 있는 영역을 인페인트하는 방식으로 이미지 생성을 개선할 수 있다고 보여준다.
- 특히, 인간 피드백 데이터가 수집된 이미지를 생성하는 데 사용된 모델들(Stable Diffusion 변형) 이외에도 다른 모델(Muse)에 대해 개선이 일반화될 수 있음을 발견하였다.

### [GAvatar: Animatable 3D Gaussian Avatars with Implicit Mesh Learning](https://arxiv.org/abs/2312.11461)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/qAT0IOLH4eC-2tTcvwfNZ.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/qAT0IOLH4eC-2tTcvwfNZ.mp4" muted="false"></video></div>

Vote: 9

Authors: Ye Yuan, Xueting Li, Xueting Li, Yangyi Huang, Shalini De Mello, Shalini De Mello, Koki Nagano, Koki Nagano, Jan Kautz, Umar Iqbal

- 가우시안 스패터링(Gaussian splatting)을 활용하여 텍스트 설명으로부터 실감나는 애니메이션 아바타를 생성하는 새로운 방법을 본 논문에서 제안하였다.
- 기존 메시(mesh) 또는 NeRF 기반 표현의 한계(유연성과 효율성 문제)를 극복하고자, 포즈 구동 원시형 기반(primitive-based) 3D 가우시안 표현 방식을 소개하였다.
- 수백만 개의 가우시언을 안정적으로 학습하고 자산화하기 위해, 가우시언 특성(예: 색상)을 예측하는 뉴럴 임플리시트 필드(neural implicit fields) 사용을 제안했다.
- 또한, 세밀한 아바타 기하학을 포착하고 상세한 메시를 추출하기 위해, 3D 가우시안의 기하학적인 구조를 정규화하고 섬세한 텍스처 메시를 추출하는 새로운 SDF 기반 임플리시트 메시 학습 방법을 제안했다.
- 제안된 GAvatar 방법론은 텍스트 프롬프트만을 사용하여 다양한 애니메이션 가능한 아바타를 대규모로 생성할 수 있게 한다.
- 퀄리티 면에서 기존 방법을 현저히 앞서고, 1K 해상도에서 초당 100프레임(100 fps)의 극단적으로 빠른 렌더링 속도를 달성한다.

### [MagicScroll: Nontypical Aspect-Ratio Image Generation for Visual Storytelling via Multi-Layered Semantic-Aware Denoising](https://arxiv.org/abs/2312.10899)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jxHGMBPg-MNyavdO2RCTr.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jxHGMBPg-MNyavdO2RCTr.mp4" muted="false"></video></div>

Vote: 9

Authors: Bingyuan Wang, Bingyuan Wang, Hengyu Meng, Hengyu Meng, Zeyu Cai, Lanjiong Li, Yue Ma, Qifeng Chen, Qifeng Chen, Zeyu Wang, Zeyu Wang

- 스크롤 그림, 만화 스트립, 파노라마처럼 비정형 화면 비율의 이미지를 사용하는 시각적 스토리텔링을 위해, MagicScroll이라는 다층의 점진적 확산 기반 이미지 생성 프레임워크를 제안한다.
- 기존 방법의 문제점인 반복적인 내용, 스타일 불일치 및 통제 불가능성을 극복하기 위해 텍스트, 이미지, 레이아웃 조건을 사용하여 개체, 장면, 배경 수준에서 생성 이미지를 미세하게 제어할 수 있는 새로운 의미 인식 디노이징 과정을 도입하였다.
- 스크롤 그림, 만화, 시네마틱 파노라마와 같은 매체를 포함한 시각적 스토리텔링을 위한 비정형 화면 비율 이미지 생성의 첫 번째 벤치마크를 확립하고, 체계적인 평가를 위한 맞춤형 메트릭을 개발하였다.
- MagicScroll은 비교 및 소거 연구를 통해 내러티브 텍스트에 부합되는 이미지를 생성, 시각적 일관성을 향상시키고 관객의 참여를 유도하는 등 유망한 결과를 보여준다.
- 연구자와 창작 실무자 간의 협력을 촉진하고 시각적 스토리텔링을 개선하기 위해 코드와 벤치마크를 배포할 계획이다.

### [MAG-Edit: Localized Image Editing in Complex Scenarios via Mask-Based Attention-Adjusted Guidance](https://arxiv.org/abs/2312.11396)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/7iYwQKjdQ9o84IeEcD62s.qt)

Vote: 8

Authors: Qi Mao, Qi Mao, Lan Chen, Lan Chen, Yuchao Gu, Yuchao Gu, Zhen Fang, Zhen Fang, Mike Zheng Shou, Mike Zheng Shou

- 최근 확산 기반 이미지 편집 접근법은 간단한 구성의 이미지에서 인상적인 편집 능력을 보여줬지만, 복잡한 상황에서의 지역화된 편집은 아직 잘 연구되지 않았음에도 불구하고 실제 수요가 증가하고 있다.
- 기존의 마스크 기반 인페인팅 방법은 편집 영역 내에서 기본 구조를 유지하는 데 한계가 있으며, 마스크가 없는 주의 기반 방법들은 더 복잡한 구성에 있어서 편집 유출과 정렬 오류를 자주 보인다.
- 이러한 문제를 해결하기 위하여, 본 연구에서는 복잡한 상황에서의 지역화된 이미지 편집을 가능하게 하는 학습이 필요 없는 추론 단계 최적화 방법인 MAG-Edit를 개발했다.
- MAG-Edit는 확산 모델의 잡음 잠재 특징을 최적화하여 편집 토큰의 마스크 기반 크로스-주의 제약 조건 두 개를 최대화함으로써, 점진적으로 원하는 프롬프트와의 지역 정렬을 향상시킨다.
- 다양한 정량적 및 정성적 실험을 통해 MAG-Edit 방법이 복잡한 시나리오 내에서 텍스트 정렬 및 구조 보존을 위한 지역화된 편집을 달성하는 데 효과적임을 입증했다.

### [M3DBench: Let's Instruct Large Models with Multi-modal 3D Prompts](https://arxiv.org/abs/2312.10763)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/_2P1nxwxiD9lshrkZWD77.png)

Vote: 6

Authors: Mingsheng Li, Mingsheng Li, Xin Chen, Chi Zhang, Chi Zhang, Sijin Chen, Sijin Chen, Hongyuan Zhu, Fukun Yin, Gang Yu, Gang Yu, Tao Chen

- 최근 3D 이해력은 자율 작동 에이전트들이 의사결정을 더 잘 수행하기 위해 인기를 얻고 있지만, 기존의 3D 데이터셋과 방법은 특정 작업에 한정됩니다.
- 그러나 대형 언어 모델(Large Language Models, LLMs) 및 다중 모드 언어 모델(Multimodal Language Models, MLMs)의 발전은 일반 언어 및 이미지 작업에서 뛰어난 성능을 보여주었습니다.
- 이러한 맥락에서, 3D 전문가로서의 MLMs의 잠재력을 해제하는 것은 폭넓은 작업을 위해 흥미로운 연구 주제가 됩니다.
- 그러나 현재 MLMs 연구는 대규모 3D 지시사항 데이터셋이 부족하여 3D 작업에 덜 초점을 맞추고 있습니다.
- 본 연구에서는 320k 이상의 지시-응답 쌍을 포함하는 대규모 3D 지시사항 데이터셋인 'M3DBench'를 소개합니다.
- 'M3DBench'는 텍스트, 이미지, 3D 객체 및 기타 시각적 프롬프트를 결합한 일반적인 멀티모달 지시사항을 지원합니다.
- 또한, 실제 3D 환경에서의 기본 능력을 다루는 지역 및 장면 수준에서 다양한 3D 작업을 통합합니다.
- 우리는 대형 모델들이 멀티모달 3D 프롬프트를 이해하는데 있어 성능을 평가하는 새로운 벤치마크를 수립했습니다.
- 광범위한 실험을 통해 제안된 데이터셋과 벤치마크가 일반 3D 중심 작업을 지원할 수 있음이 입증되어, 미래 연구에 영감을 줄 것입니다.

### [Cascade Speculative Drafting for Even Faster LLM Inference](https://arxiv.org/abs/2312.11462)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Hnyp7nUxzo_gwqxXZrp8F.png)

Vote: 5

Authors: Ziyi Chen, Xiaocong Yang, Jiacheng Lin, Jiacheng Lin, Chenkai Sun, Chenkai Sun, Jie Huang, Kevin Chen-Chuan Chang

- 대규모 언어 모델(LLM)의 효율성을 높이기 위해, Speculative Decoding이 대상 모델에 대한 초안을 작성하는 것으로 기계 번역 분야에서 사용되고 있지만, 초안 작성에는 느린 자동 회귀 생성과 동일한 시간 할당으로 다른 중요도의 토큰을 생성하는 비효율성이 존재합니다.
- 이러한 문제점을 해결하기 위해, 연구자들은 Cascade Speculative Drafting(CS. Drafting)이라는 새로운 접근법을 소개하여, 수직적 캐스케이드를 통해 자동 회귀 생성을 제거하고 수평적 캐스케이드로 효율적인 시간 할당을 진행합니다.
- 이론적 분석을 통해 최적성을 지지받는 CS. Drafting 알고리즘은 실제 실험에서 Speculative Decoding에 비해 최대 72% 빠른 속도 향상을 보였으며, 동일한 출력 분포를 유지했습니다.

### [Paloma: A Benchmark for Evaluating Language Model Fit](https://arxiv.org/abs/2312.10523)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/K__e8HpZigpT1_ipUpjE_.png)

Vote: 5

Authors: Ian Magnusson, Ian Magnusson, Akshita Bhagia, Akshita Bhagia, Valentin Hofmann, Luca Soldaini, Luca Soldaini, Ananya Harsh Jha, Oyvind Tafjord, Oyvind Tafjord, Dustin Schwenk, Dustin Schwenk, Evan Pete Walsh, Evan Pete Walsh, Yanai Elazar, Yanai Elazar, Kyle Lo, Dirk Groeneveld, Dirk Groeneveld, Iz Beltagy, Iz Beltagy, Hannaneh Hajishirzi, Noah A. Smith, Kyle Richardson, Jesse Dodge, Jesse Dodge

- 언어 모델(LMs)들은 흔히 훈련에서 제외된 단일 데이터 세트에 대한 혼란도(perplexity)를 보고하지만, 이 데이터는 nytimes.com부터 Reddit의 r/depression에 이르기까지 다양한 도메인의 언어 분포로 구성되어 있습니다.
- Paloma(Perplexity Analysis for Language Model Assessment)는 단 하나의 분포에 대한 혼란도가 다른 분포로 확장된다고 가정하는 대신, 585개의 텍스트 도메인에 대한 언어 모델의 적합성을 측정합니다.
- 이 벤치마크는 사전 훈련 과정에서 벤치마크 오염 제거와 같은 지침을 준수하는지 여부에 따라 비교 가능한 결과를 분류하도록 초대하고 있으며, 성능 대비 비용의 효율성을 비교하기 위해서 매개변수와 훈련 토큰 수를 기록할 수 있습니다.
- 6개의 베이스라인 결과로 벤치마크를 채우며, 사례 연구를 통해 Common Crawl을 넘어서는 데이터 없이 사전 훈련을 진행할 경우 많은 도메인에 대한 불일치한 적합성을 초래할 수 있음을 보여줍니다.

### [VidToMe: Video Token Merging for Zero-Shot Video Editing](https://arxiv.org/abs/2312.10656)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/6scX7w-xRxWWyLf5XhOl5.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/6scX7w-xRxWWyLf5XhOl5.mp4" muted="false"></video></div>

Vote: 4

Authors: Xirui Li, Xirui Li, Chao Ma, Xiaokang Yang, Xiaokang Yang, Ming-Hsuan Yang

- 분산 모델은 고품질 이미지 생성에 있어 주목할 만한 발전을 이루었지만, 시간적 동작의 복잡성으로 인해 비디오 생성에는 적용하기 어렵다.
- 제로 샷 비디오 편집은 사전 학습된 이미지 분산 모델을 사용하여 원본 비디오를 새로운 비디오로 변환함으로써 해결책을 제시한다.
- 그러나 기존 방법들은 시간적 일관성 유지와 메모리 효율성에 어려움을 겪고 있다.
- 본 연구에서는 프레임 간 자기 주의 토큰을 병합하여 생성된 비디오의 시간적 일관성을 향상시키는 새로운 접근법을 제안한다.
- 본 방법은 프레임 간의 시간적 대응을 기반으로 토큰을 맞추고 정렬함으로써 시간적 일관성을 자연스럽게 향상시킨다.
- 비디오 처리의 복잡성을 관리하기 위해 비디오를 청크로 나누고, 청크 내 지역 토큰 병합 및 청크 간 글로벌 토큰 병합을 개발하여 단기간 비디오 연속성과 장기간 내용 일관성을 모두 확보한다.
- 이 비디오 편집 접근법은 이미지 편집에서 이루어진 발전을 비디오 편집으로 원활하게 확장하여, 최신 방법들보다 시간적 일관성 측면에서 우수한 결과를 제공한다.

### [VolumeDiffusion: Flexible Text-to-3D Generation with Efficient Volumetric Encoder](https://arxiv.org/abs/2312.11459)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/bSPdFMgckxQZ4p_edrdQD.png)

Vote: 3

Authors: Zhicong Tang, Shuyang Gu, Chunyu Wang, Ting Zhang, Ting Zhang, Jianmin Bao, Jianmin Bao, Dong Chen, Baining Guo

- 본 논문은 텍스트-투-3D 생성을 위해 설계된 선구적인 3D 볼륨 인코더를 소개합니다.
- 멀티뷰 이미지에서 특징 볼륨을 효과적으로 취득하기 위해 가벼운 네트워크가 개발되었습니다.
- 그 다음으로, 3D U-Net을 사용하여 텍스트-투-3D 생성을 위한 확산 모델에서 3D 볼륨을 학습시킵니다.
- 이 연구는 부정확한 객체 캡션과 고차원 특징 볼륨의 도전 과제에도 더 나아가 대응합니다.
- 공개된 Objaverse 데이터셋에서 학습된 제안된 모델은 텍스트 프롬프트로부터 다양하고 인식 가능한 샘플을 생성하는 데 있어 유망한 결과를 보여줍니다.
- 주목할 만한 것은, 텍스트 신호를 통해 객체 부분 특성에 대한 세밀한 제어를 가능하게 하여 단일 객체 내에서 여러 개념을 자연스럽게 결합함으로써 모델 창의성을 증진시킵니다.
- 이 연구는 효율적이고 유연하며 확장 가능한 표현 방법론을 도입함으로써 3D 생성의 발전에 상당히 기여합니다.
- 코드는 https://github.com/tzco/VolumeDiffusion에서 이용할 수 있습니다.

### [ProTIP: Progressive Tool Retrieval Improves Planning](https://arxiv.org/abs/2312.10332)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/zhlaGAG5jE_nJlBrxrCvs.png)

Vote: 3

Authors: Raviteja Anantha, Bortik Bandyopadhyay, Anirudh Kashi, Sayantan Mahinder, Sayantan Mahinder, Andrew W Hill, Srinivas Chappidi

- 복잡한 다단계 계획 작업에 사용되는 대형 언어 모델(LLMs)에서 도구 검색(TR) 단계는 성공적인 결과 달성에 중요합니다.
- 일반적인 TR 방법에는 전체 질의를 사용하는 단일 단계 검색과 작업 분해(TD)를 사용하는 순차적 검색이 있으나, 각각 '도구 간 의존성'과 '하위 작업-도구 원자성' 정렬 문제가 있습니다.
- 이러한 한계를 해결하기 위해, '점진적 도구 검색을 통한 계획 개선(ProTIP)' 프레임워크가 소개되었습니다.
- ProTIP은 경량의 대조학습 기반 프레임워크로, 명시적인 하위 작업 라벨 요구 없이 TD를 암시적으로 수행하면서 하위 작업-도구 원자성을 유지합니다.
- 툴벤치(ToolBench) 데이터셋에서 ProTIP은 ChatGPT의 작업 분해 기반 접근법을 큰 차이로 능가하여, TR에 대한 Recall@K=10 지표에서 24% 향상을 달성하고 계획 생성에서 도구 정확도를 41% 향상시켰습니다.

### [Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models](https://arxiv.org/abs/2312.10835)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/iRoyacad-EMnij--eUxzG.png)

Vote: 2

Authors: Nikita Starodubcev, Nikita Starodubcev, Artem Fedorov, Artem Fedorov, Artem Babenko, Dmitry Baranchuk, Dmitry Baranchuk

- 최근 지식 증류 방법들은 소수의 추론 단계만 필요로 하여 대규모 확산 모델의 합성 속도를 높이는 데 유망한 방향으로 나타났습니다.
- 그러나 훈련된 학생 모델의 샘플 품질이 선생 모델에 비해 일반적으로 낮아서 실제 사용에 제약이 있습니다.
- 본 연구에서는 선생 텍스트-이미지 확산 모델과 그것의 증류된 학생 버전이 생성한 샘플의 상대적 품질을 조사했습니다.
- 주된 경험적 발견으로, 학생 모델이 생성한 샘플 중 상당 부분이 선생 모델에 비해 높은 충실도를 나타내고 있음을 발견하였습니다.
- 이러한 발견에 기반하여, 학생과 선생 확산 모델 간의 적응적 협력을 통해 텍스트-이미지 합성을 효과적으로 수행하는 방안을 제안합니다.
- 구체적으로, 증류 모델이 초기 샘플을 생성하고, 오라클이 느린 선생 모델로 더 개선이 필요한지를 결정합니다.
- 광범위한 실험을 통해 다양한 추론 예산에 대해 사람의 선호도 측면에서 최신 텍스트-이미지 대안보다 뛰어난 성능을 보이는 파이프라인을 입증했습니다.
- 제안된 접근법은 텍스트 가이드 이미지 편집 및 제어 가능한 생성과 같은 인기 있는 애플리케이션에서 자연스럽게 사용될 수 있습니다.

### [GauFRe: Gaussian Deformation Fields for Real-time Dynamic Novel View Synthesis](https://arxiv.org/abs/2312.11458)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/nhHo-h-YX26GqqzAzRwWJ.png)

Vote: 2

Authors: Yiqing Liang, Yiqing Liang, Numair Khan, Zhengqin Li, Zhengqin Li, Thu Nguyen-Phuoc, Thu Nguyen-Phuoc, Douglas Lanman, James Tompkin, James Tompkin, Lei Xiao

- 단일 카메라 비디오에 적합한 동적 장면 재구성을 위해 변형 가능한 3D 가우시안을 사용하는 방법을 제안합니다.
- 가우시안 스플래팅의 효율성을 기반으로 하여, 동적 요소들을 수용할 수 있도록 표준 공간에 있는 변형 가능한 가우시안 집합과 다층 퍼셉트론(MLP)에 의해 정의되는 시간-의존 변형 필드로 표현을 확장합니다.
- 자연 장면의 대부분은 정적인 부분을 많이 포함하고 있다는 가정 하에, MLP가 표현력을 집중할 수 있도록 정적 가우시안 점 구름을 추가로 포함합니다.
- 연결된 동적 및 정적 점 구름은 가우시안 스플래팅 래스터라이저의 입력으로 사용되며, 실시간 렌더링을 가능하게 합니다.
- 차별화 가능한 파이프라인은 자기 감독 렌더링 손실로 종단 간 최적화됩니다.
- 해당 방법은 동적 신경 방사선 필드 방법들과 비슷한 결과를 달성하면서 훨씬 빠른 최적화 및 렌더링을 허용합니다.
- 프로젝트 웹사이트: https://lynl7130.github.io/gaufre/index.html

### [Catwalk: A Unified Language Model Evaluation Framework for Many Datasets](https://arxiv.org/abs/2312.10253)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/G_wRk4ETDUvM0YfTkBOsV.png)

Vote: 2

Authors: Dirk Groeneveld, Dirk Groeneveld, Anas Awadalla, Anas Awadalla, Iz Beltagy, Iz Beltagy, Akshita Bhagia, Akshita Bhagia, Ian Magnusson, Ian Magnusson, Hao Peng, Oyvind Tafjord, Oyvind Tafjord, Pete Walsh, Kyle Richardson, Jesse Dodge, Jesse Dodge

- 대규모 언어 모델의 성공으로 자연어 처리(NLP)에서 평가 패러다임이 변화하여 다양한 작업, 도메인 및 데이터셋 간의 모델 비교에 관심이 증가하고 있습니다.
- 이러한 대규모 평가는 데이터셋과 모델 구축에 있어 통합되지 않은 노력과 호환되지 않는 형식 및 인터페이스로 인해 새로운 공학적 도전을 제기합니다.
- Catwalk는 이러한 문제를 해결하고자 개발되었으며, 기존 NLP 데이터셋 및 모델에 대한 통합 인터페이스를 제공합니다.
- 감독 학습 및 미세조정에서 현대적인 패러다임인 인컨텍스트 학습에 이르기까지 다양한 방법을 지원하고 쉽게 확장할 수 있는 잘 설계된 추상화를 가집니다.
- Catwalk는 대규모로 통제된 실험을 수행하는 데 필요한 장벽을 크게 낮춥니다.
- 예를 들어, 우리는 64개가 넘는 모델을 86개가 넘는 데이터셋에서 단일 명령어로 미세조정 및 평가를 수행할 수 있었으며, 코드 작성 없이 가능했습니다.
- Allen Institute for Artificial Intelligence (AI2)의 AllenNLP 팀이 유지 관리하는 Catwalk은 지속적인 오픈소스 노력의 일환으로 진행되고 있으며, GitHub 페이지는 https://github.com/allenai/catwalk에서 확인할 수 있습니다.

### [Silkie: Preference Distillation for Large Visual Language Models](https://arxiv.org/abs/2312.10665)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/XQkcF5PoicQ5mh_DQMBpT.png)

Vote: 2

Authors: Lei Li, Zhihui Xie, Mukai Li, Mukai Li, Shunian Chen, Peiyi Wang, Liang Chen, Liang Chen, Yazheng Yang, Benyou Wang, Lingpeng Kong

- 본 논문은 대형 시각 언어 모델(LVLMs)의 선호도 추출에 대해 탐구하며, 시각적 맥락을 기반으로 도움이 되고 신뢰할 수 있는 반응을 생성하는 능력을 향상시키는 연구를 소개합니다.
- 비전-언어 피드백(VLFeedback) 데이터셋을 인공지능 주석을 활용하여 구축, 다양한 데이터셋에서 가져온 다중 모달 지시사항에 기반한 12개의 LVLM 모델이 생성한 응답을 활용합니다.
- GPT-4V를 적용하여 생성된 결과물을 유용성, 시각적 충실도, 그리고 윤리적 고려사항 측면에서 평가합니다.
- 선호도 감독을 Qwen-VL-Chat에 직접 선호도 최적화(DPO) 방법을 통해 합류시킴으로써, 이에 따른 결과물로서, Silkie 모델은 인지 및 인지능력 측면에서 MME 벤치마크에 대해 각각 6.9% 및 9.5%의 상대적 개선을 달성합니다.
- 또한, Silkie는 MMHal-Bench 벤치마크에서 새로운 최고 기록인 3.02점을 기록, 환각을 감소시켰음을 보여줍니다.
- 추가 분석을 통해 VLFeedback 데이터셋을 활용한 DPO는 LVLMs의 미세한 지각 및 복잡한 인지 능력을 주로 향상시켜, 인간 주석이 달린 선호도 데이터셋에 비해 더 포괄적인 개선을 이끌어낸다는 것을 밝힙니다.

