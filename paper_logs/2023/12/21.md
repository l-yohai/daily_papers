## Daily Papers (2023-12-21)

### [StreamDiffusion: A Pipeline-level Solution for Real-time Interactive Generation](https://arxiv.org/abs/2312.12491)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/QlcgZAaBQdlvo90INQd3D.png)

Vote: 29

Authors: Akio Kodaira, Akio Kodaira, Chenfeng Xu, Chenfeng Xu, Toshiki Hazama, Takanori Yoshimoto, Kohei Ohno, Shogo Mitsuhori, Soichi Sugano, Hanying Cho, Zhijian Liu, Zhijian Liu, Kurt Keutzer, Kurt Keutzer

- 'StreamDiffusion'은 메타버스, 라이브 비디오 스트리밍 및 방송과 같이 실시간 상호 작용이 중요한 시나리오에 적합한 대화형 이미지 생성을 위해 고안된 실시간 확산 파이프라인을 소개합니다.
- 기존의 순차적인 노이즈 제거 프로세스를 배치 노이즈 제거 프로세스로 변환하여, 전통적인 대기-상호 작용 방식을 없애고 연속적이고 높은 처리량의 스트림을 가능하게 합니다.
- 데이터 입력과 모델 처리량 간의 빈도 차이를 해결하기 위해 병렬 스트리밍 처리를 위한 새로운 입력-출력 큐를 설계했습니다.
- 불필요한 연산을 줄이기 위해 추가적인 U-Net 계산이 필요한 기존의 분류자 없는 안내(CFG)를 사용하는 대신 새로운 잔차 분류자 없는 안내(RCFG) 알고리즘을 제안합니다.
- 이 알고리즘은 부정적 조건별 노이즈 제거 단계를 하나 또는 제로까지 감소시킵니다.
- 전력 소비를 최적화하기 위해 확률적 유사성 필터(SSF)를 소개합니다.
- 스트림 배치는 다른 노이즈 제거 수준에서 순차적 노이즈 제거 방법보다 약 1.5배 빠른 속도를 달성합니다.
- 제안된 RCFG는 기존 CFG에 비해 최대 2.05배 더 빠른 속도를 달성합니다.
- 제안된 전략과 기존의 성숙한 가속화 도구를 결합하여 이미지 대 이미지 생성을 RTX4090 하나에서 최대 91.07fps까지 달성하며, 이는 'Diffusers'에 의해 개발된 AutoPipline의 처리량을 59.56배 이상 향상시킵니다.
- 또한, StreamDiffusion은 RTX3060 하나에서 에너지 소비를 2.39배, RTX4090 하나에서는 1.99배 감소시킨다는 점도 확인할 수 있습니다.

### [PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU](https://arxiv.org/abs/2312.12456)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/F2ljTCoU1ZbhFUznZzgg_.png)

Vote: 24

Authors: Yixin Song, Yixin Song, Zeyu Mi, Zeyu Mi, Haotong Xie, Haibo Chen

- 이 논문에서는 개인용 컴퓨터(PC)에 장착된 단일 소비자용 GPU로 고속으로 동작하는 대규모 언어 모델(Large Language Model, LLM) 추론 엔진인 PowerInfer를 소개합니다.
- PowerInfer의 핵심 설계는 뉴런 활성화에 내재된 높은 지역성을 활용하는 것으로, 전력법칙(power-law) 분포를 따르는 것이 특징입니다.
- 이러한 분포에 따르면, 극소수의 '핫 뉴런(hot neurons)'이 일관되게 활성화되며, 대다수의 '콜드 뉴런(cold neurons)'은 입력에 따라 변화합니다.
- PowerInfer는 빠른 접근을 위해 GPU에 핫 뉴런을 사전 로드하고, 콜드 뉴런은 CPU에서 계산하여 GPU 메모리 요구를 현저히 줄이고 CPU-GPU 데이터 전송을 최소화하는 하이브리드 GPU-CPU 추론 엔진을 설계합니다.
- 또한, PowerInfer는 뉴런 활성화의 효율성과 연산의 희소성을 최적화하기 위해 적응형 예측기와 뉴런-인식 희소 연산자(neuron-aware sparse operators)를 통합합니다.
- 평가 결과, PowerInfer는 단일 NVIDIA RTX 4090 GPU에서 평균 13.20 토큰/초의 토큰 생성 속도와 최고 29.08 토큰/초의 성능을 달성하는데, 이는 최상급 서버급 A100 GPU에 비해 오직 18% 낮은 성능입니다.
- 이는 기존의 llama.cpp보다 최대 11.69배 빠른 성능을 나타내면서도 모델의 정확성을 유지합니다.

### [Generative Multimodal Models are In-Context Learners](https://arxiv.org/abs/2312.13286)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/g83HzHiihbV3XTzE43QjD.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/g83HzHiihbV3XTzE43QjD.mp4" muted="false"></video></div>

Vote: 19

Authors: Quan Sun, Quan Sun, Yufeng Cui, Yufeng Cui, Xiaosong Zhang, Xiaosong Zhang, Fan Zhang, Qiying Yu, Qiying Yu, Zhengxiong Luo, Yueze Wang, Yongming Rao, Yongming Rao, Jingjing Liu, Jingjing Liu, Tiejun Huang, Xinlong Wang, Xinlong Wang

- 다양한 모드의 문제를 문맥 안에서 쉽게 해결하는 인간의 능력을 모방하는 것은 현재의 다중 모드 시스템이 주로 어려워하는 부분입니다.
- 이 연구에서는 대규모 다모드 모델의 문맥 내 학습 능력을 효과적인 크기 조정을 통해 크게 향상시킬 수 있음을 보여줍니다.
- 우리는 통합 자동회귀 목표로 대규모 다모드 시퀀스에서 훈련된 370억 개의 매개변수를 가진 생성 다모드 모델 Emu2를 소개합니다.
- Emu2는 시각적 힌트 제공과 객체 기반 생성과 같이 현장 추론이 필요한 작업을 해결하는 강력한 다모드 문맥 내 학습 능력을 발휘합니다.
- 이 모델은 적은 예제 설정에서 다중 모드 이해 작업에 대한 새로운 기록을 세웁니다.
- Emu2는 구체적인 지침을 따르도록 교육 조정될 때 대규모 다모드 모델에 대한 질문 응답 벤치마크 및 개방형 주제 주도 생성과 같은 도전적인 작업에서 새로운 최고 수준을 달성합니다.
- 이러한 성과들은 Emu2가 다양한 다모드 작업을 위한 기본 모델 및 범용 인터페이스로 사용될 수 있음을 보여줍니다.
- 코드와 모델은 향후 연구를 용이하게 하기 위해 공개적으로 제공됩니다.

### [Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion Model](https://arxiv.org/abs/2312.13252)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/kWBXc0a_qw880rSSm5R7R.png)

Vote: 12

Authors: Saurabh Saxena, Saurabh Saxena, Junhwa Hur, Junhwa Hur, Charles Herrmann, Charles Herrmann, Deqing Sun, David J. Fleet

- 단안 심도 추정 방법이 표준 벤치마크에서 상당한 진전을 이루었지만 zero-shot 미터법 심도 추정 문제는 아직 해결되지 않았습니다.
- 실내외 장면을 함께 모델링하기 위해 특별히 다중 헤드 구조를 제안하는 최근 연구들과 달리, 우리는 일반적이고 과제 비특정적인 확산 모델을 제안합니다.
- 로그 스케일 심도 매개변수화을 사용하여 실내외 장면을 공동으로 모델링하고, FOV(시야각)에 대한 조건을 고려하여 규모의 모호성을 다루며, 훈련 중 FOV를 합성적으로 증가시켜 훈련 데이터 세트에 제한된 카메라 내부 매개 변수를 넘어 일반화합니다.
- 또한, 일반적으로 사용되는 것보다 더 다양한 훈련 데이터셋을 사용하고 효율적인 확산 매개변수화를 채택함으로써, 우리의 방법인 DMD(Diffusion for Metric Depth)는 적은 수의 잡음 제거 단계를 사용하여 zero-shot 실내 데이터셋에서 25%, 실외에서는 33%의 상대 오류(REL) 감소를 달성했습니다.
- 자세한 정보는 여기서 확인할 수 있습니다: https://diffusion-vision.github.io/dmd

### [InstructVideo: Instructing Video Diffusion Models with Human Feedback](https://arxiv.org/abs/2312.12490)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/CZapguKvyaGZxTGYihkly.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/CZapguKvyaGZxTGYihkly.mp4" muted="false"></video></div>

Vote: 11

Authors: Hangjie Yuan, Hangjie Yuan, Shiwei Zhang, Shiwei Zhang, Xiang Wang, Yujie Wei, Tao Feng, Yining Pan, Yining Pan, Yingya Zhang, Ziwei Liu, Ziwei Liu, Samuel Albanie, Samuel Albanie, Dong Ni

- 비디오 생성을 위한 디팩토 패러다임으로 부상한 확산 모델들은 웹 규모의 다양한 품질 데이터에 의존함으로써 시각적으로 매력적이지 않고 텍스트 프롬프트와 일치하지 않는 결과를 자주 도출합니다.
- 이 문제를 해결하기 위해, 우리는 인간 피드백을 통한 보상 미세조정으로 텍스트-투-비디오 확산 모델을 지시하는 InstructVideo를 제안합니다.
- InstructVideo는 두 가지 주요 구성 요소를 가집니다: 1) 전체 DDIM 샘플링 체인을 생성하는데 따른 보상 미세조정 비용을 감소시키기 위해, 보상 미세조정을 편집작업으로 개선합니다.
- 2) 인간 기호에 맞는 전용 비디오 보상 모델의 부재를 해결하기 위해, 예를 들어 HPSv2와 같은 이미지 보상 모델을 재활용합니다.
- 우리는 세그멘탈 비디오 보상이라는 메커니즘을 제안하며 이는 세그먼트별 희소 샘플링에 기반한 보상 신호를 제공하고, 미세조정 중 시간적 모델링 저하를 완화하는데 사용되는 시간적 감쇠 보상 방법도 제안합니다.
- 질적 및 양적인 광범위한 실험을 통해, 이미지 보상 모델을 InstructVideo에서 사용하는 것의 실용성 및 효과가 입증되었고, 일반화 능력을 해치지 않으면서 생성된 비디오의 시각적 품질을 크게 향상시키는 것으로 나타났습니다.
- 코드와 모델은 공개적으로 제공될 예정입니다.

### [Cached Transformers: Improving Transformers with Differentiable Memory Cache](https://arxiv.org/abs/2312.12742)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/9KlvZx4_qFa3EeqPysk4i.png)

Vote: 7

Authors: Zhaoyang Zhang, Zhaoyang Zhang, Wenqi Shao, Wenqi Shao, Yixiao Ge, Yixiao Ge, Xiaogang Wang, Jinwei Gu, Jinwei Gu, Ping Luo

- 이 연구는 토큰의 차별화 가능한 메모리 캐시를 활용하여 자기 주의 메커니즘을 확장하는 새로운 Transformer 모델인 Cached Transformer를 소개합니다.
- Gated Recurrent Cached(GRC) 주목은 과거와 현재의 토큰 모두에 주목할 수 있도록 하여 주의력의 수용 범위를 넓히고 장거리 의존성을 탐색할 수 있게 합니다.
- 반복적인 게이팅 유닛을 사용하여 캐시를 지속적으로 업데이트함으로써, 이 모델은 언어 모델링, 기계 번역, ListOPs, 이미지 분류, 객체 감지, 그리고 인스턴스 세분화를 포함한 여섯 가지 언어 및 비전 작업에서 중요한 진전을 이루었습니다.
- 또한, 언어 모델링과 같은 작업에서 이전의 메모리 기반 기술들을 능가하며, 더 넓은 범위의 상황에 적용 될 수 있는 능력을 보여줍니다.

### [Splatter Image: Ultra-Fast Single-View 3D Reconstruction](https://arxiv.org/abs/2312.13150)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/sYqwMJ-DQauxov6z98Nmm.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/sYqwMJ-DQauxov6z98Nmm.mp4" muted="false"></video></div>

Vote: 6

Authors: Stanislaw Szymanowicz, Christian Rupprecht, Andrea Vedaldi

- 본 논문에서는 초당 38프레임의 속도로 단일 뷰(monocular) 3D 객체 재구성을 가능하게 하는 초고속 접근법인 Splatter Image를 소개한다.
- 이 방법은 최근 실시간 렌더링과 빠른 훈련, 다중 뷰 재구성에서 뛰어난 확장성을 보여준 가우시안 스플래팅(Gaussian Splatting)에 기반하고 있다.
- 연구 팀은 가우시안 스플래팅을 최초로 단일 뷰 재구성 환경에 적용하여 각 픽셀에 대한 3D 가우시안을 매핑하는 2D 이미지 대 이미지 네트워크를 통해 입력 이미지를 재구성한다.
- 이러한 가우시안들은 Splatter Image라 불리는 이미지 형태를 갖게 되며, 여러 이미지를 입력으로 활용하기 위해 교차 뷰 어텐션(cross-view attention) 기법을 추가적으로 사용한다.
- 빠른 렌더러의 속도(초당 588프레임)를 활용하여 단일 GPU 훈련이 가능하고, LPIPS와 같은 지각적 측정 기준을 최적화하기 위해 각 반복(iteration)마다 전체 이미지를 생성한다.
- 기존 벤치마크를 통해 상당히 빠른 재구성 속도뿐만 아니라 PSNR, LPIPS 등의 다른 측정항목에서도 최근의 비용이 많이 드는 기준 대비 더 나은 결과를 보여주는 것을 입증한다.

### [UniSDF: Unifying Neural Representations for High-Fidelity 3D Reconstruction of Complex Scenes with Reflections](https://arxiv.org/abs/2312.13285)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/63K0AntavfctwuxIug9a1.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/63K0AntavfctwuxIug9a1.mp4" muted="false"></video></div>

Vote: 5

Authors: Fangjinhua Wang, Fangjinhua Wang, Marie-Julie Rakotosaona, Michael Niemeyer, Michael Niemeyer, Richard Szeliski, Marc Pollefeys, Federico Tombari

- 실세계 캡쳐의 복잡한 장면을 3D로 재구성하는 것은 여전히 도전과제이며, 기존의 범용 3D 재구성 방법은 정교한 기하학적 세부 사항과 대규모 장면의 반사면을 적절히 모델링하지 못하는 문제가 있습니다.
- 특정 반사면을 중점으로 하는 기술들은 더 나은 반사 파라미터화를 활용하여 복잡하고 정교한 반사를 모델링할 수 있지만, 반사와 비반사 요소가 모두 존재하는 무한한 실제 시나리오에서 강인성이 부족하다는 것을 발견했습니다.
- 본 연구에서는 반사면이 포함된 큰 복잡한 장면의 고정밀 3D 재구성을 가능하게 하는 일반 목적의 3D 재구성 방법인 UniSDF를 제안합니다.
- 시점 기반 및 반사 기반 색상 예측 파라미터화 기술을 조사한 결과, 이러한 표현을 3D 공간에서 명시적으로 혼합하는 것이 특히 반사면에서 기하학적 정확성이 뛰어난 표면 재구성을 가능하게 한다는 것을 발견했습니다.
- 이 표현을 점진적으로 세분화된 멀티 해상도 그리드 백본과 결합하여 종전 방법보다 빠른 재구성을 실현했습니다.
- DTU, Shiny Blender, Mip-NeRF 360, Ref-NeRF 실제와 같은 대상 수준 데이터셋과 무한한 데이터셋에 대한 광범위한 실험을 통해 저희 방법이 정교한 디테일과 반사면을 가진 복잡한 대규모 장면을 강인하게 재구성할 수 있음을 입증했습니다.
- 프로젝트 페이지에서 더 자세한 정보와 성과를 확인할 수 있습니다: https://fangjinhuawang.github.io/UniSDF/.

### [SpecNeRF: Gaussian Directional Encoding for Specular Reflections](https://arxiv.org/abs/2312.13102)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/EyHFeKDVeaxc9LuYy-6Fz.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/EyHFeKDVeaxc9LuYy-6Fz.mp4" muted="false"></video></div>

Vote: 5

Authors: Li Ma, Vasu Agrawal, Vasu Agrawal, Haithem Turki, Haithem Turki, Changil Kim, Chen Gao, Chen Gao, Pedro Sander, Michael Zollhöfer, Christian Richardt

- 신경 복셀 필드(Neural radiance fields)는 3D 장면의 외관을 모델링하는 데 뛰어난 성능을 달성했지만, 기존 접근법은 특히 복잡한 실내 조명 아래에서 윤이 나는 표면의 시점 의존적 외관을 재현하는 데 어려움을 겪고 있다.
- 기존의 원거리 조명 가정(예: 환경 맵)과 달리, 이 연구에서는 근거리 조명 조건하에서의 시점 의존적 효과를 더 잘 모델링하기 위해 학습 가능한 가우시안 방향 인코딩 방법을 제안한다.
- 새로운 방향 인코딩은 근거리 조명의 공간적으로 변화하는 특성을 포착하고, 환경 맵의 사전 필터링된 행동을 모방하여 다양한 거칠기 계수를 가진 3D 위치에서의 효율적인 스펙큘러 색상의 사전 계산된 평가를 가능하게 한다.
- 추가적으로, 반사 모델링에서의 형태와 복셀의 모호성을 완화하는 데 도움이 되는 데이터 기반의 기하학적 선행 지식을 도입한다.
- 이러한 가우시안 방향 인코딩과 기하학적 선행 지식은 신경 복셀 분야에서 도전적인 윤기 있는 반사를 모델링하는 것을 크게 개선하고, 외관을 더 물리적으로 의미 있는 구성 요소로 분해하는 데 도움이 된다는 것을 보여준다.

### [Mini-GPTs: Efficient Large Language Models through Contextual Pruning](https://arxiv.org/abs/2312.12682)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ZBPrZFvDZXHhmfuDd08DY.png)

Vote: 5

Authors: Tim Valicenti, Tim Valicenti, Justice Vidal, Justice Vidal, Ritik Patnaik, Ritik Patnaik

- 대규모 언어 모델(LLMs)의 최적화는 실용적인 적용과 지속 가능성 측면에서 AI 연구 분야의 중요한 도전 과제입니다.
- MIT의 송한 교수 연구실의 기초 연구를 바탕으로, 이 논문에서는 컨텍스처 프루닝을 통해 Mini-GPTs를 개발하는 새로운 접근 방식을 소개합니다.
- 이 방법론은 Phi-1.5와 같은 전통적인 LLM의 계산 구조를 전략적으로 프루닝하여, 중요 기능은 유지하면서 모델 크기를 크게 줄입니다.
- 다양하고 복잡한 데이터셋(미국 법률, 의료 Q&A, 스카이림 대화, 영어-대만어 번역, 경제 기사)에서 이 기술을 적용하였습니다.
- 컨텍스처 프루닝의 효율성과 유효성은 이론적 개념뿐만 아니라 도메인 특화된, 자원 효율적인 LLM을 개발하는 실용적 도구로 강조됩니다.
- 컨텍스처 프루닝은 도메인 특화된 LLM을 구축하는 유망한 방법이며, 이 연구는 향후 하드웨어 컴퓨팅, 세분화된 파인튜닝, 정량화를 통한 개발을 위한 기초를 마련합니다.

### [MaskINT: Video Editing via Interpolative Non-autoregressive Masked Transformers](https://arxiv.org/abs/2312.12468)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/TGcovb-ORhy3TP2mAsX-I.qt)

Vote: 4

Authors: Haoyu Ma, Haoyu Ma, Shahin Mahdizadehaghdam, Bichen Wu, Bichen Wu, Zhipeng Fan, Yuchao Gu, Yuchao Gu, Wenliang Zhao, Wenliang Zhao, Lior Shapira, Lior Shapira, Xiaohui Xie, Xiaohui Xie

- 최근 인공지능의 발전은 텍스트 프롬프트 제어의 맥락에서 이미지 및 비디오 편집 기술을 크게 향상시켰으나, 확산 모델 기반의 최신 접근 방식은 컴퓨팅 요구사항이 많고 훈련을 위해 대규모의 페어 데이터셋이 필요하여 실용적인 응용에 어려움이 있습니다.
- 본 연구는 텍스트 기반 비디오 편집 과정을 키 프레임 편집과 프레임 보간의 두 단계로 나누어 이러한 과제를 해결합니다.
- 첫 단계에서는 기존 텍스트-이미지 확산 모델을 사용하여 추가적인 미세 조정 없이 몇 가지 키 프레임을 동시에 편집합니다.
- 두 번째 단계에서는 중간 프레임에 의해 제공되는 구조적 가이드를 활용하여 키 프레임 사이의 프레임을 효율적으로 보간하는 비자율 마스크 생성 변환기인 MaskINT 모델을 소개합니다.
- 포괄적인 실험 결과는 MaskINT가 확산 기반 방법론에 비해 그 효과 및 효율성을 입증합니다.
- 이 연구는 텍스트 기반 비디오 편집을 위한 실용적인 해결책을 제공하며, 비자율 마스크 생성 변환기가 이 분야에서의 잠재력을 보여줍니다.

### [Repaint123: Fast and High-quality One Image to 3D Generation with Progressive Controllable 2D Repainting](https://arxiv.org/abs/2312.13271)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jj_7lYhwPvYH2gPMTR7rW.png)

Vote: 4

Authors: Junwu Zhang, Junwu Zhang, Zhenyu Tang, Zhenyu Tang, Yatian Pang, Xinhua Cheng, Xinhua Cheng, Peng Jin, Yida Wei, Wangbo Yu, Wangbo Yu, Munan Ning, Munan Ning, Li Yuan

- 현재 한 장의 이미지를 이용해 3D 컨텐츠를 생성하는 방법은 대부분 스코어 디스틸레이션 샘플링(SDS, Score Distillation Sampling)을 사용하지만, 다중 시점 불일치 및 과도한 채도와 부드러움 문제, 그리고 생성 속도의 저하 문제가 있음.
- 이러한 문제를 해결하기 위해 'Repaint123'이라는 새로운 방법을 제시하며, 이는 고품질 2D 촬영 모델의 이미지 생성 기능과 재칠하기 전략을 결합하여 일관성을 가지는 다중 시점 이미지를 생성함.
- 또한, 재칠하는 과정에서 생성된 이미지 품질을 향상시키기 위해 겹치는 영역에 대해 가시성을 고려한 적응형 재칠 강도를 제안함.
- 생성된 고품질이며 다중 시점에서 일관된 이미지를 이용하여 Mean Square Error (MSE) 손실을 적용, 빠른 3D 컨텐츠 생성이 가능해짐.
- 광범위한 실험을 통해 Repaint123 방법이 처음부터 2분 내에 다중 시점 일관성과 세밀한 텍스처를 가진 고품질 3D 컨텐츠를 생성할 수 있는 능력이 뛰어남을 입증함.
- 관련 코드는 'https://github.com/junwuzhang19/repaint123'에서 확인할 수 있음.

### [Model-Based Control with Sparse Neural Dynamics](https://arxiv.org/abs/2312.12791)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/D5tmBY375ulCifwJqbMZI.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/D5tmBY375ulCifwJqbMZI.mp4" muted="false"></video></div>

Vote: 3

Authors: Ziang Liu, Genggeng Zhou, Jeff He, Tobia Marcucci, Li Fei-Fei, Jiajun Wu, Jiajun Wu, Yunzhu Li, Yunzhu Li

- 본 논문은 깊은 신경망(DNN)을 사용하여 관측치로부터 예측 모델을 학습하는 새로운 접근방법으로 실제 계획 및 제어 문제에 대한 효과적인 해결책을 제안합니다.
- 기존의 DNN은 구조가 불분명하여 효율적인 계획 수립에 어려움이 있고, 현재 제어 방법은 광범위한 샘플링이나 지역 그래디언트 하강에 주로 의존합니다.
- 이에, 연구팀은 ReLU 신경 모델을 바탕으로 시스템 동역학을 모델링하고, 불필요한 뉴런을 제거하여 예측 정확도에 큰 손실 없이 모델을 점차 희소화하는 새로운 프레임워크를 제안합니다.
- 희소화 과정은 연속적인 문제로 근사되어, 모델 구조와 가중치 매개변수 모두에 대한 종단간 최적화를 가능하게 합니다.
- 희소화된 모델은 혼합 정수 예측 제어기에 의해 사용되며, 여기서 뉴런 활성화를 이진 변수로 표현하고 효율적인 분기 한정(branch-and-bound) 알고리즘을 활용합니다.
- 제안된 프레임워크는 단순한 다층 퍼셉트론부터 복잡한 그래프 신경 동역학에 이르기까지 다양한 DNN에 적용 가능합니다.
- 복잡한 접촉 동역학을 다루는 과제들, 예를 들어 물체 밀기, 구성 물체 분류, 변형 가능한 물체 조작 같은 작업을 효과적으로 처리할 수 있습니다.
- 수치적 및 하드웨어 실험 결과에 따르면, 공격적인 희소화에도 불구하고, 제안된 프레임워크는 기존의 최신 방법들보다 더 나은 폐루프 성능을 제공함을 보여줍니다.

### [RadEdit: stress-testing biomedical vision models via diffusion image editing](https://arxiv.org/abs/2312.12865)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Yf6TQ0StOVN_n4KKKPT8C.png)

Vote: 3

Authors: Fernando Pérez-García, Fernando Pérez-García, Sam Bond-Taylor, Pedro P. Sanchez, Pedro P. Sanchez, Boris van Breugel, Boris van Breugel, Daniel C. Castro, Harshita Sharma, Valentina Salvatelli, Valentina Salvatelli, Maria T. A. Wetscherek, Hannah Richardson, Matthew P. Lungren, Aditya Nori, Javier Alvarez-Valle, Javier Alvarez-Valle, Ozan Oktay, Ozan Oktay, Maximilian Ilse

- 바이오메디컬 영상 데이터셋은 종종 규모가 작고 편향되어 있어서, 실제 세계에서 예측 모델의 성능이 예상보다 훨씬 낮을 수 있다.
- 이 연구는 생성적 이미지 편집을 사용하여 데이터셋의 변화를 시뮬레이션하고, 바이오메디컬 비전 모델의 실패 모드를 진단하는 방법을 제안한다; 이를 통해 배포 전 준비 상태를 평가하고 비용 및 환자 피해를 줄일 수 있다.
- 기존 편집 방법들은 바람직하지 않은 변화를 유발하여, 질병과 치료 개입의 공존으로 인해 학습된 허위 상관관계로 인해 실용적 적용성이 제한된다.
- 이를 해결하기 위해, 본 연구는 여러 가지 흉부 X선 데이터셋에 대한 텍스트-이미지 확산 모델을 훈련시키고, 존재하는 경우 여러 가지 마스크를 사용하여 이미지 편집 시 변경 사항을 제한하고 일관성을 유지하는 새로운 편집 방법인 RadEdit을 도입한다.
- 연구팀은 데이터 수집 추가 없이 모델의 견고함을 진단하고 정량화할 수 있는 방법으로써, 획득 변화(acquisition shift), 질병 표현 변화(manifestation shift), 그리고 인구 변화(population shift)라는 세 가지 유형의 데이터셋 변화를 고려한다.
- 저자들의 접근 방식은 기존의 설명 가능한 인공지능(AI) 도구를 보완하는 방식으로 실패를 진단하며 모델의 견고성을 정량화할 수 있다는 점을 시연한다.

### [Adaptive Guidance: Training-free Acceleration of Conditional Diffusion Models](https://arxiv.org/abs/2312.12487)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/r0FLqX9PtLtlA-qs6SYqV.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/r0FLqX9PtLtlA-qs6SYqV.mp4" muted="false"></video></div>

Vote: 3

Authors: Angela Castillo, Jonas Kohler, Jonas Kohler, Juan C. Pérez, Juan C. Pérez, Juan Pablo Pérez, Albert Pumarola, Bernard Ghanem, Pablo Arbeláez, Ali Thabet

- 이 논문은 텍스트 조건의 확산 모델에서 분류기-없는 지도 방법(CFG)의 역할에 대한 종합적인 연구를 제시하며, 특히 추론 효율성의 관점에서 CFG의 기본적인 적용을 재고해본다.
- 연구팀은 모든 확산 단계에 CFG를 적용하는 것 대신에 보다 효율적인 지도 정책을 탐색하고, 이를 찾기 위해 차별화 가능한 신경망 아키텍처 검색 프레임워크를 사용한다.
- 연구 결과에 따르면, CFG에 의해 제안된 제잡음 단계는 간단한 조건부 단계와 점점 정렬되기 때문에, 특히 제잡음 과정의 후반부에서는 CFG의 추가 신경망 평가가 불필요할 수 있음을 밝힌다.
- 이러한 통찰을 바탕으로 'Adaptive Guidance'(AG)라는 효율적인 CFG 변형을 제안하여, 제잡음 과정이 수렴을 보일 때 네트워크 평가를 적응적으로 생략한다.
- 실험을 통해 AG는 CFG의 이미지 품질을 유지하면서 계산을 25% 줄일 수 있음을 보여주며, 특히 학습 없이도 부정적인 프롬프트 처리 능력을 유지할 수 있다.
- 마지막으로, 확산 과정의 첫 절반에서 CFG의 추가적인 중복성을 발견하고, 과거 점수 추정치의 단순한 아핀 변환으로 전체 신경 기능 평가를 대체할 수 있는 방법인 'LinearAG'를 소개한다.
- 이 LinearAG 방법은 기본 모델로부터의 변형을 감수하면서도 더 저렴한 추론을 제공한다.
- 이 연구는 조건부 제잡음 과정의 효율성에 대한 통찰을 제공하며, 텍스트 조건의 확산 모델의 더 실용적이고 빠른 배포에 기여한다.

