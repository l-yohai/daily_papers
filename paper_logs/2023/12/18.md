## Daily Papers (2023-12-18)

### [Amphion: An Open-Source Audio, Music and Speech Generation Toolkit](https://arxiv.org/abs/2312.09911)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/_PDKG60wfHH13zPUONSV7.png)

Vote: 33

Authors: Xueyao Zhang, Xueyao Zhang, Liumeng Xue, Liumeng Xue, Yuancheng Wang, Yuancheng Wang, Yicheng Gu, Xi Chen, Zihao Fang, Zihao Fang, Haopeng Chen, Lexiao Zou, Lexiao Zou, Chaoren Wang, Chaoren Wang, Jun Han, Jun Han, Kai Chen, Haizhou Li, Zhizheng Wu, Zhizheng Wu

- Amphion은 오디오, 음악, 그리고 음성 생성 분야의 연구 및 개발을 새로 시작하는 연구원과 엔지니어들에게 도움을 주기 위한 도구 모음입니다.
- 이 툴킷은 고전 모델이나 구조의 시각화 기능을 제공하여, 더 나은 모델 이해를 지원합니다.
- Amphion의 주요 목표는 다양한 입력을 일반 오디오로 변환하는 연구를 위한 플랫폼을 제공하는 것입니다.
- 개별 생성 작업을 지원하도록 설계되었으며, 특정 생성 작업뿐만 아니라 다양한 보코더와 평가 지표를 포함하고 있습니다.
- 보코더는 고품질 오디오 신호를 생성하는 중요한 모듈이며, 평가 지표는 생성 작업에서 일관된 측정 기준을 보장하는 데 중요합니다.
- 이 논문에서는 Amphion에 대한 개요를 고찰하며, 이 툴킷이 연구 재현성을 지원하는 방법을 설명합니다.

### [Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision](https://arxiv.org/abs/2312.09390)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/YJRlXy-6kefFVvA4TeocC.png)

Vote: 20

Authors: Collin Burns, Pavel Izmailov, Pavel Izmailov, Jan Hendrik Kirchner, Jan Hendrik Kirchner, Bowen Baker, Leo Gao, Leopold Aschenbrenner, Yining Chen, Adrien Ecoffet, Adrien Ecoffet, Manas Joglekar, Jan Leike, Ilya Sutskever, Jeff Wu

- 인간의 피드백에서 강화 학습(RLHF)과 같이 널리 사용되는 정렬 기술은 모델이 지시를 충실하게 따르거나 안전한 결과를 생성하는지 평가하는 인간의 감독 능력에 의존합니다.
- 미래의 초인간 모델들은 인간이 신뢰성 있게 평가하기 어려운 복잡한 방식으로 행동할 것이며, 이는 인간이 초인간 모델을 약하게만 감독할 수 있음을 의미합니다.
- 연구진은 강력한 모델의 전체 능력을 약한 모델 감독으로 유도할 수 있는지 여부를 연구했으며, GPT-4 계열의 선학습된 언어 모델을 사용해 자연어 처리(NLP), 체스 및 보상 모델링 작업에서 이를 테스트했습니다.
- 약한 모델이 생성한 레이블로 강력한 선학습 모델을 단순하게 미세조정할 때, 이 모델들은 일관되게 약한 감독자들보다 더 나은 성능을 보여주는 현상인 weak-to-strong generalization을 발견했습니다.
- 그러나 단순 미세조정만으로 강력한 모델의 모든 능력을 다시 얻는 것은 여전히 멀었으며, 이는 RLHF와 같은 기술이 추가 작업 없이 초인간 모델에 잘 확장되지 않을 수 있음을 시사합니다.
- 보조 신뢰도 손실과 함께 GPT-2 수준 감독자를 사용하여 GPT-4를 미세조정할 때, NLP 작업에서 거의 GPT-3.5 수준의 성능을 회복할 수 있음을 보여주는 등, 단순한 방법들이 종종 weak-to-strong generalization을 크게 개선할 수 있음을 발견했습니다.
- 이 연구 결과는 초인간 모델을 조율하는 근본적인 도전에 대한 실증적인 진척을 오늘날에도 이룰 수 있음을 시사합니다.

### [DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models](https://arxiv.org/abs/2312.09767)

[Watch Video](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/zRg6h4N4Sc3--BrwQuAqE.mp4)
<div><video controls src="https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/zRg6h4N4Sc3--BrwQuAqE.mp4" muted="false"></video></div>

Vote: 13

Authors: Yifeng Ma, Yifeng Ma, Shiwei Zhang, Shiwei Zhang, Jiayu Wang, Jiayu Wang, Xiang Wang, Yingya Zhang, Zhidong Deng

- 확산 확률 모델(Diffusion Probabilistic Models)의 성공에 힘입어, 표현력 있는 화자의 얼굴 생성(Expressive Talking Head Generation) 문제를 해결하기 위한 'DreamTalk' 프레임워크가 제안되었습니다.
- DreamTalk은 고도로 설계된 세 가지 핵심 구성 요소로 이루어져 있으며, 이를 통해 다양한 표정의 고품질 오디오 기반 얼굴 동작을 일관되게 생성할 수 있습니다.
- 표현력과 입술 동작의 정확성을 향상시키기 위해, 말하는 스타일을 고려할 수 있는 '스타일 인식 입술 전문가(Style-Aware Lip Expert)'가 도입되었습니다.
- 표정 참고 비디오나 텍스트에 대한 의존성을 줄이기 위해, 오디오에서 직접 대상 표정을 예측하는 추가 확산 기반 스타일 예측기(Style Predictor)가 사용됩니다.
- DreamTalk은 강력한 확산 모델을 활용하여 효과적으로 표현력 있는 얼굴을 생성하며, 비싼 스타일 참고 자료에 대한 의존도를 낮출 수 있습니다.
- 실험 결과, DreamTalk은 다양한 말하는 스타일과 정확한 입모양 동작을 가진 사진 같은 화자의 얼굴을 생성할 수 있으며, 기존 최신 기술들을 능가하는 성능을 보여주었습니다.

### [ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent](https://arxiv.org/abs/2312.10003)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/UptCA66CaKw4SbcExcnXK.png)

Vote: 13

Authors: Renat Aksitov, Renat Aksitov, Sobhan Miryoosefi, Zonglin Li, Zonglin Li, Daliang Li, Sheila Babayan, Kavya Kopparapu, Kavya Kopparapu, Zachary Fisher, Ruiqi Guo, Sushant Prakash, Pranesh Srinivasan, Manzil Zaheer, Felix Yu, Sanjiv Kumar

- 복잡한 자연어 질문에 대답하기 위해 다단계 추론과 외부 정보의 통합이 종종 필요합니다.
- 여러 시스템들이 지식 검색과 대형 언어 모델(LLM)을 결합하여 이러한 질문에 답했지만, 다양한 실패 사례가 나타났으며, 외부 지식과의 상호작용이 미분 가능하지 않기 때문에 이러한 실패를 직접 수정하기 위해 종단간(end-to-end) 훈련이 불가능합니다.
- 이러한 결점을 해결하기 위해, 우리는 외부 지식에 대해 추론하고 작용할 수 있는 능력을 갖춘 ReAct 스타일의 LLM 에이전트를 정의합니다.
- 더 나아가, 이전 경로(트래젝토리)를 반복적으로 훈련하는 ReST 같은 방법으로 에이전트를 세밀하게 다듬으며, 지속적인 자가 개선 및 자가 증류를 위해 성장 배치 강화 학습과 AI 피드백을 활용합니다.
- 처음에는 주어진 대형 모델로부터 시작하였지만, 이 알고리즘을 두 번의 반복 후, 작은 모델을 미세 조정하여 구성 질문 답변 벤치마크에서 기존 모델보다 훨씬 적은 매개변수를 가지면서도 비슷한 성능을 달성할 수 있었습니다.

### [Weight subcloning: direct initialization of transformers using larger pretrained ones](https://arxiv.org/abs/2312.09299)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/l3H9Uz4lmL4FV-hEnIncR.png)

Vote: 12

Authors: Mohammad Samragh, Mehrdad Farajtabar, Mehrdad Farajtabar, Sachin Mehta, Sachin Mehta, Raviteja Vemulapalli, Fartash Faghri, Devang Naik, Oncel Tuzel, Mohammad Rastegari

- 큰 트랜스포머 모델을 처음부터 목표 작업에 대해 훈련하는 것은 많은 데이터와 상당한 계산 자원을 요구합니다.
- 이러한 과제를 극복하기 위해, 같은 크기와 사양을 가진 사전 훈련된 모델의 가중치로 모델을 초기화하여 전이 학습을 일반적으로 사용합니다.
- 그러나 필요한 크기의 사전 훈련된 모델이 없는 경우에는 어떻게 할까요?
- 본 논문에서는, 사전 훈련된 모델의 지식을 보다 작은 변형체로 전달하는 간단하지만 효과적인 기술인 'weight subcloning'을 소개합니다.
- Weight subcloning은 큰 사전 훈련된 모델의 가중치를 초기화하여 축소된 트랜스포머의 훈련을 가속화하는 과정을 포함합니다.
- 첫 번째로, 사전 훈련된 모델에서 임베딩 차원을 줄이기 위해 뉴런 중요도 순위 결정을 도입합니다.
- 그 다음으로, 축소된 네트워크의 레이어 수에 맞게 트랜스포머 모델에서 블록을 제거합니다.
- 이를 통해 훈련에 들어가기 준비가 된 네트워크를 얻을 수 있으며, 무작위 초기화보다 훈련 속도에 상당한 향상을 보입니다.
- 예를 들어, 이미지 분류를 위한 비전 트랜스포머와 다음 토큰 예측용 언어 모델 훈련에서 무작위 초기화 대비 4배 빠른 훈련을 달성합니다.

### [MobileSAMv2: Faster Segment Anything to Everything](https://arxiv.org/abs/2312.09579)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/1E11WpQgU7uhTA1-XIn9h.png)

Vote: 11

Authors: Chaoning Zhang, Chaoning Zhang, Dongshen Han, Sheng Zheng, Jinwoo Choi, Tae-Ho Kim, Tae-Ho Kim, Choong Seon Hong

- '모든 것을 분할하는 모델(Segment Anything model, SAM)'은 관심 있는 단일 객체의 마스크를 예측하는 '아무 것이나 분할하기(SegAny)'와 이미지상의 모든 객체에 대한 마스크를 예측하는 '모든 것을 분할하기(SegEvery)'라는 두 가지 실용적이면서도 도전적인 분할 작업을 다룹니다.
- SAM의 SegAny가 느린 이유는 무거운 이미지 인코더 때문이며, 이는 MobileSAM에서 분리된 지식 전달을 통해 해결되었습니다.
- 반면에 SAM의 SegEvery의 효율성 병목 현상은 수많은 마스크를 생성한 후 유효한 마스크만 필터링하여 최종 결과를 얻어야 하기 때문에 마스크 디코더에 있습니다.
- 우리는 객체 발견을 통해 유효한 프롬프트를 얻어 최종 마스크만 직접 생성하는 방식으로 효율성을 향상시키는 접근 방식을 제안합니다.
- 제안된 접근 방식은 마스크 디코더의 총 시간을 적어도 16배 줄이는 동시에 성능도 향상시킵니다.
- 구체적으로, LVIS 데이터셋에서 제로샷 객체 제안 작업에 대해 마스크 AR@K 지표로 3.6\%의 평균 성능 향상(42.5\% 대 38.9\%)을 달성했습니다.
- 질적인 결과에서 우리의 접근 방식은 미세한 마스크를 생성하면서 과도한 분할을 피한다는 것을 보여줍니다.
- 이 프로젝트는 원래 SAM보다 더 빠른 SegEvery를 목표로 하며, SegAny를 더 빠르게 하는 MobileSAM과 구별하기 위해 MobileSAMv2로 명명되었습니다.
- 또한, 우리는 새로운 프롬프트 샘플링이 MobileSAM의 분리된 이미지 인코더와도 호환되어 효율적인 SegAny와 SegEvery를 위한 통합된 프레임워크에 기여한다는 것을 보여줍니다.
- 관련 코드는 MobileSAM 프로젝트 링크와 동일한 주소에서 제공됩니다: https://github.com/ChaoningZhang/MobileSAM

### [Point Transformer V3: Simpler, Faster, Stronger](https://arxiv.org/abs/2312.10035)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ZEfc7q8wC4BLPVWh_W2UU.png)

Vote: 7

Authors: Xiaoyang Wu, Xiaoyang Wu, Li Jiang, Peng-Shuai Wang, Peng-Shuai Wang, Zhijian Liu, Zhijian Liu, Xihui Liu, Xihui Liu, Yu Qiao, Wanli Ouyang, Tong He, Tong He, Hengshuang Zhao

- 이 논문은 주목 메커니즘의 혁신을 추구하기보다는 포인트 클라우드 처리 분야에서 정확성과 효율성 사이의 기존 트레이드오프를 극복하고, 스케일의 힘을 활용하는데 초점을 맞춥니다.
- 최근 3D 대규모 표현 학습에서의 진보에서 영감을 받아, 모델 성능이 복잡한 설계보다는 스케일에 더 크게 영향을 받는다는 점을 인식하고, Point Transformer V3 (PTv3)를 제시합니다.
- PTv3는 전체 성능에 크게 기여하지 않는 일부 정확성 메커니즘, 예를 들어 정밀한 이웃 검색을 효율적인 직렬화된 이웃 매핑으로 대체하는 등의 단순성과 효율성에 우선순위를 둡니다.
- 이 원칙은 16개에서 1024개의 포인트에 이르는 수신 필드 확장을 가능하게 하며, PTv2와 비교해 처리 속도는 3배, 메모리 효율성은 10배 향상시키면서도 효율적입니다.
- PTv3는 실내 및 실외 시나리오를 포함해 20개가 넘는 다운스트림 작업에서 최첨단 결과를 달성합니다.
- 다중 데이터셋 공동 학습으로 더욱 강화된 PTv3는 이러한 결과를 더 높은 수준으로 끌어올리고 있습니다.

### [Self-Evaluation Improves Selective Generation in Large Language Models](https://arxiv.org/abs/2312.09300)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/J7L79GACHr2kXmA8Mb4M7.png)

Vote: 7

Authors: Jie Ren, Yao Zhao, Tu Vu, Tu Vu, Peter J. Liu, Peter J. Liu, Balaji Lakshminarayanan

- 대규모 언어 모델(LLMs)을 안전하게 배포하기 위해 생성된 콘텐츠의 평가를 통해 발화를 자제하거나 선택적으로 생성할 수 있는 신뢰할 수 있는 방법이 필요합니다.
- 확률 기반 지표인 perplexity는 널리 사용되지만, LLM이 제공하는 시퀀스 수준 확률 추정치가 생성 품질의 신뢰할 수 있는 지표로 작동하지 않는 한계가 최근 연구로 드러났습니다.
- 반면에, LLM은 다지선다형 질문의 정답 선택이나 참/거짓 진술 평가 등 토큰 수준에서 강한 교정 능력을 보여줍니다.
- 본 연구는 개방형 생성 과제를 토큰 수준 예측 과제로 재구성하고, LLM의 토큰 수준에서의 우수한 교정을 활용합니다.
- LLM에게 자체의 답변을 자가 평가하도록 지시하며, 다중방식 비교 또는 일대일 평가 방식을 사용하고, 모델의 불확실성을 명시적으로 표현하기 위해 "위의 어떤 것도 아니다" 옵션을 포함할 수 있습니다.
- 자가 평가 기반 점수 시스템을 다양한 점수 매기기 방법과 함께 벤치마킹하고 TruthfulQA 및 TL;DR을 사용하여 선택적 생성에서의 성능을 평가합니다.
- PaLM-2와 GPT-3를 사용한 실험을 통해, 자가 평가 기반 점수가 정확도를 향상시키는 것은 물론 생성된 콘텐츠의 전반적인 품질과 더 잘 상관되는 것을 보여줍니다.

### [Extending Context Window of Large Language Models via Semantic Compression](https://arxiv.org/abs/2312.09571)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ii4WN6pbNmWjV_ktvVRRU.png)

Vote: 4

Authors: Weizhi Fei, Weizhi Fei, Xueyan Niu, Pingyi Zhou, Pingyi Zhou, Lu Hou, Lu Hou, Bo Bai, Lei Deng, Wei Han

- 트랜스포머 기반 대규모 언어 모델(LLMs)에서 긴 텍스트 입력에 대한 제약을 극복하기 위해, 의미적 압축 방법론을 새롭게 제안했습니다.
- 이 방법은 정보 이론의 원천 코딩에서 영감을 받아, 긴 입력의 의미적 중복을 줄이는 데 사전 훈련된 모델을 활용합니다.
- 세부적으로, 별도의 미세 조정이나 큰 계산 부담 없이도 텍스트의 길이를 6-8배까지 처리할 수 있는 일반화 능력을 보여주었습니다.
- 질문 응답, 요약, 소수샷 학습, 정보 검색 등 다양한 작업에 걸쳐 LLM의 컨텍스트 창을 효과적으로 확장하는 데 기여하였다는 실험 결과를 제시했습니다.
- 제안된 의미적 압축 방법은 텍스트 생성의 유창성을 유지하는 동시에 계산 비용을 줄인다는 장점을 보여줍니다.

### [Faster Diffusion: Rethinking the Role of UNet Encoder in Diffusion Models](https://arxiv.org/abs/2312.09608)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/yOSgIhwO7mJSWkck8aN2u.png)

Vote: 4

Authors: Senmao Li, Senmao Li, Taihang Hu, Taihang Hu, Fahad Shahbaz Khan, Linxuan Li, Shiqi Yang, Shiqi Yang, Yaxing Wang, Yaxing Wang, Ming-Ming Cheng, Ming-Ming Cheng, Jian Yang

- 이 논문은 확산 모델 내에서 중요한 구성 요소인 UNet의 노이즈 예측 기능에 대해 다루며, UNet 디코더의 기본 속성은 많이 탐구되었으나, 인코더는 상대적으로 미개척 영역임을 지적합니다.
- 연구진은 UNet 인코더를 최초로 종합적으로 분석하였고, 인퍼런스 과정에서의 인코더 특징 변화에 대한 중요한 질문에 대한 통찰력을 제공합니다.
- 그들은 인코더의 특징이 부드럽게 변하고, 반면에 디코더의 특징은 다른 시간 단계에 걸쳐 상당한 변화를 보인다는 것을 발견했습니다.
- 이 발견에 영감을 받아, 연구진은 인접한 시간 단계에서 인코더를 생략하고 이전 시간 단계의 인코더 특징을 디코더에서 순환적으로 재사용하는 방법을 제안했습니다.
- 이 관찰을 기반으로, 연구진은 확산 샘플링을 가속화하기 위해 간단하지만 효과적인 인코더 전파 방식을 소개하였으며, 이를 통해 인접한 시간 단계에서 디코더를 병렬로 수행할 수 있습니다.
- 추가로, 생성된 이미지의 텍스처 디테일을 향상시키기 위한 사전 노이즈 주입 방법을 소개합니다.
- 표준 텍스트-이미지 작업 뿐만 아니라, 텍스트-비디오, 개인화 생성 및 참조 가이드 생성과 같은 다른 작업에 대해서도 접근법을 검증합니다.
- 어떠한 지식 증류 기술도 활용하지 않고, 연구진의 접근 방식은 Stable Diffusion (SD) 및 DeepFloyd-IF 모델 샘플링을 각각 41%와 24% 가속화하면서도 고품질의 생성 성능을 유지합니다.
- 연구진의 코드는 https://github.com/hutaiHang/Faster-Diffusion{FasterDiffusion}에서 확인할 수 있습니다.

### [Stable Score Distillation for High-Quality 3D Generation](https://arxiv.org/abs/2312.09305)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/co45quiAM-h8gUDYcra70.png)

Vote: 4

Authors: Boshi Tang, Jianan Wang, Zhiyong Wu, Zhiyong Wu, Lei Zhang

- 점수 증류 샘플링(SDS)은 조건부 3D 콘텐츠 생성에서 뛰어난 성과를 보였지만, SDS의 이론적 이해가 부족하여 3D 생성 발전이 제한되고 있다.
- 연구진은 SDS를 모드-분리(mode-disengaging), 모드-추구(mode-seeking), 분산-감소(variance-reducing) 용어로 구성된 조합으로 해석하고 각 부분의 성질을 분석했다.
- 연구 결과, 과도한 평활화(over-smoothness)와 색상 포화(color-saturation) 같은 문제점들은 차도을 부족함으로 인해 생긴 것이며, SDS에 의해 도입된 분산-감소 용어가 최적이 아님을 밝혔다.
- 또한, 이 연구는 큰 분류자 없는 지침(Classifier-Free Guidance, CFG) 스케일을 3D 생성에 적용하는 것에 대한 이해를 제공한다.
- 이 분석을 바탕으로, 연구진은 'Stable Score Distillation (SSD)'라는 이름의 간단하지만 효과적인 접근법을 제안하여 고품질의 3D 생성을 위해 각 용어를 전략적으로 조정한다.
- 광범위한 실험을 통해 연구진의 접근법이 높은 충실도의 3D 콘텐츠를 생성할 수 있으며, 가장 까다로운 NeRF 표현에서도 낮은 CFG 조건에서 과도한 평활화나 과포화 문제에 빠지지 않는 것을 증명했다.

### [Challenges with unsupervised LLM knowledge discovery](https://arxiv.org/abs/2312.10029)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/uSCe3Dz38Hv5iPkY7ufEm.png)

Vote: 4

Authors: Sebastian Farquhar, Vikrant Varma, Zachary Kenton, Johannes Gasteiger, Vladimir Mikulik, Rohin Shah

- 기존의 무감독 방법들은 대규모 언어 모델(Large Language Model, LLM)의 활성화에서 지식을 발견하지 못하고 가장 두드러진 특징을 찾아내는 것으로 나타났습니다.
- 무감독 지식 추출의 아이디어는 지식이 일관성 있는 구조를 만족시켜 지식을 발견할 수 있다는 점에 기초하고 있습니다.
- 연구진은 '대조 일관성 검색(contrast-consistent search)'이라는 특정 무감독 지식 추출 방법의 일관성 구조를 지식뿐만 아니라 임의의 특징들이 만족시킬 수 있음을 이론적으로 증명했습니다.
- 실험들을 통해 무감독 방법들이 지식을 예측하는 분류기가 아닌 다른 두드러진 특징을 예측하는 분류기를 결과로 나타내는 상황을 제시하였습니다.
- 연구진은 현재의 무감독 방법들이 잠재적 지식을 발견하는 데에 충분하지 않음을 결론짓고 향후 지식 추출 방법을 평가할 때 적용할 수 있는 검증 체크리스트를 제공했습니다.
- 개념적으로 연구진은 여기서 탐구된 식별 문제들, 예를 들어 모델의 지식과 가상 인물의 지식을 구별하는 것,이 미래의 무감독 방법에도 지속될 것이라 가정합니다.

### [Faithful Persona-based Conversational Dataset Generation with Large Language Models](https://arxiv.org/abs/2312.10007)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/33TQqcDhCcBt5R7qYE9GY.png)

Vote: 3

Authors: Pegah Jandaghi, Pegah Jandaghi, XiangHai Sheng, XiangHai Sheng, Xinyi Bai, Xinyi Bai, Jay Pujara, Hakim Sidahmed

- 대화형 AI 모델 개발에 필수적인 고품질 대화 데이터셋을 개선하기 위해 본 논문에서는 사용자의 성격, 동기, 행동을 반영하는 '페르소나'라는 개념을 사용한다.
- 페르소나 기반 데이터셋에서 교육된 자연어 처리(NLP) 모델들이 사용자와 더 깊은 연결을 형성하고 그들의 참여를 유지할 수 있도록 한다.
- 본 연구는 초기 데이터셋에서 출발하여 대규모 언어 모델(Large Language Models, LLMs)의 힘을 활용해서 대량의 고품질 대화 데이터셋을 생성하는 방법을 제안한다.
- 높은 품질의 대화를 생성하고, 이를 선택하는 '생성자-비평가(Generator-Critic)' 아키텍처 프레임워크를 소개한다.
- 생성자는 대화를 출력하도록 프롬프트된 LLM이며, 비평가는 생성된 대화의 품질을 관리하는 전문가 LLM들의 혼합체이다.
- 이 전문가들은 최고의 대화를 선택하며, 이를 통해 생성자를 개선한다.
- 본 연구는 초기 Persona-Chat에서 싹튼 20,000개의 대화를 포함한 Synthetic-Persona-Chat 데이터셋을 공개한다.
- 다양한 차원에서 광범위한 실험을 통해 Synthetic-Persona-Chat 및 생성 프레임워크의 품질을 평가하고, 튜링 테스트 중 Persona-Chat 대비 Synthetic-Persona-Chat의 손실률이 세 번의 반복에 걸쳐 17.2%에서 8.8%로 감소하는 것을 관찰한다.

### [SlimmeRF: Slimmable Radiance Fields](https://arxiv.org/abs/2312.10034)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/OxZaVAmuf4VjX9PSv3SEp.png)

Vote: 2

Authors: Shiran Yuan, Shiran Yuan, Hao Zhao

- 신경 복사장(Neural Radiance Field, NeRF)와 그 변형들은 최근 새로운 관점 합성과 3D 장면 재구성을 위한 성공적인 방법으로 부상했지만, 대부분의 NeRF 모델은 큰 모델 크기를 사용하여 높은 정확도를 달성하거나 정확도를 희생하면서 메모리 효율성을 높입니다.
- 이러한 제약으로 인해 고품질 모델은 메모리가 적은 장치에 적합하지 않을 수 있으며, 메모리 효율적인 모델은 고품질 요구 사항을 충족시키지 못할 수 있습니다.
- 이에 대한 해결책으로, 우리는 다른 컴퓨팅 예산을 가진 시나리오에 모두 적합한 SlimmeRF라는 모델을 소개하며, 이는 간소화를 통해 모델 크기와 정확도 사이의 즉석에서 트레이드오프를 가능하게 합니다.
- 새롭게 제안된 텐서 랭크 증가 알고리즘인 텐서리얼 랭크 인크리멘테이션(TRaIn)을 통해 훈련하는 동안 모델의 텐서 표현의 랭크를 점진적으로 늘림으로써 이를 달성했습니다.
- 우리는 모델이 희소한 관점 시나리오에서 더 효과적인 트레이드오프를 제공하며, 때로는 간소화된 후에도 더 높은 정확도를 달성한다는 점을 관찰했습니다.
- 이는 부정확한 정보, 예를 들어 공중에 떠있는 객체들(floater)이 높은 랭크에 해당하는 구성 요소에 저장되기 때문이라고 분석합니다.
- 해당 모델의 구현은 https://github.com/Shiran-Yuan/SlimmeRF 에서 확인할 수 있습니다.

### [Perspectives on the State and Future of Deep Learning -- 2023](https://arxiv.org/abs/2312.09323)

![](https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/QK4i5qke46Vvv3kFcX9Pd.png)

Vote: 2

Authors: Micah Goldblum, Anima Anandkumar, Anima Anandkumar, Richard Baraniuk, Tom Goldstein, Tom Goldstein, Kyunghyun Cho, Kyunghyun Cho, Zachary C Lipton, Melanie Mitchell, Preetum Nakkiran, Max Welling, Andrew Gordon Wilson

- 이 시리즈의 목표는 현재의 머신러닝 분야의 의견과 문제점을 기록하고 시간이 지남에 따라 어떻게 변하는지 추적하는 것입니다.
- 이 조사는 AI 싱귤래리티 혹은 종이 클립으로 인한 종말의 시나리오가 도래하기 전까지 정기적으로 시행될 계획이며, 매번 새로운 커뮤니티 멤버를 인터뷰하고 관련 질문 목록을 업데이트 할 예정입니다.
- 이번 호에서는 해석 가능한 AI, 현대 NLP에서 벤치마킹의 가치, 딥러닝 이해 측면에서의 진전 상황, 그리고 학계의 미래에 대한 사람들의 의견을 물었습니다.
- 제시된 내용은 딥러닝의 현재 상태와 미래에 대한 관점을 조망하는 데 초점을 맞추고 있음을 반영합니다.

